[
  {
    "title": "Helping our customers through the CrowdStrike outage",
    "link": "https://blogs.microsoft.com/blog/2024/07/20/helping-our-customers-through-the-crowdstrike-outage/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNU9ZbWxzYVZFMGRYZ3hiRmxTVFJESUFSajhBU2dCTWdhQm9aVG5PQWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-07-20T07:00:00.000Z",
    "time": "Jul 20",
    "articleType": "regular",
    "content": "On July 18, CrowdStrike, an independent cybersecurity company, released a software update that began impacting IT systems globally. Although this was not a Microsoft incident, given it impacts our ecosystem, we want to provide an update on the steps we’ve taken with CrowdStrike and others to remediate and support our customers.\nSince this event began, we’ve maintained ongoing communication with our customers, CrowdStrike and external developers to collect information and expedite solutions. We recognize the disruption this problem has caused for businesses and in the daily routines of many individuals. Our focus is providing customers with technical guidance and support to safely bring disrupted systems back online. Steps taken have included:\nEngaging with CrowdStrike to automate their work on developing a solution. CrowdStrike has recommended a workaround to address this issue and has also issued a public statement. Instructions to remedy the situation on Windows endpoints were posted on the Windows Message Center.\nDeploying hundreds of Microsoft engineers and experts to work directly with customers to restore services.\nCollaborating with other cloud providers and stakeholders, including Google Cloud Platform (GCP) and Amazon Web Services (AWS), to share awareness on the state of impact we are each seeing across the industry and inform ongoing conversations with CrowdStrike and customers.\nQuickly posting manual remediation documentation and scripts found here.\nKeeping customers informed of the latest status on the incident through the Azure Status Dashboard here.\nWe’re working around the clock and providing ongoing updates and support. Additionally, CrowdStrike has helped us develop a scalable solution that will help Microsoft’s Azure infrastructure accelerate a fix for CrowdStrike’s faulty update. We have also worked with both AWS and GCP to collaborate on the most effective approaches.\nWhile software updates may occasionally cause disturbances, significant incidents like the CrowdStrike event are infrequent. We currently estimate that CrowdStrike’s update affected 8.5 million Windows devices, or less than one percent of all Windows machines. While the percentage was small, the broad economic and societal impacts reflect the use of CrowdStrike by enterprises that run many critical services.\nThis incident demonstrates the interconnected nature of our broad ecosystem — global cloud providers, software platforms, security vendors and other software vendors, and customers. It’s also a reminder of how important it is for all of us across the tech ecosystem to prioritize operating with safe deployment and disaster recovery using the mechanisms that exist. As we’ve seen over the last two days, we learn, recover and move forward most effectively when we collaborate and work together. We appreciate the cooperation and collaboration of our entire sector, and we will continue to update with learnings and next steps.",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Introducing Copilot+ PCs",
    "link": "https://blogs.microsoft.com/blog/2024/05/20/introducing-copilot-pcs/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNHhWMjlXWmtKWlJrbHNkakZUVFJDb0FSaXNBaWdCTWdtQmNKUzJzQ2V4N0FF=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-20T07:00:00.000Z",
    "time": "May 20",
    "articleType": "regular",
    "content": "An on-demand recording of our May 20 event is available.\nToday, at a special event on our new Microsoft campus, we introduced the world to a new category of Windows PCs designed for AI, Copilot+ PCs.\nCopilot+ PCs are the fastest, most intelligent Windows PCs ever built. With powerful new silicon capable of an incredible 40+ TOPS (trillion operations per second), all–day battery life and access to the most advanced AI models, Copilot+ PCs will enable you to do things you can’t on any other PC. Easily find and remember what you have seen in your PC with Recall, generate and refine AI images in near real-time directly on the device using Cocreator, and bridge language barriers with Live Captions, translating audio from 40+ languages into English.\nThese experiences come to life on a set of thin, light and beautiful devices from Microsoft Surface and our OEM partners Acer, ASUS, Dell, HP, Lenovo and Samsung, with pre-orders beginning today and availability starting on June 18. Starting at $999, Copilot+ PCs offer incredible value.\nThis first wave of Copilot+ PCs is just the beginning. Over the past year, we have seen an incredible pace of innovation of AI in the cloud with Copilot allowing us to do things that we never dreamed possible. Now, we begin a new chapter with AI innovation on the device. We have completely reimagined the entirety of the PC – from silicon to the operating system, the application layer to the cloud – with AI at the center, marking the most significant change to the Windows platform in decades.\nThe fastest, most secure Windows PCs ever built\nWe introduced an all-new system architecture to bring the power of the CPU, GPU, and now a new high performance Neural Processing Unit (NPU) together. Connected to and enhanced by the large language models (LLMs) running in our Azure Cloud in concert with small language models (SLMs), Copilot+ PCs can now achieve a level of performance never seen before. They are up to 20x more powerful[1] and up to 100x as efficient[2] for running AI workloads and deliver industry-leading AI acceleration. They outperform Apple’s MacBook Air 15” by up to 58% in sustained multithreaded performance[3], all while delivering all-day battery life.  With incredible efficiency, Copilot+ PCs can deliver up to 22 hours of local video playback or 15 hours of web browsing on a single charge.[4] That is up to 20% more battery in local video playback than the MacBook Air 15”.[5]\nWindows now has the best implementation of apps on the fastest chip, starting with Qualcomm. We now offer more native Arm64 experiences than ever before, including our fastest implementation of Microsoft 365 apps like Teams, PowerPoint, Outlook, Word, Excel, OneDrive and OneNote. Chrome, Spotify, Zoom, WhatsApp, Adobe Photoshop, Adobe Lightroom, Blender, Affinity Suite, DaVinci Resolve and many more now run​ natively on Arm to give you great performance with additional apps, like Slack, releasing later this year. In fact, 87% of the total app minutes people spend in apps today have native Arm versions.[6] With a powerful new emulator, Prism, your apps run great, whether native or emulated.\nEvery Copilot+ PC comes secured out of the box. The Microsoft Pluton Security processor will be enabled by default on all Copilot+ PCs and we have introduced a number of new features, updates and defaults to Windows 11 that make it easy for users to stay secure. And, we’ve built in personalized privacy controls to help you protect what’s important to you. You can read more about how we are making Windows more secure here.\nEntirely new, powerful AI experiences\nCopilot+ PCs leverage powerful processors and multiple state-of-the-art AI models, including several of Microsoft’s world-class SLMs, to unlock a new set of experiences you can run locally, directly on the device. This removes previous limitations on things like latency, cost and even privacy to help you be more productive, creative and communicate more effectively.\nWe set out to solve one of the most frustrating problems we encounter daily – finding something we know we have seen before on our PC. Today, we must remember what file folder it was stored in, what website it was on, or scroll through hundreds of emails trying to find it.\nNow with Recall, in preview starting June 18, you can access virtually what you have seen or done on your PC in a way that feels like having photographic memory. Copilot+ PCs organize information like we do – based on relationships and associations unique to each of our individual experiences. This helps you remember things you may have forgotten so you can find what you’re looking for quickly and intuitively by simply using the cues you remember. [7]\nYou can scroll across time to find the content you need in your timeline across any application, website, document, or more. Interact intuitively using snapshots with screenray to help you take the next step using suggested actions based on object recognition. And get back to where you were, whether to a specific email in Outlook or the right chat in Teams.\nRecall leverages your personal semantic index, built and stored entirely on your device. Your snapshots are yours; they stay locally on your PC. You can delete individual snapshots, adjust and delete ranges of time in Settings, or pause at any point right from the icon in the System Tray on your Taskbar. You can also filter apps and websites from ever being saved. You are always in control with privacy you can trust.\nCocreate with AI-powered image creation and editing, built into Windows\nSince the launch of Image Creator, almost 10 billion images have been generated, helping more people bring their ideas to life easily by using natural language to describe what they want to create. Yet, today’s cloud offerings may limit the number of images you can create, keep you waiting while the artwork processes or even present privacy concerns. By using the Neural Processing Units (NPUs) and powerful local small language models, we are bringing innovative new experiences to your favorite creative applications like Paint and Photos.\nCombine your ink strokes with text prompts to generate new images in nearly real time with Cocreator. As you iterate, so does the artwork, helping you more easily refine, edit and evolve your ideas. Powerful diffusion-based algorithms optimize for the highest quality output over minimum steps to make it feel like you are creating alongside AI. Use the creativity slider to choose from a range of artwork from more literal to more expressive. Once you select your artwork, you can continue iterating on top of it, helping you express your ideas, regardless of your creative skills.\nTake photo editing and image creation to the next level. With Restyle Image, you can reimagine your personal photos with a new style combining image generation and photo editing in Photos. Use a pre-set style like Cyberpunk or Claymation to change the background, foreground or full picture to create an entirely new image. Or jumpstart your next creative project and get visual inspiration with Image Creator in Photos. On Copilot+ PCs you can generate endless images for free, fast, with the ability to fine tune images to your liking and to save your favorites to collections.\nInnovative AI experiences from the creative apps you love\nWe are also partnering with some of the biggest and most-loved applications on the planet to leverage the power of the NPU to deliver new innovative AI experiences.\nTogether with Adobe, we are thrilled to announce Adobe’s flagship apps are coming to Copilot+ PCs, including Photoshop, Lightroom and Express – available today. Illustrator, Premiere Pro and more are coming this summer. And we’re continuing to partner to optimize AI in these apps for the NPU. For Adobe Creative Cloud customers, they will benefit from the full performance advantages of Copilot+ PCs to express their creativity faster than ever before.\nEffortlessly apply visual effects to objects and people using NPU-accelerated Magic Mask in DaVinci Resolve Studio.\nRemove the background from any video clip in a snap using Auto Cutout running on the NPU in CapCut.\nStay in your flow with faster, more responsive adaptive input controls, like head movement or facial expressions via the new NPU-powered camera pipeline in Cephable.\nMake quicker and smarter annotations to documents, using AI features that run entirely on-device via NPU, so data stays private in LiquidText.\nHave fun breaking down and remixing any music track, with a new, higher-quality version of NeuralMix™ that’s exclusive to NPU in Algoriddim’s djay Pro.\nConnect and communicate effortlessly with live captions\nIn an increasingly connected and global world, Windows wants to bring people closer together. Whether catching up on your favorite podcast from a different country, or watching your favorite international sports team, or even collaborating with friends and colleagues across the world, we want to make more content accessible to more people.\nLive Captions now has live translations and will turn any audio that passes through your PC into a single, English-language caption experience, in real time on your screen across all your apps consistently. You can translate any live or pre-recorded audio in any app or video platform from over 40 languages into English subtitles instantly, automatically and even while you’re offline. Powered by the NPU and available across all Copilot+ PCs, now you can have confidence your words are understood as intended.\nNew and enhanced Windows Studio Effects\nLook and sound your best automatically with easily accessible controls at your fingertips in Quick Settings. Portrait light automatically adjusts the image to improve your perceived illumination in a dark environment or brighten the foreground pixels when in a low-light environment. Three new creative filters (illustrated, animated or watercolor) add an artistic flare. Eye contact teleprompter helps you maintain eye contact while reading your screen. New improvements to voice focus and portrait blur help ensure you’re always in focus.\nCopilot, your everyday AI companion\nEvery Copilot+ PC comes with your personal powerful AI agent that is just a single tap away on keyboards with the new Copilot key.[8] Copilot will now have the full application experience customers have been asking for in a streamlined, simple yet powerful and personal design. Copilot puts the most advanced AI models at your fingertips. In the coming weeks, get access to the latest models including GPT-4o from our partners at OpenAI, so you can have voice conversations that feel more natural.\nNew Copilot+ PCs from Microsoft Surface and our partners\nWe have worked with each of the top OEMs — Acer, ASUS, Dell, HP, Lenovo, Samsung — and of course Surface, to bring exciting new Copilot+ PCs that will begin to launch on June 18. Starting at $999, these devices are up to $200 less than similar spec’d devices[9].\nSurface plays a key role in the Windows ecosystem, as we design software and hardware together to deliver innovative designs and meaningful experiences to our customers and fans. We are introducing the first-ever Copilot+ PCs from Surface: The all-new Surface Pro and Surface Laptop.\nSurface Pro and Surface Laptop\nThe new Surface Laptop is a powerhouse in an updated, modern laptop design with razor-thin bezels, a brilliant touchscreen display, AI-enhanced camera, premium audio, and now with a haptic touchpad.\nChoose between a 13.8” and 15” display and four stunning colors. Enjoy up to 22 hours of local video playback on Surface Laptop 15” or up to 20 hours on Surface Laptop13.8” on top of incredible performance and all-new AI experiences.\nNew Copilot+ PCs from the biggest brands available starting June 18:\nAcer: Acer’s Swift 14 AI 2.5K touchscreen enables you to draw and edit your vision with greater accuracy and with color-accurate imagery. Launch and discover AI-enhanced features, like Acer PurifiedVoice 2.0 and Purified View, with a touch of the dedicated AcerSense button.\nASUS: The ASUS Vivobook S 15 is a powerful device that brings AI experiences to life with its Snapdragon X Elite Platform and built-in Qualcomm® AI. It boasts 40+ NPU TOPS, a dual-fan cooling system, and up to 1 TB of storage. Next-gen AI enhancements include Windows Studio effects v2 and ASUS AiSense camera, with presence-detection capabilities for Adaptive Dimming and Lock. Built for portability, it has an ultra-slim and light all-metal design, a high-capacity battery, and premium styling with a single-zone RGB backlit keyboard.\nDell: Dell is launching five new Copilot+ PCs, including the XPS 13, Inspiron 14 Plus, Inspiron 14, Latitude 7455, and Latitude 5455, offering a range of consumer and commercial options that deliver groundbreaking battery life and unique AI experiences. The XPS 13 is powered by Snapdragon X Elite processors and features a premium, futuristic design, while the Latitude 7455 boasts a stunning QHD+ display and quad speakers with AI noise reduction. The Inspiron14 and Inspiron 14 Plus feature a Snapdragon X Plus 1and are crafted with lightweight, low carbon aluminum and are energy efficient with EPEAT Gold rating.\nHP: HP’s OmniBook X AI PC and HP EliteBook Ultra G1q AI PC with Snapdragon X Elite are slim and sleek designs, delivering advanced performance and mobility for a more personalized computing experience. Features include long-lasting battery life and AI-powered productivity tools, such as real-time transcription and meeting summaries. A 5MP camera with automatic framing and eye focus is supported by Poly Studio’s crystal-clear audio for enhanced virtual interactions.\nLenovo: Lenovo is launching two AI PCs: one built for consumers, Yoga Slim 7x, and one for commercial, ThinkPad T14s Gen 6. The Yoga Slim 7x brings efficiency for creatives, featuring a 14.5” touchscreen with 3K Dolby Vision and optimized power for 3D rendering and video editing. The T14s Gen 6 brings enterprise-level experiences and AI performance to your work tasks, with features including a webcam privacy shutter, Wi-Fi 7 connectivity and up to 64GB RAM.\nSamsung: Samsung’s new Galaxy Book4 Edge is ultra-thin and light, with a 3K resolution, Dynamic AMOLED 2X display and Wi-Fi 7 connectivity. It has a long-lasting battery that provides up to 22 hours of video playback, making it perfect for work or entertainment on the go.\nStart testing for commercial deployment today\nCopilot+ PCs offer businesses the most performant Windows 11 devices with unique AI capabilities to unlock productivity, improve collaboration and drive efficiency. As a Windows PC, businesses can deploy and manage a Copilot+ PC with the same tools and processes used today including IT controls for new features and AppAssure support. We recommend IT admins begin testing and readying for deployment to start empowering your workforce with access to powerful AI features on these high-performance devices. You can read more about our commercial experiences here.\nAI innovation across the Windows ecosystem\nLike we’ve always done with Windows, we have built a platform for our ecosystem partners to build on.\nThe first Copilot+ PCs will launch with both the Snapdragon® X Elite and Snapdragon® X Plus processors and feature leading performance per watt thanks to the custom Qualcomm Oryon™ CPU, which delivers unrivaled performance and battery efficiency. Snapdragon X Series delivers 45 NPU TOPS all-in-one system on a chip (SoC). The premium integrated Qualcomm® Adreno™ GPU delivers stunning graphics for immersive entertainment. We look forward to expanding through deep partnerships with Intel and AMD, starting with Lunar Lake and Strix Point. We will bring new Copilot+ PC experiences at a later date. In the future we expect to see devices with this silicon paired with powerful graphics cards like NVIDIA GeForce RTX and AMD Radeon™, bringing Copilot+ PC experiences to reach even broader audiences like advanced gamers and creators.\nWe are at an inflection point where the PC will accelerate AI innovation. We believe the richest AI experiences will only be possible when the cloud and device work together in concert. Together with our partners, we’re setting the frame for the next decade of Windows innovation.\nEditor’s note: This blog has been updated to note that Recall is launching in preview on June 18.\nEditor’s note – June 17, 2024: Information about the Recall feature was updated.\n[1] Based on snapshot of aggregated, non-gaming app usage data as of April 2024 for iGPU-based laptops and 2-in-1 devices running Windows 10 and Windows 11 in US, UK, CA, FR, AU, DE, JP.\n[2] Tested April 2024 using Phi SLM workload running 512-token prompt processing in a loop with default settings comparing pre-release Copilot+ PC builds with Snapdragon Elite X 12 Core and Snapdragon X Plus 10 core configurations (QNN build) to Windows 11 PC with NVIDIA 4080 GPU configuration (CUDA build).\n[3] Tested May 2024 using Cinebench 2024 Multi-Core benchmark comparing Copilot+ PCs with Snapdragon X Elite 12 core and Snapdragon X Plus 10 core configurations to MacBook Air 15” with M3 8 core CPU / 10 Core GPU configuration. Performance will vary significantly between device configuration and usage.\n[4] *Battery life varies significantly by device and with settings, usage and other factors. See aka.ms/cpclaims*\n[5] *Battery life varies significantly based on device configuration, usage, network and feature configuration, signal strength, settings and other factors. Testing conducted May 2024 using the prelease Windows ADK full screen local video playback assessment under standard testing conditions, with the device connected to Wi-Fi and screen brightness set to 150 nits, comparing Copilot+ PCs with Snapdragon X Elite 12 core and Snapdragon X Plus 10 core configurations running Windows Version 26097.5003 (24H2) to MacBook Air 15” M3 8-Core CPU/ 10 Core GPU running macOS 14.4 with similar device configurations and testing scenario.\n[6] Based on snapshot of aggregated, non-gaming app usage data as of April 2024 for iGPU-based laptops and 2-in-1 devices running Windows 10 and Windows 11 in US, UK, CA, FR, AU, DE, JP.\n[8] Copilot key functionality may vary. See aka.ms/keysupport\n[9] Based on MSRPs; actual savings may vary",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Staying ahead of threat actors in the age of AI",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/02/14/staying-ahead-of-threat-actors-in-the-age-of-ai/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNW5XVkpYVHkxaVptRlBkRmxwVFJDM0FSaVRBaWdCTWdZRm9vd0l2UVU=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-02-14T08:00:00.000Z",
    "time": "Feb 14",
    "articleType": "regular",
    "content": "Over the last year, the speed, scale, and sophistication of attacks has increased alongside the rapid development and adoption of AI. Defenders are only beginning to recognize and apply the power of generative AI to shift the cybersecurity balance in their favor and keep ahead of adversaries. At the same time, it is also important for us to understand how AI can be potentially misused in the hands of threat actors. In collaboration with OpenAI, today we are publishing research on emerging threats in the age of AI, focusing on identified activity associated with known threat actors, including prompt-injections, attempted misuse of large language models (LLM), and fraud. Our analysis of the current use of LLM technology by threat actors revealed behaviors consistent with attackers using AI as another productivity tool on the offensive landscape. You can read OpenAI’s blog on the research here. Microsoft and OpenAI have not yet observed particularly novel or unique AI-enabled attack or abuse techniques resulting from threat actors’ usage of AI. However, Microsoft and our partners continue to study this landscape closely.\nThe objective of Microsoft’s partnership with OpenAI, including the release of this research, is to ensure the safe and responsible use of AI technologies like ChatGPT, upholding the highest standards of ethical application to protect the community from potential misuse. As part of this commitment, we have taken measures to disrupt assets and accounts associated with threat actors, improve the protection of OpenAI LLM technology and users from attack or abuse, and shape the guardrails and safety mechanisms around our models. In addition, we are also deeply committed to using generative AI to disrupt threat actors and leverage the power of new tools, including Microsoft Copilot for Security, to elevate defenders everywhere.\nA principled approach to detecting and blocking threat actors\nThe progress of technology creates a demand for strong cybersecurity and safety measures. For example, the White House’s Executive Order on AI requires rigorous safety testing and government supervision for AI systems that have major impacts on national and economic security or public health and safety. Our actions enhancing the safeguards of our AI models and partnering with our ecosystem on the safe creation, implementation, and use of these models align with the Executive Order’s request for comprehensive AI safety and security standards.\nIn line with Microsoft’s leadership across AI and cybersecurity, today we are announcing principles shaping Microsoft’s policy and actions mitigating the risks associated with the use of our AI tools and APIs by nation-state advanced persistent threats (APTs), advanced persistent manipulators (APMs), and cybercriminal syndicates we track.\nIdentification and action against malicious threat actors’ use: Upon detection of the use of any Microsoft AI application programming interfaces (APIs), services, or systems by an identified malicious threat actor, including nation-state APT or APM, or the cybercrime syndicates we track, Microsoft will take appropriate action to disrupt their activities, such as disabling the accounts used, terminating services, or limiting access to resources.\nNotification to other AI service providers: When we detect a threat actor’s use of another service provider’s AI, AI APIs, services, and/or systems, Microsoft will promptly notify the service provider and share relevant data. This enables the service provider to independently verify our findings and take action in accordance with their own policies.\nCollaboration with other stakeholders: Microsoft will collaborate with other stakeholders to regularly exchange information about detected threat actors’ use of AI. This collaboration aims to promote collective, consistent, and effective responses to ecosystem-wide risks.\nTransparency: As part of our ongoing efforts to advance responsible use of AI, Microsoft will inform the public and stakeholders about actions taken under these threat actor principles, including the nature and extent of threat actors’ use of AI detected within our systems and the measures taken against them, as appropriate.\nMicrosoft remains committed to responsible AI innovation, prioritizing the safety and integrity of our technologies with respect for human rights and ethical standards. These principles announced today build on Microsoft’s Responsible AI practices, our voluntary commitments to advance responsible AI innovation and the Azure OpenAI Code of Conduct. We are following these principles as part of our broader commitments to strengthening international law and norms and to advance the goals of the Bletchley Declaration endorsed by 29 countries.\nMicrosoft and OpenAI’s complementary defenses protect AI platforms\nBecause Microsoft and OpenAI’s partnership extends to security, the companies can take action when known and emerging threat actors surface. Microsoft Threat Intelligence tracks more than 300 unique threat actors, including 160 nation-state actors, 50 ransomware groups, and many others. These adversaries employ various digital identities and attack infrastructures. Microsoft’s experts and automated systems continually analyze and correlate these attributes, uncovering attackers’ efforts to evade detection or expand their capabilities by leveraging new technologies. Consistent with preventing threat actors’ actions across our technologies and working closely with partners, Microsoft continues to study threat actors’ use of AI and LLMs, partner with OpenAI to monitor attack activity, and apply what we learn to continually improve defenses. This blog provides an overview of observed activities collected from known threat actor infrastructure as identified by Microsoft Threat Intelligence, then shared with OpenAI to identify potential malicious use or abuse of their platform and protect our mutual customers from future threats or harm.\nRecognizing the rapid growth of AI and emergent use of LLMs in cyber operations, we continue to work with MITRE to integrate these LLM-themed tactics, techniques, and procedures (TTPs) into the MITRE ATT&CK® framework or MITRE ATLAS™ (Adversarial Threat Landscape for Artificial-Intelligence Systems) knowledgebase. This strategic expansion reflects a commitment to not only track and neutralize threats, but also to pioneer the development of countermeasures in the evolving landscape of AI-powered cyber operations. A full list of the LLM-themed TTPs, which include those we identified during our investigations, is summarized in the appendix.\nSummary of Microsoft and OpenAI’s findings and threat intelligence\nThe threat ecosystem over the last several years has revealed a consistent theme of threat actors following trends in technology in parallel with their defender counterparts. Threat actors, like defenders, are looking at AI, including LLMs, to enhance their productivity and take advantage of accessible platforms that could advance their objectives and attack techniques. Cybercrime groups, nation-state threat actors, and other adversaries are exploring and testing different AI technologies as they emerge, in an attempt to understand potential value to their operations and the security controls they may need to circumvent. On the defender side, hardening these same security controls from attacks and implementing equally sophisticated monitoring that anticipates and blocks malicious activity is vital.\nWhile different threat actors’ motives and complexity vary, they have common tasks to perform in the course of targeting and attacks. These include reconnaissance, such as learning about potential victims’ industries, locations, and relationships; help with coding, including improving things like software scripts and malware development; and assistance with learning and using native languages. Language support is a natural feature of LLMs and is attractive for threat actors with continuous focus on social engineering and other techniques relying on false, deceptive communications tailored to their targets’ jobs, professional networks, and other relationships.\nImportantly, our research with OpenAI has not identified significant attacks employing the LLMs we monitor closely. At the same time, we feel this is important research to publish to expose early-stage, incremental moves that we observe well-known threat actors attempting, and share information on how we are blocking and countering them with the defender community.\nWhile attackers will remain interested in AI and probe technologies’ current capabilities and security controls, it’s important to keep these risks in context. As always, hygiene practices such as multifactor authentication (MFA) and Zero Trust defenses are essential because attackers may use AI-based tools to improve their existing cyberattacks that rely on social engineering and finding unsecured devices and accounts.\nThe threat actors profiled below are a sample of observed activity we believe best represents the TTPs the industry will need to better track using MITRE ATT&CK® framework or MITRE ATLAS™ knowledgebase updates.\nForest Blizzard (STRONTIUM) is a Russian military intelligence actor linked to GRU Unit 26165, who has targeted victims of both tactical and strategic interest to the Russian government. Their activities span across a variety of sectors including defense, transportation/logistics, government, energy, non-governmental organizations (NGO), and information technology. Forest Blizzard has been extremely active in targeting organizations in and related to Russia’s war in Ukraine throughout the duration of the conflict, and Microsoft assesses that Forest Blizzard operations play a significant supporting role to Russia’s foreign policy and military objectives both in Ukraine and in the broader international community. Forest Blizzard overlaps with the threat actor tracked by other researchers as APT28 and Fancy Bear.\nForest Blizzard’s use of LLMs has involved research into various satellite and radar technologies that may pertain to conventional military operations in Ukraine, as well as generic research aimed at supporting their cyber operations. Based on these observations, we map and classify these TTPs using the following descriptions:\nLLM-informed reconnaissance: Interacting with LLMs to understand satellite communication protocols, radar imaging technologies, and specific technical parameters. These queries suggest an attempt to acquire in-depth knowledge of satellite capabilities.\nLLM-enhanced scripting techniques: Seeking assistance in basic scripting tasks, including file manipulation, data selection, regular expressions, and multiprocessing, to potentially automate or optimize technical operations.\nMicrosoft observed engagement from Forest Blizzard that were representative of an adversary exploring the use cases of a new technology. All accounts and assets associated with Forest Blizzard have been disabled.\nEmerald Sleet (THALLIUM) is a North Korean threat actor that has remained highly active throughout 2023. Their recent operations relied on spear-phishing emails to compromise and gather intelligence from prominent individuals with expertise on North Korea. Microsoft observed Emerald Sleet impersonating reputable academic institutions and NGOs to lure victims into replying with expert insights and commentary about foreign policies related to North Korea. Emerald Sleet overlaps with threat actors tracked by other researchers as Kimsuky and Velvet Chollima.\nEmerald Sleet’s use of LLMs has been in support of this activity and involved research into think tanks and experts on North Korea, as well as the generation of content likely to be used in spear-phishing campaigns. Emerald Sleet also interacted with LLMs to understand publicly known vulnerabilities, to troubleshoot technical issues, and for assistance with using various web technologies. Based on these observations, we map and classify these TTPs using the following descriptions:\nLLM-assisted vulnerability research: Interacting with LLMs to better understand publicly reported vulnerabilities, such as the CVE-2022-30190 Microsoft Support Diagnostic Tool (MSDT) vulnerability (known as “Follina”).\nLLM-enhanced scripting techniques: Using LLMs for basic scripting tasks such as programmatically identifying certain user events on a system and seeking assistance with troubleshooting and understanding various web technologies.\nLLM-supported social engineering: Using LLMs for assistance with the drafting and generation of content that would likely be for use in spear-phishing campaigns against individuals with regional expertise.\nLLM-informed reconnaissance: Interacting with LLMs to identify think tanks, government organizations, or experts on North Korea that have a focus on defense issues or North Korea’s nuclear weapon’s program.\nAll accounts and assets associated with Emerald Sleet have been disabled.\nCrimson Sandstorm (CURIUM) is an Iranian threat actor assessed to be connected to the Islamic Revolutionary Guard Corps (IRGC). Active since at least 2017, Crimson Sandstorm has targeted multiple sectors, including defense, maritime shipping, transportation, healthcare, and technology. These operations have frequently relied on watering hole attacks and social engineering to deliver custom .NET malware. Prior research also identified custom Crimson Sandstorm malware using email-based command-and-control (C2) channels. Crimson Sandstorm overlaps with the threat actor tracked by other researchers as Tortoiseshell, Imperial Kitten, and Yellow Liderc.\nThe use of LLMs by Crimson Sandstorm has reflected the broader behaviors that the security community has observed from this threat actor. Interactions have involved requests for support around social engineering, assistance in troubleshooting errors, .NET development, and ways in which an attacker might evade detection when on a compromised machine. Based on these observations, we map and classify these TTPs using the following descriptions:\nLLM-supported social engineering: Interacting with LLMs to generate various phishing emails, including one pretending to come from an international development agency and another attempting to lure prominent feminists to an attacker-built website on feminism.\nLLM-enhanced scripting techniques: Using LLMs to generate code snippets that appear intended to support app and web development, interactions with remote servers, web scraping, executing tasks when users sign in, and sending information from a system via email.\nLLM-enhanced anomaly detection evasion: Attempting to use LLMs for assistance in developing code to evade detection, to learn how to disable antivirus via registry or Windows policies, and to delete files in a directory after an application has been closed.\nAll accounts and assets associated with Crimson Sandstorm have been disabled.\nCharcoal Typhoon (CHROMIUM) is a Chinese state-affiliated threat actor with a broad operational scope. They are known for targeting sectors that include government, higher education, communications infrastructure, oil & gas, and information technology. Their activities have predominantly focused on entities within Taiwan, Thailand, Mongolia, Malaysia, France, and Nepal, with observed interests extending to institutions and individuals globally who oppose China’s policies. Charcoal Typhoon overlaps with the threat actor tracked by other researchers as Aquatic Panda, ControlX, RedHotel, and BRONZE UNIVERSITY.\nIn recent operations, Charcoal Typhoon has been observed interacting with LLMs in ways that suggest a limited exploration of how LLMs can augment their technical operations. This has consisted of using LLMs to support tooling development, scripting, understanding various commodity cybersecurity tools, and for generating content that could be used to social engineer targets. Based on these observations, we map and classify these TTPs using the following descriptions:\nLLM-informed reconnaissance: Engaging LLMs to research and understand specific technologies, platforms, and vulnerabilities, indicative of preliminary information-gathering stages.\nLLM-enhanced scripting techniques: Utilizing LLMs to generate and refine scripts, potentially to streamline and automate complex cyber tasks and operations.\nLLM-supported social engineering: Leveraging LLMs for assistance with translations and communication, likely to establish connections or manipulate targets.\nLLM-refined operational command techniques: Utilizing LLMs for advanced commands, deeper system access, and control representative of post-compromise behavior.\nAll associated accounts and assets of Charcoal Typhoon have been disabled, reaffirming our commitment to safeguarding against the misuse of AI technologies.\nSalmon Typhoon (SODIUM) is a sophisticated Chinese state-affiliated threat actor with a history of targeting US defense contractors, government agencies, and entities within the cryptographic technology sector. This threat actor has demonstrated its capabilities through the deployment of malware, such as Win32/Wkysol, to maintain remote access to compromised systems. With over a decade of operations marked by intermittent periods of dormancy and resurgence, Salmon Typhoon has recently shown renewed activity. Salmon Typhoon overlaps with the threat actor tracked by other researchers as APT4 and Maverick Panda.\nNotably, Salmon Typhoon’s interactions with LLMs throughout 2023 appear exploratory and suggest that this threat actor is evaluating the effectiveness of LLMs in sourcing information on potentially sensitive topics, high profile individuals, regional geopolitics, US influence, and internal affairs. This tentative engagement with LLMs could reflect both a broadening of their intelligence-gathering toolkit and an experimental phase in assessing the capabilities of emerging technologies.\nBased on these observations, we map and classify these TTPs using the following descriptions:\nLLM-informed reconnaissance: Engaging LLMs for queries on a diverse array of subjects, such as global intelligence agencies, domestic concerns, notable individuals, cybersecurity matters, topics of strategic interest, and various threat actors. These interactions mirror the use of a search engine for public domain research.\nLLM-enhanced scripting techniques: Using LLMs to identify and resolve coding errors. Requests for support in developing code with potential malicious intent were observed by Microsoft, and it was noted that the model adhered to established ethical guidelines, declining to provide such assistance.\nLLM-refined operational command techniques: Demonstrating an interest in specific file types and concealment tactics within operating systems, indicative of an effort to refine operational command execution.\nLLM-aided technical translation and explanation: Leveraging LLMs for the translation of computing terms and technical papers.\nSalmon Typhoon’s engagement with LLMs aligns with patterns observed by Microsoft, reflecting traditional behaviors in a new technological arena. In response, all accounts and assets associated with Salmon Typhoon have been disabled.\nIn closing, AI technologies will continue to evolve and be studied by various threat actors. Microsoft will continue to track threat actors and malicious activity misusing LLMs, and work with OpenAI and other partners to share intelligence, improve protections for customers and aid the broader security community.\nUsing insights from our analysis above, as well as other potential misuse of AI, we’re sharing the below list of LLM-themed TTPs that we map and classify to the MITRE ATT&CK® framework or MITRE ATLAS™ knowledgebase to equip the community with a common taxonomy to collectively track malicious use of LLMs and create countermeasures against:\nLLM-informed reconnaissance: Employing LLMs to gather actionable intelligence on technologies and potential vulnerabilities.\nLLM-enhanced scripting techniques: Utilizing LLMs to generate or refine scripts that could be used in cyberattacks, or for basic scripting tasks such as programmatically identifying certain user events on a system and assistance with troubleshooting and understanding various web technologies.\nLLM-aided development: Utilizing LLMs in the development lifecycle of tools and programs, including those with malicious intent, such as malware.\nLLM-supported social engineering: Leveraging LLMs for assistance with translations and communication, likely to establish connections or manipulate targets.\nLLM-assisted vulnerability research: Using LLMs to understand and identify potential vulnerabilities in software and systems, which could be targeted for exploitation.\nLLM-optimized payload crafting: Using LLMs to assist in creating and refining payloads for deployment in cyberattacks.\nLLM-enhanced anomaly detection evasion: Leveraging LLMs to develop methods that help malicious activities blend in with normal behavior or traffic to evade detection systems.\nLLM-directed security feature bypass: Using LLMs to find ways to circumvent security features, such as two-factor authentication, CAPTCHA, or other access controls.\nLLM-advised resource development: Using LLMs in tool development, tool modifications, and strategic operational planning.\nRead the sixth edition of Cyber Signals, spotlighting how we are protecting AI platforms from emerging threats related to nation-state cyberthreat actors: Navigating cyberthreats and strengthening defenses in the era of AI.\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.\nTo hear stories and insights from the Microsoft Threat Intelligence community about the ever-evolving threat landscape, listen to the Microsoft Threat Intelligence podcast: https://thecyberwire.com/podcasts/microsoft-threat-intelligence.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "With a systems approach to chips, Microsoft aims to tailor everything ‘from silicon to service’ to meet AI demand - Source",
    "link": "https://news.microsoft.com/source/features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVVSa0ZvTFdkT2JYUTRXRmxEVFJDM0FSaVRBaWdCTWdZQklJNTN2QVU=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-11-15T08:00:00.000Z",
    "time": "Nov 15, 2023",
    "articleType": "regular",
    "content": "Tucked away on Microsoft’s Redmond campus is a lab full of machines probing the basic building block of the digital age: Silicon. This multi-step process meticulously tests the silicon, in a method Microsoft engineers have been refining in secret for years.\nToday at Microsoft Ignite the company unveiled two custom-designed chips and integrated systems that resulted from that journey: the Microsoft Azure Maia AI Accelerator, optimized for artificial intelligence (AI) tasks and generative AI, and the Microsoft Azure Cobalt CPU, an Arm-based processor tailored to run general purpose compute workloads on the Microsoft Cloud.\nThe chips represent a last puzzle piece for Microsoft to deliver infrastructure systems – which include everything from silicon choices, software and servers to racks and cooling systems – that have been designed from top to bottom and can be optimized with internal and customer workloads in mind.\nThe chips will start to roll out early next year to Microsoft’s datacenters, initially powering the company’s services such as Microsoft Copilot or Azure OpenAI Service. They will join an expanding range of products from industry partners to help meet the exploding demand for efficient, scalable and sustainable compute power and the needs of customers eager to take advantage of the latest cloud and AI breakthroughs.\n“Microsoft is building the infrastructure to support AI innovation, and we are reimagining every aspect of our datacenters to meet the needs of our customers,” said Scott Guthrie, executive vice president of Microsoft’s Cloud + AI Group. “At the scale we operate, it’s important for us to optimize and integrate every layer of the infrastructure stack to maximize performance, diversify our supply chain and give customers infrastructure choice.”\nOptimizing every layer of the stack\nChips are the workhorses of the cloud. They command billions of transistors that process the vast streams of ones and zeros flowing through datacenters. That work ultimately allows you to do just about everything on your screen, from sending an email to generating an image in Bing with a simple sentence.\nMuch like building a house lets you control every design choice and detail, Microsoft sees the addition of homegrown chips as a way to ensure every element is tailored for Microsoft cloud and AI workloads. The chips will nestle onto custom server boards, placed within tailor-made racks that fit easily inside existing Microsoft datacenters. The hardware will work hand in hand with software – co-designed together to unlock new capabilities and opportunities.\nThe end goal is an Azure hardware system that offers maximum flexibility and can also be optimized for power, performance, sustainability or cost, said Rani Borkar, corporate vice president for Azure Hardware Systems and Infrastructure (AHSI).\n“Software is our core strength, but frankly, we are a systems company. At Microsoft we are co-designing and optimizing hardware and software together so that one plus one is greater than two,” Borkar said. “We have visibility into the entire stack, and silicon is just one of the ingredients.”\nRani Borkar, corporate vice president for Azure Hardware Systems and Infrastructure (AHSI) at Microsoft. Photo courtesy of Microsoft.\nAt Microsoft Ignite, the company also announced the general availability of one of those key ingredients: Azure Boost, a system that makes storage and networking faster by taking those processes off the host servers onto purpose-built hardware and software.\nTo complement its custom silicon efforts, Microsoft also announced it is expanding industry partnerships to provide more infrastructure options for customers. Microsoft launched a preview of the new NC H100 v5 Virtual Machine Series built for NVIDIA H100 Tensor Core GPUs, offering greater performance, reliability and efficiency for mid-range AI training and generative AI inferencing. Microsoft will also add the latest NVIDIA H200 Tensor Core GPU to its fleet next year to support larger model inferencing with no increase in latency.\nThe company also announced it will be adding AMD MI300X accelerated VMs to Azure. The ND MI300 virtual machines are designed to accelerate the processing of AI workloads for high range AI model training and generative inferencing, and will feature AMD’s latest GPU, the AMD Instinct MI300X.\nBy adding first party silicon to a growing ecosystem of chips and hardware from industry partners, Microsoft will be able to offer more choice in price and performance for its customers, Borkar said.\n“Customer obsession means we provide whatever is best for our customers, and that means taking what is available in the ecosystem as well as what we have developed,” she said. “We will continue to work with all of our partners to deliver to the customer what they want.”\nThe company’s new Maia 100 AI Accelerator will power some of the largest internal AI workloads running on Microsoft Azure. Additionally, OpenAI has provided feedback on Azure Maia and Microsoft’s deep insights into how OpenAI’s workloads run on infrastructure tailored for its large language models is helping inform future Microsoft designs.\n“Since first partnering with Microsoft, we’ve collaborated to co-design Azure’s AI infrastructure at every layer for our models and unprecedented training needs,” said Sam Altman, CEO of OpenAI. “We were excited when Microsoft first shared their designs for the Maia chip, and we’ve worked together to refine and test it with our models. Azure’s end-to-end AI architecture, now optimized down to the silicon with Maia, paves the way for training more capable models and making those models cheaper for our customers.”\nThe Maia 100 AI Accelerator was also designed specifically for the Azure hardware stack, said Brian Harry, a Microsoft technical fellow leading the Azure Maia team. That vertical integration – the alignment of chip design with the larger AI infrastructure designed with Microsoft’s workloads in mind – can yield huge gains in performance and efficiency, he said.\n“Azure Maia was specifically designed for AI and for achieving the absolute maximum utilization of the hardware,” he said.\nMeanwhile, the Cobalt 100 CPU is built on Arm architecture, a type of energy-efficient chip design, and optimized to deliver greater efficiency and performance in cloud native offerings, said Wes McCullough, corporate vice president of hardware product development. Choosing Arm technology was a key element in Microsoft’s sustainability goal. It aims to optimize “performance per watt” throughout its datacenters, which essentially means getting more computing power for each unit of energy consumed.\nThese servers inside a datacenter in Quincy, Washington, are the first to be powered by the Microsoft Azure Cobalt 100 CPU. Photo by John Brecher for Microsoft.\n“The architecture and implementation is designed with power efficiency in mind,” he said. “We’re making the most efficient use of the transistors on the silicon. Multiply those efficiency gains in servers across all our datacenters, it adds up to a pretty big number.”\nCustom hardware, from chip to datacenter\nBefore 2016, most layers of the Microsoft cloud were bought off the shelf, said Pat Stemen, partner program manager on the AHSI team. Then Microsoft began to custom build its own servers and racks, driving down costs and giving customers a more consistent experience. Over time, silicon became the primary missing piece.\nThe ability to build its own custom silicon allows Microsoft to target certain qualities and ensure that the chips perform optimally on its most important workloads. Its testing process includes determining how every single chip will perform under different frequency, temperature and power conditions for peak performance and, importantly, testing each chip in the same conditions and configurations that it would experience in a real-world Microsoft datacenter.\nThe silicon architecture unveiled today also lets Microsoft not only enhance cooling efficiency but optimize the use of its current datacenter assets and maximize server capacity within its existing footprint, the company said.\nFor example, no racks existed to house the unique requirements of the Maia 100 server boards. So Microsoft built them from scratch. These racks are wider than what typically sits in the company’s datacenters. That expanded design provides ample space for both power and networking cables, essential for the unique demands of AI workloads.\nA custom-built rack for the Maia 100 AI Accelerator and its “sidekick” inside a thermal chamber at a Microsoft lab in Redmond, Washington. The sidekick acts like a car radiator, cycling liquid to and from the rack to cool the chips as they handle the computational demands of AI workloads. Photo by John Brecher for Microsoft.\nSuch AI tasks come with intensive computational demands that consume more power. Traditional air-cooling methods fall short for these high-performance chips. As a result, liquid cooling – which uses circulating fluids to dissipate heat – has emerged as the preferred solution to these thermal challenges, ensuring they run efficiently without overheating.\nBut Microsoft’s current datacenters weren’t designed for large liquid chillers. So it developed a “sidekick” that sits next to the Maia 100 rack. These sidekicks work a bit like a radiator in a car. Cold liquid flows from the sidekick to cold plates that are attached to the surface of Maia 100 chips. Each plate has channels through which liquid is circulated to absorb and transport heat. That flows to the sidekick, which removes heat from the liquid and sends it back to the rack to absorb more heat, and so on.\nThe tandem design of rack and sidekick underscores the value of a systems approach to infrastructure, McCullough said. By controlling every facet — from the low-power ethos of the Cobalt 100 chip to the intricacies of datacenter cooling — Microsoft can orchestrate a harmonious interplay between each component, ensuring that the whole is indeed greater than the sum of its parts in reducing environmental impact.\nMicrosoft has shared its design learnings from its custom rack with industry partners and can use those no matter what piece of silicon sits inside, said Stemen. “All the things we build, whether infrastructure or software or firmware, we can leverage whether we deploy our chips or those from our industry partners,” he said. “This is a choice the customer gets to make, and we’re trying to provide the best set of options for them, whether it’s for performance or cost or any other dimension they care about.”\nMicrosoft plans to expand that set of options in the future; it is already designing second-generation versions of the Azure Maia AI Accelerator series and the Azure Cobalt CPU series. The company’s mission remains clear, Stemen said: optimize every layer of its technological stack, from the core silicon to the end service.\n“Microsoft innovation is going further down in the stack with this silicon work to ensure the future of our customers’ workloads on Azure, prioritizing performance, power efficiency and cost,” he said. “We chose this innovation intentionally so that our customers are going to get the best experience they can have with Azure today and in the future.”\nRead more: Microsoft delivers purpose-built cloud infrastructure in the era of AI\nRead more: Azure announces new AI optimized VM series featuring AMD’s flagship MI300X GPU\nRead more: Introducing Azure NC H100 v5 VMs for mid-range AI and HPC workloads\nTop image: A technician installs the first server racks containing Microsoft Azure Cobalt 100 CPUs at a datacenter in Quincy, Washington. It’s the first CPU designed by Microsoft for the Microsoft Cloud. Photo by John Brecher for Microsoft.",
    "favicon": "https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2022/10/cropped-Microsoft_logo.svg_-300x300-1-128x120.png"
  },
  {
    "title": "Bringing the full power of Copilot to more people and businesses",
    "link": "https://blogs.microsoft.com/blog/2024/01/15/bringing-the-full-power-of-copilot-to-more-people-and-businesses/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNXVVRzA0WlVaUGRraExkSFZvVFJDb0FSaXNBaWdCTWdZQlFKRE5HUW8=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-01-15T08:00:00.000Z",
    "time": "Jan 15",
    "articleType": "regular",
    "content": "As we kick off a new year, we’re thrilled to see people increasingly using and loving Microsoft Copilot for work and life. Our goal is to empower every person and every organization on the planet to achieve more by bringing Copilot, the everyday AI companion, to millions of people around the world. We have reached another milestone in this mission with more than 5 billion chats and more than 5 billion images to date. As Copilot continues to earn preference and usage, we’re receiving valuable feedback on how to improve. Two examples: First, there are a set of Copilot power users like creators, researchers, programmers and others who want more rapid access to the very latest we have to offer. And second, our Microsoft 365 customers want access to Copilot in the Microsoft 365 apps for personal use.\nTo help address those needs, today we’re delighted to announce more options for power users, creators and anyone looking to take their Copilot experience to the next level. This begins with the introduction of Copilot Pro, a new premium subscription for individuals that provides a higher tier of service for AI capabilities, brings Copilot AI capabilities to Microsoft 365 Personal and Family subscribers, and new capabilities, such as the ability to create Copilot GPTs. We are also announcing the general availability of our Copilot app for iOS and Android phones. Finally, we’re excited to bring Copilot for Microsoft 365 to more commercial customers by expanding the availability to businesses of all sizes, including small- and medium-sized businesses, starting today.\nIntroducing Copilot Pro: Supercharge your creativity and productivity\nToday we’re announcing the availability of Copilot Pro, a new subscription that delivers the most advanced features and capabilities of Microsoft Copilot to individuals looking to supercharge their Copilot experience. Whether you need advanced help with writing, coding, designing, researching or learning, Copilot Pro brings greater performance, productivity and creativity.\nA single AI experience that runs across your devices, understanding your context on the web, on your PC, across your apps and soon on your phone to bring the right skills to you when you need them.\nAccess to Copilot in Word, Excel[i], PowerPoint, Outlook, and OneNote on PC, Mac and iPad for Microsoft 365 Personal and Family subscribers.\nPriority access to the very latest models – starting today with OpenAI’s GPT-4 Turbo. With Copilot Pro you’ll have access to GPT-4 Turbo during peak times for faster performance and, coming soon, the ability to toggle between models to optimize your experience how you choose.\nEnhanced AI image creation with Image Creator from Designer (formerly Bing Image Creator) – ensuring it’s faster with 100 boosts per day while bringing you more detailed image quality as well as landscape image format.\nThe ability to build your own Copilot GPT – a customized Copilot tailored for a specific topic – in our new Copilot GPT Builder (coming soon) with just a simple set of prompts.\nYou can subscribe to Copilot Pro today for $20 per month/per user.\nExpanding Copilot for Microsoft 365 to businesses of all sizes\nCopilot for Microsoft 365 is now generally available for small businesses with Microsoft 365 Business Premium and Business Standard Customers can purchase between one and 300 seats for $30 per person per month.\nWe’re removing the 300-seat purchase minimum for commercial plans and making Copilot available for Office 365 E3 and E5 customers (A Microsoft 365 license was previously required).\nCommercial customers can now purchase Copilot for Microsoft 365 through our amazing network of Microsoft Cloud Solution Provider partners.\nLast month, we also announced eligibility of Copilot for Microsoft 365 for education faculty and staff.\nIntroducing new features in Copilot\nAs we expand the availability of Copilot to even more people, we continue to offer a great free experience for anyone interested in exploring how Copilot can transform productivity and creativity using AI. Today we’re excited to share additional updates to Copilot. You can get started by visiting copilot.microsoft.com.\nCopilot GPTs – Today we’re announcing Copilot GPTs. Copilot GPTs let you customize the behavior of Microsoft Copilot on a topic that is of particular interest to you.  A handful of Copilot GPTs will start to roll out beginning today with specific purposes such as fitness, travel, cooking and more. Soon, Copilot Pro users will also be able to create their own Copilot GPTs using Copilot GPT Builder. Stay tuned for more on this experience as we get closer to availability.\nCopilot mobile app – The Copilot mobile app is now available for Android and iOS. The Copilot app gives you the power of Copilot on the go as your Copilot queries and chats will roam across your phone and PC. The Copilot mobile app includes the same capabilities of Copilot on your PC including access to GPT-4, Dall-E 3 for image creation, and the ability to use images from your phone when chatting with Copilot. Download the app from the Google Play Store or the Apple App Store.\nCopilot in the Microsoft 365 mobile app – We’re also adding Copilot to the Microsoft 365 mobile app for Android and iOS for individuals with a Microsoft account. This new feature is rolling out over the next month. Access Copilot right inside the app and easily export the content you create to a Word or PDF document. Download the app from the Google Play Store or the Apple App Store.\nWith today’s announcements, we continue to bring Copilot to more customers with more options that work for them. Whether you’re looking to get started with Copilot for free, want to supercharge your Copilot experience with Copilot Pro or are an SMB or Enterprise customer looking to increase your productivity in new ways with Copilot for Microsoft 365, there’s a Copilot experience for everyone.\n[i] Currently in preview, English only\nTags: AI, Copilot Pro, Microsoft 365 Copilot",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Announcing Microsoft Copilot, your everyday AI companion",
    "link": "https://blogs.microsoft.com/blog/2023/09/21/announcing-microsoft-copilot-your-everyday-ai-companion/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVdkV2xhTFhGWmJUSlljWGhVVFJDb0FSaXNBaWdCTWdhdFZZN09xUVU=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-21T07:00:00.000Z",
    "time": "Sep 21, 2023",
    "articleType": "regular",
    "content": "We are entering a new era of AI, one that is fundamentally changing how we relate to and benefit from technology. With the convergence of chat interfaces and large language models you can now ask for what you want in natural language and the technology is smart enough to answer, create it or take action. At Microsoft, we think about this as having a copilot to help navigate any task. We have been building AI-powered copilots into our most used and loved products – making coding more efficient with GitHub, transforming productivity at work with Microsoft 365, redefining search with Bing and Edge and delivering contextual value that works across your apps and PC with Windows.\nToday we take the next step to unify these capabilities into a single experience we call Microsoft Copilot, your everyday AI companion. Copilot will uniquely incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance – with your privacy and security at the forefront. It will be a simple and seamless experience, available in Windows 11, Microsoft 365, and in our web browser with Edge and Bing. It will work as an app or reveal itself when you need it with a right click. We will continue to add capabilities and connections to Copilot across to our most-used applications over time in service of our vision to have one experience that works across your whole life.\nCopilot will begin to roll out in its early form as part of our free update to Windows 11, starting Sept. 26 — and across Bing, Edge, and Microsoft 365 Copilot this fall. We’re also announcing some exciting new experiences and devices to help you be more productive, spark your creativity, and to meet the everyday needs of people and businesses.\nWith over 150 new features, the next Windows 11 update is one of our most ambitious yet, bringing the power of Copilot and new AI powered experiences to apps like Paint, Photos, Clipchamp and more right to your Windows PC.\nBing will add support for the latest DALL.E 3 model from OpenAI and deliver more personalized answers based on your search history, a new AI-powered shopping experience, and updates to Bing Chat Enterprise, making it more mobile and visual.\nMicrosoft 365 Copilot will be generally available for enterprise customers on Nov. 1, 2023, along with Microsoft 365 Chat, a new AI assistant that will completely transform the way you work.\nAdditionally, we introduced powerful new Surface devices that bring all these AI experiences to life for you, and they are available for pre-order beginning today.\nNew Windows 11 Update delivers over 150 new features, including bringing the power of Copilot to the PC\nToday, we’re thrilled to share our next step toward making Windows the destination for the best AI experiences – with a new update that delivers our most personal experience yet coming on Sept. 26.\nHere’s a look at some of what’s new in the latest update for Windows 11:\nCopilot in Windows (in preview) empowers you to create faster, complete tasks with ease and lessens your cognitive load – making once complicated tasks, simple. We’ve made accessing the power of Copilot seamless as it’s always right there for you on the taskbar or with the Win+C keyboard shortcut providing assistance alongside all your apps, on all screen sizes at work, school or at home.\nPaint has been enhanced with AI for drawing and digital creation with the addition of background removal and layers as well as a preview of Cocreator that brings the power of generative AI to the Paint app.\nPhotos has also been enhanced with AI including new features to make editing your photos a breeze. With Background Blur you can make the subject of your photo stand out quickly and easily. The Photos app automatically finds the background in the photo, and with a single click, instantly highlights your subject and blurs out the background. We’ve improved search, with photos stored in OneDrive (home or personal) accounts, you can now quickly find the photo you’re looking for based on the content of the photo. You can also now find photos based on the location where they were taken.\nSnipping Tool now offers more ways to capture content on your screen – with this update you can now extract specific text content from an image to paste in another application or, you can easily protect your sensitive information with text redaction by using text actions on the post capture screen. And, with the addition of sound capturing using audio and mic support, it’s easier to create compelling videos and content from your screen.\nClipchamp, now with auto compose, helps you with scenes suggestions, edits and narratives based on your images and footage automatically so you can create and edit videos to share with family, friends, and social media like a pro.\nNotepad will start automatically saving your session state allowing you to close Notepad without any interrupting dialogs and then pick up where you left off when you return. Notepad will automatically restore previously open tabs as well as unsaved content and edits across those open tabs.\nModernized File Explorer, we are introducing a modernized File Explorer home, address bar and search box all designed to help you more easily access important and relevant content, stay up to date with file activity and collaborate without even opening a file. Also coming to File Explorer is a new Gallery feature designed to make it easy to access your photo collection.\nNew text authoring experiences to voice access and new natural voices in Narrator, continuing our ongoing commitment to making Windows 11 the most accessible version of Windows yet.\nWindows Backup makes moving to a new Windows 11 PC easier than ever. With Windows Backup, transitioning most files, apps and settings from one PC to another, is seamless so everything is right where you left it, exactly how you like it.\nThese experiences, including Copilot in Windows and more will start to become available on Sept. 26 as part of our latest update to Windows 11, version 22H2.\nBing and Edge are redefining how we interact with the web\nToday, we’re announcing new features in Bing and Edge to supercharge your day powered by the latest models delivering the most advanced capabilities for AI available. You can use Bing Chat today with Microsoft Edge or at bing.com/chat. Features will begin to roll out soon.\nPersonalized answers. Now, your chat history can inform your results. For example, if you’ve used Bing to track your favorite soccer team, next time you’re planning a trip it can proactively tell you if the team is playing in your destination city. If you prefer responses that don’t use your chat history, you can turn this feature off in Bing settings.\nDALL.E 3 model from OpenAI in Bing Image Creator. DALL.E 3 delivers a huge leap forward with more beautiful creations and better renderings for details like fingers and eyes. It also has a better understanding of what you’re asking for, which results in delivering more accurate images. We’re also integrating Microsoft Designer directly into Bing to make editing your creations even easier.\nContent Credentials. As we continue to take a responsible approach to generative AI, we’re adding new Content Credentials which uses cryptographic methods to add an invisible digital watermark to all AI-generated images in Bing – including time and date it was originally created. We will also bring support for Content Credentials to Paint and Microsoft Designer.\nBing Chat Enterprise Updates. Since its introduction just two months ago, more than 160 million Microsoft 365 users now have access to Bing Chat Enterprise at no additional cost and the response has been incredible. Today we’re announcing that Bing Chat Enterprise is now available in the Microsoft Edge mobile app. We’re also bringing support for multimodal visual search and Image Creator to Bing Chat Enterprise. Boost your creativity at work with the ability to find information using images and creating them.\nTransforming work with Microsoft 365 Copilot, Bing Chat Enterprise and Windows\nIn March, we showed you what Microsoft 365 Copilot can do in the apps millions of people use every day across work and life – Word, Excel, PowerPoint, Outlook and Teams – using just your own words. After months of learning alongside customers like Visa, General Motors, KPMG and Lumen Technologies, we’re excited to share that Microsoft 365 Copilot will be generally available for enterprise customers on Nov. 1.\nToday, we’re also introducing a new, hero experience in Microsoft 365 Copilot: Microsoft 365 Chat. You saw a glimpse of Microsoft 365 Chat in March, then called Business Chat — but rapid advancements over the last few months have taken it to a whole new level. Microsoft 365 Chat combs across your entire universe of data at work, including emails, meetings, chats, documents and more, plus the web. Like an assistant, it has a deep understanding of you, your job, your priorities and your organization. It goes far beyond simple questions and answers to give you a head start on some of your most complex or tedious tasks — whether that’s writing a strategy document, booking a business trip, or catching up on emails.\nOver the past few years, the pace and volume of work have only increased. On a given workday, our heaviest users search for what they need 18 times, receive over 250 Outlook emails and send or read nearly 150 Teams chats.[1] Teams users globally are in three times more meetings each week than they were in 2020.[2] And on Windows, some people use 11 apps in a single day to get work done. [3] Microsoft 365 Chat tames the complexity, eliminates the drudgery and helps you reclaim time at work. Preview customers can access it today on Microsoft365.com, Teams, or in Bing when signed in with their work account. In the future you’ll be able to access it wherever you see the Copilot icon when signed in with your work account.\nUnleashing personal productivity and creativity with Designer and Copilot in Microsoft 365\nDesigner, the newest addition to our family of Microsoft 365 consumer apps, helps you quickly create stunning visuals, social media posts, invitations, and more using cutting-edge AI. Today, we’re showing some powerful new features, many of which will be powered by OpenAI’s Dall.E 3. Generative expand uses AI to extend your image beyond its borders, generative fill adds a new object or background, and generative erase can remove unwanted objects.[4] Dall.E 3 will also soon power the image generation experience in Designer, making it easy to add original, higher quality images to your design in seconds.\nWe’re also integrating Designer into Microsoft 365 Copilot for consumers — starting with Word. Designer uses the context of your document to propose visuals to choose from; you can make it more personal by uploading your own photos too. And within moments, you can transform a text-heavy document with custom graphics. We’re starting to test Microsoft 365 Copilot with a small group of Microsoft 365 consumer subscribers and look forward to expanding the preview to more people over time. Seventy percent of creators tell us one of the most difficult parts of the creation process is just getting started.[5] With creative tools like Designer, plus Bing Image Creator, Clipchamp and Paint, you can now have an immediate visual draft of almost anything — with a few simple prompts.\nIntroducing new Surface devices available for pre-order beginning today for people and businesses\nThere is no better stage to bring to life all of the incredible AI experiences from across Microsoft than our new Surface devices. Surface is at the forefront of device performance and processor technology. We have been investing in silicon advancements to augment this next wave of AI innovation, unlocking experiences like Windows Studio Effects in Surface Pro 9 with 5G and continuing to increase performance to run the latest AI models with powerful devices like the new Surface Laptop Studio 2.\nThe new Surface Laptop Studio 2 is the most powerful Surface we’ve ever built. Turbocharged with the latest Intel® Core processors and cutting-edge NVIDIA® Studio tools for creators-with up to 2x more graphics performance than MacBook Pro M2 Max, [6] Surface Laptop Studio brings together the versatility to create and the power to perform — a stunning 14.4″ PixelSense Flow touchscreen display and flexible design with three unique postures. And with new customizations brought to the haptic touchpad to improve accessibility – we’re proud to call it the most inclusive touchpad on any laptop today.\nThe new Surface Laptop Go 3 will turn heads with its balance of style and performance. It’s our lightest and most portable Surface Laptop, with a touchscreen display, and packed with premium features like an incredible typing experience and a Fingerprint Power Button, and it comes in four stylish colors. With Intel® Core i5 performance, all-day battery life, and robust RAM and storage options, it’s the perfect everyday laptop and stage for the latest AI tools from Microsoft.\nSurface Go 4 for Business is our most portable Surface 2-in-1. This fall, the new Surface Go will be available exclusively for organizations to meet the growing needs of frontline workers and educators. We can’t wait to see how it will help businesses modernize and make their users more productive.\nSurface Hub 3 is the premier collaboration device built for hybrid work, designed end-to-end by Microsoft. The Microsoft Teams Rooms on Windows experience is familiar and intuitive on a brilliant 50” or 85” screen. The 50” Surface Hub 3 brings entirely new ways to co-create with Portrait, Smart Rotation and Smart AV. AI-enhanced collaboration tools – like Cloud IntelliFrame and Copilot in Whiteboard – shine on Surface Hub 3.\n3D printable Adaptive Pen Grips for Surface Pen have been added to our lineup of adaptive accessories enabling more people to engage in digital inking and creation than before. They are available for purchase through Shapeways or as downloadable plans for 3D printing. To hear more about how we’re taking steps to close the disability divide, check out our video.\nThe new era of AI with Copilot from Microsoft is here – and it’s ready for you\nWe believe that Microsoft is the place where powerful, useful AI experiences come together – simply, securely and responsibly – into the products you use most. Today, we showed you how we are not only increasing the usefulness of these experiences, but we are expanding them​. From Windows 11 as the destination for the best AI experiences to empower people using it at work, school and home​. To Microsoft 365, the most trusted productivity suite on the planet​. To Bing and Edge, the most innovative search engine and browser available​. All of it coming together on Windows 11 PCs like Surface​. And with Copilot helping you get things done, helping you create and connect to people you care about or the world around you​. We can’t wait to see what you can do with these experiences.\n[1] Data represents top 20% of users by volume of searches across M365 services, emails received, and sent and read chats in Teams, respectively.\n[2] Microsoft annual Work Trend Index 2023- Work Trend Index | Will AI Fix Work? (microsoft.com)\n[3] Data reflects the top 20% Windows devices by app volume per day.\n[4] Generative erase in Microsoft Designer is generally available to try today, with generative expand and fill coming soon.\n[5] Survey of 941 creators commissioned by Microsoft in June 2022.\n[6] Tested by Microsoft in September 2023 using CineBench 2024 GPU benchmark comparing Surface Laptop Studio 2 with RTX 2000 Ada Generation to MacBook Pro14” with M2 Max 19 12 core / 30 core configuration.\nTags: AI, Bing, Designer, Microsoft 365, Microsoft Copilot, Microsoft Edge, Surface, Windows 11",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Press Release & Webcast",
    "link": "https://www.microsoft.com/en-us/investor/earnings/fy-2024-q3/press-release-webcastR",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNU9ZbWxzYVZFMGRYZ3hiRmxTVFJESUFSajhBU2dCTWdhQm9aVG5PQWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-25T20:14:10.000Z",
    "time": "Apr 25",
    "articleType": "regular",
    "content": "",
    "favicon": "//www.microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Introducing Mistral-Large on Azure in partnership with Mistral AI",
    "link": "https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNTRjV05tU1RoTVZGcFZhRjlJVFJDb0FSaXNBaWdCTWdZTm9wUUhPUWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-02-26T08:00:00.000Z",
    "time": "Feb 26",
    "articleType": "regular",
    "content": "Today, we are announcing a multi-year partnership between Microsoft and Mistral AI. We are fueled by a steadfast dedication to innovation and practical applications, bridging the gap between pioneering research and real-world solutions.\nThe AI industry is undergoing a significant transformation with growing interest in more efficient and cost-effective models, emblematic of a broader trend in technological advancement. In the vanguard is Mistral AI, an innovator and trailblazer. Their commitment to fostering the open-source community and achieving exceptional performance aligns harmoniously with Microsoft’s commitment to develop trustworthy, scalable, and responsible AI solutions.\nToday, we are announcing a multi-year partnership between Microsoft and Mistral AI, a recognized leader in generative artificial intelligence. Both companies are fueled by a steadfast dedication to innovation and practical applications, bridging the gap between pioneering research and real-world solutions.\nIntroducing Mistral Large, our most advanced large language model (LLM)\nThis partnership with Microsoft enables Mistral AI with access to Azure’s cutting-edge AI infrastructure, to accelerate the development and deployment of their next generation large language models (LLMs) and represents an opportunity for Mistral AI to unlock new commercial opportunities, expand to global markets, and foster ongoing research collaboration.\n“We are thrilled to embark on this partnership with Microsoft. With Azure’s cutting-edge AI infrastructure, we are reaching a new milestone in our expansion propelling our innovative research and practical applications to new customers everywhere. Together, we are committed to driving impactful progress in the AI industry and delivering unparalleled value to our customers and partners globally.”\nArthur Mensch, Chief Executive Officer, Mistral AI\nMicrosoft’s partnership with Mistral AI is focused on three core areas:\nSupercomputing infrastructure: Microsoft will support Mistral AI with Azure AI supercomputing infrastructure delivering best-in-class performance and scale for AI training and inference workloads for Mistral AI’s flagship models.\nScale to market: Microsoft and Mistral AI will make Mistral AI’s premium models available to customers through the Models as a Service (MaaS) in the Azure AI Studio and Azure Machine Learning model catalog. In addition to OpenAI models, model catalog offers a diverse selection of both open-source and commercial models. The ability to use Microsoft Azure Consumption Commitment (MACC) for purchasing Mistral AI’s models is available today. Azure’s AI-optimized infrastructure and enterprise-grade capabilities offer Mistral AI additional opportunities to promote, sell, and distribute their models to Microsoft customers worldwide.\nAI research and development: Microsoft and Mistral AI will explore collaboration around training purpose-specific models for select customers, including European public sector workloads.\nExpand your AI functions with Azure and Mistral AI\nIn November 2023, at Microsoft Ignite, Microsoft unveiled the integration of Mistral 7B into the Azure AI model catalog accessible through Azure AI Studio and Azure Machine Learning. We are excited to announce Mistral AI’s flagship commercial model, Mistral Large, available first on Azure AI and the Mistral AI platform, marking a noteworthy expansion of our offerings. Mistral Large is a general-purpose language model that can deliver on any text-based use case thanks to state-of-the-art reasoning and knowledge capabilities. It is proficient in code and mathematics, able to process dozens of documents in a single call, and handles French, German, Spanish, and Italian (in addition to English).\nThis latest addition of Mistral AI’s premium models into Models as a Service (MaaS) within Azure AI Studio and Azure Machine Learning provides Microsoft customers with a diverse selection of the best state-of-the-art and open-source models for crafting and deploying custom AI applications, paving the way for novel AI-driven innovations.\n“We have tested Mistral Large through the Azure AI Studio in a use case aimed at internal efficiency. The performance was comparable with state-of-the-art models with even better latency. We are looking forward to exploring further this technology in our business.”\nPhilippe Rambach, Chief AI Officer, Schneider Electric\nNacim Rahal, Senior Director, Data and AI, Doctolib\n“The Mistral AI models have been crucial in enhancing productivity and collaboration at CMA CGM. Their advanced capabilities have significantly improved the performance of our internal personal assistant, MAIA. Employees are now able to quickly access and engage with information like never before. We are confident that Mistral AI on Azure is the right choice to support our employees and drive innovation across our organization.”\nSéverine Grégoire, Head of Digital, Innovation and AI at CMA CGM\nMicrosoft is committed to supporting global AI innovation and growth, offering world-class datacenter AI infrastructure, and developing technology securely to empower individuals with the skills they need to leverage AI effectively. This partnership with Mistral AI is founded on a shared commitment to build trustworthy and safe AI systems and products. It further reinforces Microsoft’s ongoing efforts to enhance our AI offerings and deliver unparalleled value to our customers. Additionally, the integration into AI Studio ensures that customers can utilize Azure AI Content Safety and responsible AI tools, further enhancing the security and reliability of AI solutions.\nExplore solutions with Azure and Mistral AI today\nVisit the Mistral Large model card and sign in with your Azure subscription to get started with Mistral Large on Azure AI today. You can also review the technical blog to learn how to use Mistral Large on Azure AI. Visit Mistral AI’s blog to get deeper insights about the model.\nBuild intelligent apps at enterprise scale with the Azure AI portfolio",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft and Activision Blizzard Restructure Proposed Acquisition",
    "link": "https://blogs.microsoft.com/on-the-issues/2023/08/21/microsoft-activision-restructure-acquisition/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNXZaazVWVGt4SlUwTTJXazVqVFJDM0FSaVRBaWdCTWdZQmNZZ3dOUVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-08-21T07:00:00.000Z",
    "time": "Aug 21, 2023",
    "articleType": "regular",
    "content": "Microsoft and Activision Blizzard restructure proposed acquisition and notify restructured transaction to the UK’s Competition and Markets Authority\nIn January 2022, Microsoft announced the proposed acquisition of Activision Blizzard, Inc., to advance our goal to bring more creative and innovative games to players everywhere and on any device. Today, we are taking another important step regarding this transaction. To address the concerns about the impact of the proposed acquisition on cloud game streaming raised by the UK Competition and Markets Authority, we are restructuring the transaction to acquire a narrower set of rights. This includes executing an agreement effective at the closing of our merger that transfers the cloud streaming rights for all current and new Activision Blizzard PC and console games released over the next 15 years to Ubisoft Entertainment SA, a leading global game publisher. The rights will be in perpetuity.\nAs a result of the agreement with Ubisoft, Microsoft believes its proposed acquisition of Activision Blizzard presents a substantially different transaction under UK law than the transaction Microsoft submitted for the CMA’s consideration in 2022. As such, Microsoft today has notified the restructured transaction to the CMA and anticipates that the CMA review processes can be completed before the 90-day extension in its acquisition agreement with Activision Blizzard expires on October 18.\nUnder the restructured transaction, Microsoft will not be in a position either to release Activision Blizzard games exclusively on its own cloud streaming service – Xbox Cloud Gaming – or to exclusively control the licensing terms of Activision Blizzard games for rival services.\nThe agreement provides Ubisoft with a unique opportunity to commercialize the distribution of games via cloud streaming. The agreement will enable Ubisoft to innovate and encourage different business models in the licensing and pricing of these games on cloud streaming services worldwide. Ubisoft will compensate Microsoft for the cloud streaming rights to Activision Blizzard’s games through a one-off payment and through a market-based wholesale pricing mechanism, including an option that supports pricing based on usage. It will also give Ubisoft the opportunity to offer Activision Blizzard’s games to cloud gaming services running non-Windows operating systems.\nOf importance, Microsoft’s obligations to provide cloud streaming rights in the European Economic Area remain in place, in full compliance with Microsoft’s commitments to the European Commission. The agreement with Ubisoft has been structured so that Microsoft will still acquire the rights needed to honor fully its legal obligations under its commitments to the European Commission, as well as its existing contractual obligations to other cloud game streaming providers, including Nvidia, Boosteroid, Ubitus, and Nware. Microsoft is engaging closely with the European Commission to support the EC’s assessment of the agreement and confirmation that the commitments remain undisturbed.\nSince our initial announcement with Activision Blizzard in January last year, we have endeavored to earn regulatory approval for the transaction, addressing concerns when raised, including by entering into binding legal commitments to bring Call of Duty to rival consoles and Activision Blizzard games to rival cloud streaming platforms. As a result, the transaction is now in a position to move forward in more than 40 countries.\nWe believe that this development is positive for players, the progression of the cloud game streaming market, and for the growth of our industry. And, as we continue to navigate the review process with the CMA, we remain as committed as ever to bringing the incredible benefits of the acquisition to players, developers, and the industry. Today’s development brings us one step closer to bringing the joy of gaming to players everywhere.\nTags: Activision Blizzard, cloud gaming, Xbox Live",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "Microsoft announces new Copilot Copyright Commitment for customers - Microsoft On the Issues",
    "link": "https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVpkRkU1WTJkcU1FMHpjR3hMVFJDM0FSaVRBaWdCTWdhbElwZ3duUWs=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-07T07:00:00.000Z",
    "time": "Sep 7, 2023",
    "articleType": "regular",
    "content": "|\t\t\t\t\tBrad Smith, Vice Chair and President, Hossein Nowbar, CVP and Chief Legal Officer\nannounced the expansion of the Copilot Copyright Commitment, now called the Customer Copyright Commitment, include commercial customers using the Azure OpenAI Service. By extending the  cover the outputs from the Azure OpenAI Service, Microsoft is broadening our commitment to defend these customers and pay for any adverse judgments if they are sued for copyright infringement for the use of the Azure OpenAI Service outputs.  This expansion of our copyright commitment is intended to further address customer concerns relating to potential IP infringement liability that could result from the use of the output of Microsoft’s Copilots and Azure OpenAI Service.  required  .  For our Azure OpenAI Service, we offer documentation and tooling that support the responsible use of AI and reduce risks of infringing copyrighted content.\nMicrosoft’s AI-powered Copilots are changing the way we work, making customers more efficient while unlocking new levels of creativity. While these transformative tools open doors to new possibilities, they are also raising new questions. Some customers are concerned about the risk of IP infringement claims if they use the output produced by generative AI. This is understandable, given recent public inquiries by authors and artists regarding how their own work is being used in conjunction with AI models and services.\nTo address this customer concern, Microsoft is announcing our new Copilot Copyright Commitment. As customers ask whether they can use Microsoft’s Copilot services and the output they generate without worrying about copyright claims, we are providing a straightforward answer: yes, you can, and if you are challenged on copyright grounds, we will assume responsibility for the potential legal risks involved.\nThis new commitment extends our existing intellectual property indemnity support to commercial Copilot services and builds on our previous AI Customer Commitments. Specifically, if a third party sues a commercial customer for copyright infringement for using Microsoft’s Copilots or the output they generate, we will defend the customer and pay the amount of any adverse judgments or settlements that result from the lawsuit, as long as the customer used the guardrails and content filters we have built into our products.\nYou’ll find more details below. Let me start with why we are offering this program:\nWe believe in standing behind our customers when they use our products. We are charging our commercial customers for our Copilots, and if their use creates legal issues, we should make this our problem rather than our customers’ problem. This philosophy is not new: For roughly two decades we’ve defended our customers against patent claims relating to our products, and we’ve steadily expanded this coverage over time. Expanding our defense obligations to cover copyright claims directed at our Copilots is another step along these lines.\nWe are sensitive to the concerns of authors, and we believe that Microsoft rather than our customers should assume the responsibility to address them. Even where existing copyright law is clear, generative AI is raising new public policy issues and shining a light on multiple public goals. We believe the world needs AI to advance the spread of knowledge and help solve major societal challenges. Yet it is critical for authors to retain control of their rights under copyright law and earn a healthy return on their creations. And we should ensure that the content needed to train and ground AI models is not locked up in the hands of one or a few companies in ways that would stifle competition and innovation. We are committed to the hard and sustained efforts that will be needed to take creative and constructive steps to advance all these goals.\nWe have built important guardrails into our Copilots to help respect authors’ copyrights. We have incorporated filters and other technologies that are designed to reduce the likelihood that Copilots return infringing content. These build on and complement our work to protect digital safety, security, and privacy, based on a broad range of guardrails such as classifiers, metaprompts, content filtering, and operational monitoring and abuse detection, including that which potentially infringes third-party content. Our new Copilot Copyright Commitment requires that customers use these technologies, creating incentives for everyone to better respect copyright concerns.\nMore details on our Copilot Copyright Commitment\nThe Copilot Copyright Commitment extends Microsoft’s existing IP indemnification coverage to copyright claims relating to the use of our AI-powered Copilots, including the output they generate, specifically for paid versions of Microsoft commercial Copilot services and Bing Chat Enterprise. This includes Microsoft 365 Copilot that brings generative AI to Word, Excel, PowerPoint, and more – enabling a user to reason across their data or turn a document into a presentation. It also includes GitHub Copilot, which enables developers to spend less time on rote coding, and more time on creating wholly new and transformative outputs.There are important conditions to this program, recognizing that there are potential ways that our technology could intentionally be misused to generate harmful content. To protect against this, customers must use the content filters and other safety systems built into the product and must not attempt to generate infringing materials, including not providing input to a Copilot service that the customer does not have appropriate rights to use.\nThis new benefit doesn’t change Microsoft’s position that it does not claim any intellectual property rights in the outputs of its Copilot services.\nWe have published more details of the Copilot Copyright Commitment for customers and welcome the opportunity to have further conversations as Copilots become more widely available.\nToday’s announcement is a first step. Like all new technologies, AI raises legal questions that our industry will need to work through with a wide array of stakeholders. This step represents a pledge to our customers that the copyright liability of our products is ours to shoulder, not theirs.\nMicrosoft is bullish on the benefits of AI, but, as with any powerful technology, we’re clear-eyed about the challenges and risks associated with it, including protecting creative works. It is our responsibility to help manage these risks by listening to and working with others in the tech sector, authors and artists and their representatives, government officials, the academic community, and civil society. We look forward to building on such announcements with new initiatives that help ensure that AI advances the spread of knowledge while protecting the rights and needs of creators.\nTags: AI, artificial intelligence, copilot copyright commitment",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "Delivering Copilot for everyone",
    "link": "https://blogs.microsoft.com/blog/2024/02/07/delivering-copilot-for-everyone/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNHdURWx4VEdFeFdDMU9aWFZJVFJDM0FSaVRBaWdCTWdhZGM1UnNOUWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-02-07T08:00:00.000Z",
    "time": "Feb 7",
    "articleType": "regular",
    "content": "As we approach Super Bowl weekend, we’re thrilled to be a part of the festivities for the first time in four years. This year, we’re proud to celebrate the transformative power of AI and Microsoft Copilot, showcasing peoples’ “watch me” moments with Copilot enabling people to do things previously unattainable. With a simple sentence or two, you will see a budding entrepreneur turn a fledgling idea for a new product into an actionable business plan, a filmmaker’s concept into a rich set of storyboards, and a fantasy football player’s team come to life with a mascot image they can edit inline.\nCoincident with the launch of our Super Bowl ad, we are also launching a significant new update to our Microsoft Copilot experience on copilot.microsoft.com and our Copilot app on iOS and Android app stores.  Today when you visit Copilot, you will see a more streamlined look and feel designed to help you bring your ideas to life and more easily gain understanding about the world. We have introduced a cleaner, sleeker look and feel for answers and a fun new carousel of suggested prompts to showcase the power of Copilot.\nToday marks exactly one year since our entry into AI-powered experiences for people with Bing Chat. In that year we have learned so many new things and seen the use of our Copilot experiences explode with over 5 billion chats and 5 billion images created to date which have led to sustained growth in Edge and Bing share. Now with Copilot as our singular experience for people looking to get more out of AI creation, we are today introducing further image creation capabilities.\nWith Designer in Copilot, you can go beyond just creating images to now customize your generated images with inline editing right inside Copilot1, keeping you in the flow of your chat. Whether you want to highlight an object to make it pop with enhanced color, blur the background of your image to make your subject shine, or even reimagine your image with a different effect like pixel art,2 Copilot has you covered, all for free.  If you’re a Copilot Pro subscriber, in addition to the above, you can also now easily resize and regenerate images between square and landscape without leaving chat. Lastly, we will soon roll out our new Designer GPT inside Copilot, which offers an immersive, dedicated canvas inside of Copilot where you can visualize your ideas.\nCopilot is free to use and works on Microsoft Edge, Chrome, Firefox and Safari. Or download the Copilot mobile app on iOS or Android.\nAI is the defining technology of our time. Microsoft’s advancements in AI align with our company mission to empower every person and organization on the planet to achieve more. With Copilot, we’re democratizing our breakthroughs in AI to help make the promise of AI real for everyone.\n1Available in English in the United States, United Kingdom, Australia, India and New Zealand.\n215 daily boosts included in Copilot, 100 daily boosts with a Copilot Pro subscription to be used for creative needs, faster image generation, and more detailed images.\nTags: AI, Copilot Pro, Microsoft Copilot, Microsoft Designer",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Discoveries in weeks, not years: How AI and high-performance computing are speeding up scientific discovery",
    "link": "https://news.microsoft.com/source/features/ai/how-ai-and-hpc-are-speeding-up-scientific-discovery/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWtRVlEwZW5JNVNHRmZiRnBrVFJDM0FSaVRBaWdCTWdZQlE1SXhvUWc=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-01-09T08:00:00.000Z",
    "time": "Jan 9",
    "articleType": "regular",
    "content": "Computing has already accelerated scientific discovery. Now scientists say a combination of advanced AI with next-generation cloud computing is turbocharging the pace of discovery to speeds unimaginable just a few years ago.\nMicrosoft and the Pacific Northwest National Laboratory (PNNL) in Richland, Washington, are collaborating to demonstrate how this acceleration can benefit chemistry and materials science – two scientific fields pivotal to finding energy solutions that the world needs.\nScientists at PNNL are testing a new battery material that was found in a matter of weeks, not years, as part of the collaboration with Microsoft to use to advanced AI and high-performance computing (HPC), a type of cloud-based computing that combines large numbers of computers to solve complex scientific and mathematical tasks.\nPNNL materials scientist Shannon Lee mixes raw materials to synthesize a new solid electrolyte, one of the promising candidates predicted using AI and HPC tools in the Azure Quantum Elements service. Photo by Dan DeLong for Microsoft.\nAs part of this effort, the Microsoft Quantum team used AI to identify around 500,000 stable materials in the space of a few days.\nThe new battery material came out of a collaboration using Microsoft’s Azure Quantum Elements to winnow 32 million potential inorganic materials to 18 promising candidates that could be used in battery development in just 80 hours. Most importantly, this work breaks ground for a new way of speeding up solutions for urgent sustainability, pharmaceutical and other challenges while giving a glimpse of the advances that will become possible with quantum computing.\n“We think there’s an opportunity to do this across a number of scientific fields,” says Brian Abrahamson, the chief digital officer at PNNL. “Recent technology advancements have opened up the opportunity to accelerate scientific discovery.”\nPNNL is a U.S. Department of Energy laboratory doing research in several areas, including chemistry and materials science, and its objectives include energy security and sustainability. That made it the ideal collaborator with Microsoft to leverage advanced AI models to discover new battery material candidates.\n“The development of novel batteries is an incredibly important global challenge,” Abrahamson says. “It has been a labor-intensive process. Synthesizing and testing materials at a human scale is fundamentally limiting.”\nLearning through trial and error\nThe traditional first step of materials synthesis is to read all the published studies of other materials and hypothesize how different approaches might work out. “But one of the main challenges is that people publish their success stories, not their failure stories,” says Vijay Murugesan, materials sciences group lead at PNNL. That means scientists rarely benefit from learning from each other’s failures.\nThe next traditional scientific step is testing the hypotheses, typically a long, iterative process. “If it’s a failure, we go back to the drawing board again,” Murugesan says. One of his previous projects at PNNL, a vanadium redox flow battery technology, required several years to solve a problem and design a new material.\nVijay Murugesan, material sciences group lead at PNNL, says the Microsoft AI and HPC tools allow scientists to eliminate the time-consuming trial-and-error discovery steps and focus on the best candidates for testing. Photo by Andrea Starr for PNNL.\nThe traditional method requires looking at how to improve on what has been done in the past. Another approach would be to take all the possibilities and, through elimination, find something new. Designing new materials requires a lot of calculations, and chemistry is likely to be among the first applications of quantum computing. Azure Quantum Elements offers a cloud computing system designed for chemistry and materials science research with an eye toward eventual quantum computing, and is already working on these kinds of models, tools and workflows. These models will be improved for future quantum computers, but they are already proving useful for advancing scientific discovery using traditional computers.\nTo evaluate its progress in the real world, the Microsoft Quantum team focused on something ubiquitous in our lives – materials for batteries.\nTeaching materials science to AI\nMicrosoft first trained different AI systems to do sophisticated evaluations of all the workable elements and to suggest combinations. The algorithm proposed 32 million candidates – like finding a needle in a haystack. Next, the AI system found all the materials that were stable. Another AI tool filtered out candidate molecules based on their reactivity, and another based on their potential to conduct energy.\nThe idea isn’t to find every single possible needle in the hypothetical haystack, but to find most of the good ones. Microsoft’s AI technology whittled the 32 million candidates down to about 500,000 mostly new stable materials, then down to 800.\n“At every step of the simulation where I had to run a quantum chemistry calculation, instead I’m calling the machine learning model. So I still get the insight and the detailed observations that come from running the simulation, but the simulation can be up to half a million times faster,” says Nathan Baker, Product Leader for Azure Quantum Elements.\nAI may be fast, but it isn’t perfectly accurate. The next set of filters used HPC, which provides high accuracy but uses a lot of computing power. That makes it a good tool for a smaller set of candidate materials. The first HPC verification used density functional theory to calculate the energy of each material relative to all the other states it could be in. Then came molecular dynamics simulations that combined AI and HPC to analyze the movements of atoms and molecules inside each material.\nThis process culled the list to 150 candidates. Finally, Microsoft scientists used HPC to evaluate the practicality of each material – availability, cost and such – to trim the list to 23 – five of which were already known.\nThanks to this AI-HPC combination, discovering the most promising material candidates took just 80 hours.\nThe HPC portion accounted for 10 percent of the time spent computing – and that was on an already-targeted set of molecules. This intense computing is the bottleneck, even at universities and research institutions that have supercomputers, which not only are not tailored to a specific domain but also are shared, so researchers may have to wait their turn. Microsoft’s cloud-based AI tools relieve this situation.\nMicrosoft scientists used AI to do the vast majority of the winnowing, accounting for about 90 percent of the computational time spent. PNNL materials scientists then vetted the short list down to half a dozen candidate materials. Because Microsoft’s AI tools are trained for chemistry, not just battery systems, they can be used for any kind of materials research, and the cloud is always accessible.\n“We think the cloud is a tremendous resource in improving the accessibility to research communities,” Abrahamson says.\nBrian Abrahamson, chief digital officer at PNNL. Photo by Andrea Starr for PNNL.\nToday, Microsoft supports a chemistry-specific copilot and AI tools that together act like a magnet that pulls possible needles out of the haystack, trimming the number of candidates for further exploration so scientists know where to focus. “The vision we are working toward is generative materials where I can ask for list of new battery compounds with my desired attributes,” Baker says.\nThe hands-on stage is where the project stands now. The material has been successfully synthesized and turned into prototype batteries that are functional and will undergo multiple tests in the lab. Making the material at this point, before it’s commercialized, is artisanal. One of the first steps is to take solid precursors of the materials and to grind them by hand with a mortar and pestle, explains Shannon Lee, a PNNL materials scientist. She then uses a hydraulic press to compact the material into a dime-shaped pellet. It goes into a vacuum tube and is heated to 450 to 650 degrees Celsius (842 to 1202 degrees Fahrenheit), transferred to a box to keep it away from oxygen or water, and then ground into a powder for analysis.\nFor this material, the 10-or-more-hour process is “relatively quick,” Lee says. “Sometimes it takes a week or two weeks to make a single material.”\nThen hundreds of working batteries must be tested, over thousands of different charging cycles and other conditions, and later different battery shapes and sizes to realize commercial use. Murugesan dreams of the development of a digital twin for chemistry or materials, “so you don’t need to go to a lab and put this material together and make a battery and test it. You can say, ‘this is my anode and this is my cathode and that’s the electrolyte and this is how much voltage I’m going to apply,’ and then it can predict how everything will work together. Even details like, after 10,000 cycles and five years of usage, the material performance will be like this.”\nMicrosoft is already working on digital tools to speed up the other parts of the scientific process.\nThe lengthy traditional process is illustrated by lithium-ion batteries. Lithium got attention as a battery component in the early 1900s, but rechargeable lithium-ion batteries didn’t hit the market until the 1990s.\nToday, lithium-ion batteries increasingly run our world, from phones to medical devices to electric vehicles to satellites. Lithium demand is expected to rise five to ten times by 2030, according to the U.S. Department of Energy. Lithium is already relatively scarce, and thus expensive. Mining it is environmentally and geopolitically problematic. Traditional lithium-ion batteries also pose safety issues, with the potential to catch fire or explode.\nMany researchers are looking for alternatives, both for lithium and for the materials used as electrolytes. Solid-state electrolytes show promise for their stability and safety.\nThe newly discovered material PNNL scientists are currently testing uses both lithium and sodium, as well as some other elements, thus reducing the lithium content considerably – possibly by as much as 70 percent. It is still early in the process – the exact chemistry is subject to optimization and might not work out when tested at larger scale, Abrahamson cautions. He points out that the story here is not about this particular battery material, but rather the speed at which a material was identified. The scientists say the exercise itself is immensely valuable, and it has revealed some surprises.\nThe AI-derived material is a solid-state electrolyte. Ions shuttle back and forth through the electrolyte, between the cathode and the anode, ideally with minimal resistance.\nIt was thought that sodium ions and lithium ions couldn’t be used together in a solid-state electrolyte system because they are similarly charged but have different sizes. It was assumed that the structural framework of a solid-state electrolyte material couldn’t support the movement of two different ions. But after testing, Murugesan says, “we found that the sodium and lithium ions seem to help each other.”\nThe new material has a bonus, Baker says, because its molecular structure naturally has built-in channels that help both ions move through the electrolyte.\nWork on the new material is in early stages but “irrespective of whether it’s a viable battery in the long run, the speed at which we found a workable battery chemistry is pretty compelling,” Abrahamson says.\nAdditional discoveries are still possible. Murugesan and his team have yet to make and test most of the other new material candidates that the Microsoft models suggested. The collaboration continues, with PNNL computational chemists learning to use the new tools, including a copilot trained on chemistry and other scientific publications.\n“With Microsoft and PNNL, this is an enduring collaboration to accelerate scientific discovery, bringing the power of these computational paradigm shifts to bear, with the chemistry and material science that are a hallmark strength of the Pacific Northwest National Laboratory,” Abrahamson says.\n“We’re sitting on the precipice of this maturation of the artificial intelligence models, the computational power needed to train and make them useful, and the ability to train them on specific scientific domains with specific intelligence,” he adds. “That, we believe, is going to usher in a new era of acceleration. That is exciting, because these problems matter to the world.”\nRead Unlocking a new era for scientific discovery with AI: How Microsoft’s AI screened over 32 million  candidates to find a better battery\nRead Azure Quantum Elements aims to compress 250 years of chemistry into the next 25\nRead:  PNNL-Microsoft Collaboration: Accelerating Scientific Discovery\nRead the PNNL press release: Energy Storage, Materials Discovery Kick-Off Three-Year Collaboration with Microsoft\nTop image: Dan Thien Nguyen, a PNNL materials scientist, assembles a coin cell with the synthesized solid electrolyte. With AI tools guiding researchers, synthesis and testing can be focused in the right direction toward better materials for particular applications. Photo by Dan DeLong for Microsoft.",
    "favicon": "https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2022/10/cropped-Microsoft_logo.svg_-300x300-1-128x120.png"
  },
  {
    "title": "Microsoft Digital Defense Report 2023 (MDDR)",
    "link": "https://www.microsoft.com/en-us/security/security-insider/microsoft-digital-defense-report-2023",
    "image": "https://news.google.com/api/attachments/CC8iMkNnNXFOMEZTVVRBeGJscFBOakpsVFJERkFSaUFBaWdCTWdzQkVJaWpuS1JTOXdoOGN3=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-10-05T13:21:19.000Z",
    "time": "Oct 5, 2023",
    "articleType": "regular",
    "content": "This protects against compromised user passwords and helps to provide extra resilience for identities.       The cornerstone of any resilience plan is to limit the impact of an attack on an organization: explicitly verify, use least privilege access, and always assume breach.       Implement software to detect and automatically block attacks and provide insights to the security operations software. Monitoring insights from threat detection systems is essential to being able to respond to threats in a timely fashion.       Unpatched and out-of-date systems are a key reason many organizations fall victim to an attack. Ensure all systems are kept up to date including firmware, the operating system, and applications.       Knowing your important data, where it is located, and whether the right defenses are implemented is crucial to implementing the appropriate protection.",
    "favicon": "/favicon.ico?v2"
  },
  {
    "title": "Announcing Copilot for Microsoft 365 general availability and Microsoft 365 Chat",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2023/09/21/announcing-microsoft-365-copilot-general-availability-and-microsoft-365-chat/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWZabWxST0VSMFVYbE5UMlp0VFJDb0FSaXNBaWdCTWdZZFZJNnRwUWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-21T07:00:00.000Z",
    "time": "Sep 21, 2023",
    "articleType": "regular",
    "content": "Today at an event in New York, we announced our vision for Microsoft Copilot—a digital companion for your whole life—that will create a single Copilot user experience across Bing, Edge, Microsoft 365, and Windows. As a first step toward realizing this vision, we’re unveiling a new visual identity—the Copilot icon—and creating a consistent user experience that will start to roll out across all our Copilots, first in Windows on September 26 and then in Copilot for Microsoft 365 when it is generally available for enterprise customers on November 1.\nTo summarize today’s announcements, here is the product line-up for commercial customers:\nMicrosoft Copilot in Windows will be available on September 26. It will empower you to create faster and complete tasks with ease and lessen your cognitive load—making once-complicated tasks simple. We’ve made accessing the power of Copilot seamless as it’s always right there for you on the taskbar or with the Win+C keyboard shortcut, providing assistance alongside all your apps. Copilot in Windows will feature the new Copilot icon, the new Copilot user experience, Bing Chat, and will be available to commercial customers for free.\nBing Chat Enterprise builds on Microsoft Copilot and adds commercial data protection—so you can be confident your business data is protected and will not leak outside the organization. With Bing Chat Enterprise, chat data is not saved, Microsoft has no eyes-on access, and your data is not used to train the large language models (LLM). Bing Chat Enterprise is available as a standalone for $5 per user per month and is included in Microsoft 365 E3 and Microsoft 365 E5.\nRead on for more details about today’s announcements in Copilot for Microsoft 365, Bing Chat Enterprise, and Copilot in Windows.\nCopilot for Microsoft 365—your AI assistant at work\nIn March, we showed you how Copilot can unlock productivity and unleash creativity in the apps that millions of people use every day—Word, Excel, PowerPoint, Outlook, and Teams. Today, we unveiled a new, hero experience in Copilot for Microsoft 365: Microsoft 365 Chat. You saw a glimpse of Microsoft 365 Chat in March, then called Business Chat, but rapid advancements over the last few months have taken it to a whole new level. It’s a powerful new capability in Copilot for Microsoft 365 that goes far beyond simple questions and answers to tame the complexity, eliminate the drudgery, and reclaim time at work. Like an assistant, it has a deep understanding of you, your job, your priorities, and your organization. It can find whatever you need in your files (even the files you forgot existed), connect the dots across all your content and context at the speed of light, and even integrate with the apps you use to run your business. Preview customers can access it today on Microsoft365.com or in Teams when signed in with their work account. In the future, you’ll be able to access it wherever you see the Copilot icon when signed in with your work account.\nUnlock productivity and unleash creativity in the apps millions of people use every day across work and life.\nOver the past few years, the pace and volume of work have only increased. On a given workday, our heaviest users search for what they need 18 times, receive over 250 Outlook emails, and send or read nearly 150 Teams chats.1 Teams users globally are in three times more meetings each week than they were in 2020.2 And on Windows, some people use 11 apps in a single day to get their work done. Microsoft 365 Chat will help everyone lift the weight of work.3\nLearn to work in a whole new way with Copilot Lab\nWe also announced Copilot Lab to help everyone learn to work iteratively with AI and get the most out of Copilot for Microsoft 365. Just as customers turned to Microsoft in the shift to remote and flexible work, they are relying on us to help people build new work habits for a new AI-powered era of productivity. And we want to help. With Copilot Lab, you can learn to turn a good prompt into a great one, share your favorite prompts with coworkers, and get inspired as we all learn how to work in a whole new way together. Once it’s generally available, Copilot Lab will be integrated into Copilot for Microsoft 365 and accessible via a website to all Copilot for Microsoft 365 users.\nUnlock productivity and unleash creativity with Copilot for Microsoft 365\nWe’re continuing to add new Copilot experiences in the Microsoft 365 apps. All updates will be generally available for commercial customers in November unless noted as “coming soon.”\nCopilot in Outlook helps you stay on top of your inbox and create impactful communication in a fraction of the time.  Now you can:\nAsk Copilot to summarize an email thread to get key information with annotations that help you quickly jump to the source of the summarized content, and suggested action items, replies, and follow-up meetings.\nChoose “Sound like me” to match your unique writing style and voice when you’re using Copilot to draft an email.\nFollow a Teams meeting that you could not attend live, directly from Outlook on your own time. When the meeting starts, Teams notifies participants to record it. When the recording is ready, Copilot notifies you in Outlook.\nCopilot in Word transforms every part of the writing process to make you more creative and efficient.Now you can:\nAsk Copilot for a summary of any document to share as a recap or quickly get up to speed, and Copilot will now deliver a more in-depth bulleted summation with all the information you need.\nAsk Copilot to “rewrite” a paragraph, then scroll through a series of options to see what fits best. You can then adjust the rewrite tone to make it more neutral, casual, or professional.\nRefine a prompt by asking Copilot to do things like “make answer more concise” or “add a column in the table for the project owner.”\nSave time on formatting by asking Copilot to generate a table from your copy.\nCopilot in Excel enables anyone to analyze and visualize data like a data analyst.  Now you can:\nWork with Copilot in Excel to help analyze, format, and edit your data to gain deeper understanding and insights.\nQuickly add a formula column, highlight key data with a prompt like “make all cells red where the value is under 1000,” filter and sort your data, and ask questions to instantly uncover key insights.\nUse Copilot to access advanced analytics; create powerful, professional visualizations, generate forecasts, and save time sorting through data with Python in Excel.\nCopilot in Loop unlocks the power of shared thinking, helping teams cocreate, stay up to date, and pick up where others left off.  Now you can:\nIterate with Copilot collaboratively as a team, cocreating prompts and reviewing earlier interactions to edit and improve on work together.\nAsk Copilot to generate a quick table on the page to help organize team projects. You can easily turn the table into a Loop component to share with teammates wherever they’re working—in Teams, Outlook, Microsoft Whiteboard, and Word on the web.\nQuickly catch up where your teammates left off by asking Copilot for a summary of a page or asking open-ended questions like “What key assignments were made since I was last on this page?”\nGenerate a recap for a teammate that you’re handing work off to, so they can get up to speed on any updates or changes.\nSave time writing code with Copilot-suggested Code blocks that pop up automatically using the context of your work.\nCopilot in OneNote helps you stay organized, prepared, and ready to take action.  Now you can:\nGain deeper insights on your notes by asking comprehensive questions like: “What are the pros and cons of this process?”\nQuickly generate summaries of your OneNote content.\nType just a few sentences and get a Copilot-generated paragraph, bulleted list, or organized section.\nMake your writing clearer and more effective with a quick Copilot edit.\nCopilot in Stream helps you find the insights and information you need from a video—in the Microsoft Stream web app or anywhere Stream videos work across Microsoft 365 apps—in seconds.  Now you can:\nGet a quick summary of the video with a transcript of the relevant spots you need to review.\nAsk Copilot open-ended questions—“What was the discussion outcome?” “How did the site walkthrough go?”—to quickly understand outcomes and key points.\nAsk Copilot to identify when people, teams, or topics are discussed, then jump right to that point in the video.\nAsk Copilot for suggested follow-ups or actions from a video you missed.\nCopilot in OneDrive helps you find all the insights and information you need—without ever opening a file. Now you can:\nAsk Copilot open-ended questions related to an individual file or get a summary of the content.\nBing Chat Enterprise—be confident using generative AI at work\nIn July, we introduced Bing Chat Enterprise. As organizations adopt AI, they want to be confident that their data is protected. Bing Chat Enterprise adds commercial data protection, ensuring that sensitive business data is never seen by anyone, that the queries are never stored, and user input is never used to train the foundation models.\nToday, we also announced that Bing Chat Enterprise is now available in the Microsoft Edge mobile app and we’re bringing support for multimodal visual search and Image Creator to Bing Chat Enterprise. Boost your creativity at work with the ability to find information using images and creating them while protecting sensitive enterprise data.\nBing Chat Enterprise is already part of Microsoft 365 E3 and E5, Business Standard, and Business Premium, which means more than 160 million people already have access.\nIn May, we announced that Copilot was coming to Windows 11. Copilot in Windows—in preview starting September 26—empowers you to create faster, complete tasks with ease, and lessens your cognitive load—making once complicated tasks, simple. We’ve made accessing the power of Copilot seamless as it’s always right there for you on the taskbar or with the Win+C keyboard shortcut providing assistance alongside all your apps, on all screen sizes at work, school, or at home.\nAnd we’re empowering IT admins with controls to decide when they deploy Copilot in Windows to their enterprise and who has access. To help bring Copilot to more people across more organizations, we are excited to announce that Windows 365 Boot and Windows 365 Switch will also be available in this update, making it easier than ever to get a full, secure, personalized Windows 365 Cloud PC with Copilot—on any device. Microsoft was recently recognized as a Leader in Gartner® Magic Quadrant™ for Desktop as a Service (DaaS).\nAs we bring Copilot to customers, we are guided by our AI principles, Responsible AI Standard, and decades of research on AI. And our Copilot Copyright Commitment means customers can be confident using our Copilot services and the output they generate without worrying about copyright claims.\n1 Data represents top 20 percent of users by volume of searches across M365 services, emails received, and sent and read chats in Teams, respectively\n2 Microsoft annual Work Trend Index 2023: Work Trend Index | Will AI Fix Work? (microsoft.com)\n3 Data reflects the top 20 percent Windows devices by app volume per day",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "What Can Copilot’s Earliest Users Teach Us About Generative AI at Work?",
    "link": "https://www.microsoft.com/en-us/worklab/work-trend-index/copilots-earliest-users-teach-us-about-generative-ai-at-work",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNTJORmxEU0RCVWRWSk5SemgwVFJDb0FSaXNBaWdCTWdrSlVZeElMZWc5Y0FF=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-11-15T08:00:00.000Z",
    "time": "Nov 15, 2023",
    "articleType": "regular",
    "content": "",
    "favicon": ""
  },
  {
    "title": "New ways to get creative with Microsoft Designer, powered by AI",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2024/07/17/new-ways-to-get-creative-with-microsoft-designer-powered-by-ai/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNUZOemREZG1KbFlXZzNTR2RMVFJDb0FSaXNBaWdCTWdhTmdwQkpOUWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-07-17T07:00:00.000Z",
    "time": "Jul 17",
    "articleType": "regular",
    "content": "Every creative process begins with an idea—and that idea starts with you. Today we’re announcing that the Microsoft Designer app is now generally available with a personal Microsoft account, with new features that help you create and edit like never before. You can express yourself in brand new ways and bring your most creative ideas to life in seconds—all with the help of AI. A blank canvas no longer has to be intimidating—just describe what you want to see, and Designer can create it for you. And if you’re not sure what that is, Designer can help you get started.\nThe true power of Designer is the ability to access it whenever and wherever it’s most helpful to you in your daily life to keep you in your creative flow. Designer now integrates seamlessly with Microsoft products including Word and PowerPoint through Microsoft Copilot1 and Microsoft Photos2 to keep you in your flow when inspiration strikes. Designer is now supported in more than 80 languages on the web, available as a free mobile app, and as an app in Windows.\nUnleash your creativity—create and edit anything you can imagine with AI.\nUse Designer across many Microsoft apps and on the go wherever inspiration strikes\nDesigner is now available through Copilot across some of your favorite Microsoft 365 apps on web and PC apps to help you uplevel your slides and documents.1 With a Copilot Pro subscription, when you’re in Word and PowerPoint you can create images and designs right in the heart of your workflow. From Word or PowerPoint, click on the Copilot icon and describe an image you’d like to create. In Word, coming soon, you can even ask to create a banner for your document and a design will be generated for you based on the content of your document.\nDesigner is now available as a free mobile app (iOS and Android). It’s packed with AI-powered features to unlock your creativity on the go—including creating images and designs with words and editing images to make them pop.\nWe’re also bringing Designer’s generative AI editing and creation capabilities to more Microsoft apps where you edit your photos, starting with Microsoft Photos available to Windows Insiders today.2 Without leaving Photos, you can edit your photos to erase objects, remove backgrounds, auto crop, make adjustments, apply filters, markup, or even add text without leaving your flow. For more details check out the Windows Insider blog. In the future, similar capabilities will be rolling out to Microsoft Edge for convenient use right from the browser.\nNew Designer app features offer innovative ways to create\nWhether you use Designer in the mobile app or on the web, the experience starts with a new homepage—redesigned based on feedback we gathered from you during preview—to help you jump right into whatever you want to create or edit. We’re also introducing new ways to create and help you get even more from Designer, available now:\nEveryone has come up against the dreaded blank page. New prompt templates help jumpstart the creative process. These templates are pre-populated with ideas, styles, and descriptions that you can experiment with and customize, helping you get the hang of how to prompt. We are now rolling out prompt templates across more features to help you create with AI. When you’re ready, you can even share templates with friends or fellow creators and build on each other’s ideas, sparking inspiration across your creative community.\nYou can share ideas, thoughts, or phrases, and Designer will create custom stickers that help you stand out on places like messaging apps and social. You can also create emojis, clip art, wallpapers, monograms, avatars, and more—all starting with a simple description.\nMake the perfect greeting card. From birthday cards to holiday cards and beyond, create custom cards with personalized messages—even when you’re at a loss for words—by describing what you want to convey. Similarly, create personalized invitations for birthdays, graduations, anniversaries, and more, simply by describing what you want to see.\nTransform any photo into a work of art with Restyle image. Upload an image, choose from a set of styles, and write in any extra details you want to see to get a brand-new image created just for you.\nCreate custom image frames to turn your photos into shareable memories. With Frame image, upload an image and write a description or choose from a set of styles to get a personalized frame. For multiple images, bring your memories together with collages by selecting your photos, choosing from a set of styles, and adding a description to customize even more.\nWe are always looking for ways to improve and empower your creativity, and will be adding more features over time. Soon, we will be rolling out Replace background in preview in select markets. We look forward to your feedback.\nEasily replace the background of your still life photos like a pro. Upload your photo, explain the vision for your background, and AI will create it for you. Perfect for showing off your craft and hobby projects in a new light.\nToday, Designer comes with 15 free daily boosts that you can use to create or edit AI-powered images and designs faster. Boosts are automatically used whenever you’re creating or editing images or designs both in the Designer app and where Designer is integrated across Microsoft apps. You can upgrade to a Copilot Pro subscription to receive 100 boosts per day.\nAt Microsoft, we are focused on building tools that harness the incredible potential of generative AI while providing a safe experience for our users. We are committed to ensuring that our systems are used in a responsible and ethical manner. We have implemented a responsible AI process and taken actions to mitigate negative outcomes and further prevent misuse, including guardrails, threat monitoring, and abuse detection, and provenance technology, and we are continuously working to strengthen our safety systems to help create a safer environment. Read more here: Making our generative AI products safer for consumers.\nGet started with Microsoft Designer today to unleash your creativity and start designing and editing anything you can imagine with AI. If you can describe it, you can design it.\n1A Copilot Pro subscription unlocks the use of Copilot in Microsoft 365 apps like Word and PowerPoint.  Those who have a separate Microsoft 365 Personal or Family subscription get the added benefit of using Copilot in the more fully featured PC apps. Creating banners with Copilot in Word will be available soon.\n2Designer’s editing experience in Microsoft Photos is currently limited to Windows Insiders with language set to English, Spanish, French, German, Italian, or Portuguese (Brazil), and available in most countries. To get the latest Photos experience, update your app to version number 2024.11070.12001.0 or higher.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Press Release & Webcast",
    "link": "https://www.microsoft.com/en-us/investor/earnings/fy-2024-q2/press-release-webcastR",
    "source": "Microsoft",
    "datetime": "2024-01-30T08:00:00.000Z",
    "time": "Jan 30",
    "articleType": "regular",
    "content": "",
    "favicon": "//www.microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Celebrating the first year of Copilot with significant new innovations",
    "link": "https://blogs.microsoft.com/blog/2023/12/05/celebrating-the-first-year-of-copilot-with-significant-new-innovations/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNDFjM0JqWDNvd1YyNVFWV0V4VFJDb0FSaXNBaWdCTWdZUmRKTE9NUWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-12-05T08:00:00.000Z",
    "time": "Dec 5, 2023",
    "articleType": "regular",
    "content": "This year will be remembered as the moment that we, as individuals, began to harness the power of AI in our daily lives. The last 10 months reflect years of AI research, close partnerships, and breakthrough innovations coming together. This culmination is now unifying our product vision to empower every person and every organization on the planet to achieve more.\nWe started with the introduction of Bing Chat, and the feedback was incredible! Right away, people began to change how they search on the Internet, shop, code, prepare for job interviews, improve their gaming skills, and create beautiful documents and images. We proceeded to incorporate these capabilities into Microsoft 365, Microsoft Edge and Windows, unlocking new scenarios with ever greater context and intelligence for people.\nTwo weeks ago, we took the significant step to bring together all of this under one brand and one experience that we call Microsoft Copilot, launching http://copilot.microsoft.com and making it accessible to anyone on any device.\nWe’re thrilled by the impact it is having on the industry and, more importantly, on the lives of hundreds of millions of people. Recent survey data shows that Copilot for Microsoft 365 makes people more productive and faster overall in tasks like searching and writing.\nAs we set our sights on 2024, we’re committed to bringing more innovation and advanced capabilities to Copilot to provide you with the leading way to benefit from AI.  Here are some incredible new features that we have begun testing that you will see roll out soon:\nGPT-4 Turbo – Soon, Copilot will be able to generate responses using OpenAI’s latest model, GPT-4 Turbo, enabling you to tackle more complex and longer tasks. This model is currently being tested with select users and will be widely integrated into Copilot in the coming weeks.\nNew DALL-E 3 Model – You can now use Copilot to create images that are even higher quality and more accurate to the prompt with an updated DALL-E 3 model. These capabilities are available to you now by visiting bing.com/create or by prompting Copilot to create an image.\nInline Compose with rewrite menu – With Copilot, Microsoft Edge users can easily write from most websites. Just select the text you want to change and ask Copilot to rewrite it for you. Coming to all Edge users soon.\nMulti-Modal with Search Grounding – We are combining the power of GPT-4 with vision with Bing image search and web search data to deliver better image understanding for your queries. This new capability will be available soon.\nCode Interpreter – We are developing a new capability that will enable you to perform complex tasks such as more accurate calculations, coding, data analysis, visualization, math and more. We are gathering feedback on these capabilities from a select set of users and plan to make it widely available soon.\nDeep Search – Coming soon to Bing, Deep Search harnesses the power of GPT-4 to deliver optimized search results for complex topics. Activating Deep Search expands search queries into more comprehensive descriptions to deliver more relevant results. More information can be found on our Bing Blog.\nTo share a sense of the breadth of what Copilot can do for you, we’ve created a list of some of our favorite use cases for you to try right now – inspired* by our community of fans and preview testers.\nTry one of the prompts below and follow your curiosity. Just copy and paste into Copilot at copilot.microsoft.com, in Copilot in Bing or directly from the Copilot tab in Windows 11.\nHow can I design and improve activity plans for elementary school students to experience and learn about different plants?\nWhat are the best methods and tools for stealth and hacking in Starfield?\nExplain how to choose a mattress based on firmness level and sleeping preferences. What are the different firmness levels and how do they affect comfort and support?\nPlan a 4-day itinerary for visiting Paris and Amsterdam. What are the must-see attractions, activities, and restaurants in each city?\nAnalyze Michelangelo’s legacy as an artist and a person. What are the achievements and influences on Michelangelo’s art and life and how did he shape society?\nExplain like I’m five the structure of city-states and the characteristics of civilizations throughout Mesopotamia.\nAre depictions of pirates in movies and novels accurate?\nHow can I make my living room look more open and refreshing? What are the tips and tricks for choosing and arranging furniture, colors, lighting, and accessories?\nIdentify and describe the flowers and plants that attract bees and how I can grow them in my garden. How do you pollinate a garden by hand?\nCreate an image I can use as inspiration for a tattoo. It should be minimalist in design and feature a sun, moon and golden retriever.\nHow can I get into the semiconductor industry and what are some related fields of study? What are the skills, qualifications, and experiences required?\nWhat advice do you have for hiking and sightseeing in Big Four Ice Caves?\nExplain the theory of parallel universes. What is the concept and evidence of parallel universes?\nRecommend some DAC (digital-to-analog converter) options for audiophiles. What are the features, benefits, and drawbacks of each option?\nWho were some of the most influential female musicians of the 1960s and how did they impact culture?\nSuggest some recipe ideas for a vegetarian dinner on a low-carb diet. What are the ingredients and recipes of each dish?\nCreate an upper body workout routine for beginners focused on chest and arms using body weight techniques at home. What are the exercises, sets, reps, and rest periods for each session?\nDesign an algorithm to find the majority book preference among a group of friends for a book club. What are the inputs and outputs of the algorithm?\nDiscuss how to work effectively with others in a professional work environment. What are the skills and qualities of a good team player?\nWhat are the best places to eat and drink in Renton, Washington? What are the specialties, prices, and ratings of each place?\nWhat are some tips for someone who has been out of the workforce for a few years but is looking to get back into it?\nCompare and contrast the MBA and MHA degrees for a nurse executive. What are the career opportunities and outcomes of each degree?\nPlan a 5-day summer trip to Hawaii that includes a visit to Diamond Head.\nWrite a congratulatory message for a small gift store’s fifth anniversary. Praise their service and atmosphere and express your gratitude and loyalty as a customer.\nWrite a story about a cat named Babbi who escapes outside and gets scared. How does Babbi escape and how does he return home?\nResearch and summarize the internet’s reviews about Meta’s Quest 3. What are the features, specs, and pros and cons of the headset?\nCreate an image I can put on a holiday card featuring 10 English bulldogs.\n*Prompts seen in this post showcase some of our favorite use cases of the consumer version of Copilot, formerly known as Bing Chat, since entering preview in February. All prompts seen below are inspired by popular conversation topics and were generated by Microsoft. No real user prompts are shown above.\nTags: AI, Copilot for Microsoft 365, Copilot in Bing, Microsoft Copilot",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Microsoft and NVIDIA announce major integrations to accelerate generative AI for enterprises everywhere - Stories",
    "link": "https://news.microsoft.com/2024/03/18/microsoft-and-nvidia-announce-major-integrations-to-accelerate-generative-ai-for-enterprises-everywhere/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNTRNRmR4UW5ZdFZtNXRVVTV6VFJDb0FSaXNBaWdCTWdhbFZJNk9KUVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-03-18T07:00:00.000Z",
    "time": "Mar 18",
    "articleType": "regular",
    "content": "Microsoft Azure to adopt NVIDIA Grace Blackwell Superchip to accelerate customer and first-party AI offerings\nNVIDIA DGX Cloud’s native Integration with Microsoft Fabric to streamline custom AI model development with customer’s own data\nNVIDIA Omniverse Cloud APIs first on Azure Power ecosystem of industrial design and simulation tools\nMicrosoft Copilot enhanced with NVIDIA AI and accelerated computing platforms\nNew NVIDIA generative AI Microservices for enterprise, developer and healthcare applications coming to Microsoft Azure AI\nREDMOND, Wash., and SAN JOSE, Calif. — March 18, 2024 — At GTC on Monday, Microsoft Corp. and NVIDIA expanded their longstanding collaboration with powerful new integrations that leverage the latest NVIDIA generative AI and Omniverse™ technologies across Microsoft Azure, Azure AI services, Microsoft Fabric and Microsoft 365.\n“Together with NVIDIA, we are making the promise of AI real, helping drive new benefits and productivity gains for people and organizations everywhere,” said Satya Nadella, chairman and CEO, Microsoft. “From bringing the GB200 Grace Blackwell processor to Azure, to new integrations between DGX Cloud and Microsoft Fabric, the announcements we are making today will ensure customers have the most comprehensive platforms and tools across every layer of the Copilot stack, from silicon to software, to build their own breakthrough AI capability.”\n“AI is transforming our daily lives — opening up a world of new opportunities,” said Jensen Huang, founder and CEO of NVIDIA. “Through our collaboration with Microsoft, we’re building a future that unlocks the promise of AI for customers, helping them deliver innovative solutions to the world.”\nMicrosoft will be one of the first organizations to bring the power of NVIDIA Grace Blackwell GB200 and advanced NVIDIA Quantum-X800 InfiniBand networking to Azure, deliver cutting-edge trillion-parameter foundation models for natural language processing, computer vision, speech recognition and more.\nMicrosoft is also announcing the general availability of its Azure NC H100 v5 VM virtual machine (VM) based on the NVIDIA H100 NVL platform. Designed for midrange training and inferencing, the NC series of virtual machines offers customers two classes of VMs from one to two NVIDIA H100 94GB PCIe Tensor Core GPUs and supports NVIDIA Multi-Instance GPU (MIG) technology, which allows customers to partition each GPU into up to seven instances, providing flexibility and scalability for diverse AI workloads.\nHealthcare and life sciences breakthroughs\nMicrosoft is expanding its collaboration with NVIDIA to transform healthcare and life sciences through the integration of cloud, AI and supercomputing technologies. By harnessing the power of Microsoft Azure alongside NVIDIA DGX™ Cloud and the NVIDIA Clara™ suite of microservices, healthcare providers, pharmaceutical and biotechnology companies, and medical device developers will soon be able to innovate rapidly across clinical research and care delivery with improved efficiency.\nIndustry leaders such as Sanofi and the Broad Institute of MIT and Harvard, industry ISVs such as Flywheel and SOPHiA GENETICS, academic medical centers like the University of Wisconsin School of Medicine and Public Health, and health systems like Mass General Brigham are already leveraging cloud computing and AI to drive transformative changes in healthcare and to enhance patient care.\nNVIDIA Omniverse Cloud APIs will be available first on Microsoft Azure later this year, enabling developers to bring increased data interoperability collaboration, and physics-based visualization to existing software applications. At NVIDIA GTC, Microsoft is demonstrating a preview of what is possible using Omniverse Cloud APIs on Microsoft Azure. Using an interactive 3D viewer in Microsoft Power BI, factory operators can see real-time factory data overlaid on a 3D digital twin of their facility to gain new insights that can speed up production.\nNVIDIA Triton Inference Server and Microsoft Copilot\nNVIDIA GPUs and NVIDIA Triton Inference Server™ help serve AI inference predictions in Microsoft Copilot for Microsoft 365. Copilot for Microsoft 365, soon available as a dedicated physical keyboard key on Windows 11 PCs, combines the power of large language models with proprietary enterprise data to deliver real-time contextualized intelligence, enabling users to enhance their creativity, productivity and skills.\nFrom AI training to AI deployment\nNVIDIA NIM™ inference microservices are coming to Azure AI to turbocharge AI deployments. Part of the NVIDIA AI Enterprise software platform, also available on the Azure Marketplace, NIM provides cloud-native microservices for optimized inference on more than two dozen popular foundation models, including NVIDIA-built models that users can experience at ai.nvidia.com. For deployment, the microservices deliver prebuilt, run-anywhere containers powered by NVIDIA AI Enterprise inference software — including Triton Inference Server, TensorRT™ and TensorRT-LLM — to help developers speed time to market of performance-optimized production AI applications.\nSince its founding in 1993, NVIDIA (NASDAQ: NVDA) has been a pioneer in accelerated computing. The company’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined computer graphics, ignited the era of modern AI and is fueling industrial digitalization across markets. NVIDIA is now a full-stack computing infrastructure company with data-center-scale offerings that are reshaping industry. More information at https://nvidianews.nvidia.com/.\nMicrosoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.\nMicrosoft Media Relations, WE Communications for Microsoft, (425) 638-7777, rapidresponse@we-worldwide.com\nNatalie Hereth, NVIDIA Corporation, nhereth@nvidia.com\nCertain statements in this press release including, but not limited to, statements as to: the benefits, impact, performance, features, and availability of NVIDIA’s products and technologies, including NVIDIA Grace Blackwell Superchip, NVIDIA DGX Cloud, NVIDIA Omniverse Cloud APIs, NVIDIA AI and Accelerated Computing Platforms, and NVIDIA Generative AI Microservices; the benefits and impact of NVIDIA’s collaboration with Microsoft, and the features and availability of its services and offerings; AI transforming our daily lives, the way we work and opening up a world of new opportunities; and building a future that unlocks the promise of AI for customers and brings transformative solutions to the world through NVIDIA’s continued collaboration with Microsoft are forward-looking statements that are subject to risks and uncertainties that could cause results to be materially different than expectations. Important factors that could cause actual results to differ materially include: global economic conditions; NVIDIA’s reliance on third parties to manufacture, assemble, package and test NVIDIA’s products; the impact of technological development and competition; development of new products and technologies or enhancements to NVIDIA’s existing product and technologies; market acceptance of NVIDIA’s products or NVIDIA partners’ products; design, manufacturing or software defects; changes in consumer preferences or demands; changes in industry standards and interfaces; unexpected loss of performance of NVIDIA’s products or technologies when integrated into systems; as well as other factors detailed from time to time in the most recent reports NVIDIA files with the Securities and Exchange Commission, or SEC, including, but not limited to, its annual report on Form 10-K and quarterly reports on Form 10-Q. Copies of reports filed with the SEC are posted on the company’s website and are available from NVIDIA without charge. These forward-looking statements are not guarantees of future performance and speak only as of the date hereof, and, except as required by law, NVIDIA disclaims any obligation to update these forward-looking statements to reflect future events or circumstances.\nMany of the products and features described herein remain in various stages and will be offered on a when-and-if-available basis. The statements above are not intended to be, and should not be interpreted as a commitment, promise, or legal obligation, and the development, release, and timing of any features or functionalities described for our products is subject to change and remains at the sole discretion of NVIDIA. NVIDIA will have no liability for failure to deliver or delay in the delivery of any of the products, features or functions set forth herein.\n© 2024 NVIDIA Corporation. All rights reserved. NVIDIA, the NVIDIA logo, DGX, NVIDIA Clara, NVIDIA NIM, NVIDIA Omniverse, NVIDIA Triton Inference Server, and TensorRT are trademarks and/or registered trademarks of NVIDIA Corporation in the U.S. and/or other countries. Other company and product names may be trademarks of the respective companies with which they are associated. Features, pricing, availability, and specifications are subject to change without notice.",
    "favicon": "https://news.microsoft.com/wp-content/uploads/prod/2017/03/cropped-microsoft_logo_element-150x150.png"
  },
  {
    "title": "Broadening AI innovation: Microsoft's pledge to the National AI Research Resource pilot - Microsoft On the Issues",
    "link": "https://blogs.microsoft.com/on-the-issues/2024/01/24/national-ai-research-resource-nairr-artificial-intelligence/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNVFSaTAxTUd0amJGRmpMVU5hVFJDb0FSaXNBaWdCTWdOOUFEdw=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-01-24T08:00:00.000Z",
    "time": "Jan 24",
    "articleType": "regular",
    "content": "We are delighted to announce our support for the National AI Research Resource (NAIRR) pilot, a vital initiative highlighted in the President’s Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. This initiative aligns with our commitment to broaden AI research and spur innovation by providing greater computing resources to AI researchers and engineers in academia and non-profit sectors. We look forward to contributing to the pilot and sharing insights that can help inform the envisioned full-scale NAIRR.\nThe NAIRR’s objective is to democratize access to the computational tools essential for advancing AI in critical areas such as safety, reliability, security, privacy, environmental challenges, infrastructure, health care, and education. Advocating for such a resource has been a longstanding goal of ours, one that promises to equalize the field of AI research and stimulate innovation across diverse sectors. As a commissioner on the National Security Commission on AI (NSCAI), I worked with colleagues on the committee to propose an early conception of the NAIRR, underlining our nation’s need for this resource as detailed in the NSCAI Final Report. Concurrently, we enthusiastically supported a university-led initiative pursuing a national computing resource. It’s rewarding to see these early ideas and endeavors now materialize into a tangible entity.\nOur backing of the NAIRR pilot builds on our enduring support for the academic research community with resources and model access for deep learning through initiatives like the Turing Academic Program (MS-TAP) and Accelerate Foundation Models Research (AFMR) program.\nAs part of our commitment to the NAIRR pilot, Microsoft will contribute:\n$20 million in Microsoft Azure compute credits\nAccess to leading-edge models, including those available via Azure OpenAI Service\nAdvanced resources for developing trustworthy AI, including tools for research in AI fairness, accuracy, reliability, transparency, privacy, security, and model orchestration\nResources to enable HIPAA-compliant computing in support of health care research\nInnovative tools for scientific discovery via Azure Quantum Elements\nCollaborative opportunities with Microsoft’s scientists and engineers\nAs we continue on this shared journey of AI innovation, it is crucial to equip the broader research community with the necessary resources to pioneer advancements at the frontiers of our understandings and capabilities. The NAIRR pilot represents a significant step in this direction, bolstering collaborative efforts and promoting a well-resourced, inclusive approach to AI innovation. This commitment is more than just an investment in technology; it’s an investment in our future, and a testament to the power of broad collaboration in unlocking the full potential of AI to benefit humanity.\nTags: AI, NAIRR, Responsible AI",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "Unlocking a new era for scientific discovery with AI: How Microsoft’s AI screened over 32 million candidates to find a better battery",
    "link": "https://azure.microsoft.com/en-us/blog/quantum/2024/01/09/unlocking-a-new-era-for-scientific-discovery-with-ai-how-microsofts-ai-screened-over-32-million-candidates-to-find-a-better-battery/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVlZelV0VlVSd1dua3pZbFJ6VFJDb0FSaXNBaWdCTWdZTlVZNjJLQWc=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-01-09T08:00:00.000Z",
    "time": "Jan 9",
    "articleType": "regular",
    "content": "AI is transforming every cognitive task we perform, from writing an email to developing software. Since the dawn of civilization, scientific discovery has been the ultimate cognitive task that has made us thrive and prosper as a species. For this reason, scientific discovery has probably the highest impact and is the most exciting use case for AI. We are announcing how the Microsoft Quantum team achieved a major milestone toward that vision, using advanced AI to screen over 32 million candidates to discover and synthesize a new material that holds the potential for better batteries—the first real-life example of many that will be achieved in a new era of scientific discovery driven by AI.\nWe believe that chemistry and materials science are the hero scenario for full-scale quantum computers. That led us to design and launch Azure Quantum Elements, a product built specifically to accelerate scientific discovery with the power of AI, cloud computing, and eventually, full-scale quantum computers. Our beliefs were confirmed by working with companies like Johnson Matthey, 1910 Genetics, AkzoNobel, and many others, which led to the launch of Azure Quantum Elements in June. Over the summer, we had already demonstrated a massive screening of materials candidates, but we knew that showing what might be possible is not the same thing as proving the technology could identify something new and novel that could be synthesized. We needed a real proof point and decided to start with something useful from everyday life to hyperscale data centers: battery technology.\nAs demonstrated in results published in August, we used novel AI models to digitally screen over 32 million potential materials and found over 500,000 stable candidates. However, identifying candidates is only the first step of scientific discovery. Finding a material among those candidates with the right properties for the task, in this case for a new solid-state battery electrolyte, is like finding a needle in a haystack. It would involve lengthy high-performance computing (HPC) calculations and costly lab experimentation that would take multiple lifespans to complete.\nToday we are sharing how AI is radically transforming this process, accelerating it from years to weeks to just days. Joining forces with the Department of Energy’s Pacific Northwest National Laboratory (PNNL), the Azure Quantum team applied advanced AI along with expertise from PNNL to identify a new material, unknown to us and not present in nature, with potential for resource-efficient batteries. Not only that, PNNL scientists synthesized and tested this material candidate from raw material to a working prototype, demonstrating its unique properties and its potential for a sustainable energy-storage solution, using significantly less lithium than other materials announced by industry.\nThis is important for many reasons. Solid-state batteries are assumed to be safer than traditional liquid or gel-like lithium batteries, and they provide more energy density. Lithium is already relatively scarce, and thus expensive. Mining it is environmentally and geopolitically problematic. Creating a battery that might reduce lithium requirements by approximately 70% could have tremendous environmental, safety, and economic benefits.\nThis collaboration is just the beginning of an exciting new journey bringing the power of AI to nearly every aspect of scientific research. More broadly, Microsoft is putting these breakthroughs into customers’ hands through our Azure Quantum Elements platform. It is the combination of scientific expertise and AI that will compress the next 250 years of chemistry and materials science innovation into the next 25, transforming every industry and ultimately unlocking a new era for scientific discovery.\nThe need for sustainable energy sources\nMany of the hardest problems facing society, like reversing climate change, addressing food insecurity, or solving energy crises, are related to chemistry and materials science. We’ve long believed that materials discovery is a key scenario for tackling some of these issues, but time is our greatest challenge—the number of possible stable materials that must be explored to find solutions is believed to surpass the number of atoms in the known universe. That’s why at Microsoft, we recently released Azure Quantum Elements. Our cloud platform brings together a new generation of AI, cloud-powered HPC, and eventually quantum computing breakthroughs to empower our partners with the right tools to drive innovation by accelerating their discovery pipeline and dramatically reducing the time to screen new candidates.\nPNNL advances the frontiers of knowledge, taking on some of the world’s greatest science and technology challenges. Distinctive strengths in chemistry, Earth sciences, biology, and data science are central to its scientific discovery mission. PNNL has established leadership in developing and validating next-generation energy storage technologies. Among the most recognizable forms of portable energy storage, lithium-ion batteries remain a cornerstone of modern portable energy storage because of their high energy-storage capacity and long lifespan.\n“Lithium and other strategic elements used in these batteries are finite resources with limited and geographically concentrated supplies. One of the main thrusts of our work at PNNL has been identifying new materials for increased energy storage needs of the future; ones made with sustainable materials that conserve and protect the Earth’s limited resources.”\n—Vijay Murugesan, Group Leader—Materials Science, PNNL.\nThrough this collaboration, Microsoft and PNNL harnessed AI and cloud-powered HPC to accelerate research aimed at creating new types of battery materials—such as those that use less lithium than traditional lithium-ion batteries, while maintaining significant conductivity. These new types of batteries could benefit both the environment and consumers. Within nine months, PNNL validated this proof-of-concept, demonstrating the potential of new HPC and AI approaches to significantly accelerate the innovation cycle—it would be impossible for researchers to synthesize and test the millions of materials that were evaluated by advanced AI models in less than a week.\nAccelerating computational materials discovery with AI\nTo achieve these results, our Azure Quantum team at Microsoft combined cloud-powered HPC calculations with new AI models that estimate characteristics of materials related to energy, force, stress, electronic band gap, and mechanical properties. These models have been trained on millions of data points from materials simulations and are thus able to minimize HPC calculations and predict materials properties 1,500 times faster than traditional density functional theory (DFT) calculations.\nWe began with 32.6 million candidate materials, created by substituting elements in known crystal structures with a sampling of elements across a subset of the periodic table. As a first application, we filtered this set of candidates using a workflow that combined our AI models of materials with conventional HPC-based simulations.\nThe first stage of screening—published in August—used AI models. From the initial pool of 32.6 million materials, we found 500,000 materials predicted to be stable. We used AI models to screen this pool of materials for functional properties like redox potential and band gap, further reducing the number of potential candidates to about 800. The second screening stage combined physics simulations with the AI models. Microsoft Azure HPC was used for DFT calculations to confirm the properties from AI screening. AI models have a non-zero prediction error, so the DFT validation step is used to re-compute the properties that the AI models predicted as a higher-accuracy filter. This step was followed by molecular dynamics (MD) simulations to model structural changes.\nThen, our Microsoft Quantum researchers used AI-accelerated MD simulations to investigate dynamic properties like ionic diffusivity. These simulations used AI models for forces at each MD step, rather than the slower DFT-based method. This stage reduced the number of candidates to 150. Then, practical features such as novelty, mechanics, and element availability were taken into consideration to create the set of 18 top candidates.\nFrom the 32.6 million materials, AI inference predicted an initial 500,000 stable material candidates. Traditional physics-based HPC simulations further winnowed the pool of candidates. The electrolyte was identified after applying a final set of AI property-prediction filters developed with the PNNL team based on expert criteria.\nFrom there, PNNL’s expertise provided insights into additional screening parameters that further narrowed the final structural candidates. The researchers at PNNL then synthesized the top candidate, characterized its structure, and measured its conductivity. The new electrolyte candidate uses approximately 70% less lithium compared to existing lithium-ion batteries, by replacing some lithium with sodium, an abundant compound.\nIn tests across a range of temperatures, the new compound displayed viable ionic conductivity, indicating its potential as a solid-state electrolyte material. After verifying the conductivity of the sodium-lithium chemical composition, the PNNL research team demonstrated the electrolyte’s technical viability by building a working all-solid-state battery, which was tested at both room temperature and high temperature (~80 °C).\nThis is the structure of the newly discovered material. As observed in molecular simulations, transporting lithium inside a solid material involves optimal channels that serve as a highway, with other ions attracting and propelling lithium for ionic conductivity.\nThe discovery of this new type of electrolyte material is notable not only for its potential as a sustainable energy-storage solution, but also because it demonstrates that researchers can dramatically accelerate time to results with advanced AI models. While further validation and optimization of the material is ongoing, this initial end-to-end process took less than nine months and is the first step in a promising collaboration between Microsoft and PNNL. The discovery of other materials that could increase the sustainability of energy storage is likely on the horizon.\n“We bring our scientific expertise to bear on picking the most promising material candidates to move forward with. In this case, we had the AI insights that pointed us to potentially fruitful territory so much faster. After Microsoft’s team discovered 500,000 stable materials with AI that could be used across a variety of transformative applications, we were able to modify, test, and tune the chemical composition of this new material and quickly evaluate its technical viability for a working battery, showing the promise of advanced AI to accelerate the innovation cycle.”\n—Karl Mueller, Program Development Office Director, PNNL.\nRaw material is ground down to the final material and compacted by a press into a pellet. The pellet is combined with an anode (-) and cathode (+), which allow the prototype to be charged and to provide power. Additional testing will determine the form factors the new battery material may be useful for.\nLooking ahead toward a quantum future\nThis achievement is indicative of the coming paradigm shift in how organizations across a wide range of industries approach research and development—organizations can now use computational breakthroughs to accelerate scientific discovery due to the convergence of HPC and AI. While this combination will provide scale and speed for performing quantum chemistry calculations, classical computing cannot solve certain problems without sacrificing accuracy, such as those involving many highly correlated electrons. Quantum supercomputing will help increase accuracy, and Azure Quantum Elements will integrate Microsoft’s scaled quantum supercomputer when available.\nAzure Quantum Elements includes quantum-ready tools to prepare for the fast-approaching quantum future. For example, scientists can use it to identify the active space of molecular systems and estimate the quantum computing resources needed for large active-space systems. These tools will enable the development and optimization of hybrid algorithms—those that combine classical and scaled quantum computing—so that researchers are prepared for a quantum future.\nThe discovery of 500,000 stable materials with AI, leading to the identification and synthesis of a new material, is just one of the many possibilities for how Azure Quantum Elements will create unprecedented opportunities. Almost all manufactured goods would benefit from innovations in the fields of chemistry and materials science, and our goal is to enable discoveries across all industries by empowering research and development (R&D) teams with a platform that every scientist can use.\nJoin us in exploring the potential of Azure Quantum Elements to revolutionize chemistry and materials development:\nVisit the Azure Quantum Elements website.\nCheck out the Microsoft Quantum Innovator Series webinars.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Bringing Copilot to more customers worldwide—across life and work",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2024/03/14/bringing-copilot-to-more-customers-worldwide-across-life-and-work/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNU5VVjl1ZW1SdE0yVjJlREJwVFJDb0FSaXJBaWdCTWdZbE5JNnRtUWs=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-03-14T07:00:00.000Z",
    "time": "Mar 14",
    "articleType": "regular",
    "content": "Copilot is your everyday AI companion, meant to bring the power of generative AI to everyone across work and life. We’re expanding availability and purchase options for individuals and organizations and bringing new value to Copilot Pro subscribers.\nSince launching Copilot, it’s been exciting to see our customers bring AI into their lives—both personal and professional—creating stunning images, tackling their overflowing inboxes, jump-starting the writing process, catching up on missed meetings, and so much more. With Copilot, we’re committed to giving everyone the opportunity to supercharge their creativity and productivity. Available across devices, through web or through our Copilot mobile app on iOS or Android, it’s never been easier to get started with Microsoft Copilot.\nThe expansion of Copilot Pro offerings for individuals\nWe’re making Copilot in the free Microsoft 365 web apps part of your Copilot Pro subscription—no additional Microsoft 365 subscription required. While a Microsoft 365 Personal or Family subscription is still required to unlock Copilot in the desktop apps for PC and Mac, we’re excited to bring Copilot to Word, Outlook, and more free web apps to additional Pro subscribers.1 We’ll extend this benefit to our free mobile apps as well, including the Microsoft 365 app and Outlook for iOS and Android, in the coming months.\nIn January, we launched a curated set of Copilot GPTs that can be your personal trainer, travel agent, and sous chef. And now, the ability to build and share custom Copilot GPTs with Microsoft Copilot GPT Builder is available to all Copilot Pro subscribers. Copilot GPT Builder lets you create a personalized Copilot meant to assist you with specific tasks, based on your interests. You can make a Copilot GPT that acts as your career counselor, or a study buddy that helps you to learn a new skill—the possibilities are limitless, and you can do all this from within Copilot.\nAs part of our mission to empower every person on the planet to achieve more, we are making Copilot Pro available more broadly. Copilot Pro is now available in all 222 countries/regions where Copilot is available. We want all power users, creators, and anyone else to take their Copilot experience to the next level.\nWith a Copilot Pro subscription, individuals gain the most advanced features and capabilities of Microsoft Copilot to supercharge their Copilot experience. This includes priority access to top-of-the-line models, AI capabilities in Microsoft 365 apps (a Microsoft 365 Personal or Family subscription is required to access Copilot in desktop apps), better image generation and editing capabilities, and access to Microsoft Copilot GPT Builder.\nCopilot for Microsoft 365: Available to organizations of all sizes\nWhile Copilot Pro is our best experience for individuals, Copilot for Microsoft 365 is our best experience for organizations. To empower every organization to become AI-powered, we’re making Copilot for Microsoft 365 available to businesses of all types and sizes—including frontline worker plans. Customers that have Microsoft 365 F3 and F1, Office 365 E1, Business Basic, and more will be eligible to purchase Copilot for Microsoft 365 in the coming weeks.2 That’s in addition to previously announced availability on Microsoft 365 E3 and E5, Office 365 E3 and E5, Business Standard, and Business Premium plans.\n1Copilot Pro subscribers can use Copilot in the web versions of Word, Excel, PowerPoint, OneNote, and Outlook in the following languages: English, French, German, Italian, Japanese, Portuguese, Spanish, and Chinese Simplified. Those who have a separate Microsoft 365 Personal or Family subscription get the added benefit of using Copilot in the more fully featured desktop apps. Excel features are in English only and currently in preview. Copilot features in Outlook apply to accounts with @outlook.com, @hotmail.com, @live.com or @msn.com email addresses and are available in Outlook.com, Outlook built into Windows, and Outlook on Mac.\n2Additional details and a complete list of eligible SKUs will be available on learn.microsoft.com.\n3Microsoft Fiscal Year 2024 First Quarter Earnings Conference Call, Satya Nadella, Chairman and CEO and Amy Hood, EVP & CFO. October 24, 2023.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Midnight Blizzard conducts targeted social engineering over Microsoft Teams",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/08/02/midnight-blizzard-conducts-targeted-social-engineering-over-microsoft-teams/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNUtaWHB5YjJKdFJWOVFUMHRQVFJDM0FSaVRBaWdCTWdhZFVZcktKUWc=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-08-02T07:00:00.000Z",
    "time": "Aug 2, 2023",
    "articleType": "regular",
    "content": "Microsoft Threat Intelligence has identified highly targeted social engineering attacks using credential theft phishing lures sent as Microsoft Teams chats by the threat actor that Microsoft tracks as Midnight Blizzard (previously tracked as NOBELIUM). This latest attack, combined with past activity, further demonstrates Midnight Blizzard’s ongoing execution of their objectives using both new and common techniques. In this latest activity, the threat actor uses previously compromised Microsoft 365 tenants owned by small businesses to create new domains that appear as technical support entities. Using these domains from compromised tenants, Midnight Blizzard leverages Teams messages to send lures that attempt to steal credentials from a targeted organization by engaging a user and eliciting approval of multifactor authentication (MFA) prompts. As with any social engineering lures, we encourage organizations to reinforce security best practices to all users and reinforce that any authentication requests not initiated by the user should be treated as malicious.\nOur current investigation indicates this campaign has affected fewer than 40 unique global organizations. The organizations targeted in this activity likely indicate specific espionage objectives by Midnight Blizzard directed at government, non-government organizations (NGOs), IT services, technology, discrete manufacturing, and media sectors. Microsoft has mitigated the actor from using the domains and continues to investigate this activity and work to remediate the impact of the attack. As with any observed nation-state actor activity, Microsoft has directly notified targeted or compromised customers, providing them with important information needed to secure their environments.\nMidnight Blizzard (NOBELIUM) is a Russia-based threat actor attributed by the US and UK governments as the Foreign Intelligence Service of the Russian Federation, also known as the SVR. This threat actor is known to primarily target governments, diplomatic entities, non-government organizations (NGOs), and IT service providers primarily in the US and Europe. Their focus is to collect intelligence through longstanding and dedicated espionage of foreign interests that can be traced to early 2018. Their operations often involve compromise of valid accounts and, in some highly targeted cases, advanced techniques to compromise authentication mechanisms within an organization to expand access and evade detection.\nMidnight Blizzard is consistent and persistent in their operational targeting, and their objectives rarely change. They utilize diverse initial access methods ranging from stolen credentials to supply chain attacks, exploitation of on-premises environments to laterally move to the cloud, exploitation of service providers’ trust chain to gain access to downstream customers, as well as the Active Directory Federation Service (AD FS) malware known as FOGGYWEB and MAGICWEB. Midnight Blizzard (NOBELIUM) is tracked by partner security vendors as APT29, UNC2452, and Cozy Bear.\nMidnight Blizzard’s latest credential phishing attack\nMidnight Blizzard regularly utilizes token theft techniques for initial access into targeted environments, in addition to authentication spear-phishing, password spray, brute force, and other credential attacks. The attack pattern observed in malicious activity since at least late May 2023 has been identified as a subset of broader credential attack campaigns that we attribute to Midnight Blizzard.\nUse of security-themed domain names in lures\nTo facilitate their attack, the actor uses Microsoft 365 tenants owned by small businesses they have compromised in previous attacks to host and launch their social engineering attack. The actor renames the compromised tenant, adds a new onmicrosoft.com subdomain, then adds a new user associated with that domain from which to send the outbound message to the target tenant. The actor uses security-themed or product name-themed keywords to create a new subdomain and new tenant name to lend legitimacy to the messages. These precursory attacks to compromise legitimate Azure tenants and the use of homoglyph domain names in social engineering lures are part of our ongoing investigation. Microsoft has mitigated the actor from using the domains.\nIn this activity, Midnight Blizzard either has obtained valid account credentials for the users they are targeting, or they are targeting users with passwordless authentication configured on their account – both of which require the user to enter a code that is displayed during the authentication flow into the prompt on the Microsoft Authenticator app on their mobile device.\nAfter attempting to authenticate to an account where this form of MFA is required, the actor is presented with a code that the user would need to enter in their authenticator app. The user receives the prompt for code entry on their device. The actor then sends a message to the targeted user over Microsoft Teams eliciting the user to enter the code into the prompt on their device.\nStep 1: Teams request to chat\nThe target user may receive a Microsoft Teams message request from an external user masquerading as a technical support or security team.\nFigure 1: Screenshot of a Microsoft Teams message request from a Midnight Blizzard-controlled account\nStep 2: Request authentication app action\nIf the target user accepts the message request, the user then receives a Microsoft Teams message from the attacker attempting to convince them to enter a code into the Microsoft Authenticator app on their mobile device.\nFigure 2: A Microsoft Teams prompt with a code and instructions.\nStep 3: Successful MFA authentication\nIf the targeted user accepts the message request and enters the code into the Microsoft Authenticator app, the threat actor is granted a token to authenticate as the targeted user. The actor gains access to the user’s Microsoft 365 account, having completed the authentication flow.\nThe actor then proceeds to conduct post-compromise activity, which typically involves information theft from the compromised Microsoft 365 tenant. In some cases, the actor attempts to add a device to the organization as a managed device via Microsoft Entra ID (formerly Azure Active Directory), likely an attempt to circumvent conditional access policies configured to restrict access to specific resources to managed devices only.\nMicrosoft recommends the following mitigations to reduce the risk of this threat.\nPilot and start deploying phishing-resistant authentication methods for users.\nImplement Conditional Access authentication strength to require phishing-resistant authentication for employees and external users for critical apps.\nApply security best practices for Microsoft Teams. Refer to the security guide for Microsoft Teams.Understand and select the best access settings for external collaboration for your organization.\nSpecify trusted Microsoft 365 organizations to define which external domains are allowed or blocked to chat and meet.\nKeep Microsoft 365 auditing enabled so that audit records could be investigated if required.\nAllow only known devices that adhere to Microsoft’s recommended security baselines.\nEducate users about social engineering and credential phishing attacks, including refraining from entering MFA codes sent via any form of unsolicited messages.Educate Microsoft Teams users to verify ‘External’ tagging on communication attempts from external entities, be cautious about what they share, and never share their account information or authorize sign-in requests over chat.\nEducate Microsoft Teams users about accepting or blocking people outside the organization who send messages in Microsoft Teams.\nEducate users to review sign-in activity and mark suspicious sign-in attempts as “This wasn’t me”.\nImplement Conditional Access App Control in Microsoft Defender for Cloud Apps for users connecting from unmanaged devices.\nIndicatorTypeDescriptionmlcrosoftaccounts.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomainmsftonlineservices.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomainmsonlineteam.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomainmsftservice.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomainnoreplyteam.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomainaccounteam.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomainteamsprotection.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomainidentityverification.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomainmsftprotection.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomainaccountsverification.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomainazuresecuritycenter.onmicrosoft[.]comDomain nameMalicious actor-controlled subdomain\nCustomers hunting for related activity in their environment can identify users that were targeted with the phishing lure using content search in Microsoft Purview. A content search can be created for selected Exchange mailboxes (which include Teams messages) using the following keywords (remove the [] around the “.” before use):\nWe detected a recent change to your preferred Multi-Factor Authentication (MFA)\nThe search results will include the messages that match the criteria. The first result will appear to be from <threadid>@unq.gbl.spaces addressed to the target user and the threat actor (i.e., the request to chat as described in Step 1), followed by the message sent by the threat actor, as shown in the Microsoft Purview image below:\nFigure 3: Message sent by the threat actor, as shown in Microsoft Purview\nMicrosoft Sentinel also has a range of detection and threat hunting content that customers can use to detect activity related to the activity described in this blog:\nAzure portal sign-in from another Azure tenant\nSuccessful sign-in from non-compliant device\nUser accounts – Sign-in failure due to CA spikes\nNew onmicrosoft domain added to tenant\nRead about the threat actor Midnight Blizzard (formerly tracked as NOBELIUM).\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft Mesh is generally available in Microsoft Teams | Microsoft 365 Blog",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2024/01/24/bring-virtual-connections-to-life-with-microsoft-mesh-now-generally-available-in-microsoft-teams/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNHpkVlZYUldkNmVrTnlNMUIxVFJDb0FSaXNBaWdCTWdrQmNKSzB0T2FoQ2dJ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-01-24T08:00:00.000Z",
    "time": "Jan 24",
    "articleType": "regular",
    "content": "The way we work has changed, but the secret to a thriving workplace has not. Deep human connections are required to increase engagement, stimulate performance, and retain talent. Organizations foster connection through key moments like new employee onboarding, town halls, brainstorming sessions, team socials, and networking events. However, when these activities are hosted remotely, they are less effective at building personal connections that people and organizations need to thrive. According to Microsoft’s Work Trend Index report, 43 percent of leaders say relationship building is the greatest challenge in remote and hybrid work.1\nTo support hybrid work and geographically distributed organizations, we created Microsoft Mesh. Mesh powers 3D immersive experiences using next-generation technology that help virtual connections feel more like face-to-face interactions. Mesh is available on PC and Meta Quest VR devices.2\nToday, customers like Takeda, Accenture, bp, and Mercy Ships are already benefiting from Mesh.\nConnect like never before with Microsoft Mesh, a new 3D immersive experience.\nMeeting you where you work: Mesh in Teams\nStarting today, enjoy the benefits of deeper connection from right within Microsoft Teams, the smart place to work for hundreds of millions of people. Mesh in Teams elevates engagement in Teams meetings with ready-made 3D immersive spaces crafted to suit your needs, whether it’s a team social gathering, brainstorming session, or a round-table discussion. Design an avatar to represent yourself and include everyone in the conversation. Host multiple, simultaneous small-group discussions with spatial audio, which enables productive side conversations during brainstorming, like in the physical world. This lessens the cognitive load and boosts the effectiveness of discussions.\nUse the same Teams features you love from within a 3D space, like accessing shared content for collaboration, communicating with Teams chat, and using live reactions to express yourself.\nOur customers are realizing the value of Mesh in Teams already. Takeda, a global pharmaceutical company, celebrated a milestone with their global team in a waterfront lake house. Mesh in Teams offered an exciting and sustainable way for everyone in their team to take part in a special team success.\nLeo Barella, Takeda’s Chief Technology Officer, explains that “the world of work continues to evolve at a rapid pace, but the importance of human connection has never gone away. Lunchtime conversations, hallway catch-ups, coffee chats—they often hold the key to both workplace success and employee happiness. Mesh for Teams has proven a game-changer for us; our hybrid meetings are more collaborative and immersive, and also a lot more fun. We are a people-first organization, and we want every employee to feel a true sense of belonging and togetherness—from day one, wherever they are in the world. Mesh is helping us achieve that.”\nGetting started is easy. When you’re in a meeting in new Teams from your PC, simply select the “immersive space (3D)” option from the View menu. Find out more about Mesh in Teams and get started.\nReimagine connection with custom experiences in Microsoft Mesh\nOrganizations can also host larger events with custom, immersive experiences tailored to their needs with Microsoft Mesh. With the no-code editor, start with a set of ready-made immersive spaces and customize the space by adding visual elements like banners featuring your organization’s logo, videos showcasing your product, presentation content, and more. Effortlessly orchestrate these visual elements so they fit right into the flow of your event with our easy-to-use event organizer tools. Take it a step further and harness the power of Unity with the Mesh toolkit to create your own custom interactive experiences, including venues for all hands meetings, onboarding, simulations, or training. With the no-code editor and Mesh toolkit to craft custom experiences, the opportunities are endless.\nRevolutionizing the future of work: How our customers are using Mesh today\nAt the forefront of innovative workspaces are our customers, including Takeda, Accenture, bp, and Mercy Ships. While each organization has built distinctly different spaces for onboarding, training, hosting large events, and running simulations, the benefits they’ve accrued are similar. Immersive experiences in Mesh create highly engaged, productive distributed teams while also reducing travel and real estate costs.\nBefore Takeda scaled these benefits of authentic connection to everyday meetings and smaller team interactions like the team celebration discussed earlier, they built several specialized spaces to serve as awe-inspiring introductions to this new technology.\nTheir journey began when they sought a cost-effective way to help their geo-diverse workforce connect and further their common cultural understanding. Takeda built a custom solution designed to cultivate engagement, bolster commitment to their corporate philosophy, and accelerate product innovation: the Hirameki Garden. The garden, created in Microsoft Mesh, serves as a virtual venue for large, company-wide events like town halls and all hands meetings. Employees gather from all over the world to celebrate major organizational milestones and learn directly from their top leaders, in a space that was specifically designed to represent their corporate values.\nLeo Barella shares that “the future of work is no longer simply an abstract concept—it’s already here and it’s transforming the employee experience. Microsoft Mesh empowers us to create custom virtual experiences that perfectly capture the spaces that represent our operating model, corporate philosophy, and values. Employees all over the world—regardless of their location or role type – can participate in a virtual world that brings the company to life in an engaging and meaningful way and helps them feel an authentic sense of connection. When it comes to the potential use cases and benefits, we’re only really scratching the tip of the iceberg.”\nTakeda has crafted several other virtual spaces in addition to the Hirameki Garden, including a gallery showcasing patient stories and their history of innovation in their industry. This space grounds employees in the organization’s purpose and promotes genuine empathy for their customers.\nAccenture, one of the largest consulting firms in the world, needed to scale their onboarding program to accommodate their growing global workforce in a cost-effective and sustainable way. In 2021, they partnered with Microsoft to design a solution that maintains authentic connection, promotes cultural understanding, and encourages unity across their organization. To date, Accenture has welcomed more than 300,000 new hires from around the world at One Accenture Park, a virtual campus created in Microsoft Mesh. Each new-hire cohort is invited to ride the virtual monorail to different educational exhibits, expert talks in auditoriums, and events in gathering spaces to meet their colleagues and learn about key skills to be successful in their new roles.\nEllyn Shook, Accenture’s Chief Leadership & Human Resources Officer, explains that their re-imagined onboarding experience “enables new joiners to discover our culture, core values and how Accenture drives value for our clients, people, and communities. All in a collaborative, immersive way that transcends space and place. This, coupled with key in-person experiences, deepens human connection like never before.\nBp, a global energy company, was interested in scaling specialized physical meeting spaces, called Highly Immersive Visualization Environments (HIVEs), that allow experts to comprehend and collaborate on complex issues in a way that wouldn’t be possible with traditional tools. A physical space of this caliber requires significant financial investment to build and maintain, and travel investment to accommodate in-person expert participation. So, bp partnered with Microsoft to design and pilot a cutting-edge, collaborative environment using Microsoft Mesh to connect their global teams more effectively and safely from anywhere in the world via a lower cost and lower carbon digital solution. Soon, experts will be able to come together virtually in HIVEs to monitor wind turbines in a remote location or troubleshoot equipment repairs using digital twins without ever leaving their office.\nRoger Rohatgi, Vice President and Global Head of Design for bp, shares that “highly immersive visualization environments open the path to a more digital and collaborative future for bp. By partnering with Microsoft Mesh, we are able to explore how to use advanced technology for faster, more informed, and safer decision making as we pursue our ambition to become an integrated energy company.”\nMercy Ships, an international charity that utilizes hospital ships to provide free surgical care and education to in-need communities in Africa, is comprised of predominantly volunteer-led crews with a turnover rate as high as 350%. And their 3,000-person crew is physically distributed, representing more than 60 nations. These circumstances called for more efficient training practices that remained effective and accessible to everyone, meaning they couldn’t require any special equipment beyond a PC and a network connection. With the support of Dell Technologies and Link To VR, Mercy Ships built the Global Mercy, a digital replica of one of their hospital ships, in Microsoft Mesh. This will allow their organization to educate volunteers, staff, and prospective donors on the culture and operations of the organization before ever boarding the physical ship. Remote access provided over PC or VR headset offers a truly immersive experience while significantly reducing travel costs and time commitments. More efficient training practices means more time spent maximizing the healthcare services provided to these communities in need.\nDave Shwadlenak, Vice President of Information Services at Mercy Ships, adds that their organization is “excited by the prospect of using the Global Mercy digital twin in Mesh. It allows our volunteers, who travel to our vessels from around the world, to experience our ships virtually before they physically arrive, which enhances their onboarding experience. This technology also offers a virtual experience to our donors who might not otherwise be able to travel to our ships, allowing them to see the tremendous work on our vessels and to connect with our mission in a more personal way. As you can see, we’re very pleased because it provides another means by which we can share how Mercy Ships is bringing hope and healing.”\nTake the next step in connecting your workforce today\nThese are just a few of the customers transforming work with Microsoft Mesh. We are excited to learn how your organization leverages this new technology.\nMesh experiences are generally available today.\nFind out more about Mesh in Teams and get started.3\nThank you for being part of the journey with us!\n1Hybrid Work Is Just Work. Are We Doing It Wrong? Microsoft Work Trend Index. September 22, 2022.\n2Microsoft Mesh will be available in the Meta Quest app store on January 25, 2024.\n3Customers with the following licenses have access to Mesh in Teams. Teams Essentials, Microsoft 365 Business Basic, Microsoft 365 Business Standard, Microsoft 365 Business Premium, Microsoft 365 E3/E5, and Office 365 E1/E3/E5.\n4Mesh trial requires an active Microsoft 365 or Teams business plan.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Disrupting the gateway services to cybercrime - Microsoft On the Issues",
    "link": "https://blogs.microsoft.com/on-the-issues/2023/12/13/cybercrime-cybersecurity-storm-1152-fraudulent-accounts/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVpWVmx2U25CVE1FeExZbmRqVFJDeUFSaWJBaWdCTWdhTk01TE1wUVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-12-13T08:00:00.000Z",
    "time": "Dec 13, 2023",
    "articleType": "regular",
    "content": "At Microsoft, we continue to look for creative ways to protect people online and that includes having no tolerance for those who create fraudulent copies of our products to harm others. Fraudulent online accounts act as the gateway to a host of cybercrime, including mass phishing, identity theft and fraud, and distributed denial of service (DDoS) attacks. That is why today, we, with valuable threat intelligence insights from Arkose Labs, a leading cybersecurity defense and bot management vendor, are going after the number one seller and creator of fraudulent Microsoft accounts, a group we call Storm-1152. We are sending a strong message to those who seek to create, sell or distribute fraudulent Microsoft products for cybercrime: We are watching, taking notice and will act to protect our customers.\nStorm-1152 runs illicit websites and social media pages, selling fraudulent Microsoft accounts and tools to bypass identity verification software across well-known technology platforms. These services reduce the time and effort needed for criminals to conduct a host of criminal and abusive behaviors online. To date, Storm-1152 created for sale approximately 750 million fraudulent Microsoft accounts, earning the group millions of dollars in illicit revenue, and costing Microsoft and other companies even more to combat their criminal activity.\nWith today’s action, our goal is to deter criminal behavior. By seeking to slow the speed at which cybercriminals launch their attacks, we aim to raise their cost of doing business while continuing our investigation and protecting our customers and other online users.\nHow cybercriminals use Storm-1152’s services\nStorm-1152 plays a significant role in the highly specialized cybercrime-as-a-service ecosystem. Cybercriminals need fraudulent accounts to support their largely automated criminal activities. With companies able to quickly identify and shut down fraudulent accounts, criminals require a greater quantity of accounts to circumvent mitigation efforts. Instead of spending time trying to create thousands of fraudulent accounts, cybercriminals can simply purchase them from Storm-1152 and other groups. This allows criminals to focus their efforts on their ultimate goals of phishing, spamming, ransomware, and other types of fraud and abuse. Storm-1152 and groups like them enable scores of cybercriminals to carry out their malicious activities more efficiently and effectively.\nMicrosoft Threat Intelligence has identified multiple groups engaged in ransomware, data theft and extortion that have used Storm-1152 accounts. For example, Octo Tempest, also known as Scattered Spider, obtained fraudulent Microsoft accounts from Storm-1152. Octo Tempest is a financially motivated cybercrime group that leverages broad social engineering campaigns to compromise organizations across the globe with the goal of financial extortion. Microsoft continues to track multiple other ransomware or extortion threat actors that have purchased fraudulent accounts from Storm-1152 to enhance their attacks, including Storm-0252 and Storm-0455.\nOn Thursday, December 7, Microsoft obtained a court order from the Southern District of New York to seize U.S.-based infrastructure and take offline websites used by Storm-1152 to harm Microsoft customers. While our case focuses on fraudulent Microsoft accounts, the websites impacted also sold services to bypass security measures on other well-known technology platforms. Today’s action therefore has a broader impact, benefiting users beyond Microsoft. Specifically, Microsoft’s Digital Crimes Unit disrupted:\nHotmailbox.me, a website selling fraudulent Microsoft Outlook accounts\n1stCAPTCHA, AnyCAPTCHA, and NoneCAPTCHA, websites that facilitate the tooling, infrastructure, and selling of the CAPTCHA solve service to bypass the confirmation of use and account setup by a real person. These sites sold identity verification bypass tools for other technology platforms\nThe social media sites actively used to market these services\nImages of Storm-1152’s illicit websites\nMicrosoft is committed to providing a safe digital experience for every person and organization on the planet. We work closely with Arkose Labs to deploy a next-generation CAPTCHA defense solution. The solution requires every would-be user who wishes to open a Microsoft account to represent that they are a human being (not a bot) and verify the accuracy of that representation by solving various types of challenges.\nAs founder and CEO of Arkose Labs, Kevin Gosschalk says: “Storm-1152 is a formidable foe established with the sole purpose of making money by empowering adversaries to commit complex attacks. The group is distinguished by the fact that it built its CaaS business in the light of day versus on the dark web. Storm-1152 operated as a typical internet going-concern, providing training for its tools and even offering full customer support. In reality, Storm-1152 was an unlocked gateway to serious fraud.”\nStorm-1152’s activity not only violates Microsoft’s terms of services by selling fraudulent accounts, but it also purposely seeks to harm customers of Arkose Labs and deceive victims pretending to be legitimate users in an attempt to bypass security measures.\nWhat visitors to hotmailbox.com, 1stCAPTCHA, AnyCAPTCHA, and NoneCAPTCHA will see if they try to access the websites\nIdentifying the individuals and infrastructure behind Storm-1152\nOur analysis of Storm-1152’s activity included detection, analysis, telemetry, undercover test purchases, and reverse engineering to pinpoint the malicious infrastructure hosted in the United States. Microsoft Threat Intelligence and Arkose Cyber Threat Intelligence Research unit (ACTIR) provided additional data and insights to strengthen our legal case.\nAs part of our investigation, we were able to confirm the identity of the actors leading Storm-1152’s operations – Duong Dinh Tu, Linh Van Nguyễn (also known as Nguyễn Van Linh), and Tai Van Nguyen – based in Vietnam. Our findings show these individuals operated and wrote the code for the illicit websites, published detailed step-by-step instructions on how to use their products via video tutorials and provided chat services to assist those using their fraudulent services.\nDuong Dinh Tu’s YouTube channel with “how to videos” to bypass security measures\nMicrosoft has since submitted a criminal referral to U.S. law enforcement. We are grateful for our partnership with law enforcement who can bring those looking to harm our customers to justice.\nOur ongoing commitment to fighting cybercrime\nToday’s action is a continuation of Microsoft’s strategy of taking aim at the broader cybercriminal ecosystem and targeting the tools cybercriminals use to launch their attacks. It builds on our expansion of a legal method used successfully to disrupt malware and nation-state operations. We have also partnered with other organizations across the industry to increase intelligence sharing on fraud and further enhance our artificial intelligence and machine learning algorithms that quickly detect and flag fraudulent accounts.\nAs we’ve said before, no disruption is complete in one day. Going after cybercrime requires persistence and ongoing vigilance to disrupt new malicious infrastructure. While today’s legal action will impact Storm-1152’s operations, we expect other threat actors will adapt their techniques as a result. Continued public and private sector collaboration, like todays with Arkose Labs and U.S. law enforcement, remain essential if we want to meaningfully dent the impact of cybercrime.\nTags: cyberattacks, cybercrime, cybersecurity, Digital Crimes Unit, MTAC, Storm-1152",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "Midnight Blizzard: Guidance for responders on nation-state attack",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNDNNRGhLYjFsbFVIaERZV3RTVFJDM0FSaVRBaWdCTWdZVmM0aHdyUWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-01-25T08:00:00.000Z",
    "time": "Jan 25",
    "articleType": "regular",
    "content": "The Microsoft security team detected a nation-state attack on our corporate systems on January 12, 2024, and immediately activated our response process to investigate, disrupt malicious activity, mitigate the attack, and deny the threat actor further access. The Microsoft Threat Intelligence investigation identified the threat actor as Midnight Blizzard, the Russian state-sponsored actor also known as NOBELIUM. The latest information from the Microsoft Security and Response Center (MSRC) is posted here.\nAs stated in the MSRC blog, given the reality of threat actors that are well resourced and funded by nation states, we are shifting the balance we need to strike between security and business risk – the traditional sort of calculus is simply no longer sufficient. For Microsoft, this incident has highlighted the urgent need to move even faster.\nIf the same team were to deploy the legacy tenant today, mandatory Microsoft policy and workflows would ensure MFA and our active protections are enabled to comply with current policies and guidance, resulting in better protection against these sorts of attacks.\nMicrosoft was able to identify these attacks in log data by reviewing Exchange Web Services (EWS) activity and using our audit logging features, combined with our extensive knowledge of Midnight Blizzard. In this blog, we provide more details on Midnight Blizzard, our preliminary and ongoing analysis of the techniques they used, and how you may use this information pragmatically to protect, detect, and respond to similar threats in your own environment.\nUsing the information gained from Microsoft’s investigation into Midnight Blizzard, Microsoft Threat Intelligence has identified that the same actor has been targeting other organizations and, as part of our usual notification processes, we have begun notifying these targeted organizations.\nIt’s important to note that this investigation is still ongoing, and we will continue to provide details as appropriate.\nMidnight Blizzard (also known as NOBELIUM) is a Russia-based threat actor attributed by the US and UK governments as the Foreign Intelligence Service of the Russian Federation, also known as the SVR. This threat actor is known to primarily target governments, diplomatic entities, non-governmental organizations (NGOs) and IT service providers, primarily in the US and Europe. Their focus is to collect intelligence through longstanding and dedicated espionage of foreign interests that can be traced to early 2018. Their operations often involve compromise of valid accounts and, in some highly targeted cases, advanced techniques to compromise authentication mechanisms within an organization to expand access and evade detection.\nMidnight Blizzard is consistent and persistent in their operational targeting, and their objectives rarely change. Midnight Blizzard’s espionage and intelligence gathering activities leverage a variety of initial access, lateral movement, and persistence techniques to collect information in support of Russian foreign policy interests. They utilize diverse initial access methods ranging from stolen credentials to supply chain attacks, exploitation of on-premises environments to laterally move to the cloud, and exploitation of service providers’ trust chain to gain access to downstream customers. Midnight Blizzard is also adept at identifying and abusing OAuth applications to move laterally across cloud environments and for post-compromise activity, such as email collection. OAuth is an open standard for token-based authentication and authorization that enables applications to get access to data and resources based on permissions set by a user.\nMidnight Blizzard is tracked by partner security vendors as APT29, UNC2452, and Cozy Bear.\nMidnight Blizzard observed activity and techniques\nInitial access through password spray\nMidnight Blizzard utilized password spray attacks that successfully compromised a legacy, non-production test tenant account that did not have multifactor authentication (MFA) enabled. In a password-spray attack, the adversary attempts to sign into a large volume of accounts using a small subset of the most popular or most likely passwords. In this observed Midnight Blizzard activity, the actor tailored their password spray attacks to a limited number of accounts, using a low number of attempts to evade detection and avoid account blocks based on the volume of failures. In addition, as we explain in more detail below, the threat actor further reduced the likelihood of discovery by launching these attacks from a distributed residential proxy infrastructure. These evasion techniques helped ensure the actor obfuscated their activity and could persist the attack over time until successful.\nMalicious use of OAuth applications\nThreat actors like Midnight Blizzard compromise user accounts to create, modify, and grant high permissions to OAuth applications that they can misuse to hide malicious activity. The misuse of OAuth also enables threat actors to maintain access to applications, even if they lose access to the initially compromised account. Midnight Blizzard leveraged their initial access to identify and compromise a legacy test OAuth application that had elevated access to the Microsoft corporate environment. The actor created additional malicious OAuth applications. They created a new user account to grant consent in the Microsoft corporate environment to the actor controlled malicious OAuth applications. The threat actor then used the legacy test OAuth application to grant them the Office 365 Exchange Online full_access_as_app role, which allows access to mailboxes.\nCollection via Exchange Web Services\nMidnight Blizzard leveraged these malicious OAuth applications to authenticate to Microsoft Exchange Online and target Microsoft corporate email accounts.\nUse of residential proxy infrastructure\nAs part of their multiple attempts to obfuscate the source of their attack, Midnight Blizzard used residential proxy networks, routing their traffic through a vast number of IP addresses that are also used by legitimate users, to interact with the compromised tenant and, subsequently, with Exchange Online. While not a new technique, Midnight Blizzard’s use of residential proxies to obfuscate connections makes traditional indicators of compromise (IOC)-based detection infeasible due to the high changeover rate of IP addresses.\nDue to the heavy use of proxy infrastructure with a high changeover rate, searching for traditional IOCs, such as infrastructure IP addresses, is not sufficient to detect this type of Midnight Blizzard activity. Instead, Microsoft recommends the following guidance to detect and help reduce the risk of this type of threat:\nDefend against malicious OAuth applications\nAudit the current privilege level of all identities, users, service principals, and Microsoft Graph Data Connect applications (use the Microsoft Graph Data Connect authorization portal), to understand which identities are highly privileged. Privilege should be scrutinized more closely if it belongs to an unknown identity, is attached to identities that are no longer in use, or is not fit for purpose. Identities can often be granted privilege over and above what is required. Defenders should pay attention to apps with app-only permissions as those apps may have over-privileged access. Additional guidance for investigating compromised and malicious applications.\nAudit identities that hold ApplicationImpersonation privileges in Exchange Online. ApplicationImpersonation allows a caller, such as a service principal, to impersonate a user and perform the same operations that the user themselves could perform. Impersonation privileges like this can be configured for services that interact with a mailbox on a user’s behalf, such as video conferencing or CRM systems. If misconfigured, or not scoped appropriately, these identities can have broad access to all mailboxes in an environment. Permissions can be reviewed in the Exchange Online Admin Center, or via PowerShell:\nIdentify malicious OAuth apps using anomaly detection policies. Detect malicious OAuth apps that make sensitive Exchange Online administrative activities through App governance. Investigate and remediate any risky OAuth apps.\nImplement conditional access app control for users connecting from unmanaged devices.\nMidnight Blizzard has also been known to abuse OAuth applications in past attacks against other organizations using the EWS.AccessAsUser.All Microsoft Graph API role or the Exchange Online ApplicationImpersonation role to enable access to email. Defenders should review any applications that hold EWS.AccessAsUser.All and EWS.full_access_as_app permissions and understand whether they are still required in your tenant. If they are no longer required, they should be removed.\nIf you require applications to access mailboxes, granular and scalable access can be implemented using role-based access control for applications in Exchange Online. This access model ensures applications are only granted to the specific mailboxes required.\nProtect against password spray attacks\nEducate users to review sign-in activity and mark suspicious sign-in attempts as “This wasn’t me”.\nReset account passwords for any accounts targeted during a password spray attack. If a targeted account had system-level permissions, further investigation may be warranted.\nDetect, investigate, and remediate identity-based attacks using solutions like Microsoft Entra ID Protection.\nInvestigate compromised accounts using Microsoft Purview Audit (Premium).\nEnforce on-premises Microsoft Entra Password Protection for Microsoft Active Directory Domain Services.\nUse risk detections for user sign-ins to trigger multifactor authentication or password changes.\nInvestigate any possible password spray activity using the password spray investigation playbook.\nBy reviewing Exchange Web Services (EWS) activity, combined with our extensive knowledge of Midnight Blizzard, we were able to identify these attacks in log data. We are sharing some of the same hunting methodologies here to help other defenders detect and investigate similar attack tactics and techniques, if leveraged against their organizations. The audit logging that Microsoft investigators used to discover this activity was also made available to a broader set of Microsoft customers last year.\nMicrosoft Entra ID Protection has several relevant detections that help organizations identify these techniques or additional activity that may indicate anomalous activity that needs to be investigated. The use of residential proxy network infrastructure by threat actors is generally more likely to generate Microsoft Entra ID Protection alerts due to inconsistencies in patterns of user behavior compared to legitimate activity (such as location, diversity of IP addresses, etc.) that may be beyond the control of the threat actor.\nThe following Microsoft Entra ID Protection alerts can help indicate threat activity associated with this attack:\nUnfamiliar sign-in properties – This alert flags sign-ins from networks, devices, and locations that are unfamiliar to the user.\nPassword spray – A password spray attack is where multiple usernames are attacked using common passwords in a unified brute force manner to gain unauthorized access. This risk detection is triggered when a password spray attack has been successfully performed. For example, the attacker has successfully authenticated in the detected instance.\nThreat intelligence – This alert indicates user activity that is unusual for the user or consistent with known attack patterns. This detection is based on Microsoft’s internal and external threat intelligence sources.\nSuspicious sign-ins (workload identities) – This alert indicates sign-in properties or patterns that are unusual for the related service principal.\nXDR and SIEM alerts and protection\nOnce an actor decides to use OAuth applications in their attack, a variety of follow-on activities can be identified in alerts to help organizations identify and investigate suspicious activity.\nThe following built-in Microsoft Defender for Cloud Apps alerts are automatically triggered and can help indicate associated threat activity:\nApp with application-only permissions accessing numerous emails – A multi-tenant cloud app with application-only permissions showed a significant increase in calls to the Exchange Web Services API specific to email enumeration and collection. The app might be involved in accessing and retrieving sensitive email data.\nIncrease in app API calls to EWS after a credential update – This detection generates alerts for non-Microsoft OAuth apps where the app shows a significant increase in calls to Exchange Web Services API within a few days after its certificates/secrets are updated or new credentials are added.\nIncrease in app API calls to EWS – This detection generates alerts for non-Microsoft OAuth apps that exhibit a significant increase in calls to the Exchange Web Serves  API. This app might be involved in data exfiltration or other attempts to access and retrieve data.\nApp metadata associated with suspicious mal-related activity – This detection generates alerts for non-Microsoft OAuth apps with metadata, such as name, URL, or publisher, that had previously been observed in apps with suspicious mail-related activity. This app might be part of an attack campaign and might be involved in exfiltration of sensitive information.\nSuspicious user created an OAuth app that accessed mailbox items – A user that previously signed on to a medium- or high-risk session created an OAuth application that was used to access a mailbox using sync operation or multiple email messages using bind operation. An attacker might have compromised a user account to gain access to organizational resources for further attacks.\nThe following Microsoft Defender XDR alert can indicate associated activity:\nSuspicious user created an OAuth app that accessed mailbox items – A user who previously signed in to a medium- or high-risk session created an OAuth application that was used to access a mailbox using sync operation or multiple email messages using bind operation. An attacker might have compromised a user account to gain access to organizational resources for further attacks.\nFebruary 5, 2024 update: A query that was not working for all customers has been removed.\nMicrosoft Defender XDR customers can run the following query to find related activity in their networks:\nFind MailItemsAccessed or SaaS actions performed by a labeled password spray IP\nCloudAppEvents | where Timestamp between (startTime .. endTime) | where isnotempty(IPTags) and not(IPTags has_any('Azure','Internal Network IP','branch office')) | where IPTags has_any (\"Brute force attacker\", \"Password spray attacker\", \"malicious\", \"Possible Hackers\")\nMicrosoft Sentinel customers can use the following analytic rules to find related activity in their network.\nPassword spray attempts – This query helps identify evidence of password spray activity against Microsoft Entra ID applications.\nOAuth application being granted full_access_as_app permission – This detection looks for the full_access_as_app permission being granted to an OAuth application with Admin Consent. This permission provides access to Exchange mailboxes via the EWS API and could be exploited to access sensitive data. The application granted this permission should be reviewed to ensure that it is necessary for the application’s function.\nAddition of services principal/user with elevated permissions – This rule looks for a service principal being granted permissions that could be used to add a Microsoft Entra ID object or user account to an Admin directory role.\nOffline access via OAuth for previously unknown Azure application – This rule alerts when a user consents to provide a previously unknown Azure application with offline access via OAuth. Offline access will provide the Azure app with access to the resources without requiring two-factor authentication. Consent to applications with offline access should generally be rare.\nMicrosoft Sentinel customers can also use this hunting query:\nOAuth apps reading mail both via GraphAPI and directly – This query returns OAuth Applications that access mail both directly and via Graph, allowing review of whether such dual access methods follow expected user patterns.\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.\nMicrosoft customers can use the following reports in Microsoft Defender Threat Intelligence to get the most up-to-date information about the threat actor, malicious activity, and techniques discussed in this blog. These reports provide the intelligence, protection information, and recommended actions to prevent, mitigate, or respond to associated threats found in customer environments:\nThreat overview: Cloud identity abuse\nTechniques profile: Password spray attacks\nFebruary 13, 2024 minor update: Updated guidance in “Defend against malicious OAuth applications” section with clearer wording and links to additional resources.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "New passkey support for Microsoft consumer accounts | Microsoft Security Blog",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/05/02/microsoft-introduces-passkeys-for-consumer-accounts/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNXFORjlCYVRWRk1DMW5iMnhQVFJDb0FSaXJBaWdCTWdtRmc0NVNxZWVwN2dF=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-02T07:00:00.000Z",
    "time": "May 2",
    "articleType": "regular",
    "content": "Ten years ago, Microsoft envisioned a bold future: a world free of passwords. Every year, we celebrate World Password Day by updating you on our progress toward eliminating passwords for good. Today, we’re announcing passkey support for Microsoft consumer accounts, the next step toward our vision of simple, safe access for everyone.\nIn 2015, when we introduced Windows Hello and Windows Hello for Business as secure ways to access Windows 10 without entering a password, our identity systems were detecting around 115 password attacks per second.1 Less than a decade later, that number has surged 3,378% to more than 4,000 password attacks per second.2 Password attacks are so popular because they still get results. It’s painfully clear that passwords are not sufficient for protecting our lives online. No matter how long and complicated you make your password, or how often you change it, it still presents a risk.\nThe good news is that we’ve made a lot of progress toward making passwords a relic of the past. For a while, you’ve been able to sign in to apps and websites using FIDO security keys, Windows Hello, or the Microsoft Authenticator app instead of a password. Since September 2021, you’ve not only been able to sign in to your Microsoft account without a password, but you’ve also been able to delete your password altogether.3 We’re almost there.\nAnd now there’s an even better way to sign in to more places without passwords: passkeys.\nThe future of signing in\nIf you’re like many people, you probably still use passwords to sign in to most of your websites and apps, most likely from multiple devices. This can translate into hundreds of passwords to remember, unless you use a password manager. With passkeys, instead of creating, managing, remembering, and entering passwords, you access your digital accounts the same way you unlock your device—usually with your face, fingerprint, or device PIN. More and more apps and services are adding support for passkeys; you can already use them to sign in to the most popular ones. Passkeys are so much easier and more secure than passwords that we predict passkeys will replace passwords almost entirely (and we hope this happens soon).\nStarting today, you can use a passkey to access your Microsoft account using your face, fingerprint, or device PIN on Windows, Google, and Apple platforms. Your passkey gives you quick and easy access to the Microsoft services you use every day, and it will do a much better job than your password of protecting your account from malicious attacks.\nEasier and more secure than passwords\nThink of how many times and places you sign in with a password every single day. Is it 10? 50? Not only is this a frustrating experience, it’s also an unreliable way to protect a digital account. Here’s why: When you enter a password to sign in to an account, you’re essentially sharing a secret with the website or app to prove that you should have access to the account. The problem is that anyone who gets a hold of this secret can gain access to your account, and if your password gets compromised and appears on the dark web, the repercussions can be serious.\nTo make your credentials stronger, an app or website might require you to make your password longer or more complex. But even if you follow all the best practices for creating “strong” passwords, it’s still a trivial exercise for hackers to guess, steal, or trick you into revealing them.\nYou may have experienced an attack yourself—you click on a link in an email that seems legitimate, which leads to a website that looks just like the one you’re used to, asking you to enter your credentials. But when you do, nothing happens, or you get an error message. By the time you notice that the URL in your browser address bar is different from the usual one, it’s too late. You’ve just been phished by a malicious website.\nMany app and website providers understand that even complicated passwords aren’t good enough to protect your account, so they give you the choice to use two-step or multifactor authentication with approvals and codes sent to your phone, email, or an app. While traditional multifactor authentication can help protect your account, it’s not attacker-proof, and it creates another frustrating barrier between you and your content: all these access attempts, passwords, and codes on all your devices can really add up.\nThis is why we’re so enthusiastic about passkeys.\nPasskeys work differently than passwords. Instead of a single, vulnerable secret, passkey access uses two unique keys, known as a cryptographic key pair. One key is stored safely on your device, guarded by your biometrics or PIN. The other key stays with the app or website for which you create the passkey. You need both parts of the key pair to sign in, just as you need both your key and the bank’s key to get into your safety deposit box.\nBecause this key pair combination is unique, your passkey will only work on the website or app you created it for, so you can’t be tricked into signing in to a malicious look-alike website. This is why we say that passkeys are “phishing-resistant.”\nEven better, all the goodness and strength of cryptographic authentication stays behind the scenes. All you have to do to sign in is use your device unlock gesture: look into your device camera, press your finger on a fingerprint reader, or enter your PIN. Neither your biometric information nor your PIN ever leaves your device and they never get shared with the site or service you’re signing in to. Passkeys can also sync between your devices, so if you lose or upgrade your device, your passkeys will be ready and waiting for you when you set up your new one.\nThe best part about passkeys is that you’ll never need to worry about creating, forgetting, or resetting passwords ever again.\nCreating a passkey for your Microsoft account\nCreating a passkey for your Microsoft account is easy. On the device where you want to create the passkey, follow this link, and choose the face, fingerprint, PIN, or security key option. Then follow the instructions on your device.\nSigning into your Microsoft account using a passkey\nWhen you sign in to your Microsoft account, you can use your passkey by choosing Sign-in options and then selecting face, fingerprint, PIN, or security key. Your device will open a security window, and then you can use your passkey to sign in.\nFigure 1. Signing in to your Microsoft account on mobile devices.\nToday, you can use a passkey to sign in to Microsoft apps and websites, including Microsoft 365 and Copilot on desktop and mobile browsers. Support for signing into mobile versions of Microsoft applications using your passkey will follow in the coming weeks.\nIf you want to use passkeys to sign in to work-related apps and services, your admin can configure Microsoft Entra ID to accept passkeys hosted on a hardware security key or in the Microsoft Authenticator app installed on your mobile device.\nIn this era of AI, there’s unprecedented opportunity for creativity and productivity that empowers every person on the planet—including billions of Microsoft users who access services for work and life every day—to achieve more. Protecting and accessing your digital life doesn’t need to be a hassle, and you shouldn’t have to choose between simple access and safe access. Accessing your Microsoft account with a passkey lets you put the frustration of passwords and codes behind you, so you can focus on being creative and getting things done.\n1Microsoft Password Guidance, Microsoft Identity Protection Team.\n2Microsoft Entra expands into Security Service Edge and Azure AD becomes Microsoft Entra ID, Joy Chik. July 11, 2023.\n3The passwordless future is here for your Microsoft account, Vasu Jakkal. September 15, 2021.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Analyzing Forest Blizzard’s custom post-compromise tool for exploiting CVE-2022-38028 to obtain credentials",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/04/22/analyzing-forest-blizzards-custom-post-compromise-tool-for-exploiting-cve-2022-38028-to-obtain-credentials/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNW9hMWd5WVhWV2F6RmZlRVIwVFJDb0FSaXNBaWdCTWdhdFFJYlJxQVE=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-22T07:00:00.000Z",
    "time": "Apr 22",
    "articleType": "regular",
    "content": "Microsoft Threat Intelligence is publishing results of our longstanding investigation into activity by the Russian-based threat actor Forest Blizzard (STRONTIUM) using a custom tool to elevate privileges and steal credentials in compromised networks. Since at least June 2020 and possibly as early as April 2019, Forest Blizzard has used the tool, which we refer to as GooseEgg, to exploit the CVE-2022-38028 vulnerability in Windows Print Spooler service by modifying a JavaScript constraints file and executing it with SYSTEM-level permissions. Microsoft has observed Forest Blizzard using GooseEgg as part of post-compromise activities against targets including Ukrainian, Western European, and North American government, non-governmental, education, and transportation sector organizations. While a simple launcher application, GooseEgg is capable of spawning other applications specified at the command line with elevated permissions, allowing threat actors to support any follow-on objectives such as remote code execution, installing a backdoor, and moving laterally through compromised networks.\nForest Blizzard often uses publicly available exploits in addition to CVE-2022-38028, such as CVE-2023-23397. Linked to the Russian General Staff Main Intelligence Directorate (GRU) by the United States and United Kingdom governments, Forest Blizzard primarily focuses on strategic intelligence targets and differs from other GRU-affiliated and sponsored groups, which Microsoft has tied to destructive attacks, such as Seashell Blizzard (IRIDIUM) and Cadet Blizzard (DEV-0586). Although Russian threat actors are known to have exploited a set of similar vulnerabilities known as PrintNightmare (CVE-2021-34527 and CVE-2021-1675), the use of GooseEgg in Forest Blizzard operations is a unique discovery that had not been previously reported by security providers. Microsoft is committed to providing visibility into observed malicious activity and sharing insights on threat actors to help organizations protect themselves. Organizations and users are to apply the CVE-2022-38028 security update to mitigate this threat, while Microsoft Defender Antivirus detects the specific Forest Blizzard capability as HackTool:Win64/GooseEgg.\nThis blog provides technical information on GooseEgg, a unique Forest Blizzard capability. In addition to patching, this blog details several steps users can take to defend themselves against attempts to exploit Print Spooler vulnerabilities. We also provide additional recommendations, detections, and indicators of compromise. As with any observed nation-state actor activity, Microsoft directly notifies customers that have been targeted or compromised, providing them with the necessary information to secure their accounts.\nForest Blizzard primarily targets government, energy, transportation, and non-governmental organizations in the United States, Europe, and the Middle East. Microsoft has also observed Forest Blizzard targeting media, information technology, sports organizations, and educational institutions worldwide. Since at least 2010, the threat actor’s primary mission has been to collect intelligence in support of Russian government foreign policy initiatives. The United States and United Kingdom governments have linked Forest Blizzard to Unit 26165 of the Russian Federation’s military intelligence agency, the Main Intelligence Directorate of the General Staff of the Armed Forces of the Russian Federation (GRU). Other security researchers have used GRU Unit 26165, APT28, Sednit, Sofacy, and Fancy Bear to refer to groups with similar or related activities.\nMicrosoft Threat Intelligence assesses Forest Blizzard’s objective in deploying GooseEgg is to gain elevated access to target systems and steal credentials and information. While this actor’s TTPs and infrastructure specific to the use of this tool can change at any time, the following sections provide additional details on Forest Blizzard tactics, techniques, and procedures (TTPs) in past compromises.\nLaunch, persistence, and privilege escalation\nMicrosoft has observed that, after obtaining access to a target device, Forest Blizzard uses GooseEgg to elevate privileges within the environment. GooseEgg is typically deployed with a batch script, which we have observed using the name execute.bat and doit.bat. This batch script writes the file servtask.bat, which contains commands for saving off/compressing registry hives. The batch script invokes the paired GooseEgg executable and sets up persistence as a scheduled task designed to run servtask.bat.\nThe GooseEgg binary—which has included but is not limited to the file names justice.exe and DefragmentSrv.exe—takes one of four commands, each with different run paths. While the binary appears to launch a trivial given command, in fact the binary does this in a unique and sophisticated manner, likely to help conceal the activity.\nThe first command issues a custom return code 0x6009F49F and exits; which could be indicative of a version number. The next two commands trigger the exploit and launch either a provided dynamic-link library (DLL) or executable with elevated permissions. The fourth and final command tests the exploit and checks that it has succeeded using the whoami command.\nMicrosoft has observed that the name of an embedded malicious DLL file typically includes the phrase “wayzgoose”; for example, wayzgoose23.dll. This DLL, as well as other components of the malware, are deployed to one of the following installation subdirectories, which is created under C:\\ProgramData. A subdirectory name is selected from the list below:\nA specially crafted subdirectory with randomly generated numbers and the format string \\v%u.%02u.%04u is also created and serves as the install directory. For example, a directory that looks like C:\\ProgramData\\Adobe\\v2.116.4405 may be created. The binary then copies the following driver stores to this directory:\nFigure 2. GooseEgg binary adding driver stores to an actor-controlled directory\nNext, registry keys are created, effectively generating a custom protocol handler and registering a new CLSID to serve as the COM server for this “rogue” protocol. The exploit replaces the C: drive symbolic link in the object manager to point to the newly created directory. When the PrintSpooler attempts to load C:\\Windows\\System32\\DriverStore\\FileRepository\\pnms009.inf_amd64_a7412a554c9bc1fd\\MPDW-Constraints.js, it instead is redirected to the actor-controlled directory containing the copied driver packages.\nFigure 3. Registry key creation\nFigure 4. C: drive symbolic link hijack\nThe “MPDW-constraints.js” stored within the actor-controlled directory has the following patch applied to the convertDevModeToPrintTicket function:\nfunction convertDevModeToPrintTicket(devModeProperties, scriptContext, printTicket){try{ printTicket.XmlNode.load('rogue9471://go'); } catch (e) {}\nThe above patch to the convertDevModeToPrintTicket function invokes the “rogue” search protocol handler’s CLSID during the call to RpcEndDocPrinter. This results in the auxiliary DLL wayzgoose.dll launching in the context of the PrintSpooler service with SYSTEM permissions. wayzgoose.dll is a basic launcher application capable of spawning other applications specified at the command line with SYSTEM-level permissions, enabling threat actors to perform other malicious activities such as installing a backdoor, moving laterally through compromised networks, and remotely executing code.\nMicrosoft recommends the following mitigations defend against attacks that use GooseEgg.\nReduce the Print Spooler vulnerability\nMicrosoft released a security update for the Print Spooler vulnerability exploited by GooseEgg on October 11, 2022 and updates for PrintNightmare vulnerabilities on June 8, 2021 and July 1, 2021. Customers who have not implemented these fixes yet are urged to do so as soon as possible for their organization’s security. In addition, since the Print Spooler service isn’t required for domain controller operations, Microsoft recommends disabling the service on domain controllers. Otherwise, users can install available Windows security updates for Print Spooler vulnerabilities on Windows domain controllers before member servers and workstations. To help identify domain controllers that have the Print Spooler service enabled, Microsoft Defender for Identity has a built-in security assessment that tracks the availability of Print Spooler services on domain controllers.\nFor customers, follow the credential hardening recommendations in our on-premises credential theft overview to defend against common credential theft techniques like LSASS access.\nRun Endpoint Detection and Response (EDR) in block mode so that Microsoft Defender for Endpoint can block malicious artifacts, even when your non-Microsoft antivirus does not detect the threat or when Microsoft Defender Antivirus is running in passive mode. EDR in block mode works behind the scenes to remediate malicious artifacts that are detected post-breach.\nConfigure investigation and remediation in full automated mode to let Microsoft Defender for Endpoint take immediate action on alerts to resolve breaches, significantly reducing alert volume.\nTurn on cloud-delivered protection in Microsoft Defender Antivirus, or the equivalent for your antivirus product, to cover rapidly evolving attacker tools and techniques. Cloud-based machine learning protections block a majority of new and unknown variants.\nMicrosoft Defender XDR customers can turn on the following attack surface reduction rule to prevent common attack techniques used for GooseEgg. Microsoft Defender XDR detects the GooseEgg tool and raises an alert upon detection of attempts to exploit Print Spooler vulnerabilities regardless of whether the device has been patched.\nBlock credential stealing from the Windows local security authority subsystem (lsass.exe)\nDetecting, hunting, and responding to GooseEgg\nMicrosoft Defender Antivirus detects threat components as the following malware:\nThe following alerts might also indicate threat activity related to this threat. Note, however, that these alerts can be also triggered by unrelated threat activity.\nPossible source of PrintNightmare exploitation\nPossible target of PrintNightmare exploitation attempt\nPotential elevation of privilege using print filter pipeline service\nForest Blizzard Actor activity detected\nThe following alerts might also indicate threat activity related to this threat. Note, however, that these alerts can be also triggered by unrelated threat activity.\nSuspected Windows Print Spooler service exploitation attempt (CVE-2021-34527 exploitation)\nMicrosoft customers can use the following reports in Microsoft products to get the most up-to-date information about the threat actor, malicious activity, and techniques discussed in this blog. These reports provide the intelligence, protection information, and recommended actions to prevent, mitigate, or respond to associated threats found in customer environments.\nAbuse of Windows Print Spooler for privilege escalation and persistence\nMicrosoft Sentinel customers can use the TI Mapping analytics (a series of analytics all prefixed with ‘TI map’) to automatically match the malicious domain indicators mentioned in this blog post with data in their workspace. If the TI Map analytics are not currently deployed, customers can install the Threat Intelligence solution from the Microsoft Sentinel Content Hub to have the analytics rule deployed in their Sentinel workspace. More details on the Content Hub can be found here:  https://learn.microsoft.com/azure/sentinel/sentinel-solutions-deploy.\nHunt for filenames, file extensions in ProgramData folder and file hash\nlet filenames = dynamic([\"execute.bat\",\"doit.bat\",\"servtask.bat\"]);DeviceFileEvents  | where TimeGenerated > ago(60d) // change the duration according to your requirement  | where ActionType == \"FileCreated\"  | where FolderPath == \"C:\\\\ProgramData\\\\\"  | where FileName in~ (filenames) or FileName endswith \".save\" or FileName endswith \".zip\" or ( FileName startswith \"wayzgoose\" and FileName endswith \".dll\") or SHA256 == \"7d51e5cc51c43da5deae5fbc2dce9b85c0656c465bb25ab6bd063a503c1806a9\" // hash value of execute.bat/doit.bat/servtask.bat  | project TimeGenerated, DeviceId, DeviceName, ActionType, FolderPath, FileName, InitiatingProcessAccountName,InitiatingProcessAccountUpn\nHunt for processes creating scheduled task creation\nDeviceProcessEvents| where TimeGenerated > ago(60d) // change the duration according to your requirement| where InitiatingProcessSHA256 == \"6b311c0a977d21e772ac4e99762234da852bbf84293386fbe78622a96c0b052f\" or SHA256 == \"6b311c0a977d21e772ac4e99762234da852bbf84293386fbe78622a96c0b052f\" //hash value of justice.exeor InitiatingProcessSHA256 == \"c60ead92cd376b689d1b4450f2578b36ea0bf64f3963cfa5546279fa4424c2a5\" or SHA256 == \"c60ead92cd376b689d1b4450f2578b36ea0bf64f3963cfa5546279fa4424c2a5\" //hash value of DefragmentSrv.exeor ProcessCommandLine contains \"schtasks /Create /RU SYSTEM /TN \\\\Microsoft\\\\Windows\\\\WinSrv /TR C:\\\\ProgramData\\\\servtask.bat /SC MINUTE\" or   ProcessCommandLine contains \"schtasks /Create /RU SYSTEM /TN \\\\Microsoft\\\\Windows\\\\WinSrv /TR C:\\\\ProgramData\\\\execute.bat /SC MINUTE\" or   ProcessCommandLine contains \"schtasks /Create /RU SYSTEM /TN \\\\Microsoft\\\\Windows\\\\WinSrv /TR C:\\\\ProgramData\\\\doit.bat /SC MINUTE\" or   ProcessCommandLine contains \"schtasks /DELETE /F /TN \\\\Microsoft\\\\Windows\\\\WinSrv\" or   InitiatingProcessCommandLine contains \"schtasks /Create /RU SYSTEM /TN \\\\Microsoft\\\\Windows\\\\WinSrv /TR C:\\\\ProgramData\\\\servtask.bat /SC MINUTE\" or   InitiatingProcessCommandLine contains \"schtasks /Create /RU SYSTEM /TN \\\\Microsoft\\\\Windows\\\\WinSrv /TR C:\\\\ProgramData\\\\execute.bat /SC MINUTE\" or   InitiatingProcessCommandLine contains \"schtasks /Create /RU SYSTEM /TN \\\\Microsoft\\\\Windows\\\\WinSrv /TR C:\\\\ProgramData\\\\doit.bat /SC MINUTE\" or   InitiatingProcessCommandLine contains \"schtasks /DELETE /F /TN \\\\Microsoft\\\\Windows\\\\WinSrv\"| project TimeGenerated, AccountName,AccountUpn,ActionType, DeviceId, DeviceName,FolderPath, FileName\nHunt for JavaScript constrained file\nDeviceFileEvents  | where TimeGenerated > ago(60d) // change the duration according to your requirement  | where ActionType == \"FileCreated\"  | where FolderPath startswith \"C:\\\\Windows\\\\System32\\\\DriverStore\\\\FileRepository\\\\\"  | where FileName endswith \".js\" or FileName == \"MPDW-constraints.js\"\nHunt for creation of registry key / value events\nDeviceRegistryEvents  | where TimeGenerated > ago(60d) // change the duration according to your requirement  | where ActionType == \"RegistryValueSet\"  | where RegistryKey contains \"HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\CLSID\\\\{026CC6D7-34B2-33D5-B551-CA31EB6CE345}\\\\Server\"  | where RegistryValueName has \"(Default)\"  | where RegistryValueData has \"wayzgoose.dll\" or RegistryValueData contains \".dll\"\nHunt for custom protocol handler\nDeviceRegistryEvents  | where TimeGenerated > ago(60d) // change the duration according to your requirement  | where ActionType == \"RegistryValueSet\"  | where RegistryKey contains \"HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\PROTOCOLS\\\\Handler\\\\rogue\"  | where RegistryValueName has \"CLSID\"  | where RegistryValueData contains \"{026CC6D7-34B2-33D5-B551-CA31EB6CE345}\"\nIndicatorTypeDescriptionc60ead92cd376b689d1b4450f2578b36ea0bf64f3963cfa5546279fa4424c2a5SHA-256Hash of GooseEgg binary DefragmentSrv.exe6b311c0a977d21e772ac4e99762234da852bbf84293386fbe78622a96c0b052fSHA-256Hash of GooseEgg binary justice.exe41a9784f8787ed86f1e5d20f9895059dac7a030d8d6e426b9ddcaf547c3393aaSHA-256Hash of wayzgoose[%n].dll – where %n is a random number\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.\nTo hear stories and insights from the Microsoft Threat Intelligence community about the ever-evolving threat landscape, listen to the Microsoft Threat Intelligence podcast: https://thecyberwire.com/podcasts/microsoft-threat-intelligence.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Expanding Copilot for Microsoft 365 to businesses of all sizes",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2024/01/15/expanding-copilot-for-microsoft-365-to-businesses-of-all-sizes/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNDBYM0ZyYnpaek5sSnRjWEpEVFJDb0FSaXJBaWdCTWdZQmNKRE5yUWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-01-15T08:00:00.000Z",
    "time": "Jan 15",
    "articleType": "regular",
    "content": "We are updating our Microsoft Copilot product line-up with a new Copilot Pro subscription for individuals; expanding Copilot for Microsoft 365 availability to small and medium-sized businesses; and announcing no seat minimum for commercial plans—making Copilot generally available to individuals, enterprises, and everyone in between.\nRead on for all the details.\nCopilot for Microsoft 365 enables users to enhance their creativity, productivity, and skills.\nUpdates to our Copilot product line-up\nFirst, we are announcing an update to our Copilot product line-up: Copilot Pro—a new Copilot subscription for individuals priced at $20 per individual per month.\nCopilot Pro has foundational capabilities in a single experience that runs across your devices and understands your context on the web, on your PC, across your apps, and soon on your phone to bring the right skills to you when you need them. And it has web grounding, so it always has access to the latest information. When you’re signed into Copilot with your Microsoft Entra ID, you get commercial data protection for free—which means chat data isn’t saved, Microsoft has no eyes-on access, and your data isn’t used to train the models.\nCopilot Pro provides priority access to the very latest models—starting with OpenAI’s GPT-4 Turbo. You’ll have access to GPT-4 Turbo during peak times for faster performance and, coming soon, the ability to toggle between models to optimize your experience how you choose. Microsoft 365 Personal and Family subscribers can use Copilot in Word, Excel (currently in Preview and English only), PowerPoint, Outlook, OneNote on PC, and soon on Mac and iPad. It includes enhanced AI image creation with Designer (formerly Bing Image Creator) for faster, more detailed image quality as well as landscape image format. And Copilot Pro gives you the ability to build your own Copilot GPT—a pre-customized Copilot tailored for a specific topic—in our new Copilot GPT Builder (coming soon) with just a simple set of prompts.\nWhile Copilot Pro is our best experience for individuals, Copilot for Microsoft 365 is our best experience for organizations. Copilot for Microsoft 365 gives you the same priority access to the very latest models. You get Copilot in Word, Excel, PowerPoint, Outlook, OneNote, and Microsoft Teams—combined with your universe of data in the Microsoft Graph. It has enterprise-grade data protection which means it inherits your existing Microsoft 365 security, privacy, identity, and compliance policies. And it also includes Copilot Studio, so organizations can customize Copilot for Microsoft 365 and build their own custom copilots and plugins as well as manage and secure their customizations and standalone copilots with the right access, data, user controls, and analytics.\nHere’s a summary of the updated Copilot product line-up:\nNo seat minimum and expanded availability of Copilot for Microsoft 365—including small and medium-sized businesses\nTo empower every organization to become AI-powered, we are making three changes. First, we are removing the 300-seat purchase minimum for Copilot for Microsoft 365 commercial plans. Second, we are removing the Microsoft 365 prerequisite for Copilot—so now, Office 365 E3 and E5 customers are eligible to purchase. We’re also extending Semantic Index for Copilot to Office 365 users with a paid Copilot license. Semantic Index works with the Copilot System and the Microsoft Graph to create a sophisticated map of all the data and content in your organization—enabling Microsoft 365 Copilot to deliver personalized, relevant, and actionable responses. Third, we are excited to announce that Copilot for Microsoft 365 is now generally available for small and medium-sized businesses—from solopreneurs running and launching their first business to 300-person fast-growing startups. If you are using either Microsoft 365 Business Standard or Microsoft 365 Business Premium, you can now purchase Copilot for Microsoft 365 for $30 per user per month.1\nSmall and medium-sized businesses are the heart of every community and the lifeblood of local economies. They have an outsized impact on the world and markets they support—in the United States, this category accounts for 99.9% of business and employs nearly half of the workforce.2\nThese businesses stand to gain the most from this era of generative AI—and Copilot is uniquely suited to meet their needs. Small and medium-sized business owners report that communicating with customers takes up most of their time (66%), with managing budgets (50%) and administrative tasks (48%) not far behind.3 Copilot for Microsoft 365 can help reduce this daily grind, giving business owners valuable time back to focus on what matters most: growing their business. And with the Microsoft Copilot Copyright Commitment, small business owners can trust that they are working with a reliable partner. Small and medium-sized business customers that have Microsoft 365 Business Standard or Business Premium can learn how to purchase Copilot for Microsoft 365 via our website or by contacting a partner.\n“I love that it’s in our environment. It’s able to cross-pollinate and gather information from all of the data we’ve got in Microsoft 365. As a business owner, that’s really important to me because it keeps our people working inside our systems.”\n—James Hawley, CEO and Founder at NextPath Career Partners\n“I do believe that there isn’t a single job position in the company that won’t benefit in some way from Copilot being available to them.”\n—Alex Wood, Senior Cloud Engineer at Floww\n“Copilot accurately summarizes the call and meeting notes in minutes. That’s not just faster, it means callers can add more value to the discussion rather than just take notes.”\n—Philip Burridge, Director, Operations and Strategy at Morula Health\nEmpowering partners to help every customer become AI-powered\nNext steps for Microsoft 365\nThese announcements come just one month after we announced that we are making Copilot for Microsoft 365 generally available to education customers with Microsoft 365 A3 or A5 faculty, and we’re expanding that to include Office 365 A3 or A5 faculty with no seat minimum. While education licenses are not yet included in the CSP expansion announced today, we will share updates in the coming months. It’s all part of our vision to empower everyone—from individuals to global enterprises—for an AI-powered world.\nVisit WorkLab for critical research and insights on how generative AI is transforming work.\nCopilot helps you achieve things like never before using the power of AI.\n1Copilot for Microsoft 365 may not be available for all markets and languages. To purchase, enterprise customers must have a license for Microsoft 365 E3 or E5 or Office 365 E3 or E5, and business customers must have a license for Microsoft 365 Business Standard or Business Premium.\nCopilot is currently supported in the following languages: English (US, GB, AU, CA, IN), Spanish (ES, MX), Japanese, French (FR, CA), German, Portuguese (BR), Italian, and Chinese Simplified. We plan to support the following languages (in alphabetical order) over the first half of 2024: Arabic, Chinese Traditional, Czech, Danish, Dutch, Finnish, Hebrew, Hungarian, Korean, Norwegian, Polish, Portuguese (PT), Russian, Swedish, Thai, Turkish, and Ukrainian.\n2U.S. Small Business Administration. (2023). Frequently Asked Questions.\n3Wakefield Research. (2023). Microsoft study: Small businesses intrigued by AI and the opportunities it brings.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Octo Tempest crosses boundaries to facilitate extortion, encryption, and destruction",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/10/25/octo-tempest-crosses-boundaries-to-facilitate-extortion-encryption-and-destruction/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNHRhR2RtTTNjMk5FOVdibFJLVFJDM0FSaVRBaWdCTWdrQlpZeXVKU2l4alFF=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-10-25T07:00:00.000Z",
    "time": "Oct 25, 2023",
    "articleType": "regular",
    "content": "Microsoft has been tracking activity related to the financially motivated threat actor Octo Tempest, whose evolving campaigns represent a growing concern for organizations across multiple industries. Octo Tempest leverages broad social engineering campaigns to compromise organizations across the globe with the goal of financial extortion. With their extensive range of tactics, techniques, and procedures (TTPs), the threat actor, from our perspective, is one of the most dangerous financial criminal groups.\nOcto Tempest is a financially motivated collective of native English-speaking threat actors known for launching wide-ranging campaigns that prominently feature adversary-in-the-middle (AiTM) techniques, social engineering, and SIM swapping capabilities. Octo Tempest, which overlaps with research associated with 0ktapus, Scattered Spider, and UNC3944, was initially seen in early 2022, targeting mobile telecommunications and business process outsourcing organizations to initiate phone number ports (also known as SIM swaps). Octo Tempest monetized their intrusions in 2022 by selling SIM swaps to other criminals and performing account takeovers of high-net-worth individuals to steal their cryptocurrency.\nFigure 1. The evolution of Octo Tempest’s targeting, actions, outcomes, and monetization\nBuilding on their initial success, Octo Tempest harnessed their experience and acquired data to progressively advance their motives, targeting, and techniques, adopting an increasingly aggressive approach. In late 2022 to early 2023, Octo Tempest expanded their targeting to include cable telecommunications, email, and technology organizations. During this period, Octo Tempest started monetizing intrusions by extorting victim organizations for data stolen during their intrusion operations and in some cases even resorting to physical threats.\nIn mid-2023, Octo Tempest became an affiliate of ALPHV/BlackCat, a human-operated ransomware as a service (RaaS) operation, and initial victims were extorted for data theft (with no ransomware deployment) using ALPHV Collections leak site. This is notable in that, historically, Eastern European ransomware groups refused to do business with native English-speaking criminals. By June 2023, Octo Tempest started deploying ALPHV/BlackCat ransomware payloads (both Windows and Linux versions) to victims and lately has focused their deployments primarily on VMWare ESXi servers. Octo Tempest progressively broadened the scope of industries targeted for extortion, including natural resources, gaming, hospitality, consumer products, retail, managed service providers, manufacturing, law, technology, and financial services.\nIn recent campaigns, we observed Octo Tempest leverage a diverse array of TTPs to navigate complex hybrid environments, exfiltrate sensitive data, and encrypt data. Octo Tempest leverages tradecraft that many organizations don’t have in their typical threat models, such as SMS phishing, SIM swapping, and advanced social engineering techniques. This blog post aims to provide organizations with an insight into Octo Tempest’s tradecraft by detailing the fluidity of their operations and to offer organizations defensive mechanisms to thwart the highly motivated financial cybercriminal group.\nThe well-organized, prolific nature of Octo Tempest’s attacks is indicative of extensive technical depth and multiple hands-on-keyboard operators. The succeeding sections cover the wide range of TTPs we observed being used by Octo Tempest.\nFigure 2. Octo Tempest TTPs\nOcto Tempest commonly launches social engineering attacks targeting technical administrators, such as support and help desk personnel, who have permissions that could enable the threat actor to gain initial access to accounts. The threat actor performs research on the organization and identifies targets to effectively impersonate victims, mimicking idiolect on phone calls and understanding personal identifiable information to trick technical administrators into performing password resets and resetting multifactor authentication (MFA) methods. Octo Tempest has also been observed impersonating newly hired employees in these attempts to blend into normal on-hire processes.\nOcto Tempest primarily gains initial access to an organization using one of several methods:\nCalling an employee and socially engineering the user to either:\nInstall a Remote Monitoring and Management (RMM) utility\nNavigate to a site configured with a fake login portal using an adversary-in-the-middle toolkit\nCalling an organization’s help desk and socially engineering the help desk to reset the user’s password and/or change/add a multi-factor authentication token/factor\nPurchasing an employee’s credentials and/or session token(s) on a criminal underground market\nSMS phishing employee phone numbers with a link to a site configured with a fake login portal using an adversary-in-the-middle toolkit\nUsing the employee’s pre-existing access to mobile telecommunications and business process outsourcing organizations to initiate a SIM swap or to set up call number forwarding on an employee’s phone number. Octo Tempest will initiate a self-service password reset of the user’s account once they have gained control of the employee’s phone number.\nIn rare instances, Octo Tempest resorts to fear-mongering tactics, targeting specific individuals through phone calls and texts. These actors use personal information, such as home addresses and family names, along with physical threats to coerce victims into sharing credentials for corporate access.\nFigure 3. Threats sent by Octo Tempest to targets\nCrossing borders for identity, architecture, and controls enumeration\nIn the early stage of their attacks, Octo Tempest performs various enumeration and information gathering actions to pursue advanced access in targeted environments and abuses legitimate channels for follow-on actions later in the attack sequence. Initial bulk-export of users, groups, and device information is closely followed by enumerating data and resources readily available to the user’s profile within virtual desktop infrastructure or enterprise-hosted resources.\nFrequently, Octo Tempest uses their access to carry out broad searches across knowledge repositories to identify documents related to network architecture, employee onboarding, remote access methods, password policies, and credential vaults.\nOcto Tempest then performs exploration through multi-cloud environments enumerating access and resources across cloud environments, code repositories, server and backup management infrastructure, and others. In this stage, the threat actor validates access, enumerates databases and storage containers, and plans footholds to aid further phases of the attack.\nPingCastle and ADRecon to perform reconnaissance of Active Directory\nAdvanced IP Scanner to probe victim networks\nGovmomi Go library to enumerate vCenter APIs\nPureStorage FlashArray PowerShell module to enumerate storage arrays\nAAD bulk downloads of user, groups, and devices\nPrivilege escalation and credential access\nOcto Tempest commonly elevates their privileges within an organization through the following techniques:\nUsing their pre-existing access to mobile telecommunications and business process outsourcing organizations to initiate a SIM swap or to set up call number forwarding on an employee’s phone number. Octo Tempest will initiate a self-service password reset of the user’s account once they have gained control of the employee’s phone number.\nSocial engineering – calling an organization’s help desk and socially engineering the help desk to reset an administrator’s password and/or change/add a multi-factor authentication token/factor\nFurther masquerading and collection for escalation\nOcto Tempest employs an advanced social engineering strategy for privilege escalation, harnessing stolen password policy procedures, bulk downloads of user, group, and role exports, and their familiarity with the target organizations procedures. The actor’s privilege escalation tactics often rely on building trust through various means, such as leveraging possession of compromised accounts and demonstrating an understanding of the organization’s procedures. In some cases, they go as far as bypassing password reset procedures by using a compromised manager’s account to approve their requests.\nOcto Tempest continually seeks to collect additional credentials across all planes of access. Using open-source tooling like Jercretz and TruffleHog, the threat actor automates the identification of plaintext keys, secrets, and credentials across code repositories for further use.\nModifying access policies or using MicroBurst to gain access to credential stores\nUsing open-source tooling: Mimikatz, Hekatomb, Lazagne, gosecretsdump, smbpasswd.py, LinPEAS, ADFSDump\nUsing VMAccess Extension to reset passwords or modify configurations of Azure VMs\nCreating snapshots virtual domain controller disks to download and extract NTDS.dit\nAssignment of User Access Administrator role to grant Tenant Root Group management scope\nOcto Tempest compromises security personnel accounts within victim organizations to turn off security products and features and attempt to evade detection throughout their compromise. Using compromised accounts, the threat actor leverages EDR and device management technologies to allow malicious tooling, deploy RMM software, remove or impair security products, data theft of sensitive files (e.g. files with credentials, signal messaging databases, etc.), and deploy malicious payloads.\nTo prevent identification of security product manipulation and suppress alerts or notifications of changes, Octo Tempest modifies the security staff mailbox rules to automatically delete emails from vendors that may raise the target’s suspicion of their activities.\nFigure 4. Inbox rule created by Octo Tempest to delete emails from vendors\nUsing open-source tooling like privacy.sexy framework to disable security products\nEnrolling actor-controlled devices into device management software to bypass controls\nConfiguring trusted locations in Conditional Access Policies to expand access capabilities\nReplaying harvested tokens with satisfied MFA claims to bypass MFA\nSustained intrusion with identities and open-source tools\nOcto Tempest leverages publicly available security tools to establish persistence within victim organizations, largely using account manipulation techniques and implants on hosts. For identity-based persistence, Octo Tempest targets federated identity providers using tools like AADInternals to federate existing domains, or spoof legitimate domains by adding and then federating new domains. The threat actor then abuses this federation to generate forged valid security assertion markup language (SAML) tokens for any user of the target tenant with claims that have MFA satisfied, a technique known as Golden SAML. Similar techniques have also been observed using Okta as their source of truth identity provider, leveraging Okta Org2Org functionality to impersonate any desired user account.\nTo maintain access to endpoints, Octo Tempest installs a wide array of legitimate RMM tools and makes required network modifications to enable access. The usage of reverse shells is seen across Octo Tempest intrusions on both Windows and Linux endpoints. These reverse shells commonly initiate connections to the same attacker infrastructure that deployed the RMM tools.\nFigure 5. Reverse shellcode used by Octo Tempest\nA unique technique Octo Tempest uses is compromising VMware ESXi infrastructure, installing the open-source Linux backdoor Bedevil, and then launching VMware Python scripts to run arbitrary commands against housed virtual machines.\nUsage of open-source tooling: ScreenConnect, FleetDeck, AnyDesk, RustDesk, Splashtop, Pulseway, TightVNC, LummaC2, Level.io, Mesh, TacticalRMM, Tailscale, Ngrok, WsTunnel, Rsocx, and Socat\nDeployment of Azure virtual machines to enable remote access via RMM installation or modification to existing resources via Azure serial console\nAddition of MFA methods to existing users\nUsage of the third-party tunneling tool Twingate, which leverages Azure Container instances as a private connector (without public network exposure)\nCommon trifecta: Data theft, extortion, and ransomware\nThe goal of Octo Tempest remains financially motivated, but the monetization techniques observed across industries vary between cryptocurrency theft and data exfiltration for extortion and ransomware deployment.\nLike in most cyberattacks, data theft largely depends on the data readily available to the threat actor. Octo Tempest accesses data from code repositories, large document management and storage systems, including SharePoint, SQL databases, cloud storage blobs/buckets, and email, using legitimate management clients such as DBeaver, MongoDB Compass, Azure SQL Query Editor, and Cerebrata for the purpose of connection and collection. After data harvesting, the threat actor employs anonymous file-hosting services, including GoFile.io, shz.al, StorjShare, Temp.sh, MegaSync, Paste.ee, Backblaze, and AWS S3 buckets for data exfiltration.\nOcto Tempest employs a unique technique using the data movement platform Azure Data Factory and automated pipelines to extract data to external actor hosted Secure File Transfer Protocol (SFTP) servers, aiming to blend in with typical big data operations. Additionally, the threat actor commonly registers legitimate Microsoft 365 backup solutions such as Veeam, AFI Backup, and CommVault to export the contents of SharePoint document libraries and expedite data exfiltration.\nRansomware deployment closely follows data theft objectives. This activity targets both Windows and Unix/Linux endpoints and VMware hypervisors using a variant of ALPHV/BlackCat. Encryption at the hypervisor level has shown significant impact to organizations, making recovery efforts difficult post-encryption.\nOcto Tempest frequently communicates with target organizations and their personnel directly after encryption to negotiate or extort the ransom—providing “proof of life” through samples of exfiltrated data. Many of these communications have been leaked publicly, causing significant reputational damage to affected organizations.\nUse of the third-party services like FiveTran to extract copies of high-value service databases, such as SalesForce and ZenDesk, using API connectors\nExfiltration of mailbox PST files and mail forwarding to external mailboxes\nOcto Tempest’s utilization of social engineering, living-off-the land techniques, and diverse toolsets could make hunting slightly unorthodox. Following these general guidelines alongside robust deconfliction with legitimate users will surface their activity:\nUnderstand authentication flows in the environment.\nCentralize visibility of administrative changes in the environment into a single pane of glass.\nScrutinize all user and sign-in risk detections for any administrator within the timeframe. Common alerts that are surfaced during an Octo Tempest intrusion include (but not limited to): Impossible Travel, Unfamiliar Sign-in Properties, and Anomalous Token\nReview the coverage of Conditional Access policies; scrutinize the use of trusted locations and exclusions.\nReview all existing and new custom domains in the tenant, and their federation settings.\nScrutinize administrator groups, roles, and privileges for recent modification.\nReview recently created Microsoft Entra ID users and registered device identities.\nLook for any anomalous pivots into organizational apps that may hold sensitive data, such as Microsoft SharePoint and OneDrive.\nLeverage and continuously monitor Defender for Cloud for Azure Workloads, providing a wealth of information around unauthorized resource access.\nReview Azure role-based access control (RBAC) definitions across the management group, subscription, resource group and resource structure.\nReview the public network exposure of resources and revoke any unauthorized modifications.\nReview both data plane and management plane access control for all critical workloads such as those that hold credentials and organizational data, like Key Vaults, storage accounts, and database resources.\nTightly control access to identity workloads that issue access organizational resources such as Active Directory Domain Controllers.\nReview the Azure Activity log for anomalous modification of resources.\nLook for recent additions to the indicators or exclusions of the EDR solution in place at the organization.\nReview any generation of offboarding scripts.\nReview access control within security products and EDR software suites.\nScrutinize any tools used to manage endpoints (SCCM, Intune, etc.) and look for recent rule additions, packages, or deployments.\nScrutinize use of remote administration tools across the environment, paying particular attention to recent installations regardless of whether they are used legitimately within the network already.\nEnsure monitoring at the network boundary is in place, that alerting is in place for connections with common anonymizing services and scrutinize the use of these services.\nDefending against Octo Tempest activity\nAlign privilege in Microsoft Entra ID and Azure\nPrivileges spanning Microsoft Entra ID and Azure need to be holistically aligned, with purposeful design decisions to prevent unauthorized access to critical workloads. Reducing the number of users with permanently assigned critical roles is paramount to achieving this. Segregation of privilege between on-premises and cloud is also necessary to sever the ability to pivot within the environment.\nIt is highly recommended to implement Microsoft Entra Privileged Identity Management (PIM) as a central location for the management of both Microsoft Entra ID roles and Azure RBAC. For all critical roles, at minimum:\nImplement role assignments as eligible rather than permanent.\nReview and understand the role definition Actions and NotActions – ensure to select only the roles with actions that the user requires to do their role (least privileged access).\nConfigure these roles to be time-bound, deactivating after a specific timeframe.\nRequire users to perform MFA to elevate to the role.\nOptionally require users to provide justification or a ticket number upon elevation.\nEnable notifications for privileged role elevation to a subset of administrators.\nUtilize PIM Access Reviews to reduce standing access in the organization on a periodic basis.\nEvery organization is different and, therefore, roles will be classified differently in terms of their criticality. Consider the scope of impact those roles may have on downstream resources, services, or identities in the event of compromise. For help desk administrators specifically, ensure to scope privilege to exclude administrative operations over Global Administrators. Consider implementing segregation strategies such as Microsoft Entra ID Administrative Units to segment administrative access over the tenant. For identities that leverage cross-service roles such as those that service the Microsoft Security Stack, consider implementing additional service-based granular access control to restrict the use of sensitive functionality, like Live Response and modification of IOC allow lists.\nFor organizations yet to begin or are early in their modernization journey, end-to-end guidance for cloud adoption is available through the Microsoft Azure Cloud Adoption Framework. Recommended practice and security are central pillars—Azure workloads are segregated into separate, tightly restricted areas known as landing zones. When deploying Active Directory in the cloud, it is advised to create a platform landing zone for identity—a dedicated subscription to hold all Identity-related resources such as Domain Controller VM resources. Employ least privilege across this landing zone with the aforementioned privilege and PIM guidance for Azure RBAC.\nImplement Conditional Access policies and authentication methods\nTTPs outlined in this blog leverage strategies to evade multifactor authentication defenses. However, it is still strongly recommended to practice basic security hygiene by implementing a baseline set of Conditional Access policies:\nRequire multifactor authentication for all privileged roles with the use of authentication strengths to enforce phish-resistant MFA methods such as FIDO2 security keys\nRequire phishing-resistant multifactor authentication for administrators\nEnforce MFA registration from trusted locations from a device that also meets organizational requirements with Intune device compliance policies\nUser and sign-in risk policies for signals associated to Microsoft Entra ID Protection\nOrganizations are recommended to keep their policies as simple as possible. Implementing complex policies might inhibit the ability to respond to threats at a rapid pace or allow threat actors to leverage misconfigurations within the environment.\nDevelop and maintain a user education strategy\nAn organization’s ability to protect itself against cyberattacks is only as strong as its people—it is imperative to put in place an end-to-end cybersecurity strategy highlighting the importance of ongoing user education and awareness. Targeted education and periodic security awareness campaigns around common cyber threats and attack vectors such as phishing and social engineering not only for users that hold administrative privilege in the organization, but the wider user base is crucial. A well-maintained incident response plan should be developed and refined to enable organizations to respond to unexpected cybersecurity events and rapidly regain positive control.\nOcto Tempest has been observed joining, recording, and transcribing calls using tools such as OtterAI, and sending messages via Slack, Zoom, and Microsoft Teams, taunting and threatening targets, organizations, defenders, and gaining insights into incident response operations/planning. Using out-of-band communication channels is strongly encouraged when dealing with this threat actor.\nNOTE: Several tools mentioned throughout this blog are remote administrator tools that have been utilized by Octo Tempest to maintain persistence. While these tools are abused by threat actors, they can have legitimate use cases by normal users, and are updated on a frequent basis. Microsoft recommends monitoring their use within the environment, and when they are identified, defenders take the necessary steps for deconfliction to verify their use.\nMicrosoft Defender Antivirus detects this threat as the following malware:\nTurning on tamper protection, which is part of built-in protection, prevents attackers from stopping security services.\nThe following Microsoft Defender for Endpoint alerts can indicate associated threat activity:\nThe following alerts might also indicate threat activity related to this threat. Note, however, that these alerts can also be triggered by unrelated threat activity.\nSuspicious usage of remote management software\nActivity linked to BlackCat ransomware\nTampering activity typical to ransomware attacks\nMicrosoft Defender for Cloud Apps\nUsing Microsoft Defender for Cloud Apps connectors, Microsoft 365 Defender raises AitM-related alerts in multiple scenarios. For Microsoft Entra ID customers using Microsoft Edge, attempts by attackers to replay session cookies to access cloud applications are detected by Microsoft 365 Defender through Defender for Cloud Apps connectors for Microsoft Office 365 and Azure. In such scenarios, Microsoft 365 Defender raises the following alerts:\nBackdoor creation using AADInternals tool\nSuspicious domain added to Microsoft Entra ID\nSuspicious domain trust modification following risky sign-in\nUser compromised via a known AitM phishing kit\nUser compromised in AiTM phishing attack\nSimilarly, the connector for Okta raises the following alerts:\nPossible AiTM phishing attempt in Okta\nMicrosoft Defender for Identity raises the following alerts for TTPs used by Octo Tempest such as NTDS stealing and Active Directory reconnaissance:\nUser and IP address reconnaissance (SMB)\nUser and Group membership reconnaissance (SAMR)\nSuspected DCSync attack (replication of directory services)\nSuspected AD FS DKM key read\nThe following Microsoft Defender for Cloud alerts relate to TTPs used by Octo Tempest. Note, however, that these alerts can also be triggered by unrelated threat activity.\nMicroBurst exploitation toolkit used to enumerate resources in your subscriptions\nMicroBurst exploitation toolkit used to execute code on your virtual machine\nMicroBurst exploitation toolkit used to extract keys from your Azure key vaults\nMicroBurst exploitation toolkit used to extract keys to your storage accounts\nSuspicious Azure role assignment detected\nSuspicious elevate access operation (Preview)\nSuspicious invocation of a high-risk ‘Initial Access’ operation detected (Preview)\nSuspicious invocation of a high-risk ‘Credential Access’ operation detected (Preview)\nSuspicious invocation of a high-risk ‘Data Collection’ operation detected (Preview)\nSuspicious invocation of a high-risk ‘Execution’ operation detected (Preview)\nSuspicious invocation of a high-risk ‘Impact’ operation detected (Preview)\nSuspicious invocation of a high-risk ‘Lateral Movement’ operation detected (Preview)\nUnusual user password reset in your virtual machine\nSuspicious usage of VMAccess extension was detected on your virtual machines (Preview)\nSuspicious usage of multiple monitoring or data collection extensions was detected on your virtual machines (Preview)\nRun Command with a suspicious script was detected on your virtual machine (Preview)\nSuspicious Run Command usage was detected on your virtual machine (Preview)\nSuspicious unauthorized Run Command usage was detected on your virtual machine (Preview)\nMicrosoft Sentinel customers can use the following Microsoft Sentinel Analytics template to identify potential AitM phishing attempts:\nPossible AitM Phishing Attempt Against Azure AD\nThis detection uses signals from Microsoft Entra ID Identity Protection and looks for successful sign-ins that have been flagged as high risk. It combines this with data from web proxy services, such as ZScaler, to identify where users might have connected to the source of those sign-ins immediately prior. This can indicate a user interacting with an AitM phishing site and having their session hijacked. This detection uses the Advanced Security Information Model (ASIM) Web Session schema. Refer to this article for more details on the schema and its requirements.\nMicrosoft customers can use the following reports in Microsoft products to get the most up-to-date information about the threat actor, malicious activity, and techniques discussed in this blog. These reports provide the intelligence, protection info, and recommended actions to prevent, mitigate, or respond to associated threats found in customer environments.\nOcto Tempest uses social engineering and AADInternals to compromise cloud identities\nMicrosoft 365 Defender Threat analytics\nThreat insights: Octo Tempest uses social engineering and AADInternals to compromise cloud identities\nMicrosoft Sentinel customers can use the TI Mapping analytics (a series of analytics all prefixed with ‘TI map’) to automatically match the malicious domain indicators mentioned in this blog post with data in their workspace. If the TI Map analytics are not currently deployed, customers can install the Threat Intelligence solution from the Microsoft Sentinel Content Hub to have the analytics rule deployed in their Sentinel workspace.\nMicrosoft Sentinel also has a range of detection and threat hunting content that customers can use to detect the post exploitation activity detailed in this blog in addition to Microsoft 365 Defender detections list above.\nSuspicious sign-in followed by MFA modification\nOkta login from different locations\nSharePointFileOperation via clientIP with previously unseen user agents\nSharePointFileOperation via devices with previously unseen user agents\nSharePointFileOperation via previously unseen IPs of risky ASN’s\nSharePointFileOperation via previously unseen IPs\nNew external user granted admin\nAnomolous sign-ins based on time\nNew account added to admin group\nAuthentication methods changed for privileged account\nRare run command PowerShell script\nRare operations of create and update of snapshots\nAnomalous listing of storage keys\nPotential Microsoft Security services tampering\nMultiple users Office mail forwarding\nListen to Microsoft experts discuss Octo Tempest TTPs and activities on The Microsoft Threat Intelligence Podcast.\nVisit this page for more blogs from Microsoft Incident Response.\nFor more security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.\nNovember 1, 2023 update: Updated the Actions of objectives section to fix the list of anonymous file-hosting services used by Octo Tempest for data exfiltration, which incorrectly listed Sh.Azl. It has been corrected to shz.al.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Introducing Microsoft Copilot for Finance – the newest Copilot offering in Microsoft 365 designed to transform modern finance",
    "link": "https://blogs.microsoft.com/blog/2024/02/29/introducing-microsoft-copilot-for-finance-the-newest-copilot-offering-in-microsoft-365-designed-to-transform-modern-finance/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNWpSWFl3U3pKNWVreEVka1kyVFJDM0FSaVRBaWdCTWdtVllZaElOcVk5Q1FJ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-02-29T08:00:00.000Z",
    "time": "Feb 29",
    "articleType": "regular",
    "content": "Today we’re announcing the public preview of Microsoft Copilot for Finance, the newest Copilot offering designed for business functions that extends Microsoft Copilot for Microsoft 365 and revolutionizes how finance teams approach their daily work. Copilot for Finance joins Copilot for Sales and Copilot for Service, now generally available, to provide AI-powered, role-based workflow automation, recommendations and guided actions in the flow of work.\nFinance departments are critical partners in strategic decisions impacting the direction of a company. Eighty percent of finance leaders and teams face challenges to take on more strategic work outside the operational portions of their roles[1]. However, 62% of finance professionals say they are stuck in the drudgery of data entry and review cycles [2]. Copilot for Finance can help free up time for finance to play more of a strategic role in delivering counsel and insights to the business by streamlining financial tasks, automating workflows and providing insights in the flow of work.\nCopilot for Finance includes Copilot for Microsoft 365, which means it supercharges Excel, Outlook and other widely used productivity apps with workflow and data-specific insights for the finance professional. Copilot for Finance draws on essential context from your existing financial data sources, including traditional Enterprise Resource Planning (ERP) systems, such as Microsoft Dynamics 365 and SAP, and the Microsoft Graph.\nIn public preview today, Copilot for Finance introduces several key features to enhance financial operations:\nHelps financial analysts quickly conduct a variance analysis in Excel using natural language prompts to review data sets for anomalies, risks and unmatched values. This type of analysis helps finance provide strategic insights to business leaders about where it is meeting, exceeding or falling short of planned financial outcomes and why.\nSimplifies the reconciliation process in Excel with automated data structure comparisons and guided troubleshooting to help move from insight to action, which helps ensure the reliability and accuracy of financial records.\nProvides a complete summary of relevant customer account details in Outlook, such as balance statements and invoices, to expedite the collections process.\nEnables customers to turn raw data in Excel into presentation-ready visuals and reports ready to be shared across Outlook and Teams.\nCustomers transforming business operations with Microsoft Copilot\nThe Copilot offerings designed for business functions help workers tackle a common problem: getting from insights to impact – with the relevant data and workflows specific to their roles. The latest Work Trend Index survey revealed that people are drowning in data. Roughly a quarter of their day is spent searching for information – roughly 50% of the information they consume each day is deemed necessary for their job, and a recent survey found roles like sales, finance and supply chain have role-specific needs from their data.\nCopilot helps break down information and application silos while actively deriving insights, recommendations and guidance from a variety of data sources — all in accordance with Microsoft’s responsible AI principles. With Microsoft Copilot Studio, businesses can further customize Copilot for business processes inside of Copilot for Microsoft 365 and its role-based extensions.\nCopilot for Sales is already helping sellers at more than 30,000 organizations. Companies including dentsu, Lumen Technologies, Northern Trust, Schneider Electric, Visa and hundreds more are empowering their employees with Copilot across their sales, service and finance departments.\nHere is what a few of the companies had to say:\n“Artificial intelligence is transforming the way businesses operate and thrive. At dentsu, we are constantly searching for ways to bring the power of generative AI to all our employees with a framework defined on ethical and responsible AI principles. Building on the existing use cases we’ve defined to empower our workforce with Microsoft Copilot for Microsoft 365 and Microsoft Copilot for Sales, we are excited to participate in the preview of Microsoft Copilot for Finance. We see potential for Copilot for Finance to accelerate the impact of our finance professionals by optimizing routine processes, and we anticipate efficiency gains will free up finance capacity to focus on performance across our organization.” – Carolyn Isaacs, Global Director Finance Services, dentsu\n“Northern Trust’s digital workplace transformation is rooted in empowering our employees with technology that enhances and optimizes the services that they provide our clients. Deploying Microsoft Copilot for Service is a milestone in this transformation journey and we are excited for the potential of this AI-powered solution to help modernize our client relations organization, streamline processes for our employees, and elevate our client experience.” – Shaelyn Otikor SVP, Head of Global Digital Workplace Strategy, Asset Servicing, Northern Trust\n“Building on our 30-year history of embracing AI, Visa is on a journey to roll out generative AI across our entire company to empower our employees and develop new solutions to serve and protect our cardholders, merchants and the broader ecosystem. We’ve seen our employees embrace the broad rollout of Microsoft Copilot for Microsoft 365, and we’re excited to continue to bring employees new ways to take advantage of the technology, transforming the ways in which we work and how we service our clients.” – Don Hobson, Chief Information Officer, Visa\nAt Microsoft, we are also an AI-powered organization, leveraging Copilot for Sales and Copilot for Service to improve seller and agent workflows and transform customer experiences:\nMicrosoft Copilot for Sales empowers sellers to close deals faster with AI-assisted insights and recommendations. Our study of Microsoft sellers who use Copilot for Sales at least weekly found it makes them more productive, saving an average of 90 minutes per week – and 67% reported it allowed them to spend more time with customers.\n“We have seen firsthand that an AI-powered sales organization is a more successful sales organization. Not only has Copilot for Sales helped our global sales team simplify tasks and save time, but it has also strengthened our customer relationships with AI-supported insights and recommendations that are personalized and tailored to each customer.” – Judson Althoff, Microsoft EVP and Chief Commercial Officer\nMicrosoft Copilot for Service is modernizing the contact center with AI to enhance service experiences and boost agent productivity. In Microsoft’s customer service department – one of the largest in the world – there has been a 12% reduction in average case handling times (the time actively spent on resolving customer cases via chat) in two different customer support business areas while using similar capabilities in Copilot in Dynamics 365 Customer Service. The benefits and use cases from our own Copilot deployment will continue to shape Copilot for Service and its capabilities.\n“Generative AI has been a game-changer for our own contact center at Microsoft. Agents spend less time searching for information, allowing them to focus more time on helping customers solve complex challenges. Moreover, newer agents experience significant benefits, feeling more confident and capable in their roles. This has led to reduced onboarding times and increased job satisfaction.” – Mala Anand, Microsoft CVP Customer Experience & Success\nMicrosoft Copilot for Finance streamlines financial processes and surfaces insights for better-informed decision making. Microsoft’s world-class finance organization has long prioritized adoption of AI and automation tools to modernize operations, reduce financial risk and support the company’s priorities with strategic insights. The team has helped inform the Copilot for Finance product capabilities and roadmap.\n“Our finance organization is just like any other – looking for technology to help us do our work in a more efficient and impactful way – and we’re excited to track our journey as customer zero of Microsoft Copilot for Finance” – Cory Hrncirik, Modern Finance Lead, Microsoft\nCompanies of all sizes are moving beyond AI experimentation and embracing Microsoft Copilot to strategically empower those closest to their customer interactions and critical operations to create new business value. To get started with the new Copilot for Finance, visit: aka.ms/CopilotforFinancePreview.\n[1] Future of Finance Trends | Microsoft Dynamics 365\n[2] Metric of the Month: Time Allocation in Finance | CFO\nTags: AI, Copilot for Finance, Copilot for Microsoft 365",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Microsoft Ignite 2023: AI transformation and the technology driving change",
    "link": "https://blogs.microsoft.com/blog/2023/11/15/microsoft-ignite-2023-ai-transformation-and-the-technology-driving-change/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVVaMVJaU1cxVFJuSm9iR1IxVFJDb0FSaXNBaWdCTWdhQmg1SmtNZ2M=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-11-15T08:00:00.000Z",
    "time": "Nov 15, 2023",
    "articleType": "regular",
    "content": "As we reach the end of 2023, nearly every industry is undergoing a collective transformation – discovering entirely new ways of working due to AI advancements.\nMicrosoft Ignite is a showcase of the advances being developed to help customers, partners and developers achieve the total value of Microsoft’s technology and reshape the way work is done.\nAs we round out the year, there are strong signals of AI’s potential to transform work. Take our latest Work Trend Index. Eight months ago, we introduced Copilot for Microsoft 365 to reduce digital debt and increase productivity so people can focus on the work that is uniquely human. What everyone wants to know now is: Will Copilot really change work, and how? Our research, using a combination of surveys and experiments, shows the productivity gains are real:\n70% of Copilot users said they were more productive and 68% said it improved the quality of their work; 68% say it helped jumpstart the creative process.\nOverall, users were 29% faster at specific tasks (searching, writing and summarizing).\nUsers caught up on a missed meeting nearly 4x faster.\n64% of users said Copilot helps them spend less time processing email.\n87% of users said Copilot makes it easier to get started on a first draft.\n75% of users said Copilot “saves me time by finding whatever I need in my files.”\n77% of users said once they use Copilot, they don’t want to give it up.\nToday, we will make about 100 news announcements that touch on multiple layers of an AI-forward strategy, from adoption to productivity to security. We’ll zoom in on a few key areas of impact below.\nMicrosoft has led with groundbreaking advances like partnerships with OpenAI and the integration of ChatGPT capabilities into tools used to search, collaborate, work and learn. As we accelerate further into AI, Microsoft is rethinking cloud infrastructure to ensure optimization across every layer of the hardware and software stack.\nAt Ignite we are announcing new innovations across our datacenter fleet, including the latest AI optimized silicon from our industry partners and two new Microsoft-designed chips.\nMicrosoft Azure Maia, an AI Accelerator chip designed to run cloud-based training and inferencing for AI workloads such as OpenAI models, Bing, GitHub Copilot and ChatGPT.\nMicrosoft Azure Cobalt, a cloud-native chip based on Arm architecture optimized for performance, power efficiency and cost-effectiveness for general purpose workloads.\nAdditionally, we are announcing the general availability of Azure Boost, a system that makes storage and networking faster by moving those processes off the host servers onto purpose-built hardware and software.\nComplementing our custom silicon, we are expanding partnerships with our silicon providers to provide infrastructure options for customers.\nWe’ll be adding AMD MI300X accelerated virtual machines (VMs) to Azure. The ND MI300 VMs are designed to accelerate the processing of AI workloads for high range AI model training and generative inferencing, and will feature AMD’s latest GPU, the AMD Instinct MI300X.\nThe preview of the new NC H100 v5 Virtual Machine Series built for NVIDIA H100 Tensor Core GPUs, offering greater performance, reliability and efficiency for mid-range AI training and generative AI inferencing. We’re also announcing plans for the ND H200 v5 Virtual Machine Series, an AI-optimized VM featuring the upcoming NVIDIA H200 Tensor Core GPU.\nExtending the Microsoft Copilot experience\nOver the past year we have continued to refine our vision for Microsoft Copilot, a set of tools that help people achieve more using AI. To go beyond individual productivity, we are extending Microsoft Copilot offerings across solutions to transform productivity and business processes for every role and function – from office workers and front-line workers to developers and IT professionals.\nMicrosoft is the Copilot company, and we believe in the future there will be a Copilot for everyone and for everything you do. Some of our Copilot-related announcements and updates include:\nMicrosoft Copilot Studio: AI transformation begins by tapping into an organization’s unique data and workflows. Microsoft Copilot Studio is a low-code tool designed to customize Microsoft Copilot for Microsoft 365 by integrating business-critical data and build custom copilots for internal or external use. Copilot Studio works with connectors, plugins and GPTs, allowing IT teams to steer Copilot to the best data sources for specific queries.\nMicrosoft Copilot for Service: The newest copilot to provide role-based support helps businesses accelerate their AI transformation of customer service. Copilot for Service includes Microsoft Copilot for Microsoft 365 and helps extend existing contact centers with generative AI. In customer interactions, agents can ask Copilot for Service questions in natural language and receive relevant insights based on data sources from knowledge repositories, leading to faster and smarter resolutions.\nCopilot in Microsoft Dynamics 365 Guides: Combining the power of generative AI and mixed reality, this copilot helps frontline workers complete complex tasks and resolve issues faster without disrupting workflow. Available first on HoloLens 2, the hands-free copilot will help service industry professionals use natural language and human gestures to offer interactive guidance through content and holograms overlaid on the equipment.\nMicrosoft Copilot for Azure: This is an AI companion for IT that simplifies day-to-day IT administration. More than just a tool, it is a unified chat experience that understands the user’s role and goals, and enhances the ability to design, operate and troubleshoot apps and infrastructure. Copilot for Azure helps IT teams gain new insights into their workloads, unlock untapped Azure functionality and orchestrate tasks across both cloud and edge.\nReinforcing the data and AI connection\nAI is only as good as the data that fuels it. That’s why Microsoft is committed to creating an integrated, simplified experience to connect your data to our AI tools.\nMicrosoft Fabric is part of that solution. Available now, Microsoft Fabric reshapes how teams work with data by bringing everyone together on a single, AI-powered platform that unifies all those data estates on an enterprise-grade data foundation.\nCopilot in Microsoft Fabric also integrates with Microsoft Office and Teams to foster a data culture to scale the power of data value creation throughout the organization. We’ve made more than 100 feature updates since Build and expanded our ecosystem with industry leading partners, and have over 25,000 customers including Milliman, Zeiss, London Stock Exchange and EY using it today.\nUnlocking more value for developers with Azure AI\nWe continue to expand choice and flexibility in generative AI models to offer developers the most comprehensive selection. With Model-as-a-Service, a new feature in the model catalog we announced at Microsoft Build, pro developers will be able to easily integrate the latest AI models, such as Llama 2 from Meta and upcoming premium models from Mistral, and Jais from G42, as API endpoints to their applications. They can also customize these models with their own data without needing to worry about setting up and managing the GPU infrastructure, helping eliminate complexity.\nWith the preview of Azure AI Studio, there is now a unified and trusted platform to help organizations more easily explore, build, test and deploy AI apps – all in one place. With Azure AI Studio, you can build your own copilots, train your own, or ground other foundational and open models with data that you bring.\nAnd Vector Search, a feature of Azure AI Search, is now generally available, so organizations can generate highly accurate experiences for every user in their generative AI applications.\nThe new GPT-3.5 Turbo model with a 16K token prompt length will be generally available and GPT-4 Turbo will be in public preview in Azure OpenAI Service at the end of November 2023. GPT-4 Turbo will enable customers to extend prompt length and bring even more control and efficiency to their generative AI applications.\nGPT-4 Turbo with Vision is coming soon to preview and DALL·E 3 is now available in public preview in Azure OpenAI Service, helping fuel the next generation of enterprise solutions along with GPT-4, so organizations can pursue advanced functionalities with images. And when used with our Azure AI Vision service, GPT-4 Turbo with Vision even understands video for generating text outputs, furthering human creativity.\nEnabling the responsible deployment of AI\nMicrosoft leads the industry in the safe and responsible use of AI. The company has set the standard with an industry-leading commitment to defend and indemnify commercial customers from lawsuits for copyright infringement – the Copilot Copyright Commitment (CCC).\nToday, Microsoft takes its commitment one step further by announcing the expansion of the CCC to customers using Azure OpenAI Service. The new benefit will be called the Customer Copyright Commitment. As part of this expansion, Microsoft has published new documentation to help Azure OpenAI Service customers implement technical measures to mitigate the risk of infringing content. Customers will need to comply with the documentation to take advantage of the benefit.\nAnd Azure AI Content Safety is now generally available, helping organizations detect and mitigate harmful content and create better online experiences. Customers can use Azure AI Content Safety as a built-in-safety system within Azure OpenAI Service, for open-source models as part of their prompt engineering in Azure Machine Learning, or as a standalone API service.\nIntroducing new experiences in Windows to empower employees, IT and developers\nWe continue to invest in and build Windows to empower people to navigate the platform shift to AI. We are thrilled to introduce new experiences in Windows 11 and Windows 365 for IT and employees that unlock new ways of working and make more AI accessible across any device. To further our mission of making Windows the home for developers and the best place for AI development, we announced a host of new AI and productivity tools for developers, including Windows AI Studio.\nAnnouncing NVIDIA AI foundry service\nAimed at helping enterprises and startups supercharge the development, tuning and deployment of their own custom AI models on Microsoft Azure, NVIDIA will announce their AI foundry service running on Azure. The NVIDIA AI foundry service pulls together three elements – a collection of NVIDIA AI Foundation models, NVIDIA NeMo framework and tools, and NVIDIA DGX Cloud AI supercomputing and services – that give enterprises an end-to-end solution for creating custom generative AI models. Businesses can then deploy their models with NVIDIA AI Enterprise software on Azure to power generative AI applications, including intelligent search, summarization and content generation.\nStrengthening defenses in the era of AI\nThe threat landscape has evolved dramatically in recent years, and at Microsoft Ignite we are introducing new technologies across Microsoft’s suite of security solutions to help defenders make the world a safer place.\nMicrosoft Sentinel and Microsoft Defender XDR (previously Microsoft 365 Defender) will be combined to create the industry’s first Unified Security Operations Platform, with embedded Security Copilot experiences. With built-in generative AI, it’s a single, powerful experience focused on protecting threats at machine speed and aiding defenders by simplifying the complexity of their environment.\nAdditionally, the expansion of Security Copilot embedded within Intune, Purview and Entra will help IT administrators, compliance units and identity teams simplify complex scenarios. In Entra, identity administrators can quickly troubleshoot identity access. In Purview, data security alerts deliver rich context to help resolve problems faster. In Intune, IT administrators can use “what if” analysis to keep business running while improving governance and compliance.\nAnd that’s just a snapshot of what we’ll be announcing at Ignite. As a reminder, you can view keynote sessions from Satya Nadella, Rajesh Jha and Jared Spataro, Charlie Bell and Vasu Jakkal, and Scott Guthrie live or on-demand.\nPlus, you can get more on all these announcements by exploring the Book of News, the official compendium of all today’s news, and the product blogs below.\nWatch the keynotes and get all the latest photos, videos and more from Microsoft Ignite\nThe online event for Microsoft Ignite\nWith a systems approach to chips, Microsoft aims to tailor everything ‘from silicon to service’ to meet AI demand\nIntroducing new Copilot experiences to boost productivity and elevate customer experiences across the organization\nSimplify IT management with Microsoft Copilot for Azure – save time and get answers fast\nIntroducing Microsoft Copilot Studio and new features in Copilot for Microsoft 365\nAnnouncing general availability of vector search and semantic ranker in Azure AI Search\nGPT-4 Turbo with Vision on Azure OpenAI Service\nHow Azure AI Content Safety helps protect users from the classroom to the chatroom\nElevating the developer experience on Windows with new AI tools and productivity tools\nMicrosoft unveils expansion of AI for security and security for AI at Microsoft Ignite\nTags: AI, Azure AI Content Safety, Azure AI Studio, Microsoft 365, Microsoft Copilot, Microsoft Fabric, Microsoft Ignite 2023, Microsoft Security Copilot, Model-as-a-Service",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Microsoft and Epic expand AI collaboration to accelerate generative AI’s impact in healthcare, addressing the industry’s most pressing needs",
    "link": "https://blogs.microsoft.com/blog/2023/08/22/microsoft-and-epic-expand-ai-collaboration-to-accelerate-generative-ais-impact-in-healthcare-addressing-the-industrys-most-pressing-needs/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNXBiSFpCZEhSNVRFdFlaUzFGVFJDM0FSaVRBaWdCTWdZMVJKQndIUWc=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-08-22T07:00:00.000Z",
    "time": "Aug 22, 2023",
    "articleType": "regular",
    "content": "|\t\t\t\t\tEric Boyd, Corporate Vice President, AI Platform, Microsoft\nToday, the promise of technology to help us solve some of the biggest challenges we face has never been more tangible, and nowhere is generative AI more needed, and possibly more impactful, than in healthcare. Epic and Microsoft have been paving the way to bring generative AI to the forefront of the healthcare industry. Together, we are working to help clinicians better serve their patients and are addressing some of the most urgent needs, from workforce burnout to staffing shortages.\nWe combined Microsoft’s large-scale cloud and AI technologies with Epic’s deep understanding of the healthcare industry and clinical workflows to address many current issues affecting clinicians. Today, we are announcing the expansion of our strategic initiative to bring AI to healthcare at scale, integrating conversational, ambient and generative AI technologies across the Epic electronic health record (EHR) ecosystem. Intended to speed development of solutions for healthcare’s most critical needs, the initiative will expand secure access to AI-powered clinical insights and administrative tools within a wide range of Epic modules to enhance patient care, increase operational efficiency, improve healthcare experiences, and support the financial integrity of health systems globally.\nWe are working together to rapidly deploy dozens of copilot solutions that securely unlock the potential value that the Microsoft Cloud and our AI technologies enable as health systems strive to overcome the urgent staffing, financial and clinical access challenges they face today. Epic will showcase many of these new capabilities that build on our Azure OpenAI Service and Nuance DAX Express solutions at its annual Users Group Meeting today, including:\nEnhancing clinician productivity with note summarization: Building on the previously announced AI-assisted Epic In Basket, the new solutions are targeted at increasing clinical efficiency for physicians and nurses, helping them become more productive in their daily clinical workflow. The solutions will help support faster documentation through suggested text and rapid review with in-context summaries.\nEnhancing clinician productivity with embedded ambient clinical documentation: Leveraging Nuance’s Dragon Ambient eXperience (DAX) technology, which is already deployed with hundreds of Epic customers and currently supporting thousands of physicians, Epic will showcase this DAX Express AI technology embedded into the native Epic Hyperdrive platform and Haiku mobile application, further enhancing a seamless workflow experience for users. In addition, Nuance has been named by Epic as one of the first Partners in Epic’s Partner and Pals third-party vendor program.\nDriving administrative efficiencies through reduction in manual, labor intensive processes: Revenue cycle management is one of many areas where generative AI can meaningfully improve efficiency. For example, Epic will demonstrate an AI-powered solution that provides medical coding staff with suggestions based on clinical documentation in the EHR to improve accuracy and streamline the entire coding and billing processes.\nAdvancing medicine for better patient outcomes: By using Azure OpenAI Service, Epic is now delivering generative AI exploration for an initial set of users via SlicerDicer to fill gaps in clinical evidence using real-world data and to study rare diseases and more.\nOur work to integrate Azure OpenAI Service and Nuance ambient technologies within the Epic ecosystem shows that broader strategic collaborations can rapidly accelerate the availability of actionable AI-driven solutions for healthcare organizations and the patients they serve.\nBy 2025, the U.S. Department of Health and Human Services predicts that there will be a nationwide shortage of 90,000 physicians. Additionally, 40% to 60% of clinicians report they are experiencing burnout. On top of these challenges, healthcare providers are facing financial pressures while also trying to efficiently and effectively deliver quality care. According to McKinsey & Company, nearly a quarter of U.S. national health expenditure goes toward administrative costs, which could be reduced through technology.\nAdditionally, the urgent need to improve operational and clinical efficiency was highlighted again in a recent UPMC Center for Connected Medicine/KLAS Research survey of 58 executives at provider and payor organizations. The survey found that health systems are prioritizing investments over the next two years in AI solutions focusing on operational optimization, health/disease management and prediction, diagnostic imaging, population health management, value-based care, patient engagement and clinical research.\nEpic and Microsoft’s expanded collaboration will build upon our recently announced integrations, including Azure OpenAI Service into Epic’s EHR to automatically draft message responses, as well as a solution that will bring natural language queries and interactive data analysis to SlicerDicer, Epic’s self-service reporting tool. Microsoft and Nuance also recently collaborated to integrate Nuance® Dragon® Ambient eXperience™ Express (DAX Express™) solution into the Epic platform with a comprehensive approach to incorporating a broader array of AI-powered capabilities for clinical and administrative users.\nEpic’s approach to leveraging Microsoft’s technology and infrastructure is unprecedented in time and scope. Together, we are bringing generative AI to healthcare at scale as quickly as possible, responsibly and in partnership with providers, in order to address the ongoing issues affecting healthcare.\nTags: AI, Azure OpenAI Service, healthcare",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "New study validates the business value and opportunity of AI",
    "link": "https://blogs.microsoft.com/blog/2023/11/02/new-study-validates-the-business-value-and-opportunity-of-ai/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNU5YemRUV0hnNE1tRlpTMWRHVFJDb0FSaXNBaWdCTWdNbEJBNA=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-11-02T07:00:00.000Z",
    "time": "Nov 2, 2023",
    "articleType": "regular",
    "content": "As AI becomes more woven into society, its economic impact will be significant, and organizations are just starting to understand the extent of what’s possible. For companies to invest in AI though, it must make good business sense. Business leaders and decision makers need to understand the industry and line-of-business use cases that are best positioned to drive value within their organizations, what the return on investment will be, what time to value to expect, and how to get started. In short, they need help demystifying the business case for AI.\nTo help companies understand the opportunities AI can unlock, Microsoft commissioned a study through IDC that provides unique insights into how AI is being used to drive economic impact for organizations. IDC surveyed over 2,000 business leaders and decision makers from around the world who are responsible for bringing AI transformation to life within their organizations. The study, which builds on the results from Microsoft’s Work Trend Index focused on workplace productivity, examines how companies are monetizing their AI investments, from generating new revenue streams to delivering differentiated customer experiences, to modernizing internal processes. Key findings from this study show*:\n71% of respondents say their companies are already using AI\n92% of AI deployments are taking 12 months or less\nOrganizations are realizing a return on their AI investments within 14 months\nFor every $1 a company invests in AI, it is realizing an average return of $3.5X\n52% report that a lack of skilled workers is their biggest barrier to implement and scale AI\nThe study illustrates that AI has demonstrable business value, and we are seeing this surface in core use cases within areas like employee experience, customer engagement and internal business processes, and how AI can help bend the curve on innovation. With generative AI, that value gets exponentially greater, as we’ve seen in the past year with generative AI technologies from OpenAI such as ChatGPT.\n“IDC is projecting that generative AI will add nearly $10 trillion to global GDP over the next 10 years.** Calculating the value of new investments in GenAI requires building the business case by simulating potential cost and responsible value realization,” said Ritu Jyoti, Group Vice President AI and Automation for IDC.\nThis wave of innovation has accelerated the pace of AI adoption in ways that are changing and augmenting how we work and live, and Microsoft customers are increasingly embracing AI opportunities for business transformation.\nEnrich employee experiences: Employees in every industry are dealing with an increasing volume of digital debt and administrative burdens that slow down productivity and get in the way of meaningful work. To address this challenge, AI is being used to bring together unstructured data like social media, product details and customer engagement to better tailor communications, enable more intelligent insights and solve problems faster. Additionally, employees are using Azure OpenAI and Microsoft Copilot in Microsoft 365 to augment their copywriting capabilities for things like presentations, website content, case studies, blogs, press releases, search engine optimization and digital art.\nReinvent customer engagement: With the heavy competition for customer acquisitions and retention, organizations have struggled to keep pace with the increasing amount of customer signals, and to deliver personalized service to customers in real-time. To drive greater customer loyalty, organizations are applying the AI capabilities of Dynamics 365 in contact centers for real-time assistance and guidance on suggested responses. Employees are also using AI to summarize conversations, guide on next steps, and get coaching feedback. Azure-powered virtual assistants are being used to deliver all kinds of hyper-personalized experiences across different verticals like healthcare for processing claims and entertainment for sports fans. Salespeople are using Viva Sales to help nurture leads and close deals.\nReshape business processes: Companies have pockets of valuable information scattered throughout their organization that can be difficult for employees to locate and use holistically. By finding and making connections across this information, AI can surface integrated insights that help to predict and accelerate workloads. This is particularly evident in cybersecurity, where employees are using AI insights to identify bad actors more quickly and better protect both employees and intellectual property. AI is also being used in manufacturing and operations, to create digital replicas of their supply chain environments so they can run simulations and optimize workflow management, resulting in enhanced supply chain efficiency.\nBend the curve on innovation: This is an exciting concept as companies in every industry look to regain an edge. Organizations can deploy AI to stay ahead of changing business dynamics, and to exceed customer expectations. By not having to modernize every underlying system to achieve these results, and by putting AI directly in the hands of developers with GitHub Copilot, organizations can operate with agility and accelerate innovation.  Teams can leverage AI to help scale production and speed to market while being able to focus on higher-value activities.\nIDC survey data confirms that businesses are eager to adopt AI technology, with 71% of survey respondents currently using AI tools in their organizations, and 22% planning to do so within the next 12 months. However, even with this momentum and positive outlook for what AI can help them achieve, organizations are facing challenges when it comes to implementation. A shortage of skilled employees is holding companies back from accelerating their AI-based innovations, with 52 percent of those surveyed reporting a lack of skilled workers needed to implement and scale AI initiatives across business functions as the top blocker.\nTo help address the skilling gap, Microsoft has already engaged over 6 million people globally in learning activities in the last 12 months and has ambitions to provide skills to everyone using our AI technology. We have also empowered our ecosystem of more than 400,000 partners worldwide with the skills needed to implement AI technology responsibly and to deliver greater customer value.\nThe IDC study, commissioned by Microsoft, is based on results from 2,109 enterprise organizations totaling more than 13 million employees worldwide across 16 countries globally. Through the questionnaire, respondents were identified as the decision maker for AI within their organization.\nSource: *IDC Infographic, sponsored by Microsoft, The Business Opportunity of AI, IDC #US51315823, November 2023. **Generative Artificial Intelligence: A New Chapter for Enterprise Business Applications, IDC Perspective #US50471523, March 2023.",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Microsoft to help rural hospitals defend against rising cybersecurity attacks - Stories",
    "link": "https://news.microsoft.com/2024/06/10/microsoft-to-help-rural-hospitals-defend-against-rising-cybersecurity-attacks/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWxWakJTTFV3MmNETk9kMHd3VFJDNEFSaVNBaWdCTWdZTm9wUUlPUWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-06-10T07:00:00.000Z",
    "time": "Jun 10",
    "articleType": "regular",
    "content": "New program will address exponential growth in attacks threatening access to care for Americans and bring enterprise-quality cybersecurity to the most vulnerable rural hospitals\nREDMOND, Wash. — June 10, 2024 — On Monday, Microsoft Corp. announced a new cybersecurity program to support hospitals serving more than 60 million people living in rural America. In 2023, the health care sector reported more ransomware attacks than any other critical infrastructure sector, and attacks involving ransomware against the healthcare sector were up nearly 130%. Cybersecurity attacks disrupt health care operations across the country and pose a direct threat to patient care and essential operations of hospitals. In rural communities these attacks can be devastating, particularly to smaller, independent Critical Access and Rural Emergency hospitals with limited means to prevent and remediate security risks and often the only healthcare option for many miles in the communities they serve.\nAccording to the National Rural Health Association, rural health clinics are one of the top targets for cyberattacks. The new Microsoft Cybersecurity Program for Rural Hospitals is designed to support the unique cybersecurity needs of these organizations and will deliver free and low-cost technology services for these hospitals, along with free training and support.\n“Healthcare should be available no matter where you call home, and the rise in cyberattacks threatens the viability of rural hospitals and impact communities across the U.S.,” said Justin Spelhaug, corporate vice president, Microsoft Philanthropies. “Microsoft is committed to delivering vital technology security and support at a time when these rural hospitals need them most.”\nFor independent Critical Access Hospitals and Rural Emergency Hospitals, Microsoft will provide nonprofit pricing and discounts for its security products optimized for smaller organizations, providing up to a 75% discount. And for some larger rural hospitals already using eligible Microsoft solutions, the company will be providing its most advanced security suite at no cost for one year. As part of the new program, the company is also providing Windows 10 security updates to participating rural hospitals for at least one year at no additional cost. Microsoft will also provide free cybersecurity assessments through Microsoft and its trusted partners to evaluate risks and gaps and offer free cybersecurity training to staff in rural hospitals to help them better manage the day-to-day security of their systems.\nToday’s news was announced in close collaboration with The White House, the American Hospital Association and the National Rural Health Association. Microsoft will work with all three institutions on the rollout, adoption and effectiveness of the program.\n“Cyber-attacks against the U.S. healthcare systems rose 130% in 2023, forcing hospitals to cancel procedures and impacting Americans’ access to critical care. Rural hospitals are particularly hard hit as they are often the sole source of care for the communities they serve and lack trained cyber staff and modern cyber defenses. President Biden is committed to every American having access to the care they need, and effective cybersecurity is a part of that. So, we’re excited to work with Microsoft to launch cybersecurity programs that will provide training, advice and technology to help America’s rural hospitals be safe online” said Anne Neuberger, Deputy National Security Advisory for Cyber and Emerging Technologies.\nToday’s announcement is one part of Microsoft’s work in communities across the United States and around the world to improve healthcare for those living in rural areas. Through the AI for Health program, Microsoft is working with nonprofits, researchers and organizations working on global health challenges to make advances in telemedicine and improve clinical decision- making and prediction. Microsoft is also working with rural hospital leaders to rapidly bring AI solutions to market to meet their unique needs.\n“Hospitals and health systems have invested significant resources to guard against cyberattacks, but they can’t do it alone. Cybersecurity is a shared responsibility, and these investments from Microsoft help reinforce that,” said Rick Pollack, president and CEO, the American Hospital Association. “Rural hospitals are often the primary source of healthcare in their communities, so keeping them open and safe from cyberattacks is critical. We appreciate Microsoft stepping forward to offer its expertise and resources to help secure part of America’s healthcare safety net.”\n“Rural hospitals face a unique challenge in cybersecurity, balancing limited resources with the increasing sophistication of cyberthreats, which puts patient data and critical healthcare infrastructure at risk,” said Alan Morgan, chief executive officer of NRHA. “This important partnership with Microsoft will help ensure that rural hospitals are prepared in the future to meet this rising threat in small rural facilities.”\nIn addition to the security program for rural hospitals, Microsoft is working with community colleges to deliver the Cybersecurity Skills Initiative and through the TechSpark program to drive technology and cybersecurity job creation in partnership with local organizations. Through the Microsoft Airband initiative, the company collaborates with public, private and nonprofit organizations to bring high-speed internet access to rural communities across America and build the digital infrastructure required for internet access and adoption.\nMicrosoft (Nasdaq “MSFT” @microsoft) creates platforms and tools powered by AI to deliver innovative solutions that meet the evolving needs of our customers. The technology company is committed to making AI available broadly and doing so responsibly, with a mission to empower every person and every organization on the planet to achieve more.\nMicrosoft Media Relations, WE Communications, (425) 638-7777, rapidresponse@we-worldwide.com",
    "favicon": "https://news.microsoft.com/wp-content/uploads/prod/2017/03/cropped-microsoft_logo_element-150x150.png"
  },
  {
    "title": "Introducing the Microsoft Copilot Copyright Commitment",
    "link": "https://www.microsoft.com/en-us/licensing/news/microsoft-copilot-copyright-commitment",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNTZORkZXZFhJMWNHMHhUQzFDVFJDeUFSaWJBaWdCTWdiSklZN1ZGQWs=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-07T07:00:00.000Z",
    "time": "Sep 7, 2023",
    "articleType": "regular",
    "content": "September 7, 2023Today, we announced the Microsoft Copilot Copyright Commitment, a new benefit that extends our existing intellectual property indemnity support to commercial Copilot services and builds on our previous AI Customer Commitments. Starting October 1, 2023, Microsoft is offering to defend customers from IP infringement claims arising from the customer's use and distribution of the output content generated by Microsoft’s Copilot services. Specifically, should a third party sue a commercial customer for copyright infringement for using a Microsoft Copilot service or the output they generate, we will defend the customer and pay the amount of any adverse judgements or settlements that result from the lawsuit, as long as the customer used the guardrails and content filters we have built into our products.This new commitment does not change Microsoft’s position that it does not claim any intellectual property rights in the outputs of its Copilot services.Our customers want to harness the power of generative AI technologies, and we want them to work and innovate with confidence. This commitment builds on steps we have taken to incorporate filters, classifiers, content filtering, operational monitoring and abuse detection, and other safeguards.Specifically, the Copilot Copyright Commitment will:\tCover third-party IP claims based on copyright, patent, trademark, trade secrets, or right of publicity, but not claims based on trademark use in trade or commerce, defamation, false light, or other causes of action that are not related to IP rights.\tCover the customer’s use and distribution of the output content generated by our Copilot services, but not the customer’s input data, modifications of the output content, or uses of output that the customer knows or should know will infringe the rights of others.\tRequire the customer to use the content filters and other safety systems built into the product and the customer must not attempt to generate infringing materials, including not providing input to a Copilot service that the customer does not have appropriate rights to use.Please note that this is not an exhaustive list, and the relevant contractual terms will reflect the details.The Microsoft Copilot Copyright Commitment will be effective starting October 1, 2023, and apply to paid versions of Microsoft commercial Copilot services and Bing Chat Enterprise.  It will not extend to any free products, custom-built Copilot services, or consumer products or services, even if identified as a Copilot.  It will be reflected in a single change to our Product Terms, where all applicable conditions will be detailed. No contractual change or action will be needed on behalf of our customers to benefit from this commitment. Customers who use our Copilot services and outputs in accordance with the terms and conditions of their commercial licensing agreements and the Product Terms will automatically get this benefit.",
    "favicon": "/favicon.ico?v2"
  },
  {
    "title": "Microsoft announces changes to Microsoft 365 and Office 365 to address European competition concerns",
    "link": "https://blogs.microsoft.com/eupolicy/2023/08/31/european-competition-teams-office-microsoft-365/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNUJSazFsV1hoQk5YSnJSMmhUVFJDM0FSaVRBaWdCTWdtUklZaUhLaWQ3cFFJ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-08-31T07:00:00.000Z",
    "time": "Aug 31, 2023",
    "articleType": "regular",
    "content": "|\t\t\t\t\tNanna-Louise Linde, Vice President, Microsoft European Government Affairs\nLast month, the European Commission announced that it had opened a formal investigation regarding Microsoft’s bundling of Microsoft Teams with Microsoft 365 and Office 365 suites for business customers. As we said at the time, “we will continue to cooperate with the Commission and remain committed to finding solutions that will address its concerns.”\nToday we are announcing proactive changes that we hope will start to address these concerns in a meaningful way, even while the European Commission’s investigation continues and we cooperate with it. These changes will impact our Microsoft 365 and Office 365 suites for business customers in the European Economic Area and Switzerland. They are designed to address two concerns that are central to the Commission’s investigation: (1) that customers should be able to choose a business suite without Teams at a price less than those with Teams included; and (2) that we should do more to make interoperability easier between rival communication and collaboration solutions and Microsoft 365 and Office 365 suites.\nBefore offering more details, let me provide some added context. We believe that business customers in Europe and around the world expect a modern work solution to include modern communication and collaboration capabilities. That’s why, for more than a decade, we have included these capabilities in our business suites, starting with Office Communicator in 2007 and evolving and innovating over the years through Lync, Skype for Business Online, and most recently Microsoft Teams.\nAt the same time, we recognize our responsibility as a major technology provider to support a healthy competitive environment. We appreciate the clarity that has emerged on several of the concerns from extensive and constructive discussions with the European Commission. With the benefit of this clarity, we believe it is important that we start to take meaningful steps to address those concerns. We do this not with the sense that this will necessarily resolve all concerns, whether from the Commission or our competitors, but we believe this is a constructive step that can start to lead to immediate and meaningful changes in the market.\nAccordingly, we plan to take the following steps in the coming months.\nFirst, beginning October 1, 2023, we will unbundle Teams from our Microsoft 365 and Office 365 suites in the EEA and Switzerland. We will instead simply sell these offerings without Teams at a lower price (€2 less per month or €24 per year). We will do this for our core enterprise customers, which represent most of our commercial business in the EEA and Switzerland. Teams will still be available for new enterprise customers to buy standalone and separately at a list price of €5 per month or €60 per year. Existing enterprise customers who already have a suite with Teams can choose to stay with their current productivity suite or to move to a without-Teams suite. For our small business and frontline workers, we will keep offering suites with Teams but will at the same time offer a “without-Teams” option, and this latter version will be offered at a lower price. More details are available here.\nSecond, we will enhance our existing resources on interoperability with Microsoft 365 and Office 365. Today, we offer extensive interoperability with Microsoft 365 and Office 365 apps and services. This work allows companies like Zoom and Salesforce to create tailored and integrated experiences across Exchange, Outlook and even Teams. However, as part of the investigation process, we have heard feedback that, given the broad capabilities of Microsoft 365, Microsoft could do more in terms of providing support and making development easier. To help address these concerns, we will create new support resources to better organize and point application developers to the existing and publicly available application programming interfaces (APIs) and extensibility in Microsoft 365 and Office 365 apps and services that connect with Teams. This will include new support resources to help address questions from customers and independent software vendors (ISVs), including providing additional content to explain how data can be removed from Teams and used in another solution.\nFinally, we will create new mechanisms to enable third-party solutions to host Office web applications. While Microsoft Office file formats are documented so that any program can open, edit, and display documents created in programs like Word, Excel, and PowerPoint, we have heard requests from competitors of Teams that they would like to rely on Microsoft’s functionality instead of building their own. To address these requests, we will develop a new method for hosting the Office web applications within competing apps and services much like Microsoft accomplishes in Teams.\nWe believe these changes balance the interests of our competitors with those of European business customers, providing them with access to the best possible solutions at competitive prices. We also recognize that we are still in the early stages of the European Commission’s formal investigation. We will continue to engage with the Commission, listen to concerns in the marketplace, and remain open to exploring pragmatic solutions that benefit both customers and developers in Europe.\nTags: European Commission, Microsoft 365, Microsoft Teams, Office 365",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/73/2022/10/cropped-MS_Symbol_Social_FB_TWTR_LNKD_INSTA-32x32.png"
  },
  {
    "title": "Microsoft lays off 1,900 Activision Blizzard and Xbox employees",
    "link": "https://www.theverge.com/2024/1/25/24049050/microsoft-activision-blizzard-layoffs",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNVVTVEJ4YXpSVVVUbEhRVmh5VFJDb0FSaXJBaWdCTWdrRlU0UkczcUpqYVFJ=-w400-h224-p-df-rw",
    "source": "The Verge",
    "datetime": "2024-01-25T08:00:00.000Z",
    "time": "Jan 25",
    "articleType": "regular",
    "content": "Microsoft is laying off 1,900 employees at Activision Blizzard and Xbox this week. While Microsoft is primarily laying off roles at Activision Blizzard, some Xbox and ZeniMax employees will also be impacted by the cuts.The cuts work out to roughly 8 percent of the overall Microsoft Gaming division that stands at around 22,000 employees in total. The Verge has obtained an internal memo from Microsoft Gaming CEO Phil Spencer that confirms the layoffs:It’s been a little over three months since the Activision, Blizzard, and King teams joined Microsoft. As we move forward in 2024, the leadership of Microsoft Gaming and Activision Blizzard is committed to aligning on a strategy and an execution plan with a sustainable cost structure that will support the whole of our growing business. Together, we’ve set priorities, identified areas of overlap, and ensured that we’re all aligned on the best opportunities for growth.As part of this process, we have made the painful decision to reduce the size of our gaming workforce by approximately 1900 roles out of the 22,000 people on our team. The Gaming Leadership Team and I are committed to navigating this process as thoughtfully as possible. The people who are directly impacted by these reductions have all played an important part in the success of Activision Blizzard, ZeniMax and the Xbox teams, and they should be proud of everything they’ve accomplished here. We are grateful for all of the creativity, passion and dedication they have brought to our games, our players and our colleagues. We will provide our full support to those who are impacted during the transition, including severance benefits informed by local employment laws. Those whose roles will be impacted will be notified, and we ask that you please treat your departing colleagues with the respect and compassion that is consistent with our values.Looking ahead, we’ll continue to invest in areas that will grow our business and support our strategy of bringing more games to more players around the world. Although this is a difficult moment for our team, I’m as confident as ever in your ability to create and nurture the games, stories and worlds that bring players together.PhilAlongside the layoffs, Blizzard president Mike Ybarra has decided to leave the company. “As many of you know, Mike previously spent more than 20 years at Microsoft. Now that he has seen the acquisition through as Blizzard’s president, he has decided to leave the company,” says Microsoft’s game content and studios president, Matt Booty, in an internal memo.Microsoft plans to name a new Blizzard president next week. Allen Adham, Blizzard’s chief design officer, is also leaving the company. “As one of Blizzard’s cofounders, Allen has had a broad impact on all of Blizzard’s games. His influence will be felt for years to come, both directly and indirectly as Allen plans to continue mentoring young designers across the industry,” says Booty.Blizzard’s previously announced survival game has also been canceled as part of these changes. Booty says Microsoft will be “shifting some of the people working on it to one of several promising new projects Blizzard has in the early stages of development.”The layoffs come the same month Riot Games, Google, Discord, Twitch, Unity, eBay, and others announced cuts.Microsoft completed its $68.7 billion acquisition of Activision Blizzard in October, following 20 months of battles with regulators in the UK and US. Former Activision Blizzard CEO Bobby Kotick stepped down at the end of December, with Microsoft not appointing a direct replacement. Instead, a suite of Activision Blizzard executives now report up to Matt Booty.Today’s layoffs come just a few months after some big Xbox leadership changes saw Sarah Bond promoted to Xbox president, leading all Xbox platform and hardware work. Booty was also promoted to president of game content and studios, which includes overseeing Bethesda, ZeniMax studios, and Activision Blizzard.Microsoft last announced big layoffs a year ago, affecting 10,000 employees. The software maker is due to report its fiscal Q2 2024 earnings next week, which, for the first time, will include results from the impact of the Activision Blizzard acquisition.Here’s Matt Booty’s internal memo in full:Blizzard team, As you may have read in Phil’s note, today is a challenging day as we say goodbye to some of our colleagues. This is a difficult process, but it is one that will best enable Blizzard and Xbox to deliver ambitious games for our players on more platforms and in more places than ever before. We are moving forward with a more focused strategy across Microsoft Gaming that sets us up for sustainable growth and aligns our talent and resources to our top priorities. In addition to the events today, Mike Ybarra and I have been discussing his future and some of his personal passions for some time. As many of you know, Mike previously spent more than 20 years at Microsoft. Now that he has seen the acquisition through as Blizzard’s president, he has decided to leave the company. As we move forward, we will continue to build on the positive momentum that Mike created and strive to continue exceeding the expectations of Blizzard’s players. I want to thank Mike for his leadership and for his partnership and counsel since the deal closed. I know he plans to travel and spend more time with his family. We wish him the very best.Additionally, Allen Adham, Blizzard’s Chief Design Officer, is leaving the company. As one of Blizzard’s cofounders, Allen has had a broad impact on all of Blizzard’s games. His influence will be felt for years to come, both directly and indirectly as Allen plans to continue mentoring young designers across the industry.The new Blizzard President will be announced next week. What Happens Next Those who are impacted are being informed in meetings starting today. Given the challenging day ahead, anyone who is set up to work from home and would prefer to, can work remotely today. Due to time zones and local holidays, some impacted employees in APAC and EMEA will be informed later this evening and into early next week. After the notifications are complete, leaders will bring their teams together. Please be mindful of this process in your conversations and outreach during these next few days. Details on Today’s Actions The changes announced today reflect a focus on products and strategies that hold the most promise for Blizzard’s future growth, as well as identified areas of overlap across Blizzard and Microsoft Gaming. Today’s actions affect multiple teams within Blizzard, including development teams, shared service organizations and corporate functions. As part of this focus, Blizzard is ending development on its survival game project and will be shifting some of the people working on it to one of several promising new projects Blizzard has in the early stages of development. No matter the reason behind these decisions, they are never made lightly. Changes like these affect the lives of colleagues and friends, and we are all grateful for their meaningful contributions to Blizzard and its world class lineup of games. As Phil stated, we will provide our full support to those who are impacted during the transition, including severance benefits informed by local employment laws. I understand that this is a challenging time and that it can be a lot to process. I haven’t met many of you yet, and hearing about these decisions from me may be difficult. Today, I am here on Blizzard’s Irvine campus, and I am personally committed to supporting you as teams and individuals, keeping you informed, and approaching this transition period with care and transparency. Thank you for working through these changes with us. Together we will continue to create amazing games for our players, with a culture that empowers everyone to be their most authentic selves and do their best work. - Matt Update January 25th, 10:45AM ET: Article updated with full memo from Matt Booty.",
    "favicon": "/icons/favicon.ico"
  },
  {
    "title": "Windows Security best practices for integrating and managing security tools",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/07/27/windows-security-best-practices-for-integrating-and-managing-security-tools/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNXFYMGt3WVZwTlUxVnlRamRQVFJDb0FSaXJBaWdCTWdNRmtCUQ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-07-27T22:24:03.000Z",
    "time": "4 days ago",
    "articleType": "regular",
    "content": "Windows is an open and flexible platform used by many of the world’s top businesses for high availability use cases where security and availability are non-negotiable.\nWindows provides a range of operating modes that customers can choose from. This includes the ability to limit what can run to only approved software and drivers. This can increase security and reliability by making Windows operate in a mode closer to mobile phones or appliances.\nCustomers can choose integrated security monitoring and detection capabilities that are included with Windows. Or they can choose to replace or supplement this security with a wide variety of choices from a vibrant open ecosystem of vendors.\nIn this blog post, we examine the recent CrowdStrike outage and provide a technical overview of the root cause. We also explain why security products use kernel-mode drivers today and the safety measures Windows provides for third-party solutions. In addition, we share how customers and security vendors can better leverage the integrated security capabilities of Windows for increased security and reliability. Lastly, we provide a look into how Windows will enhance extensibility for future security products.\nCrowdStrike recently published a Preliminary Post Incident Review analyzing their outage. In their blog post, CrowdStrike describes the root cause as a memory safety issue—specifically a read out-of-bounds access violation in the CSagent driver. We leverage the Microsoft WinDBG Kernel Debugger and several extensions that are available free to anyone to perform this analysis. Customers with crash dumps can reproduce our steps with these tools.\nBased on Microsoft’s analysis of the Windows Error Reporting (WER) kernel crash dumps related to the incident, we observe global crash patterns that reflect this:\nFAULTING_THREAD:  ffffe402fe868040READ_ADDRESS:  ffff840500000074 Paged poolMM_INTERNAL_CODE:  2IMAGE_NAME:  csagent.sysMODULE_NAME: csagentFAULTING_MODULE: fffff80671430000 csagentPROCESS_NAME:  SystemTRAP_FRAME:  ffff94058305ec20 -- (.trap 0xffff94058305ec20).trap 0xffff94058305ec20NOTE: The trap frame does not contain all registers.Some register values may be zeroed or incorrect.rax=ffff94058305f200 rbx=0000000000000000 rcx=0000000000000003rdx=ffff94058305f1d0 rsi=0000000000000000 rdi=0000000000000000rip=fffff806715114ed rsp=ffff94058305edb0 rbp=ffff94058305eeb0 r8=ffff840500000074  r9=0000000000000000 r10=0000000000000000r11=0000000000000014 r12=0000000000000000 r13=0000000000000000r14=0000000000000000 r15=0000000000000000iopl=0         nv up ei ng nz na po nccsagent+0xe14ed:fffff806`715114ed 458b08          mov     r9d,dword ptr [r8] ds:ffff8405`00000074=????????.trapResetting default scopeSTACK_TEXT:  ffff9405`8305e9f8 fffff806`5388c1e4     : 00000000`00000050 ffff8405`00000074 00000000`00000000 ffff9405`8305ec20 : nt!KeBugCheckEx ffff9405`8305ea00 fffff806`53662d8c     : 00000000`00000000 00000000`00000000 00000000`00000000 ffff8405`00000074 : nt!MiSystemFault+0x1fcf94  ffff9405`8305eb00 fffff806`53827529     : ffffffff`00000030 ffff8405`af8351a2 ffff9405`8305f020 ffff9405`8305f020 : nt!MmAccessFault+0x29c ffff9405`8305ec20 fffff806`715114ed     : 00000000`00000000 ffff9405`8305eeb0 ffff8405`b0bcd00c ffff8405`b0bc505c : nt!KiPageFault+0x369 ffff9405`8305edb0 fffff806`714e709e     : 00000000`00000000 00000000`e01f008d ffff9405`8305f102 fffff806`716baaf8 : csagent+0xe14edffff9405`8305ef50 fffff806`714e8335     : 00000000`00000000 00000000`00000010 00000000`00000002 ffff8405`b0bc501c : csagent+0xb709effff9405`8305f080 fffff806`717220c7     : 00000000`00000000 00000000`00000000 ffff9405`8305f382 00000000`00000000 : csagent+0xb8335ffff9405`8305f1b0 fffff806`7171ec44     : ffff9405`8305f668 fffff806`53eac2b0 ffff8405`afad4ac0 00000000`00000003 : csagent+0x2f20c7ffff9405`8305f430 fffff806`71497a31     : 00000000`0000303b ffff9405`8305f6f0 ffff8405`afb1d140 ffffe402`ff251098 : csagent+0x2eec44ffff9405`8305f5f0 fffff806`71496aee     : ffff8405`afb1d140 fffff806`71541e7e 00000000`000067a0 fffff806`7168f8f0 : csagent+0x67a31ffff9405`8305f760 fffff806`7149685b     : ffff9405`8305f9d8 ffff8405`afb1d230 ffff8405`afb1d140 ffffe402`fe8644f8 : csagent+0x66aeeffff9405`8305f7d0 fffff806`715399ea     : 00000000`4a8415aa ffff8eee`1c68ca4f 00000000`00000000 ffff8405`9e95fc30 : csagent+0x6685bffff9405`8305f850 fffff806`7148efbb     : 00000000`00000000 ffff9405`8305fa59 ffffe402`fe864050 ffffe402`fede62c0 : csagent+0x1099eaffff9405`8305f980 fffff806`7148edd7     : ffffffff`ffffffa1 fffff806`7152e5c1 ffffe402`fe864050 00000000`00000001 : csagent+0x5efbbffff9405`8305fac0 fffff806`7152e681     : 00000000`00000000 fffff806`53789272 00000000`00000002 ffffe402`fede62c0 : csagent+0x5edd7ffff9405`8305faf0 fffff806`53707287     : ffffe402`fe868040 00000000`00000080 fffff806`7152e510 006fe47f`b19bbdff : csagent+0xfe681ffff9405`8305fb30 fffff806`5381b8e4     : ffff9680`37651180 ffffe402`fe868040 fffff806`53707230 00000000`00000000 : nt!PspSystemThreadStartup+0x57 ffff9405`8305fb80 00000000`00000000     : ffff9405`83060000 ffff9405`83059000 00000000`00000000 00000000`00000000 : nt!KiStartSystemThread+0x34\n6: kd> .trap 0xffff94058305ec20.trap 0xffff94058305ec20NOTE: The trap frame does not contain all registers.Some register values may be zeroed or incorrect.rax=ffff94058305f200 rbx=0000000000000000 rcx=0000000000000003rdx=ffff94058305f1d0 rsi=0000000000000000 rdi=0000000000000000rip=fffff806715114ed rsp=ffff94058305edb0 rbp=ffff94058305eeb0 r8=ffff840500000074  r9=0000000000000000 r10=0000000000000000r11=0000000000000014 r12=0000000000000000 r13=0000000000000000r14=0000000000000000 r15=000000000000000iopl=0         nv up ei ng nz na po nccsagent+0xe14ed:fffff806`715114ed 458b08          mov     r9d,dword ptr [r8] ds:ffff8405`00000074=????????6: kd> !pte ffff840500000074!pte ffff840500000074                                           VA ffff840500000074PXE at FFFFABD5EAF57840    PPE at FFFFABD5EAF080A0    PDE at FFFFABD5E1014000    PTE at FFFFABC202800000contains 0A00000277200863  contains 0000000000000000pfn 277200    ---DA--KWEV  contains 0000000000000000not valid6: kd> ub fffff806`715114edub fffff806`715114edcsagent+0xe14d9:fffff806`715114d9 04d8            add     al,0D8hfffff806`715114db 750b            jne     csagent+0xe14e8 (fffff806`715114e8)fffff806`715114dd 4d85c0          test    r8,r8fffff806`715114e0 7412            je      csagent+0xe14f4 (fffff806`715114f4)fffff806`715114e2 450fb708        movzx   r9d,word ptr [r8]fffff806`715114e6 eb08            jmp     csagent+0xe14f0 (fffff806`715114f0)fffff806`715114e8 4d85c0          test    r8,r8fffff806`715114eb 7407            je      csagent+0xe14f4 (fffff806`715114f4)6: kd> ub fffff806`715114d9ub fffff806`715114d9                          ^ Unable to find valid previous instruction for 'ub fffff806`715114d9'6: kd> u fffff806`715114ebu fffff806`715114ebcsagent+0xe14eb:fffff806`715114eb 7407            je      csagent+0xe14f4 (fffff806`715114f4)fffff806`715114ed 458b08          mov     r9d,dword ptr [r8]fffff806`715114f0 4d8b5008        mov     r10,qword ptr [r8+8]fffff806`715114f4 4d8bc2          mov     r8,r10fffff806`715114f7 488d4d90        lea     rcx,[rbp-70h]fffff806`715114fb 488bd6          mov     rdx,rsifffff806`715114fe e8212c0000      call    csagent+0xe4124 (fffff806`71514124)fffff806`71511503 4533d2          xor     r10d,r10d6: kd> db ffff840500000074db ffff840500000074ffff8405`00000074  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????ffff8405`00000084  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????ffff8405`00000094  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????ffff8405`000000a4  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????ffff8405`000000b4  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????ffff8405`000000c4  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????ffff8405`000000d4  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????ffff8405`000000e4  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????\nOur observations confirm CrowdStrike’s analysis that this was a read-out-of-bounds memory safety error in the CrowdStrike developed CSagent.sys driver.\nWe can also see that the csagent.sys module is registered as a file system filter driver commonly used by anti-malware agents to receive notifications about file operations such as the creation or modification of a file. This is often used by security products to scan any new file saved to disk, such as downloading a file via the browser.\nFile System filters can also be used as a signal for security solutions attempting to monitor the behavior of the system. CrowdStrike noted in their blog that part of their content update was changing the sensor’s logic relating to data around named pipe creation. The File System filter driver API allows the driver to receive a call when named pipe activity (e.g., named pipe creation) occurs on the system that could enable the detection of malicious behavior. The general function of the driver correlates to the information shared by CrowdStrike.\n6: kd>!reg querykey \\REGISTRY\\MACHINE\\system\\ControlSet001\\services\\csagentHive         ffff84059ca7b000KeyNode      ffff8405a6f67f9c[SubKeyAddr]         [SubKeyName]ffff8405a6f683ac     Instancesffff8405a6f6854c     Sim Use '!reg keyinfo ffff84059ca7b000 <SubKeyAddr>' to dump the subkey details[ValueType]         [ValueName]                   [ValueData]REG_DWORD           Type                          2REG_DWORD           Start                         1REG_DWORD           ErrorControl                  1REG_EXPAND_SZ       ImagePath                     \\??\\C:\\Windows\\system32\\drivers\\CrowdStrike\\csagent.sysREG_SZ              DisplayName                   CrowdStrike FalconREG_SZ              Group                         FSFilter Activity MonitorREG_MULTI_SZ        DependOnService               FltMgr\\0REG_SZ              CNFG                          Config.sysREG_DWORD           SupportedFeatures             f\nWe can see the control channel file version 291 specified in the CrowdStrike analysis is also present in the crash indicating the file was read.\nDetermining how the file itself correlates to the access violation observed in the crash dump would require additional debugging of the driver using these tools but is outside of the scope of this blog post.\n!ca ffffde8a870a8290ControlArea  @ ffffde8a870a8290  Segment      ffff880ce0689c10  Flink      ffffde8a87267718  Blink        ffffde8a870a7d98  Section Ref                 0  Pfn Ref                   b  Mapped Views                0  User Ref                    0  WaitForDel                0  Flush Count                 0  File Object  ffffde8a879b29a0  ModWriteCount             0  System Views                0  WritableRefs                0  PartitionId                0    Flags (8008080) File WasPurged OnUnusedList       \\Windows\\System32\\drivers\\CrowdStrike\\C-00000291-00000000-00000032.sys1: kd> !ntfskd.ccb ffff880ce06f6970!ntfskd.ccb ffff880ce06f6970   Ccb: ffff880c`e06f6970 Flags: 00008003 Cleanup OpenAsFile IgnoreCaseFlags2: 00000841 OpenComplete AccessAffectsOplocks SegmentObjectReferenced  Type: UserFileOpenFileObj: ffffde8a879b29a0(018)  ffff880c`db937370  FullFileName [\\Windows\\System32\\drivers\\CrowdStrike\\C-00000291-00000000-00000032.sys](020) 000000000000004C  LastFileNameOffset (022) 0000000000000000  EaModificationCount (024) 0000000000000000  NextEaOffset (048) FFFF880CE06F69F8  Lcb (058) 0000000000000002  TypeOfOpen\nWe can leverage the crash dump to determine if any other drivers supplied by CrowdStrike may exist on the running system during the crash.\n6: kd> lmDvmCSFirmwareAnalysislmDvmCSFirmwareAnalysisBrowse full module liststart             end                 module namefffff806`58920000 fffff806`5893c000   CSFirmwareAnalysis   (deferred)                 Image path: \\SystemRoot\\system32\\DRIVERS\\CSFirmwareAnalysis.sys    Image name: CSFirmwareAnalysis.sys    Browse all global symbols  functions  data  Symbol Reload    Timestamp:        Mon Mar 18 11:32:14 2024 (65F888AE)    CheckSum:         0002020E    ImageSize:        0001C000    Translations:     0000.04b0 0000.04e4 0409.04b0 0409.04e4    Information from resource tables:6: kd> lmDvmcspcm4lmDvmcspcm4Browse full module liststart             end                 module namefffff806`71870000 fffff806`7187d000   cspcm4     (deferred)                 Image path: \\??\\C:\\Windows\\system32\\drivers\\CrowdStrike\\cspcm4.sys    Image name: cspcm4.sys    Browse all global symbols  functions  data  Symbol Reload    Timestamp:        Mon Jul  8 18:33:22 2024 (668C9362)    CheckSum:         00012F69    ImageSize:        0000D000    Translations:     0000.04b0 0000.04e4 0409.04b0 0409.04e4    Information from resource tables:6: kd> lmDvmcsboot.syslmDvmcsboot.sysBrowse full module liststart             end                 module nameUnloaded modules:fffff806`587d0000 fffff806`587dc000   CSBoot.sys    Timestamp: unavailable (00000000)    Checksum:  00000000    ImageSize:  0000C0006: kd> !reg querykey \\REGISTRY\\MACHINE\\system\\ControlSet001\\services\\csboot!reg querykey \\REGISTRY\\MACHINE\\system\\ControlSet001\\services\\csbootHive         ffff84059ca7b000KeyNode      ffff8405a6f68924[ValueType]         [ValueName]                   [ValueData]REG_DWORD           Type                          1REG_DWORD           Start                         0REG_DWORD           ErrorControl                  1REG_EXPAND_SZ       ImagePath                     system32\\drivers\\CrowdStrike\\CSBoot.sysREG_SZ              DisplayName                   CrowdStrike Falcon Sensor Boot DriverREG_SZ              Group                         Early-Launch6: kd> !reg querykey \\REGISTRY\\MACHINE\\system\\ControlSet001\\services\\csdevicecontrol!reg querykey \\REGISTRY\\MACHINE\\system\\ControlSet001\\services\\csdevicecontrolHive         ffff84059ca7b000KeyNode      ffff8405a6f694ac[SubKeyAddr]         [VolatileSubKeyName]ffff84059ce196c4     Enum Use '!reg keyinfo ffff84059ca7b000 <SubKeyAddr>' to dump the subkey details[ValueType]         [ValueName]                   [ValueData]REG_DWORD           Type                          1REG_DWORD           Start                         3REG_DWORD           ErrorControl                  1REG_DWORD           Tag                           1fREG_EXPAND_SZ       ImagePath                     \\SystemRoot\\System32\\drivers\\CSDeviceControl.sysREG_SZ              DisplayName                   @oem40.inf,%DeviceControl.SVCDESC%;CrowdStrike Device Control ServiceREG_SZ              Group                         BaseREG_MULTI_SZ        Owners                        oem40.inf\\0!csdevicecontrol.inf_amd64_b6725a84d4688d5a\\0!csdevicecontrol.inf_amd64_016e965488e83578\\0REG_DWORD           BootFlags                     146: kd> !reg querykey \\REGISTRY\\MACHINE\\system\\ControlSet001\\services\\csagent!reg querykey \\REGISTRY\\MACHINE\\system\\ControlSet001\\services\\csagentHive         ffff84059ca7b000KeyNode      ffff8405a6f67f9c[SubKeyAddr]         [SubKeyName]ffff8405a6f683ac     Instancesffff8405a6f6854c     Sim Use '!reg keyinfo ffff84059ca7b000 <SubKeyAddr>' to dump the subkey details[ValueType]         [ValueName]                   [ValueData]REG_DWORD           Type                          2REG_DWORD           Start                         1REG_DWORD           ErrorControl                  1REG_EXPAND_SZ       ImagePath                     \\??\\C:\\Windows\\system32\\drivers\\CrowdStrike\\csagent.sysREG_SZ              DisplayName                   CrowdStrike FalconREG_SZ              Group                         FSFilter Activity MonitorREG_MULTI_SZ        DependOnService               FltMgr\\0REG_SZ              CNFG                          Config.sysREG_DWORD           SupportedFeatures             f6: kd> lmDvmCSFirmwareAnalysislmDvmCSFirmwareAnalysisBrowse full module liststart             end                 module namefffff806`58920000 fffff806`5893c000   CSFirmwareAnalysis   (deferred)                 Image path: \\SystemRoot\\system32\\DRIVERS\\CSFirmwareAnalysis.sys    Image name: CSFirmwareAnalysis.sys    Browse all global symbols  functions  data  Symbol Reload    Timestamp:        Mon Mar 18 11:32:14 2024 (65F888AE)    CheckSum:         0002020E    ImageSize:        0001C000    Translations:     0000.04b0 0000.04e4 0409.04b0 0409.04e4    Information from resource tables:6: kd> !reg querykey \\REGISTRY\\MACHINE\\system\\ControlSet001\\services\\csfirmwareanalysis!reg querykey \\REGISTRY\\MACHINE\\system\\ControlSet001\\services\\csfirmwareanalysisHive         ffff84059ca7b000KeyNode      ffff8405a6f69d9c[SubKeyAddr]         [VolatileSubKeyName]ffff84059ce197cc     Enum Use '!reg keyinfo ffff84059ca7b000 <SubKeyAddr>' to dump the subkey details[ValueType]         [ValueName]                   [ValueData]REG_DWORD           Type                          1REG_DWORD           Start                         0REG_DWORD           ErrorControl                  1REG_DWORD           Tag                           6REG_EXPAND_SZ       ImagePath                     system32\\DRIVERS\\CSFirmwareAnalysis.sysREG_SZ              DisplayName                   @oem43.inf,%FirmwareAnalysis.SVCDESC%;CrowdStrike Firmware Analysis ServiceREG_SZ              Group                         Boot Bus ExtenderREG_MULTI_SZ        Owners                        oem43.inf\\0!csfirmwareanalysis.inf_amd64_12861fc608fb1440\\06: kd> !reg querykey \\REGISTRY\\MACHINE\\system\\Controlset001\\control\\earlylaunch!reg querykey \\REGISTRY\\MACHINE\\system\\Controlset001\\control\\earlylaunch\nAs we can see from the above analysis, CrowdStrike loads four driver modules. One of those modules receives dynamic control and content updates frequently based on the CrowdStrike Preliminary Post-incident-review timeline.\nWe can leverage the unique stack and attributes of this crash to identify the Windows crash reports generated by this specific CrowdStrike programming error. It’s worth noting the number of devices which generated crash reports is a subset of the number of impacted devices previously shared by Microsoft in our blog post, because crash reports are sampled and collected only from customers who choose to upload their crashes to Microsoft. Customers who choose to enable crash dump sharing help both driver vendors and Microsoft to identify and remediate quality issues and crashes.\nFigure 1 CrowdStrike driver associated crash dump reports over time\nWe make this information available to driver owners so they can assess their own reliability via the Hardware Dev Center analytics dashboard. As we can see from the above, any reliability problem like this invalid memory access issue can lead to widespread availability issues when not combined with safe deployment practices. Let’s dig into why security solutions leverage kernel drivers on Windows.\nWhy do security solutions leverage kernel drivers?\nMany security vendors such as CrowdStrike and Microsoft leverage a kernel driver architecture and there are several reasons for this.\nVisibility and enforcement of security related events\nKernel drivers allow for system wide visibility, and the capability to load in early boot to detect threats like boot kits and root kits which can load before user-mode applications. In addition, Microsoft provides a rich set of capabilities such as system event callbacks for process and thread creation and filter drivers which can watch for events like file creation, deletion, or modification. Kernel activity can also trigger call backs for drivers to decide when to block activities like file or process creations. Many vendors also use drivers to collect a variety of network information in the kernel using the NDIS driver class.\nKernel drivers are often utilized by security vendors for potential performance benefits. For example, analysis or data collection for high throughput network activity may benefit from a kernel driver. There are many scenarios where data collection and analysis can be optimized for operation outside of kernel mode and Microsoft continues to partner with the ecosystem to improve performance and provide best practices to achieve parity outside of kernel mode.\nA second benefit of loading into kernel mode is tamper resistance. Security products want to ensure that their software cannot be disabled by malware, targeted attacks, or malicious insiders, even when those attackers have admin-level privileges. They also want to ensure that their drivers load as early as possible so that they can observe system events at the earliest possible time. Windows provides a mechanism to launch drivers marked as Early Launch Antimalware (ELAM) early in the boot process for this reason. CrowdStrike signs the above CSboot driver as ELAM, enabling it to load early in the boot sequence.\nIn the general case, there is a tradeoff that security vendors must rationalize when it comes to kernel drivers. Kernel drivers provide the above properties at the cost of resilience. Since kernel drivers run at the most trusted level of Windows, where containment and recovery capabilities are by nature constrained, security vendors must carefully balance needs like visibility and tamper resistance with the risk of operating within kernel mode.\nAll code operating at kernel level requires extensive validation because it cannot fail and restart like a normal user application. This is universal across all operating systems. Internally at Microsoft, we have invested in moving complex Windows core services from kernel to user mode, such as font file parsing from kernel to user mode.\nIt is possible today for security tools to balance security and reliability. For example, security vendors can use minimal sensors that run in kernel mode for data collection and enforcement limiting exposure to availability issues. The remainder of the key product functionality includes managing updates, parsing content, and other operations can occur isolated within user mode where recoverability is possible. This demonstrates the best practice of minimizing kernel usage while still maintaining a robust security posture and strong visibility.\nFigure 2 Example security product architecture which balances security and reliability\nWindows provides several user mode protection approaches for anti-tampering, like Virtualization-based security (VBS) Enclaves and Protected Processes that vendors can use to protect their key security processes. Windows also provides ETW events and user-mode interfaces like Antimalware Scan Interface for event visibility. These robust mechanisms can be used to reduce the amount of kernel code needed to create a security solution, which balances security and robustness.\nMicrosoft engages with third-party security vendors through an industry forum called the Microsoft Virus Initiative (MVI). This group consists of Microsoft and Security Industry and was created to establish a dialogue and collaboration across the Windows security ecosystem to improve robustness in the way security products use the platform. With MVI, Microsoft and vendors collaborate on the Windows platform to define reliable extension points and platform improvements, as well as share information about how to best protect our customers.\nMicrosoft works with members of MVI to ensure compatibility with Windows updates, improve performance, and address reliability issues. MVI partners actively participating in the program contribute to making the ecosystem more resilient and gain benefits including technical briefings, feedback loops with Microsoft product teams, and access to antimalware platform features such as ELAM and Protected Processes. Microsoft also provides runtime protection such as Patch Guard to prevent disruptive behavior from kernel driver types like anti-malware.\nIn addition, all drivers signed by the Microsoft Windows Hardware Quality Labs (WHQL) must run a series of tests and attest to a number of quality checks, including using fuzzers, running static code analysis and testing under runtime driver verification, among other techniques. These tests have been developed to ensure that best practices around security and reliability are followed. Microsoft includes all these tools in the Windows Driver Kit used by all driver developers. A list of the resources and tools is available here.\nAll WHQL signed drivers are run through Microsoft’s ingestion checks and malware scans and must pass before being approved for signing. Additionally, if a third-party vendor chooses to distribute their driver via Windows Update (WU), the driver also goes through Microsoft’s flighting and gradual rollout processes to observe quality and ensure the driver meets the necessary quality criteria for a broad release.\nCan customers deploy Windows in a higher security mode to increase reliability?\nWindows at its core is an open and versatile OS, and it can easily be locked down for increased security using integrated tools. In addition, Windows is constantly increasing security defaults, including dozens of new security features enabled by default in Windows 11.\nSecurity features enabled by default in Windows 11\nAreaFeatureHardware Security BaselineTPM2.0Secure bootVirtualization-based security (VBS)Memory integrity (Hypervisor-protected Code Integrity (HVCI))Hardware-enforced stack protectionKernel Direct Memory Access (DMA) protectionHW-based kernel protection (HLAT)Enhanced sign-in security (ESS) for built-in biometric sensorsEncryptionBitLocker (commercial)Device Encryption (consumer)Identity ManagementCredential GuardEntra primary refresh token (PRT) hardware protectedMDM deployed SCEP certs hardware protectedMDM enrollment certs hardware protectedLocal Security Authority (LSA) PPL prevents token/credential dumpingAccount lockout policy (for 10 failed sign-ins)Enhanced phishing protection with Microsoft DefenderMicrosoft Defender SmartScreenNPLogonNotification doesn’t include passwordWDigest SSO removed to reduce password disclosureAD Device Account protected by CredGuard*Multi-Factor Authentication(Passwordless)MSA & Entra users lead through Hello enablement by defaultMSA password automatically removed from Windows if never usedHello container VSM protectedPeripheral biometric sensors blocked for ESS enabled devicesLock on leave integrated into HelloSecurity Incident ReductionCommon Log File Systems run from trusted sourceMove tool-tip APIs from kernel to user modeModernize print stack by removing untrusted driversDPAPI moved from 3DES to AESTLS 1.3 default with TLS 1.0/1.1 disabled by defaultNTLM-less*OS lockdownMicrosoft Vulnerable Driver Blocklist3P driver security baseline enforced via WHCPSmart App Control**Feature available in the Windows Insider Program or currently off by default and on a path for default enablement\nWindows has integrated security features to self-defend. This includes key anti-malware features enabled by default, such as:\nSecure Boot, which helps prevent early boot malware and rootkits by enforcing signing consistently across Windows boots.\nMeasured Boot, which provides TPM-based hardware cryptographic measurements on boot-time properties available through integrated attestation services such as Device Health Attestation.\nMemory integrity (also known as hypervisor-protected code integrity or HVCI), which prevents runtime generation of dynamic code in the kernel and helps ensure control flow integrity.\nVulnerable driver blocklist, which is on by default, integrated into the OS, and managed by Microsoft. This complements the malicious driver block list.\nProtected Local Security Authority is on by default in Windows 11 to protect a range of credentials. Hardware-based credential protection is on by default for enterprise versions of Windows.\nMicrosoft Defender Antivirus is enabled by default in Windows and offers anti-malware capabilities across the OS.\nThese security capabilities provide layers of protection against malware and exploitation attempts in modern Windows. Many Windows customers have leveraged our security baseline and Windows security technologies to harden their systems and these capabilities collectively have reduced the attack surface significantly.\nUsing the integrated security features of Windows to prevent adversary attacks such as those displayed in the MITRE ATT&CK® framework increases security while reducing cost and complexity. It leverages best practices to achieve maximum security and reliability. These best practices include:\nUsing App Control for Business (formerly Windows Defender Application Control), you can author a security policy to allow only trusted and/or business-critical apps. Your policy can be crafted to deterministically and durably prevent nearly all malware and “living off the land” style attacks. It can also specify which kernel drivers are allowed by your organization to durably guarantee that only those drivers will load on your managed endpoints.\nUse Memory integrity with a specific allow list policy to further protect the Windows kernel using Virtualization-based security (VBS). Combined with App Control for Business, memory integrity can reduce the attack surface for kernel malware or boot kits. This can also be used to limit any drivers that might impact reliability on systems.\nRunning as Standard User and elevating only as necessary. Companies that follow the best practices to run as standard user and reduce privileges mitigate many of the MITRE ATT&CK® techniques.\nUse Device Health Attestation (DHA) to monitor devices for the right security policy, including hardware-based measurements for the security posture of the machine. This is a modern and exceptionally durable approach to ensure security for high availability scenarios and uses Microsoft’s Zero Trust architecture.\nWindows is a self-protecting operating system that has produced dozens of new security features and architectural changes in recent versions. We plan to work with the anti-malware ecosystem to take advantage of these integrated features to modernize their approach, helping to support and even increase security along with reliability.\nThis includes helping the ecosystem by:\nProviding safe rollout guidance, best practices, and technologies to make it safer to perform updates to security products.\nReducing the need for kernel drivers to access important security data.\nProviding enhanced isolation and anti-tampering capabilities with technologies like our recently announced VBS enclaves.\nEnabling zero trust approaches like high integrity attestation which provides a method to determine the security state of the machine based on the health of Windows native security features.\nAs we move forward, Windows is continuing to innovate and offer new ways for security tools to detect and respond to emerging threats safely and securely. Windows has announced a commitment around the Rust programming language as part of Microsoft’s Secure Future Initiative (SFI) and has recently expanded the Windows kernel to support Rust.\nThe information in this blog post is provided as part of our commitment to communicate learnings and next steps after the CrowdStrike incident. We will continue to share ongoing guidance on security best practices for Windows and work across our broad ecosystem of customers and partners to develop new security capabilities based on your feedback.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Turn your ideas into songs with Suno on Microsoft Copilot",
    "link": "https://www.microsoft.com/en-us/microsoft-copilot/blog/2023/12/19/turn-your-ideas-into-songs-with-suno-on-microsoft-copilot/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNDRXWGxJVkZsdU5sSlJOamRPVFJDOEFSaU5BaWdCTWdZbE5aVE9IUWc=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-12-19T08:00:00.000Z",
    "time": "Dec 19, 2023",
    "articleType": "regular",
    "content": "We are excited to share that that we have partnered with Suno, a leader in artificial intelligence-based music creation to bring their capabilities to Microsoft Copilot. Through this partnership, people will have at their fingertips the ability, regardless of musical background, to create fun, clever, and personalized songs with a simple prompt.\nWe are excited to share that that we have partnered with Suno, a leader in artificial intelligence-based music creation to bring their capabilities to Microsoft Copilot. Through this partnership, people will have at their fingertips the ability, regardless of musical background, to create fun, clever, and personalized songs with a simple prompt. Suno has been a leader in AI music technology, pioneering the ability to generate complete songs—lyrics, instrumentals, and singing voices—from a single sentence.\nYou don’t have to know how to sing, play an instrument, or read music to bring your musical ideas to life. Microsoft Copilot and Suno will do all the hard work for you, matching the song to cues in your prompt. To get started creating your music, simply follow these steps:\nOpen Microsoft Edge, visit copilot.microsoft.com and ensure you’re signed in with your Microsoft Account\nEnable the Suno plugin or click on the Suno logo that says, “Make music with Suno”\nAsk Copilot to create a song for you such as, “Create a pop song about adventures with your family”\nJam along to your new tune\nShare on social or with your friends and colleagues\nWe believe that this partnership will open new horizons for creativity and fun, making music creation accessible to everyone. This experience will begin rolling out to users starting today, ramping up in the coming weeks. We can’t wait to see (and hear!) what you create.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Tiny but mighty: The Phi-3 small language models with big potential - Source",
    "link": "https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNDRUMko1YTJJdGNFaFVUMmczVFJDM0FSaVRBaWdCTWdhNVU0eFJvUWc=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-23T07:00:00.000Z",
    "time": "Apr 23",
    "articleType": "regular",
    "content": "Sometimes the best way to solve a complex problem is to take a page from a children’s book. That’s the lesson Microsoft researchers learned by figuring out how to pack more punch into a much smaller package.\nLast year, after spending his workday thinking through potential solutions to machine learning riddles, Microsoft’s Ronen Eldan was reading bedtime stories to his daughter when he thought to himself, “how did she learn this word? How does she know how to connect these words?”\nThat led the Microsoft Research machine learning expert to wonder how much an AI model could learn using only words a 4-year-old could understand – and ultimately to an innovative training approach that’s produced a new class of more capable small language models that promises to make AI more accessible to more people.\nLarge language models (LLMs) have created exciting new opportunities to be more productive and creative using AI.  But their size means they can require significant computing resources to operate.\nWhile those models will still be the gold standard for solving many types of complex tasks, Microsoft has been developing a series of small language models (SLMs) that offer many of the same capabilities found in LLMs but are smaller in size and are trained on smaller amounts of data.\nThe company announced today the Phi-3 family of open models, the most capable and cost-effective small language models available. Phi-3 models outperform models of the same size and next size up across a variety of benchmarks that evaluate language, coding and math capabilities, thanks to training innovations developed by Microsoft researchers.\nMicrosoft is now making the first in that family of more powerful small language models publicly available: Phi-3-mini, measuring 3.8 billion parameters, which performs better than models twice its size, the company said.\nStarting today, it will be available in the Microsoft Azure AI Model Catalog and on Hugging Face, a platform for machine learning models, as well as Ollama, a lightweight framework for running models on a local machine. It will also be available as an NVIDIA NIM microservice with a standard API interface that can be deployed anywhere.\nMicrosoft also announced additional models to the Phi-3 family are coming soon to offer more choice across quality and cost. Phi-3-small (7 billion parameters) and Phi-3-medium (14 billion parameters) will be available in the Azure AI Model Catalog and other model gardens shortly.\nGraphic illustrating how the quality of new Phi-3 models, as measured by performance on the Massive Multitask Language Understanding (MMLU) benchmark, compares to other models of similar size. (Image courtesy of Microsoft)\nSmall language models are designed to perform well for simpler tasks, are more accessible and easier to use for organizations with limited resources and they can be more easily fine-tuned to meet specific needs.\n“What we’re going to start to see is not a shift from large to small, but a shift from a singular category of models to a portfolio of models where customers get the ability to make a decision on what is the best model for their scenario,” said Sonali Yadav, principal product manager for Generative AI at Microsoft.\n“Some customers may only need small models, some will need big models and many are going to want to combine both in a variety of ways,” said Luis Vargas, vice president of AI at Microsoft.\nChoosing the right language model depends on an organization’s specific needs, the complexity of the task and available resources. Small language models are well suited for organizations looking to build applications that can run locally on a device (as opposed to the cloud) and where a task doesn’t require extensive reasoning or a quick response is needed.\nLarge language models are more suited for applications that need orchestration of complex tasks involving advanced reasoning, data analysis and understanding of context.\nSmall language models also offer potential solutions for regulated industries and sectors that encounter situations where they need high quality results but want to keep data on their own premises, said Yadav.\nVargas and Yadav are particularly excited about the opportunities to place more capable SLMs on smartphones and other mobile devices that operate “at the edge,” not connected to the cloud. (Think of car computers, PCs without Wi-Fi, traffic systems, smart sensors on a factory floor, remote cameras or devices that monitor environmental compliance.) By keeping data within the device, users can “minimize latency and maximize privacy,” said Vargas.\nLatency refers to the delay that can occur when LLMs communicate with the cloud to retrieve information used to generate answers to users prompts. In some instances, high-quality answers are worth waiting for while in other scenarios speed is more important to user satisfaction.\nBecause SLMs can work offline, more people will be able to put AI to work in ways that haven’t previously been possible, Vargas said.\nFor instance, SLMs could also be put to use in rural areas that lack cell service. Consider a farmer inspecting crops who finds signs of disease on a leaf or branch. Using a SLM with visual capability, the farmer could take a picture of the crop at issue and get immediate recommendations on how to treat pests or disease.\n“If you are in a part of the world that doesn’t have a good network,” said Vargas, “you are still going to be able to have AI experiences on your device.”\nThe role of high-quality data\nJust as the name implies, compared to LLMs, SLMs are tiny, at least by AI standards. Phi-3-mini has “only” 3.8 billion parameters – a unit of measure that refers to the algorithmic knobs on a model that help determine its output. By contrast, the biggest large language models are many orders of magnitude larger.\nThe huge advances in generative AI ushered in by large language models were largely thought to be enabled by their sheer size. But the Microsoft team was able to develop small language models that can deliver outsized results in a tiny package. This breakthrough was enabled by a highly selective approach to training data – which is where children’s books come into play.\nTo date, the standard way to train large language models has been to use massive amounts of data from the internet. This was thought to be the only way to meet this type of model’s huge appetite for content, which it needs to “learn” to understand the nuances of language and generate intelligent answers to user prompts. But Microsoft researchers had a different idea.\n“Instead of training on just raw web data, why don’t you look for data which is of extremely high quality?” asked Sebastien Bubeck, Microsoft vice president of generative AI research who has led the company’s efforts to develop more capable small language models. But where to focus?\nInspired by Eldan’s nightly reading ritual with his daughter, Microsoft researchers decided to create a discrete dataset starting with 3,000 words – including a roughly equal number of nouns, verbs and adjectives. Then they asked a large language model to create a children’s story using one noun, one verb and one adjective from the list – a prompt they repeated millions of times over several days, generating millions of tiny children’s stories.\nThey dubbed the resulting dataset “TinyStories” and used it to train very small language models of around 10 million parameters. To their surprise, when prompted to create its own stories, the small language model trained on TinyStories generated fluent narratives with perfect grammar.\nNext, they took their experiment up a grade, so to speak. This time a bigger group of researchers used carefully selected publicly-available data that was filtered based on educational value and content quality to train Phi-1. After collecting publicly available information into an initial dataset, they used a prompting and seeding formula inspired by the one used for TinyStories, but took it one step further and made it more sophisticated, so that it would capture a wider scope of data. To ensure high quality, they repeatedly filtered the resulting content before feeding it back into a LLM for further synthesizing. In this way, over several weeks, they built up a corpus of data large enough to train a more capable SLM.\n“A lot of care goes into producing these synthetic data,” Bubeck said, referring to data generated by AI, “looking over it, making sure it makes sense, filtering it out. We don’t take everything that we produce.” They dubbed this dataset “CodeTextbook.”\nThe researchers further enhanced the dataset by approaching data selection like a teacher breaking down difficult concepts for a student. “Because it’s reading from textbook-like material, from quality documents that explain things very, very well,” said Bubeck, “you make the task of the language model to read and understand this material much easier.”\nDistinguishing between high- and low-quality information isn’t difficult for a human, but sorting through more than a terabyte of data that Microsoft researchers determined they would need to train their SLM would be impossible without help from a LLM.\n“The power of the current generation of large language models is really an enabler that we didn’t have before in terms of synthetic data generation,” said Ece Kamar, a Microsoft vice president who leads the Microsoft Research AI Frontiers Lab, where the new training approach was developed.\nStarting with carefully selected data helps reduce the likelihood of models returning unwanted or inappropriate responses, but it’s not sufficient to guard against all potential safety challenges. As with all generative AI model releases, Microsoft’s product and responsible AI teams used a multi-layered approach to manage and mitigate risks in developing Phi-3 models.\nFor instance, after initial training they provided additional examples and feedback on how the models should ideally respond, which builds in an additional safety layer and helps the model generate high-quality results. Each model also undergoes assessment, testing and manual red-teaming, in which experts identify and address potential vulnerabilities.\nFinally, developers using the Phi-3 model family can also take advantage of a suite of tools available in Azure AI  to help them build safer and more trustworthy applications.\nChoosing the right-size language model for the right task\nBut even small language models trained on high quality data have limitations. They are not designed for in-depth knowledge retrieval, where large language models excel due to their greater capacity and training using much larger data sets.\nLLMs are better than SLMs at complex reasoning over large amounts of information due to their size and processing power. That’s a function that could be relevant for drug discovery, for example, by helping to pore through vast stores of scientific papers, analyze complex patterns and understand interactions between genes, proteins or chemicals.\n“Anything that involves things like planning where you have a task, and the task is complicated enough that you need to figure out how to partition that task into a set of sub tasks, and sometimes sub-sub tasks, and then execute through all of those to come with a final answer … are really going to be in the domain of large models for a while,” said Vargas.\nBased on ongoing conversations with customers, Vargas and Yadav expect to see some companies “offloading” some tasks to small models if the task is not too complex.\nSonali Yadav, principal product manager for Generative AI at Microsoft. (Photo by Dan DeLong for Microsoft)\nFor instance, a business could use Phi-3 to summarize the main points of a long document or extract relevant insights and industry trends from market research reports. Another organization might use Phi-3 to generate copy, helping create content for marketing or sales teams such as product descriptions or social media posts. Or, a company might use Phi-3 to power a support chatbot to answer customers’ basic questions about their plan, or service upgrades.\nInternally, Microsoft is already using suites of models, where large language models play the role of router, to direct certain queries that require less computing power to small language models, while tackling other more complex requests itself.\n“The claim here is not that SLMs are going to substitute or replace large language models,” said Kamar. Instead, SLMs “are uniquely positioned for computation on the edge, computation on the device, computations where you don’t need to go to the cloud to get things done. That’s why it is important for us to understand the strengths and weaknesses of this model portfolio.”\nAnd size carries important advantages. There’s still a gap between small language models and the level of intelligence that you can get from the big models on the cloud, said Bubeck. “And maybe there will always be a gap because you know – the big models are going to keep making progress.”\nRead more: Introducing Phi-3, redefining what’s possible with SLMs\nRead more: Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\nTop image: Sebastien Bubeck, Microsoft vice president of Generative AI research who has led the company’s efforts to develop more capable small language models. (Photo by Dan DeLong for Microsoft)",
    "favicon": "https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2022/10/cropped-Microsoft_logo.svg_-300x300-1-128x120.png"
  },
  {
    "title": "Adobe and Microsoft partner to bring new generative AI capabilities to marketers as they work in Microsoft 365 applications",
    "link": "https://news.microsoft.com/2024/03/26/adobe-and-microsoft-partner-to-bring-new-generative-ai-capabilities-to-marketers-as-they-work-in-microsoft-365-applications/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWlNWFZsV1hORVMyZzJOak5ZVFJDZkFSaS1BaWdCTWdZRnNaYUdQZ2M=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-03-26T07:00:00.000Z",
    "time": "Mar 26",
    "articleType": "regular",
    "content": "Adobe and Microsoft partner to connect Adobe Experience Cloud workflows and insights with Microsoft Copilot to deliver generative-AI powered capabilities that enable marketers to increase collaboration, efficiency and creativity.\nSAN JOSE, Calif. and REDMOND, Wash. – Mar. 26, 2024 – Today at Adobe Summit – the world’s largest digital experience conference – Adobe (Nasdaq:ADBE) and Microsoft (Nasdaq:MSFT) announced plans to bring Adobe Experience Cloud workflows and insights to Microsoft Copilot for Microsoft 365 to help marketers overcome application and data silos and more efficiently manage everyday workflows. These new integrated capabilities will bring relevant marketing insights and workflows from Adobe Experience Cloud applications and Microsoft Dynamics 365 to Microsoft Copilot, assisting marketers as they work in tools such as Outlook, Microsoft Teams and Word to develop creative briefs, create content, manage content approvals, deliver experiences and more.\n“The demand for personalized content across social media, mobile and other fast-moving channels has been exploding, pushing marketers to drive greater efficiency and productivity in their everyday work,” said Amit Ahuja, senior vice president, Digital Experience Business at Adobe. “Marketers spend a great deal of their day working across Adobe and Microsoft applications, and the partnership provides a unique offering for marketing teams, streamlining daily tasks across planning, collaboration, create and campaign execution.”\n“Microsoft and Adobe share a common goal of empowering marketers to focus on the work that’s most important – creating impactful campaigns and enhancing customer experiences,” said Jared Spataro, corporate vice president, AI at Work, Microsoft. “By integrating contextual marketing insights from Adobe Experience Cloud applications and Dynamics 365 within the flow of work through Copilot for Microsoft 365, we deliver on our shared goal while helping marketers streamline their efforts, break down barriers, and deliver exceptional results.”\nThe marketing discipline is complex and made up of specialized roles which require specialized tools – from designing brand content and managing campaigns, to tracking audience insights across channels with internal and external partners and reporting out results. This means marketers face challenges of working in silos and in different applications, which can lead to misalignment and negatively impact speed and productivity. According to a recent survey conducted by Microsoft[1], 43 percent of marketing and communications professionals reported that having to switch between digital applications and programs was disruptive to their creativity.\nTogether, Adobe and Microsoft will address these challenges. Initial capabilities will focus on addressing the needs of marketers who often work across multiple teams internally and externally while managing campaign goals, status and actions. The capabilities will address scenarios including:\nStrategic insights in the flow of work: Enriched with relevant campaign insights from Adobe Experience Cloud applications such as Adobe Customer Journey Analytics and Adobe Workfront, combined with Dynamics 365, the Copilot for Microsoft 365 experience helps marketers get quick insights and updates in Outlook, Teams and Word. Marketers can ask questions to get the status of a marketing project, understand the effectiveness of a campaign, outstanding approvals, and actions to take, or the audience and KPIs being defined in the latest campaign brief.\nCreate campaign briefs, presentations, website updates and emails with relevant context: Marketers can be even more data-driven without having to go to multiple tools or people for insights. Marketing insights from Adobe and Dynamics 365 will be available in Copilot for Microsoft 365 to create briefs, presentations for exec reviews, or any kind of report or message. Marketers can also create imagery with Adobe Firefly generative AI or copy for marketing experiences through Adobe Experience Manager Sites; marketers can create content in Word that gets published directly to channels such as web and mobile.\nKeep projects moving with in-context notifications and summaries: Often marketers will need to go into multiple applications, emails and chats to compile a project status – from feedback and approvals to work item changes or due dates. These integrated capabilities informed by Adobe Workfront can work across these applications to create notifications informed by relevant marketing data to stay on top of any changes and actions to take.\nMicrosoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.\nMicrosoft Media Relations, WE Communications for Microsoft, (425) 638-7777, rapidresponse@we-worldwide.com\n[1] Global survey on function-specific pain points and opportunities\nThis survey was conducted as part of our Work Trend Index research by an independent research firm, Edelman Data x Intelligence, among 18,100 full-time employed or self-employed workers across 12 markets between July 21, 2023, and November 1, 2023.",
    "favicon": "https://news.microsoft.com/wp-content/uploads/prod/2017/03/cropped-microsoft_logo_element-150x150.png"
  },
  {
    "title": "Here’s how we’re working with journalists to create the newsrooms of the future with AI - Microsoft On the Issues",
    "link": "https://blogs.microsoft.com/on-the-issues/2024/02/05/journalism-news-generative-ai-democracy-forward/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNU9kbFU1UlVrMFVVa3dObTUxVFJDM0FSaVRBaWdCTWdZQkk1d3VsUW8=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-02-05T08:00:00.000Z",
    "time": "Feb 5",
    "articleType": "regular",
    "content": "What will the newsroom of the future look like?\nToday, Microsoft is launching several collaborations with news organizations to adopt generative AI. In a year where billions of people will vote in democratic elections worldwide, journalism is critical to creating healthy information ecosystems, and it is our mission, working with the industry, to ensure that newsrooms can innovate to serve this year and in the future.\nThrough these new programs, we are helping these organizations identify and refine the procedures and policies to use AI responsibly in newsgathering and business practices, helping train a new generation of reporters on best uses of AI and identify ways AI can help create efficient business practices and help build sustainable newsrooms for generations to come.\nSemafor will work with us to harness AI tools to assist journalists in their research, source discovery, translation, and more with Semafor Signals, helping journalists provide a diverse array of credible local, national, and global sources to their audience.\nThe Craig Newmark Graduate School of Journalism at CUNY will invite experienced journalists to a tuition-free program to explore ways to incorporate generative AI into their work and newsrooms in a three-month hybrid and highly interactive program. The AI Journalism Lab will be run by Nikita Roy, a data scientist, entrepreneur, and host of the podcast Newsroom Robots, which explores AI applications in journalism.\nThe Online News Association is launching programming to support journalists and newsroom leaders as they navigate the evolving AI ecosystem. ONA’s AI in Journalism Initiative offers a menu of opportunities addressing what is possible across the newsroom through AI, collaboratively exploring and experimenting with tools, and creating opportunities for greater audience reach and business sustainability.\nThe GroundTruth Project, which sends local journalists into newsrooms around the world through its Report for America and Report for the World programs, will add an AI track of work for its corps members through the AI in Local News initiative with the goal of helping make reporting and newsrooms themselves more efficient and sustainable for the future.\nNota, a startup dedicated to putting high-quality AI tools into newsrooms to help improve newsroom operations, has expanded to more than a 100 newsrooms with support from Microsoft. Its suite of tools are helping newsrooms reach new audiences, expand social media presence and better tailor content to audience information needs. Nota will soon release a new tool called PROOF, an assistive recommendation widget that will give real-time tips to journalists and editors about how to better reach audiences with their content through readability, SEO analysis, link integrity, and more.\nThese collaborators are established industry groups, leading academics, local news champions, and global newsrooms who are seeking to educate, experiment, lead, and scale AI solutions that support the industry. Each organization will have access to Microsoft experts, technology, and support this year, and has committed to sharing the results of their projects with the wider industry to teach, inspire, and innovate the way news will be produced in the future.\nWorking directly with newsrooms, universities, journalists, and industry groups, we will help these organizations use AI to grow audiences, streamline time-consuming tasks in the newsroom, and build sustainable business operations. Our goal is to support thriving, sustainable newsrooms with the technology they need to perform the essential function of informing the world.\nThese projects build on Microsoft’s existing commitment to sustainable journalism, and pledges to reduce risk, restore trust, and rebuild capacity in news ecosystems through the Democracy Forward program.\nLocal, national, and global news organizations depend on being able to innovate responsibly with emerging technology to stay competitive. The survival of fact-based news is inextricably linked to healthy democracies, thriving communities, and civic participation. Journalism has an essential function in fighting against information operations and threats to democracy.\nCentral to all of these commitments is journalists themselves.\nHealthy news organizations do not exist without journalists who know their communities and topics, have deep relationships with leaders in government and civic life, and understand how to reach their communities. This work is challenging – and our goal is to find ways to support journalists in this mission, not replace them. By working with these organizations, we hope to shed light on the promise that the newsroom of the future can hold.\nTags: AI, journalism, Responsible AI, Semafor",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "New subscription structure for Microsoft 365 in Europe",
    "link": "https://www.microsoft.com/en-us/licensing/news/microsoft365-teams-eea",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNDRRMUkwVkVnMVduWlJUa3ROVFJDeUFSaWJBaWdCTWdPcGxRUQ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-08-31T07:00:00.000Z",
    "time": "Aug 31, 2023",
    "articleType": "regular",
    "content": "Today, Microsoft announced important changes to the way we license Microsoft 365, Office 365, and Microsoft Teams in the European Economic Area (EEA) and Switzerland. See below for details on how these changes will impact Microsoft customers and partners in these regions.\nWe believe that business customers in Europe and around the world expect a modern work solution to include modern communication and collaboration capabilities. That’s why, for more than a decade, we have included these capabilities in our business suites, starting with Office Communicator in 2007 and evolving and innovating over the years through Lync, Skype for Business Online, and most recently Microsoft Teams. As work continues to evolve, we remain committed to helping our customers adapt and thrive. We do this by studying how work is changing, responding to customer needs, and being responsive to feedback from governments and competitors.\nIn an effort to remain focused on the needs of our customers while also taking meaningful steps to address concerns that have been raised with the European Commission, we are updating the way Microsoft 365, Office 365, and Teams are licensed in the EEA and Switzerland. Starting October 1, 2023, we will introduce 1) a new lineup of commercial Microsoft 365 and Office 365 suites in these regions that do not include Teams, and 2) a new standalone Teams offering for Enterprise customers. These changes will not impact currently subscribed customers, and will be implemented in the following way:",
    "favicon": "/favicon.ico?v2"
  },
  {
    "title": "AI at Work Is Here. Now Comes the Hard Part",
    "link": "https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVFjRVJDTTA4MU1sTTBUbUoxVFJDb0FSaXNBaWdCTWdZNVE1SlNwUVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-08T07:00:00.000Z",
    "time": "May 8",
    "articleType": "regular",
    "content": "",
    "favicon": "https://worklab-d8hngjfqgfdvh5g5.z01.azurefd.net/en-us/worklab/favicon-32x32.png?v=910981313277ba02145e9a269c3423e3"
  },
  {
    "title": "Flax Typhoon using legitimate software to quietly access Taiwanese organizations",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/08/24/flax-typhoon-using-legitimate-software-to-quietly-access-taiwanese-organizations/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNHpSRlZWUmpnemVXZFBhVVZQVFJDM0FSaVRBaWdCTWdrQlk1cFNKZW5JS3dJ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-08-24T07:00:00.000Z",
    "time": "Aug 24, 2023",
    "articleType": "regular",
    "content": "Microsoft has identified a nation-state activity group tracked as Flax Typhoon, based in China, that is targeting dozens of organizations in Taiwan with the likely intention of performing espionage. Flax Typhoon gains and maintains long-term access to Taiwanese organizations’ networks with minimal use of malware, relying on tools built into the operating system, along with some normally benign software to quietly remain in these networks. Microsoft has not observed Flax Typhoon using this access to conduct additional actions. This blog aims to raise awareness of the techniques used by this threat actor and inform better defenses to protect against future attacks.\nMicrosoft has observed a distinctive pattern of malicious activity almost exclusively affecting organizations in Taiwan using techniques that could be easily reused in other operations outside the region and would benefit from broader industry visibility. Microsoft attributes this campaign to Flax Typhoon (overlaps with ETHEREAL PANDA), a nation-state actor based out of China. Flax Typhoon’s observed behavior suggests that the threat actor intends to perform espionage and maintain access to organizations across a broad range of industries for as long as possible. However, Microsoft has not observed Flax Typhoon act on final objectives in this campaign. Microsoft is choosing to highlight this Flax Typhoon activity at this time because of our significant concern around the potential for further impact to our customers. Although our visibility into these threats has given us the ability to deploy detections to our customers, the lack of visibility into other parts of the actor’s activity compelled us to drive broader community awareness to further investigations and protections across the security ecosystem.\nIn this blog post, we share information on Flax Typhoon, the current campaign targeting Taiwan, and the actor’s tactics for achieving and maintaining unauthorized access to target networks. Because this activity relies on valid accounts and living-off-the-land binaries (LOLBins), detecting and mitigating this attack could be challenging. Compromised accounts must be closed or changed. Compromised systems must be isolated and investigated. At the end of this blog post, we share more mitigation steps and best practices, as well as provide details on how Microsoft 365 Defender detects malicious and suspicious activity to protect organizations from such stealthy attacks.\nFlax Typhoon has been active since mid-2021 and has targeted government agencies and education, critical manufacturing, and information technology organizations in Taiwan. Some victims have also been observed elsewhere in Southeast Asia, as well as in North America and Africa. Flax Typhoon focuses on persistence, lateral movement, and credential access. As with any observed nation-state actor activity, Microsoft has directly notified targeted or compromised customers, providing them with important information needed to secure their environments.\nFlax Typhoon is known to use the China Chopper web shell, Metasploit, Juicy Potato privilege escalation tool, Mimikatz, and SoftEther virtual private network (VPN) client. However, Flax Typhoon primarily relies on living-off-the-land techniques and hands-on-keyboard activity. Flax Typhoon achieves initial access by exploiting known vulnerabilities in public-facing servers and deploying web shells like China Chopper. Following initial access, Flax Typhoon uses command-line tools to first establish persistent access over the remote desktop protocol, then deploy a VPN connection to actor-controlled network infrastructure, and finally collect credentials from compromised systems. Flax Typhoon further uses this VPN access to scan for vulnerabilities on targeted systems and organizations from the compromised systems.\nFigure 1. Flax Typhoon attack chain\nFlax Typhoon achieves initial access by exploiting known vulnerabilities in public-facing servers. The services targeted vary, but include VPN, web, Java, and SQL applications. The payload in these exploits is a web shell, such as China Chopper, which allows for remote code execution on the compromised server.\nIn cases where the process compromised via web shell does not have local administrator privileges, Flax Typhoon downloads and runs a piece of malware that exploits one or more known vulnerabilities to obtain local system privileges. Microsoft has observed the actor use Juicy Potato, BadPotato, and other open-source tools to exploit these vulnerabilities.\nOnce Flax Typhoon can access Windows Management Instrumentation command-line (WMIC), PowerShell, or the Windows Terminal with local administrator privileges, the actor establishes a long-term method of accessing the compromised system using the remote desktop protocol (RDP). To accomplish this, the actor disables network-level authentication (NLA) for RDP, replaces the Sticky Keys binary, and establishes a VPN connection.\nWhen using RDP, NLA requires the connecting user to authenticate to the remote system before a full remote session is established and the Windows sign-in screen is displayed. When NLA is disabled, any user attempting to access the remote system can interact with the Windows sign-in screen before authenticating, which can expose the remote system to malicious actions by the connecting user. Flax Typhoon changes a registry key to disable NLA, allowing them to access the Windows sign-in screen without authenticating, whereupon the actor will use the Sticky Keys shortcut.\nFigure 2. Flax Typhoon command disabling NLA\nSticky Keys is an accessibility feature in Windows that allows users to press modifier keys (such as Shift, Ctrl, Alt) one at a time instead of simultaneously. It includes a shortcut where the user can press the Shift key five times in succession to launch sethc.exe, the program that manages Sticky Keys. The user can invoke this shortcut at any time, including at the sign-in screen. To take advantage of this feature, Flax Typhoon changes a registry key that specifies the location of sethc.exe. The actor adds arguments that cause the Windows Task Manager to be launched as a debugger for sethc.exe. As a result, when the actor uses the Sticky Keys shortcut on the Windows sign-in screen, Task Manager launches with local system privileges.\nFigure 3. Flax Typhoon command altering Sticky Keys behavior\nAt this stage, Flax Typhoon can access the compromised system via RDP, use the Sticky Keys shortcut at the sign-in screen, and access Task Manager with local system privileges. From there, the actor can launch the Terminal, create memory dumps, and take nearly any other action on the compromised system. The only issue the actor faces with this persistence method is that RDP is most likely running on an internal-facing network interface. Flax Typhoon’s solution is to install a legitimate VPN bridge to automatically connect to actor-controlled network infrastructure.\nTo deploy the VPN connection, Flax Typhoon downloads an executable file for SoftEther VPN from their network infrastructure. The actor downloads the tool using one of several LOLBins, such as the PowerShell Invoke-WebRequest utility, certutil, or bitsadmin. Flax Typhoon then uses the Service Control Manager (SCM) to create a Windows service that launches the VPN connection automatically when the system starts. This could allow the actor to monitor the availability of the compromised system and establish an RDP connection.\nFigure 4. Flax Typhoon command downloading a SoftEther VPN executable\nFigure 5. Flax Typhoon command creating a service to launch the VPN connection\nFlax Typhoon takes several precautions with their VPN connection to make it harder to identify. First, the actor uses a legitimate VPN application that could be found in enterprise environments. As a result, the file itself is almost certain to go undetected by antivirus products. Second, the actor almost always renames the executable file from vpnbridge.exe to conhost.exe or dllhost.exe. These names imitate the legitimate Windows components Console Window Host Process and Component Object Model Surrogate respectively. Third, the actor uses SoftEther’s VPN-over-HTTPS operation mode, which uses protocol tunneling to encapsulate Ethernet packets into compliant HTTPS packets and transmit them to TCP port 443. This makes the VPN connection very difficult to differentiate from legitimate HTTPS traffic, which most network security appliances would not block.\nIn cases where Flax Typhoon needs to move laterally to access other systems on the compromised network, the actor uses LOLBins, including Windows Remote Management (WinRM) and WMIC.\nMicrosoft has observed Flax Typhoon routing network traffic to other targeted systems through the SoftEther VPN bridge installed on compromised systems. This network traffic includes network scanning, vulnerability scanning, and exploitation attempts.\nOnce Flax Typhoon becomes established on the target system, Microsoft observes the actor conducting credential access activities using common tools and techniques. Most commonly, Flax Typhoon targets the Local Security Authority Subsystem Service (LSASS) process memory and Security Account Manager (SAM) registry hive. Both stores contain hashed passwords for users signed into the local system. Flax Typhoon frequently deploys Mimikatz, a publicly available malware that can automatically dump these stores when improperly secured. The resulting password hashes can be cracked offline or used in pass-the-hash (PtH) attacks to access other resources on the compromised network.\nFlax Typhoon also enumerates restore points used by System Restore. Restore points contain data about the Windows operating system that the system owner can use to revert changes to the system if it becomes inoperable, rather than a backup of user data. Flax Typhoon could use this information to better understand the compromised system or as a template for removing indicators of malicious activity.\nThis pattern of activity is unusual in that minimal activity occurs after the actor establishes persistence. Flax Typhoon’s discovery and credential access activities do not appear to enable further data-collection and exfiltration objectives. While the actor’s observed behavior suggests Flax Typhoon intents to perform espionage and maintain their network footholds, Microsoft has not observed Flax Typhoon act on final objectives in this campaign.\nDefending against techniques used by Flax Typhoon begins with vulnerability and patch management, particularly on systems and services exposed to the public internet. The credential access techniques used can also be mitigated with proper system hardening.\nWhat to do now if you’re affected\nAffected organizations need to assess the scale of Flax Typhoon activity in their network, remove malicious tools and C2 infrastructure, and check logs for signs of compromised accounts that may have been used for malicious purposes.\nInvestigating Suspected compromised accounts or affected systems\nFind LSASS and SAM dumping to identify affected accounts.\nExamine the activity of compromised accounts for any malicious actions or exposed data.\nClose or change credentials for all compromised accounts. Depending on the level of activity, many accounts may be affected.\nAffected systems should be isolated and forensically examined for artifacts of malicious activity.\nBecause Flax Typhoon alters the configuration of the operating system to produce malicious behavior, affected systems may need to be decommissioned or restored to a known-good configuration.\nDefending against Flax Typhoon attacks\nKeep public-facing servers up to date to defend against malicious activity. As prime targets for threat actors, public-facing servers need additional monitoring and security. User input validation, file integrity monitoring, behavioral monitoring, and web application firewalls can all help to better secure these servers.\nMonitor the Windows registry for unauthorized changes. The Audit Registry feature allows administrators to generate events when specific registry keys are modified. Such policies can detect registry changes that undermine the security of a system, like those made by Flax Typhoon.\nUse network monitoring and intrusion detection systems to identify unusual or unauthorized network traffic. If an organization does not use RDP for a specific business purpose, any RDP traffic should be considered unauthorized and generate alerts.\nEnsure that Windows systems are kept updated with the latest security patches, including MS16-075.\nMitigate the risk of compromised valid accounts by enforcing strong multifactor authentication (MFA) policies using hardware security keys or Microsoft Authenticator. Passwordless sign-in methods (for example, Windows Hello, FIDO2 security keys, or Microsoft Authenticator), password expiration rules, and deactivating unused accounts can also help mitigate risk from this access method.\nRandomize Local Administrator passwords with a tool like Local Administrator Password Solution (LAPS) to prevent lateral movement using local accounts with shared passwords.\nReduce the attack surface. Microsoft customers can turn on the following attack surface reduction rules to block or audit some observed activity associated with this threat:\nBlock credential stealing from the Windows local security authority subsystem (lsass.exe).\nBlock process creations originating from PSExec and WMI commands. Some organizations may experience compatibility issues with this rule on certain server systems but should deploy it to other systems to prevent lateral movement originating from PsExec and WMI.\nHarden the LSASS process by enabling Protective Process Light (PPL) for LSASS on Windows 11 devices. New, enterprise-joined Windows 11 (22H2 update) installs have this feature enabled by default. In addition, enable Windows Defender Credential Guard, which is also turned on by default for organizations using the Enterprise edition of Windows 11, as well as Memory integrity (also referred to as hypervisor-protected code integrity or HVCI) for stronger protections on Windows.\nSet the WDigest UseLogonCredential registry value via Group Policy Object to reduce the risk of successful LSASS process memory dumping.\nTurn on cloud-delivered protection in Microsoft Defender Antivirus to cover rapidly evolving attacker tools, techniques, and behaviors such as those exhibited by Flax Typhoon.\nRun endpoint detection and response (EDR) in block mode so that Microsoft Defender for Endpoint can block malicious artifacts, even when your non-Microsoft antivirus does not detect the threat, or when Microsoft Defender Antivirus is running in passive mode. EDR in block mode works behind the scenes to remediate malicious artifacts that are detected post-compromise.\nDetection details and hunting queries\nMicrosoft Defender Antivirus detects threat components as the following malware:\nThe following alerts might indicate threat activity related to this threat. Note, however, that these alerts can also be triggered by unrelated threat activity.\nMalicious credential theft tool execution detected\nSuspicious access to LSASS service\nUse of LOLBin to run malicious code\nMicrosoft 365 Defender customers can run the following queries to find related activity in their networks:\nNetwork activity with Flax Typhoon network infrastructure\nlet ipAddressTimes = datatable(ip: string, startDate: datetime, endDate: datetime)[    \"101.33.205.106\", datetime(\"2022-11-07\"), datetime(\"2022-11-08\"),    \"39.98.208.61\", datetime(\"2023-07-28\"), datetime(\"2023-08-12\"),    \"45.195.149.224\", datetime(\"2023-01-04\"), datetime(\"2023-03-29\"),    \"122.10.89.230\", datetime(\"2023-01-12\"), datetime(\"2023-01-13\"),    \"45.204.1.248\", datetime(\"2023-02-23\"), datetime(\"2023-05-09\"),    \"45.204.1.247\", datetime(\"2023-07-24\"), datetime(\"2023-08-10\"),    \"45.88.192.118\", datetime(\"2022-11-07\"), datetime(\"2022-11-08\"),    \"154.19.187.92\", datetime(\"2022-12-01\"), datetime(\"2022-12-02\"),    \"134.122.188.20\", datetime(\"2023-06-13\"), datetime(\"2023-06-20\"),    \"104.238.149.146\", datetime(\"2023-07-13\"), datetime(\"2023-07-14\"),    \"139.180.158.51\", datetime(\"2022-08-30\"), datetime(\"2023-07-27\"),    \"137.220.36.87\", datetime(\"2023-02-23\"), datetime(\"2023-08-04\"),    \"192.253.235.107\", datetime(\"2023-06-06\"), datetime(\"2023-06-07\")];let RemoteIPFiltered = DeviceNetworkEvents    | join kind=inner (ipAddressTimes) on $left.RemoteIP == $right.ip    | where Timestamp between (startDate .. endDate);let LocalIPFiltered = DeviceNetworkEvents    | join kind=inner (ipAddressTimes) on $left.LocalIP == $right.ip    | where Timestamp between (startDate .. endDate);union RemoteIPFiltered, LocalIPFiltered\nSoftEther VPN bridge launched by SQL Server process\nDeviceProcessEvents | where ProcessVersionInfoOriginalFileName == \"vpnbridge.exe\" or ProcessVersionInfoFileDescription == \"SoftEther VPN\"  | where InitiatingProcessParentFileName == \"sqlservr.exe\"\nSoftEther VPN bridge renamed to “conhost.exe” or “dllhost.exe”\nDeviceProcessEvents | where ProcessVersionInfoOriginalFileName == \"vpnbridge.exe\" or ProcessVersionInfoFileDescription == \"SoftEther VPN\"  | where ProcessCommandLine has_any (\"conhost.exe\", \"dllhost.exe\") or FolderPath has_any (\"mssql\", \"conhost.exe\", \"dllhost.exe\")\nCertutil launched by SQL Server process\nDeviceProcessEvents | where ProcessCommandLine has_all (\"certutil\", \"-urlcache\") | where InitiatingProcessFileName has_any (\"sqlservr.exe\", \"sqlagent.exe\", \"sqlps.exe\", \"launchpad.exe\", \"sqldumper.exe\")\nFile downloaded by MSSQLSERVER account using certutil\nDeviceFileEvents | where InitiatingProcessAccountName == \"MSSQLSERVER\"  | where InitiatingProcessFileName == \"certutil.exe\"\nFile renamed to “conhost.exe” or “dllhost.exe”, downloaded using certutil\nDeviceFileEvents | where InitiatingProcessFileName == \"certutil.exe\" | where FileName in (\"conhost.exe\", \"dllhost.exe\")\nNetwork connection made by SoftEther VPN bridge renamed to “conhost.exe” or “dllhost.exe”\nDeviceNetworkEvents | where InitiatingProcessVersionInfoOriginalFileName == \"vpnbridge.exe\" or InitiatingProcessVersionInfoProductName == \"SoftEther VPN\" | where InitiatingProcessFileName == \"conhost.exe\"\nNetwork connection made by MSSQLSERVER account, using SoftEther VPN bridge\nDeviceNetworkEvents | where InitiatingProcessVersionInfoOriginalFileName == \"vpnbridge.exe\" or InitiatingProcessVersionInfoProductName == \"SoftEther VPN\" | where InitiatingProcessAccountName == \"MSSQLSERVER\"\nMicrosoft Sentinel customers can use the TI Mapping analytics (a series of analytics all prefixed with ‘TI map’) to automatically match the malicious domain indicators mentioned in this blog post with data in their workspace. If the TI Map analytics are not currently deployed, customers can install the Threat Intelligence solution from the Microsoft Sentinel Content Hub to have the analytics rule deployed in their Sentinel workspace. More details on the Content Hub can be found here:  https://learn.microsoft.com/azure/sentinel/sentinel-solutions-deploy.\nMicrosoft Sentinel also has a range of detection and threat hunting content that customers can use to detect the post exploitation activity detailed in this blog in addition to Microsoft 365 Defender detections list above.\nIn addition to compromised SOHO devices and compromised devices used for traffic proxying, Flax Typhoon maintains actor-controlled network infrastructure, including virtual private servers (VPS). Over the course of the campaign, the IP addresses listed in the table below were used during the corresponding timeframes.\nIP addressFirst seenLast seenDescription101.33.205[.]1062022-11-072022-11-07Flax Typhoon network infrastructure39.98.208[.]612023-07-282023-08-11Flax Typhoon network infrastructure45.195.149[.]2242023-01-042023-03-28Flax Typhoon network infrastructure122.10.89[.]2302023-01-122023-01-12Flax Typhoon network infrastructure45.204.1[.]2482023-02-232023-05-09Flax Typhoon network infrastructure45.204.1[.]2472023-07-242023-08-09Flax Typhoon network infrastructure45.88.192[.]1182022-11-072022-11-07Flax Typhoon network infrastructure154.19.187[.]922022-12-012022-12-01Flax Typhoon network infrastructure134.122.188[.]202023-06-132023-06-19Flax Typhoon network infrastructure104.238.149[.]1462023-07-132023-07-13Flax Typhoon network infrastructure139.180.158[.]512022-08-302023-07-26Flax Typhoon network infrastructure192.253.235[.]1072023-06-062023-06-06Flax Typhoon network infrastructure\nFlax Typhoon hosts its SofEther VPN servers on its own network infrastructure. Because the servers use the HTTPS protocol to disguise network traffic, they must present TLS certificates. Flax Typhoon used the certificates listed in the table below on these VPN servers.\nSHA-1 TLS fingerprintCommon name (CN)7992c0a816246b287d991c4ecf68f2d32e4bca18vpn437972693.sednc[.]cn5437d0195c31bf7cedc9d90b8cb0074272bc55dfasljkdqhkhasdq.softether[.]netcc1f0cdc131dfafd43f60ff0e6a6089cd03e92f1vpn472462384.softether[.]net2c95b971aa47dc4d94a3c52db74a3de11d9ba658softether\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.\nTo get notified about new publications and to join discussions on social media, follow us at https://twitter.com/MsftSecIntel.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Providing further transparency on our responsible AI efforts - Microsoft On the Issues",
    "link": "https://blogs.microsoft.com/on-the-issues/2024/05/01/responsible-ai-transparency-report-2024/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNXRNWEZhWlhGSmFVVjVZWGxLVFJDM0FSaVRBaWdCTWdNSmdnUQ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-01T07:00:00.000Z",
    "time": "May 1",
    "articleType": "regular",
    "content": "|\t\t\t\t\tBrad Smith, Vice Chair & President; Natasha Crampton, Chief Responsible AI Officer\nThe following is the foreword to the inaugural edition of our annual Responsible AI Transparency Report. The FULL REPORT is available at this link.\nWe believe we have an obligation to share our responsible AI practices with the public, and this report enables us to record and share our maturing practices, reflect on what we have learned, chart our goals, hold ourselves accountable, and earn the public’s trust.\nIn 2016, our Chairman and CEO, Satya Nadella, set us on a clear course to adopt a principled and human-centered approach to our investments in artificial intelligence (AI). Since then, we have been hard at work building products that align with our values. As we design, build, and release AI products, six values – transparency, accountability, fairness, inclusiveness, reliability and safety, and privacy and security – remain our foundation and guide our work every day.\nTo advance our transparency practices, in July 2023, we committed to publishing an annual report on our responsible AI program, taking a step that reached beyond the White House Voluntary Commitments that we and other leading AI companies agreed to. This is our inaugural report delivering on that commitment, and we are pleased to publish it on the heels of our first year of bringing generative AI products and experiences to creators, non-profits, governments, and enterprises around the world.\nAs a company at the forefront of AI research and technology, we are committed to sharing our practices with the public as they evolve. This report enables us to share our maturing practices, reflect on what we have learned, chart our goals, hold ourselves accountable, and earn the public’s trust. We’ve been innovating in responsible AI for eight years, and as we evolve our program, we learn from our past to continually improve. We take very seriously our responsibility to not only secure our own knowledge but also to contribute to the growing corpus of public knowledge, to expand access to resources, and promote transparency in AI across the public, private, and non-profit sectors.\nIn this inaugural annual report, we provide insight into how we build applications that use generative AI; make decisions and oversee the deployment of those applications; support our customers as they build their own generative applications; and learn, evolve, and grow as a responsible AI community. First, we provide insights into our development process, exploring how we map, measure, and manage generative AI risks. Next, we offer case studies to illustrate how we apply our policies and processes to generative AI releases. We also share details about how we empower our customers as they build their own AI applications responsibly. Last, we highlight how the growth of our responsible AI community, our efforts to democratize the benefits of AI, and our work to facilitate AI research benefit society at large.\nThere is no finish line for responsible AI. And while this report doesn’t have all the answers, we are committed to sharing our learnings early and often and engaging in a robust dialogue around responsible AI practices. We invite the public, private organizations, non-profits, and governing bodies to use this first transparency report to accelerate the incredible momentum in responsible AI we’re already seeing around the world.\nTags: AI, generative ai, Responsible AI, Responsible AI Transparency Report, transparency, White House Voluntary Commitments",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "How Microsoft and Quantinuum achieved reliable quantum computing",
    "link": "https://azure.microsoft.com/en-us/blog/quantum/2024/04/03/how-microsoft-and-quantinuum-achieved-reliable-quantum-computing/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVVaRWRwV1ZFM2MzWkdOV05CVFJDb0FSaXNBaWdCTWdZWm81RE11UVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-03T07:00:00.000Z",
    "time": "Apr 3",
    "articleType": "regular",
    "content": "By applying an innovative qubit-virtualization system to ion-trap hardware, Microsoft and Quantinuum were able to create four highly reliable logical qubits from only 30 physical qubits, while demonstrating an 800x improvement in error rate.\nA hybrid supercomputer that combines both classical and quantum capabilities has the potential to solve formerly intractable problems and address the most pressing global issues. When powered by 100 reliable logical qubits, a hybrid machine could potentially solve scientific problems that are unsolvable on classical machines. To make this potential a reality, scientific and engineering breakthroughs are required. Today, Microsoft is announcing a critical breakthrough that advances the field of quantum computing by improving the logical error rate by 800x when compared to the error rate on corresponding physical qubits, thus creating the most reliable logical qubits to date.\n2 Physical and logical qubits\nQuantum computing uses qubits to store and process information. However, today’s qubits are prone to errors that limit their usefulness and the practicality of all noisy, intermediate-scale quantum computers. There are two approaches for reducing these errors:\nImprove the quality of the physical qubits and their operation.\nUse advanced techniques to combine multiple physical qubits into more reliable virtual qubits, which are often referred to as logical qubits.\nMerely increasing the number of physical qubits with a high error rate—without improving that error rate—is futile because doing so would result in a large quantum computer that is not any more powerful than before. In contrast, when physical qubits with sufficient quality of operation are used with a specialized orchestration-and-diagnostics system to enable virtual qubits, only then does increasing the number of physical qubits result in powerful, fault-tolerant quantum computers able to perform longer, more complex computation.\nUsing qubit virtualization to create highly reliable logical qubits\nThe results presented here were achieved by coupling Microsoft’s qubit-virtualization system with Quantinuum’s specialized hardware. Quantinuum’s H-Series ion-trap qubits and unique Quantum Charged Coupled Device architecture have an excellent two-qubit gate fidelity of 99.8%. By applying our qubit-virtualization system to their qubits, we have been able to run 14,000 independent instances so far without a single error. Our sophisticated system has error diagnostics and corrections built in, allowing us to easily determine which errors need to be fixed and how to fix them.\nWith our qubit-virtualization system, we were able to create four highly reliable logical qubits from only 30 physical qubits of the available 32 on Quantinuum’s machine. When entangled, these logical qubits exhibited a circuit error rate of 10-5 or 0.00001, which means they would experience an error only once in every 100,000 runs. That is an 800x improvement over the circuit error rate of 8×10-3 or 0.008, measured from entangled physical qubits. This result was achieved through a combination of advanced runtime error diagnostics with computational run rejection and error correction. You can read more about our methods and results.\nAn 800x improvement in error rate corresponds to a 29 dB improvement of signal, which is the same as that achieved with a high-quality noise-canceling headset. To expand on that analogy, the environmental noise that exists on an airplane represents the noise level that the physical qubits exhibit. Activating the noise-canceling function on the headphones to listen to music, while removing most of the environmental noise, is akin to applying our qubit-virtualization system.\nThe 800x improvement was made possible through advances in Microsoft’s fault-tolerance protocols, which have been developed by our team over many years and involve careful design and optimization to greatly reduce both the number of physical qubits and the physical operations needed to produce reliable logical qubits. These results will improve further as we continue to optimize our methods.\nAdvancing the field of quantum computing\nWith the logical qubits we created, we were able to successfully perform multiple active syndrome extractions, which is when errors are diagnosed and corrected without destroying the logical qubits. Syndrome extraction is important because it permits longer and more complex computation to proceed without failure, which is necessary to achieve fault-tolerant quantum computing.\nThree fundamental criteria to advance from noisy, intermediate-scale quantum computing to reliable quantum computing are:\nAchieve a large separation between logical and physical error rates.\nCorrect all individual circuit errors.\nGenerate entanglement between at least two logical qubits.\nWe have demonstrated, for the first time on record, that all three of the above criteria have been met. For the first criterion, we achieved an 800x improvement in logical error rate compared to the physical error rate. To quantify this 800x improvement, we entangled qubits and performed runtime error diagnostics and error corrections on the measurements (as seen in Figures 1 and 2), thus satisfying the second and third criteria.\nIn addition to meeting the three criteria above, we have demonstrated several rounds of active syndrome extraction on two logical qubits, which marks the transition to reliable quantum computing. This achievement is a prerequisite for building a hybrid classical-quantum supercomputer that outperforms even the most powerful classical computers.\nFigure 1: A depiction of the preparation we used to entangle qubits. The portion inside the dashed line is a rough representation of the circuit used to create the entangled state. A and B represent measurements that can be applied to each half of the state. In the absence of errors, the outcome on one half should agree with the outcome on the other half, if the types of measurement applied to each half are the same. Impressively, after this procedure was run 14,000 times, there were no disagreements between the measurement outcomes.\nFigure 2: The discrepancies (errors) between entangled qubits. Discrepancies are revealed by comparing the images from each qubit in a pair, and any differences that exist appear as dots in the central image between each pair. Errors exist between pairs of physical qubits, as evidenced by the dots in the central images of the top row. In contrast, no errors remain between entangled logical qubits, as apparent from the lack of dots in the central images in the lower row.\nNot all logical qubits have the same degree of usefulness and only those with very low error rates, such as those reported here, may reliably perform non-trivial computations. Integrating these highly reliable logical qubits, created with Quantinuum’s hardware and our qubit-virtualization system, into Azure Quantum Elements will provide a truly hybrid computing experience to users—one that combines the power of cloud high-performance computing with advanced AI models and improved quantum-computing capabilities.\nAchieving reliable quantum computing is a notable milestone and will enable new capabilities and scientific discoveries as Microsoft’s qubit-virtualization system continues to improve. As we take advantage of these opportunities, we will continue to invest in technology that can scale to the level of hybrid supercomputing, which will require logical qubits that experience much less than one error for every 100 million operations. A hybrid supercomputer that combines classical and quantum capabilities could solve commercially significant problems that are far too complex for classical computers. To reach this level of quantum computing, Microsoft is developing a qubit with built-in error protection and digital control known as a topological qubit, and we have released results on recent advancements in that endeavor.\nRead today’s announcement on highly reliable logical qubits on the Official Microsoft Blog.\nRegister for the Microsoft Quantum Innovator Series in April 2024 to discover how Microsoft and Quantinuum are collaborating to push the boundaries of quantum computing and enable new possibilities.\nCustomers of Azure Quantum Elements can explore these new quantum capabilities in the coming months by signing up for a private preview.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft to invest US$2.9 billion in AI and cloud infrastructure in Japan while boosting the nation’s skills, research and cybersecurity",
    "link": "https://news.microsoft.com/apac/2024/04/10/microsoft-to-invest-us2-9-billion-in-ai-and-cloud-infrastructure-in-japan-while-boosting-the-nations-skills-research-and-cybersecurity/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNDJkbE5PYW1ad2FXSXdhbnBWVFJDM0FSaVRBaWdCTWdhTklaclJIQW8=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-10T07:00:00.000Z",
    "time": "Apr 10",
    "articleType": "regular",
    "content": "Picture left to right: Fumio Kishida, Prime Minister of Japan; Brad Smith, Vice Chair and President, Microsoft; Suzanne P. Clark, President and CEO, US Chamber of Commerce; Rahm Emanuel, US Ambassador to Japan; Miki Tsusaka, President, Microsoft Japan.\nWashington D.C., April 9 ET, 2024 – Today, Microsoft announced it will invest US$2.9 billion over the next two years to increase its hyperscale cloud computing and AI infrastructure in Japan. It will also expand its digital skilling programs with the goal of providing AI skilling to more than 3 million people over the next three years, open its first Microsoft Research Asia lab in Japan, and deepen its cybersecurity collaboration with the Government of Japan.\nThese investments aim to support Japan’s key pillar to tackle deflation and stimulate the economy by expanding the infrastructure, skilled talent, and security required to accelerate Japan’s digital transformation and adoption of AI. The announcement coincides with Japanese Prime Minister Fumio Kishida’s state visit to the United States, where he was joined by Microsoft Vice Chair and President Brad Smith, and Microsoft Japan President Miki Tsusaka.\nExpanding Japan’s AI and cloud infrastructure capacity\nThe US$2.9 billion commitment is Microsoft’s single largest investment in its 46-year history in Japan, also the site of its first international office. It effectively doubles the company’s existing financial commitment to expand its AI and cloud infrastructure across Japan.\nThis significant enhancement in digital capacity will enable Microsoft to provide more advanced computing resources in Japan, including the latest graphics processing units (GPUs), which are crucial for speeding up AI workloads. It builds on Microsoft’s support for the Generative AI Accelerator Challenge (GENIAC), a program led by the Ministry of Economy, Trade and Industry which helps innovative startups and established enterprises develop foundation models as a core technology of generative AI in Japan.\nBuilding Japan’s AI capability by training 3 million people\nMicrosoft will also invest in training 3 million full-time and part-time workers across Japan over the next three years, giving them the skills they need to build and work with AI technologies. This investment will be delivered through programs focused on assisting organizations and society at large, including women in general and also with a focus on developers and students.\nMicrosoft will expand its Code; Without Barriers program to Japan and provide dedicated training for women looking to participate in AI-enabled work. It will also provide free and widely accessible content on AI, cybersecurity, and digital skills in partnership with the United Nations Institute for Training and Research (UNITAR).\nNurturing advanced AI professionals who can drive further AI integration, Microsoft will offer courses and reference architectures for AI developers and technology companies in Japan. These will be augmented by Microsoft’s AI coding assistant, GitHub Copilot. The company will also support startups with resources through the Microsoft for Startups Founders Hub and help implement AI-centric programs in vocational high schools.\nTo advance the societal benefits offered by AI through companies of all sizes, governments, and public entities – including the Tokyo Metropolitan Government – Microsoft will continue with established programs that support the widespread adoption and application of AI tools. Furthermore, Microsoft provides support in developing customers’ internal AI policies, including data management and security to ensure its responsible and safe use.\nOpening Japan’s first Microsoft Research Asia lab in Tokyo\nMicrosoft Research Asia is extending its research leadership in the Asia-Pacific region with the opening of a lab in Tokyo.\nThe new lab will have a unique focus on areas including embodied AI and robotics, societal AI and wellbeing, and scientific discovery that align with Japan’s socioeconomic priorities. Its establishment reflects Microsoft’s long-term commitment to Japan and its belief in the nation’s potential to lead the world in innovation.\nMicrosoft Research is a division of Microsoft that pursues bold ideas and technical breakthroughs in AI, while building on a legacy of foundational computer science advances. As its fundamental research arm in the Asia-Pacific region, Microsoft Research Asia has collaborated with Japanese academia for more than two decades which have been instrumental in propelling cross-disciplinary research and fostering talent.\nTo foster enhanced research collaboration, Microsoft will provide US$10 million resource grants over the next five years to both The University of Tokyo and to the Partnership on Artificial Intelligence Research between Keio University and Carnegie Mellon University.\nPartnering to strengthen Japan’s cybersecurity defenses\nMicrosoft will collaborate with Japan’s Cabinet Secretariat to strengthen cybersecurity resilience for the government, business, and society, as the nation enhances its cybersecurity approach under the government’s updated National Security Strategy.\nThe collaboration will build on the services Microsoft provides to protect thousands of Japanese organizations every day. It will focus on areas such as information sharing, talent development, and technology solutions, with Microsoft to provide its expertise and advanced cloud and AI-driven security services as part of joint efforts to tackle cybersecurity threats.\nFumio Kishida, Prime Minister of Japan\n“As economic activities in the digital space increase, it is important for the Japanese industry as a whole to work with global companies like Microsoft that are equipped with a set of digital infrastructure. We appreciate Microsoft’s announcement of its new investment in Japan. Microsoft has made significant contributions to the social implementation of generative AI in Japan through various initiatives, and we look forward to further collaboration. We also look forward to deepening our cooperation in the field of cybersecurity.”\nBrad Smith, Vice Chair and President, Microsoft\n“Today’s announcement represents Microsoft’s most significant investment in Japan since we set roots here in 1978. These investments in digital infrastructure, AI skills, cybersecurity, and AI research are essential ingredients for Japan to build a robust AI Economy.”\nKen Saito, Minister of Economy, Trade and Industry\n“As digital investments increase around the world, we welcome Microsoft’s announcement of new investment in Japan and look forward to its future contribution to promoting Japan’s digital industries, including AI. Ministry of Economy, Trade and Industry will continue to work with Microsoft, a world leader in the digital field, to create both innovation and discipline.”\nTakuya Hirai, Chairperson, Headquarters for the Promotion of a Digital Society, Policy Research Council, Member of the House of the Representatives\n“The adoption of digital tools is essential for addressing Japan’s societal challenges of an aging population and the pursuit of economic growth and regional revitalization. Microsoft’s investment contributes significantly in advancing Japan’s AI capabilities, particularly in infrastructure and talent development. I wholeheartedly welcome this initiative and look forward to the leadership role Microsoft can play in promoting collaboration between Japan and the United States, as well as across public and private sectors.”\nMiki Tsusaka, President, Microsoft Japan\n“We are honored to contribute to Japan and its future with our largest investment to date, technology and knowledge. In collaboration with our partners, Microsoft Japan is fully committed to supporting the people and organizations of Japan to solve social problems and achieve more.”\nYuriko Koike, Governor of Tokyo Metropolitan\n“The Tokyo Metropolitan Government and Microsoft entered into a partnership last year and have been empowering Japan’s workforce with digital skills. Today’s announcement by Microsoft, which includes programs to encourage women to embrace AI and provide AI skilling to three million people, is a significant step for Japan to lead in the age of digitalization. The Tokyo Metropolitan Government pioneered the use of generative AI to make our offices more efficient and improve the quality of services provided to our citizens. We will continue to embrace cutting-edge technology and lead Japan’s digital transformation with unwavering dedication.”\nChisa Mikami, Head of Hiroshima Office, UNITAR\n“Through the collaboration between UNITAR and Microsoft, we will strive to democratize access to AI education, ensuring that knowledge is freely available to all. Together, we pave the way for advanced AI professionals, foster innovation in startups, and promote responsible AI practices across industries and sectors. With collective effort, we harness the transformative power of AI for the betterment of society.”\nKevin Scott, Chief Technology Officer and Executive Vice President of AI, Microsoft\n“The impact that AI is poised to create over the coming years has the potential to generate unprecedented societal benefit for the entire world. The steps we are taking today to empower Japanese citizens through AI technologies and programs—whether job training and skilling, improvements to infrastructure capacity, or new research investments—will in the aggregate help accelerate this process of beneficial innovation. We’re particularly excited for Microsoft Research’s global footprint to further expand into Japan, extending the ability for our world-class research efforts to both contribute to and benefit from local diversity of thought and talent.”\nTeruo Fujii, President, The University of Tokyo\n“The University of Tokyo is committed to contributing to the realization of a better society through research and education focused on cutting-edge technologies such as artificial intelligence. To maximize the benefits of those technologies and promote innovation while minimizing risks, it is essential to collaborate with partners who share our objectives. With the establishment of Microsoft Research Asia’s new lab in Tokyo, we enter an exciting new phase in our more than two decades of partnership with Microsoft. We look forward to working together to further advance our research community and spearhead the development of outstanding human resources as we continue our journey together.”",
    "favicon": "https://news.microsoft.com/wp-content/themes/microsoft-news-center-2016/assets/img/site-icon.png"
  },
  {
    "title": "Realigning global licensing for Microsoft 365",
    "link": "https://www.microsoft.com/en-us/licensing/news/microsoft365-teams-ww",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNDBVM0ZDT1VsNlFVbDNURTlJVFJDeUFSaWJBaWdCTWdNRk1BUQ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-01T07:00:00.000Z",
    "time": "Apr 1",
    "articleType": "regular",
    "content": "April 1, 2024Last year Microsoft updated the way Microsoft 365, Office 365, and Teams were licensed in the European Economic Area (EEA) and Switzerland. Now we are announcing our plan to extend that approach worldwide.Globally consistent licensing helps ensure clarity for customers and streamline decision making and negotiations. To that end, we are now updating the way Microsoft 365, Office 365, and Teams are licensed outside of Europe in keeping with the recent changes in the EEA. Starting today, we are introducing 1) a new lineup of commercial Microsoft 365 and Office 365 suites that do not include Teams in regions outside the EEA and Switzerland, and 2) a new standalone Teams offering for Enterprise customers in those regions.As in the EEA and Switzerland, customers with existing subscriptions that include Microsoft Teams will be able to continue using plans they have already chosen. Additional details follow below.",
    "favicon": "/favicon.ico?v2"
  },
  {
    "title": "Expanding Microsoft’s Secure Future Initiative (SFI) | Microsoft Security Blog",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/05/03/security-above-all-else-expanding-microsofts-secure-future-initiative/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNXFXRzVhTlRkRGFqSnVhMTlTVFJDb0FSaXNBaWdCTWdZcFJwVHRJUWc=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-03T07:00:00.000Z",
    "time": "May 3",
    "articleType": "regular",
    "content": "Last November, we launched the Secure Future Initiative (SFI) to prepare for the increasing scale and high stakes of cyberattacks. SFI brings together every part of Microsoft to advance cybersecurity protection across our company and products.\nSince then, the threat landscape has continued to rapidly evolve, and we have learned a lot. The recent findings by the Department of Homeland Security’s Cyber Safety Review Board (CSRB) regarding the Storm-0558 cyberattack from last July, and the Midnight Blizzard attack we reported in January, underscore the severity of the threats facing our company and our customers.\nMicrosoft plays a central role in the world’s digital ecosystem, and this comes with a critical responsibility to earn and maintain trust. We must and will do more.\nWe are making security our top priority at Microsoft, above all else—over all other features. We’re expanding the scope of SFI, integrating the recent recommendations from the CSRB as well as our learnings from Midnight Blizzard to ensure that our cybersecurity approach remains robust and adaptive to the evolving threat landscape.\nWe will mobilize the expanded SFI pillars and goals across Microsoft and this will be a dimension in our hiring decisions. In addition, we will instill accountability by basing part of the compensation of the company’s Senior Leadership Team on our progress in meeting our security plans and milestones.\nBelow are details to demonstrate the seriousness of our work and commitment.\nExpansion of SFI approach and scope\nWe have evolved our security approach, and going forward our work will be guided by the following three security principles:\nSecure by design: Security comes first when designing any product or service.\nSecure by default: Security protections are enabled and enforced by default, require no extra effort, and are not optional.\nSecure operations: Security controls and monitoring will continuously be improved to meet current and future threats.\nWe are further expanding our goals and actions aligned to six prioritized security pillars and providing visibility into the details of our execution:\n1. Protect identities and secrets\nReduce the risk of unauthorized access by implementing and enforcing best-in-class standards across all identity and secrets infrastructure, and user and application authentication and authorization. As part of this, we are taking the following actions:\nProtect identity infrastructure signing and platform keys with rapid and automatic rotation with hardware storage and protection (for example, hardware security module (HSM) and confidential compute).\nStrengthen identity standards and drive their adoption through use of standard SDKs across 100% of applications.\nEnsure 100% of user accounts are protected with securely managed, phishing-resistant multifactor authentication.\nEnsure 100% of applications are protected with system-managed credentials (for example, Managed Identity and Managed Certificates).\nEnsure 100% of identity tokens are protected with stateful and durable validation.\nAdopt more fine-grained partitioning of identity signing keys and platform keys.\nEnsure identity and public key infrastructure (PKI) systems are ready for a post-quantum cryptography world.\n2. Protect tenants and isolate production systems\nProtect all Microsoft tenants and production environments using consistent, best-in-class security practices and strict isolation to minimize breadth of impact. As part of this, we are taking the following actions:\nMaintain the security posture and commercial relationships of tenants by removing all unused, aged, or legacy systems.\nProtect 100% of Microsoft, acquired, and employee-created tenants, commerce accounts, and tenant resources to the security best practice baselines.\nManage 100% of Microsoft Entra ID applications to a high, consistent security bar.\nEliminate 100% of identity lateral movement pivots between tenants, environments, and clouds.\n100% of applications and users have continuous least-privilege access enforcement.\nEnsure only secure, managed, healthy devices will be granted access to Microsoft tenants.\nProtect Microsoft production networks and implement network isolation of Microsoft and customer resources. As part of this, we are taking the following actions:\nSecure 100% of Microsoft production networks and systems connected to the networks by improving isolation, monitoring, inventory, and secure operations.\nApply network isolation and microsegmentation to 100% of the Microsoft production environments, creating additional layers of defense against attackers.\nEnable customers to easily secure their networks and network isolate resources in the cloud.\nProtect software assets and continuously improve code security through governance of the software supply chain and engineering systems infrastructure. As part of this, we are taking the following actions:\nBuild and maintain inventory for 100% of the software assets used to deploy and operate Microsoft products and services.\n100% of access to source code and engineering systems infrastructure is secured through Zero Trust and least-privilege access policies.\n100% of source code that deploys to Microsoft production environments is protected through security best practices.\nSecure development, build, test, and release environments with 100% standardized, governed pipelines and infrastructure isolation.\nSecure the software supply chain to protect Microsoft production environments.\n5. Monitor and detect threats\nComprehensive coverage and automatic detection of threats to Microsoft production infrastructure and services. As part of this, we are taking the following actions:\nMaintain a current inventory across 100% of Microsoft production infrastructure and services.\nRetain 100% of security logs for at least two years and make six months of appropriate logs available to customers.\n100% of security logs are accessible from a central data lake to enable efficient and effective security investigation and threat hunting.\nAutomatically detect and respond rapidly to anomalous access, behaviors, and configurations across 100% of Microsoft production infrastructure and services.\n6. Accelerate response and remediation\nPrevent exploitation of vulnerabilities discovered by external and internal entities, through comprehensive and timely remediation. As part of this, we are taking the following actions:\nReduce the Time to Mitigate for high-severity cloud security vulnerabilities with accelerated response.\nIncrease transparency of mitigated cloud vulnerabilities through the adoption and release of Common Weakness Enumeration™ (CWE™), and Common Platform Enumeration™ (CPE™) industry standards for released high severity Common Vulnerabilities and Exposures (CVE) affecting the cloud.\nImprove the accuracy, effectiveness, transparency, and velocity of public messaging and customer engagement.\nThese goals directly align to our learnings from the Midnight Blizzard incident as well as all four CSRB recommendations to Microsoft and all 12 recommendations to cloud service providers (CSPs), across the areas of security culture, cybersecurity best practices, auditing logging norms, digital identity standards and guidance, and transparency.\nWe are delivering on these goals through a new level of coordination with a new operating model that aligns leaders and teams to the six SFI pillars, in order to drive security holistically and break down traditional silos. The pillar leaders are working across engineering Executive Vice Presidents (EVPs) to drive integrated, cross-company engineering execution, doing this work in waves. These engineering waves involve teams across Microsoft Azure, Windows, Microsoft 365, and Security, with additional product teams integrating into the process weekly.\nWhile there is much more to do, we’ve made progress in executing against SFI priorities. For example, we’ve implemented automatic enforcement of multifactor authentication by default across more than one million Microsoft Entra ID tenants within Microsoft, including tenants for development, testing, demos, and production. We have eliminated or reduced application targets by removing 730,000 apps to date across production and corporate tenants that were out-of-lifecycle or not meeting current SFI standards. We have expanded our logging to give customers deeper visibility. And we recently announced a significant shift on our response process: We are now publishing root cause data for Microsoft CVEs using the CWE™ industry standard.\nAdhering to standards with paved paths systems\nPaved paths are best practices from our learned experiences, drawing upon lessons such as how to optimize productivity of our software development and operations, how to achieve compliance (such as Software Bill of Materials, Sarbanes-Oxley Act, General Data Protection Regulation, and others), and how to eliminate entire categories of vulnerabilities and mitigate related risks. A paved path becomes a standard when adoption significantly improves the developer or operations experience or security, quality, or compliance.\nWith SFI, we are explicitly defining standards for each of the six security pillars, and adherence to these standards will be measured as objectives and key results (OKRs).\nThe Secure Future Initiative empowers all of Microsoft to implement the needed changes to deliver security first. Our company culture is based on a growth mindset that fosters an ethos of continuous improvement. We continually seek feedback and new perspectives to tune our approach and progress. We will take our learnings from security incidents, feed them back into our security standards, and operationalize these learnings as paved paths that can enable secure design and operations at scale.\nWe are also taking major steps to elevate security governance, including several organizational changes and additional oversight, controls, and reporting.\nMicrosoft is implementing a new security governance framework spearheaded by the Chief Information Security Officer (CISO). This framework introduces a partnership between engineering teams and newly formed Deputy CISOs, collectively responsible for overseeing SFI, managing risks, and reporting progress directly to the Senior Leadership Team. Progress will be reviewed weekly with this executive forum and quarterly with our Board of Directors.\nFinally, given the importance of threat intelligence, we are bringing the full breadth of nation-state actor and threat hunting capabilities into the CISO organization.\nCulture can only be reinforced through our daily behaviors. Security is a team sport and is best realized when organizational boundaries are overcome. The engineering EVPs, in close coordination with SFI pillar leaders, are holding broadscale weekly and monthly operational meetings that include all levels of management and senior individual contributors. These meetings work on detailed execution and continuous improvement of security in context with what we collectively deliver to customers. Through this process of bottom-to-top and end-to-end problem solving, security thinking is ingrained in our daily behaviors.\nUltimately, Microsoft runs on trust and this trust must be earned and maintained. As a global provider of software, infrastructure, and cloud services, we feel a deep responsibility to do our part to keep the world safe and secure. Our promise is to continually improve and adapt to the evolving needs of cybersecurity. This is job number one for us.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Announcing new Copilot in Microsoft Teams enhancements | Microsoft 365 Blog",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2024/03/26/ai-powered-collaboration-with-microsoft-teams/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWtaRzgwTkdzNVVWRktPVVE1VFJDb0FSaXJBaWdCTWdZUlFJaDJ2QVE=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-03-26T07:00:00.000Z",
    "time": "Mar 26",
    "articleType": "regular",
    "content": "As we bring Microsoft Copilot to more customers around the world, people are already unlocking its value and learning the power of generative AI at work. Our recent Copilot customer research shows that 11 minutes of time savings is all it takes for most people to feel like AI is useful, and that after 11 weeks—about one business quarter—most users say it improves their work across key areas like productivity and having fewer meetings.\nMicrosoft Teams is where work happens, and now we’re excited to announce new Copilot in Teams enhancements that will supercharge collaboration and make hybrid meetings even better.\nRead on for all the details.\nCollaborate more effectively with a faster, simpler, smarter, and more flexible Teams.\nBased on customer feedback, in May, we are enhancing the Copilot in meeting experience. Copilot in meetings will now provide information and insights from the meeting chat in addition to the meeting transcript. When you open Copilot in the meeting chat, you will have a more comprehensive and inclusive view of what was covered in the meeting, whether it was spoken (transcript) or written (chat).\nIn April, with Copilot in Teams chat compose box, you can prompt Copilot to adjust your message and provide a custom rewritten version. For example, Copilot can adjust your message to add a call to action, or even to make you sound like a pirate. Soon, you will also be able to generate a new message with a prompt by typing just a few words in Teams chat. This will save you time thinking about where to start, and let you adapt and edit messages with ease.\nIntelligent call recap brings one of the best meetings AI features to calling. Intelligent call recap can provide AI-powered insights and recaps of your VoIP and Public Switched Telephone Network calls in Teams. This feature will be generally available in June with Teams Premium and Copilot.\nHybrid meetings with attendees participating both in-room and remote can be less than ideal. Remote participants often have a hard time knowing who is in the room or who is speaking. Microsoft IntelliFrame helps hybrid meeting attendees to see people in Teams Rooms more clearly, using Cloud AI to identify and capture individual video feeds of each in-room participant. We’ve now made it even easier to ensure your meeting spaces are ready for hybrid work by turning on Intelliframe by default on Teams Rooms devices. More people than ever are now experiencing the power of great hybrid meetings.\nThe remote experience continues to get better as automatic camera switching for IntelliFrame becomes available later this year. Using AI to determine and select the optimized view of each person in a meeting room, this capability ensures that every remote participant knows who is in the room at all times. It compares multiple video sources, such as individual laptop and room cameras, and ensures the room captures, segments, and presents the best head pose for the benefit of remote participants—for example, choosing laptop video feeds instead of the front of room camera when multiple people are in the same room. If a camera view for someone in the room becomes obstructed, another camera view will be chosen to provide remote participants with a clear view.\nNot all Teams Rooms have intelligent speakers, but starting in public preview in April 2024, speaker recognition capabilities for any existing microphone will improve transcript accuracy and Copilot provided meeting insights for Teams Rooms on Windows environments. When you join a meeting from a Teams Room, what you say in the meeting is isolated and attributed to you in the transcript, simply by enrolling your voice and face profiles.\nWhen you need to join a call or meeting in a noisy location, voice isolation, generally available in April 2024, can help ensure that only your voice is heard. Once you complete a short enrollment process, this AI-based advanced noise suppression feature will isolate your voice and eliminate all other background noise—including other people’s voices.\nWindows Autopilot for Teams Rooms reduces the time it takes IT admins to deploy Teams Rooms from days to minutes. This new integration with Windows Autopilot and auto-login of Teams Rooms on Windows offers low-friction provisioning that will enable devices to sign in to the account associated with the Autopilot device seamlessly. Additionally, the Microsoft Teams Rooms for Windows app automatically checks for and installs new applications and Windows updates during the initial setup, ensuring devices are protected and up to date on day one. Autopilot for Teams Rooms will be in public preview this week.\nOur Bring-Your-Own Device (BYOD) ecosystem is also growing. Shared Display mode is now generally available and ensures that you are in full control of the content you share to a display. Support for intelligent speakers in BYOD spaces will allow in-person meeting participants to attribute speech to individual attendees. This feature will enter public preview later this year.\nFinally, BYOD IT Management now gives IT admins the power to easily discover, inventory, and generate insights about BYOD peripherals, and will be generally available in April 2024.\nExpanding Teams Phone and customer-facing role capabilities\nTeams Phone gives you a reliable and simple way to connect, no matter where you are. As of April 1, 2024, we’re updating our Teams Phone financially-backed service level agreement to 99.999% uptime. Additionally, we’re continuing to expand survivable calling capabilities made possible with the Survivable Branch Appliance capabilities. Starting next quarter, Teams Phone will support call transfer, forwarding, and incoming calls from call queues or auto attendants in the event of a network outage.\nTo make it easier to communicate on the go, Teams Phone Mobile gives you a single number across both Teams and your mobile device native dialer. We are excited to announce that several new partners including AT&T, Odido, Virgin Media O2, and Vodafone UK will begin offering Teams Phone Mobile later this year.\nSoon, an enhancement to Copilot for Service will allow agents to chat with Copilot during a meeting and ask questions over cases and contacts, summarize cases, reason over knowledge, and more. This builds on the current capability of using Copilot in Teams to browse and update CRM records. Download the Copilot for Service app for Teams and Outlook.\nOur vision with Copilot is to bring the power of generative AI to everyone. We are committed to continue to improve the Copilot experience in Teams to help everyone be more creative and productive.\nVisit WorkLab for critical research and insights on how generative AI is transforming work.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Khan Academy and Microsoft partner to expand access to AI tools that personalize teaching and help make learning fun",
    "link": "https://news.microsoft.com/source/features/ai/khan-academy-and-microsoft-partner-to-expand-access-to-ai-tools/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNU9ZbGhwTlhoVVJHSlpkWFpIVFJETEFSajRBU2dCTWdZRlVJN1ZHQW8=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-21T07:00:00.000Z",
    "time": "May 21",
    "articleType": "regular",
    "content": "Tucked away in a high school chemistry classroom in Northern Indiana are pressure gauges intended to teach a fundamental principle of chemistry known as Boyle’s Law.\nIn their place, Hobart High School chemistry teacher Melissa Higgason is using a variety of seemingly random items – including mini marshmallows, plastic water bottles, balloons and eyedroppers – to inspire her students to design their own experiments and see what happens to gas under different conditions.\n“There are simulations where students are changing a variable and watching a number climb up and go down,” said Higgason. “But gas laws are very abstract. It’s hard for kids to make all those connections without hands on experiences that are relevant to them.”\nWhile Higgason has decades of experience in education, she’s the first to admit the idea of using everyday items to teach physics came from an AI-powered teaching assistant called Khanmigo for Teachers, a pilot program introduced last year by Khan Academy, the non-profit online educational organization started in 2008 by Sal Khan with a mission to provide a free, world-class education to anyone, anywhere.\nThe two companies will also collaborate to explore opportunities to improve AI tools for math tutoring in an affordable, scalable and adaptable way with a new version of Phi-3, a family of small language models (SLMs) developed by Microsoft.\nWith AI tools, teachers have more time to spend on students\n“I use Khanmigo to spice up my classroom to make it fun and engaging,” said Higgason. For example, in another class of Higgason’s, Khanmigo suggested explaining net ionic equations by asking students if they’ve ever been to a dance party, comparing ions to dancers who change partners.\nBesides offering creative lesson plans, Khanmigo provides an array of AI-powered suggestions and teacher tools that relieve teachers of many of the administrative burdens that contribute to teacher burnout. With a click of an onscreen dashboard, in just a few minutes and often less, teachers can generate custom lesson plans, suggest student groupings, or “level” up or down text passages for learners who are either struggling or need more of a challenge. Used together, Khan Academy estimates these tools can save teachers an average of five working hours each week.\nIn less than a minute, teachers can access first drafts of creative lesson plans from Khanmigo for Teachers that save time and surprise and delight students. Photo by Scott Eklund for Microsoft.\n“Teachers are super overworked,” said Sal Khan, noting record numbers of teachers are leaving the profession. School districts in underserved areas have been especially hard hit, with teachers citing low pay and unmanageable workloads exacerbated by the COVID-19 pandemic as some of the top reasons they are giving up on teaching. Using AI for education isn’t just a powerful way to potentially help accelerate student learning, said Khan, it’s also a way “to make teaching more sustainable.”\nBringing high-quality educational experiences to more learners\nWhile earning rave reviews from teachers like Higgason since it launched in March 2023, Khanmigo previously cost teachers $4 per month. The fees covered the cost of developing and testing the new technology and accessing the large language models (LLMs) that power Khanmigo.\nAs part of the new partnership, Khan Academy’s teacher tools will now be powered by Azure OpenAI Service. Microsoft’s donation of Azure infrastructure will enable the nonprofit educational organization to scale those teacher tools more widely and offer them to all K-12 teachers in the U.S. at no cost.\nThe companies will also explore how small language models (SLMs) such as Microsoft’s new Phi-3 family of models, which can perform well for simpler AI tasks and are more cost effective and easier to use than larger models, might help improve and scale AI tutoring tools. To that end, Khan Academy is collaborating with Microsoft to explore the development of new, open-source small language models based on Phi-3. The goal of the exploratory work is to enable state-of-the-art math tutoring capabilities in an affordable and scalable manner.\nSmall language models offer many of the same capabilities found in large language models but are smaller and trained on smaller amounts of data. They are also designed to be more accessible and easier to use for organizations with limited resources.\nUnder their new agreement, Khan Academy will also give Microsoft access to explanatory educational content such as math problem questions and step-by-step answers to develop AI-powered math tutoring capabilities using Phi-3. Khan Academy will also provide ongoing feedback and benchmarking data to evaluate performance. None of Khan Academy’s user data will be used to train the model.\nKhan is excited about the opportunity to collaborate with Microsoft to train small language models in math tutoring – an area where he sees great potential.\nNot only are small language models easier to customize than large language models for specific tasks, such as teaching math, English or chemistry – they are also more efficient. “If they can get comparable to the larger frontier models but at a dramatically lower cost, that dramatically increases the speed at which we can make this accessible to more people,” said Khan.\nIn the future, Khan hopes small language models that operate locally on a device (as opposed to the cloud) will create opportunities to provide teacher tools and tutors for resource-constrained schools outside the U.S. that lack computing infrastructure.\nFinally, the two organizations will also work to integrate more Khan Academy content into Copilot and Teams for Education, a free version of Microsoft’s popular Teams app to enhance collaboration and learning customized to meet the needs of educators and students. The integration will make Khan Academy’s vast educational library available to even more learners, while providing high-quality content to users of Copilot and Teams for Education.\nTutoring with AI and the Socratic method\nBack in Hobart, Indiana, students in Higgason’s class, who have access to a separate set of AI-powered Khanmigo learning tools through its Khan Academy Districts partner program, have embraced its conversational Socratic method of tutoring, characterized by cheerful, energetic questioning to encourage critical thinking by students\nHobart High School student Jzehbel Garcia learned about molality, an abstract chemistry concept, under cheerful questioning from Khanmigo. Photo by Scott Eklund for Microsoft.\nHobart High School student Aleksandar Tatum says Khanmigo “learns the same way I do.” Photo by Scott Eklund for Microsoft.\nHobart High school student Madisyn Sanders says she appreciates the creative lesson plans her teachers develop with Khanmigo. Photo by Scott Eklund for Microsoft.\nThey’ve also welcomed the AI teaching assistant’s creative suggestions to enliven normally staid chemistry lessons that have saved Higgason so much time.\n“Using a marshmallow and an eye dropper in a lab – I didn’t think you could use that to show a gas law,” said Madisyn Sanders, a 16-year-old sophomore. “It was a really interesting experiment.”\n“Khanmigo learns the same way I do,” added Aleksandar Tatum, 16. “It’s almost taking the steps with you. It helps you build a connection to help you better understand subjects.”\nUsing AI to cheat is a major concern of many parents and teachers, but cheating is difficult with Khanmigo, as it does not do the writing for students. Instead of providing answers, Khanmigo asks questions and provides support as a tutor would do.\nStudents compare notes while learning about chemistry using everyday items, a lesson suggested by Khanmigo for Teachers. Photo by Scott Eklund for Microsoft.\nIn English class, Tatum and his classmates were asked to read “Romeo and Juliet”and then write a story that changed some of the scenes. Tatum prompted Khanmigo to describe a scene he had trouble remembering. “It was a genuine question I had about Act 1 Scene 3,” he said. But Khanmigo would only respond, “I’m here to help you create a story,” and Tatum had to go back to the original text to refresh his memory.\nWhen Jzehbel Garcia, 17, asked Khanmigo to provide the formula for “molality,” another abstract chemistry concept, Khanmigo responded with a hint and then a question: “What two pieces of information do you think you need to calculate molality?”\n“What’s really nice from a teacher’s perspective is it does not give my students answers. It gives them questions,” said Higgason. “Science is about asking really good questions. That’s how we learn and grow and innovate.”\nKhan Academy also provides guardrails and safety mechanisms in Khanmigo. Messages at the top of the screen notify students that their chat history and activities are visible to parents and teachers. The system also automatically flags questions or comments from students that are considered problematic, so teachers can review and decide if follow-up with the student is needed.\nUsing Khanmigo teacher tools to meet unique student needs\nBefore Khanmigo was introduced to Hobart in 2023, “I was drowning,” said Stephanie Franco, a teaching specialist who supports over 40 students still learning English by collaborating with more than 70 teachers located in two different buildings on the school campus.\nShe was skeptical about bringing AI into the classroom, concerned like many parents and educators that it would lead to cheating.\nStephanie Franco, who supports students learning English, says Khanmigo’s teacher tools save her hours of time each week. Photo by Scott Eklund for Microsoft.\nBut once she discovered Khanmigo’s translation tools, “it was a breakthrough,” said Franco. Before Khanmigo was available at Hobart, she would spend hours scouring her students’ assignments to change wording or vocabulary that could prove challenging.\nNow she simply copies and pastes those assignments into the Khanmigo teacher chat function and types “make this understandable to a 7th grader.” In seconds, she said, she has a new assignment tailored to the needs of her students: “So instead of my students not being able to be included in the same assignments as their classmates since they’re still learning English, I can now provide them with a similar assignment that is more tailored to their learning needs.”\nBesides offering support for multi-language learners, Franco also teaches English as a second language. Again, she taps Khanmigo to create lesson plans and prompts to engage her students in discussion. “I’ll say, ‘Help me find a story that would help my students with reading comprehension.’ Or I can tell Khanmigo about a famous story and it will make up questions to ask the kiddos,” she said.\nBen Horjus, an English teacher at Hobart High School, likes Khanmigo’s “leveler” tool for tailoring content to make it more accessible to students. Photo by Scott Eklund for Microsoft.\nAsking questions is not something that comes naturally to most high schoolers. Writing, too, is a challenge for many students, who often don’t know where to begin. Ben Horjus, who teaches essay writing and composition at Hobart, said many high school students “struggle to pick a focus area, to recognize credible sources, and to synthesize information so they can develop a stance supported by research. In this vast sea of information, it’s hard for them to know how to navigate and not feel lost.”\nWith these challenges in mind, Horjus uses several Khanmigo teacher tools, including the “learning objectives” feature, which gives him ideas for student assignments along with activities and discussion topics. He also likes using it to develop guides for instruction for individual students or groups of students.  And he’s looking forward to using the “leveler” function, which can be used to simplify complex text, to demystify the more challenging parts of “The Crucible,” which he plans to teach next fall.\nIn many ways, Khan said, the advent of AI-powered teaching and learning is a throwback to the origins of education, when 1:1 tutoring was the norm. Alexander the Great, the Macedonian conqueror, was tutored by Aristotle, the Greek philosopher, who in turn was tutored by Plato, who was tutored by Socrates, who pioneered the Socratic method of asking questions to guide students to knowledge.\n“You could imagine that if young Alexander was having difficulty with some topic, that Aristotle would slow down or speed up, or make sure that this young man who’s going to be a future king or emperor is engaged in his learning,” said Khan.\nBy partnering with Microsoft, Khan hopes to provide more support for teachers so they can bring personalized teaching and learning to more classrooms, enabling many more students to one day help solve the world’s toughest challenges. “We can use the same tools,” said Khan, “to treat every kid like a future emperor.”\nRead more: Enhancing the future of education with Khan Academy\nRead more: Khanmigo for Teachers is free to all U.S. teachers thanks to support from Microsoft\nRead more: Tiny but Mighty: The Phi-3 small language models with big potential\nHear more: Khan Academy Founder Sal Khan on the Future of Learning (WorkLab podcast)\nTop image: Melissa Higgason, who teaches chemistry at Hobart High School in Hobart, Indiana, instructs her students on how to use marshmallows and water bottles to understand an abstract chemistry concept, an idea suggested by Khanmigo for Teachers, a pilot AI-powered teaching assistant. Photo by Scott Eklund for Microsoft.",
    "favicon": "https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2022/10/cropped-Microsoft_logo.svg_-300x300-1-128x120.png"
  },
  {
    "title": "Advancing science: Microsoft and Quantinuum demonstrate the most reliable logical qubits on record with an error rate 800x better than physical qubits",
    "link": "https://blogs.microsoft.com/blog/2024/04/03/advancing-science-microsoft-and-quantinuum-demonstrate-the-most-reliable-logical-qubits-on-record-with-an-error-rate-800x-better-than-physical-qubits/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNUlWblZZUVVka1JteHFlRFpKVFJDb0FSaXNBaWdCTWdhbE5JcXVuUWs=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-03T07:00:00.000Z",
    "time": "Apr 3",
    "articleType": "regular",
    "content": "Quantinuum scientists making adjustments to a beam line array used to deliver laser pulses in H-Series quantum computers. Photo courtesy of Quantinuum.\nToday signifies a major achievement for the entire quantum ecosystem: Microsoft and Quantinuum demonstrated the most reliable logical qubits on record. By applying Microsoft’s breakthrough qubit-virtualization system, with error diagnostics and correction, to Quantinuum’s ion-trap hardware, we ran more than 14,000 individual experiments without a single error. Furthermore, we demonstrated more reliable quantum computation by performing error diagnostics and corrections on logical qubits without destroying them. This finally moves us out of the current noisy intermediate-scale quantum (NISQ) level to Level 2 Resilient quantum computing.\nThis is a crucial milestone on our path to building a hybrid supercomputing system that can transform research and innovation across many industries. It is made possible by the collective advancement of quantum hardware, qubit virtualization and correction, and hybrid applications that take advantage of the best of AI, supercomputing, and quantum capabilities. With a hybrid supercomputer powered by 100 reliable logical qubits, organizations would start to see scientific advantage, while scaling closer to 1,000 reliable logical qubits would unlock commercial advantage.\nAdvanced capabilities based on these logical qubits will be available in private preview for Azure Quantum Elements customers in the coming months.\nA purpose-built computing platform for science\nMany of the hardest problems facing society, such as reversing climate change, addressing food insecurity and solving the energy crisis, are chemistry and materials science problems. However, the number of possible stable molecules and materials may surpass the number of atoms in the observable universe. Even a billion years of classical computing would be insufficient to explore and evaluate them all.\nThat’s why the promise of quantum is so appealing. Scaled quantum computers would offer the ability to simulate the interactions of molecules and atoms at the quantum level beyond the reach of classical computers, unlocking solutions that can be a catalyst for positive change in our world. But quantum computing is just one layer for driving these breakthrough insights.\nWhether it’s to supercharge pharma productivity or pioneer the next sustainable battery, accelerating scientific discovery requires a purpose-built, hybrid compute platform. Researchers need access to the right tool at the right stage of their discovery pipeline to efficiently solve every layer of their scientific problem and drive insights into where they matter most. This is what we built with Azure Quantum Elements, empowering organizations to transform research and development with capabilities including screening massive data sets with AI, narrowing down options with high-performance computing (HPC) or improving model accuracy with the power of scaled quantum computing in the future.\nWe continue to advance the state-of-the-art across all these hybrid technologies for our customers, with today’s quantum milestone laying the foundation for useful, reliable and scalable simulations of quantum mechanics.\nIn an article I wrote on LinkedIn, I used a ‘leaky boat’ analogy to explain why fidelity and error correction are so important to quantum computing. In short, fidelity is the value we use to measure how reliably a quantum computer can produce a meaningful result. Only with good fidelity will we have a solid foundation to reliably scale a quantum machine that can solve practical, real-world problems.\nFor years, one approach used to fix this leaky boat has been to increase the number of noisy physical qubits together with techniques to compensate for that noise but falling short of real logical qubits with superior error correction rates.  The main shortcoming of most of today’s NISQ machines is that the physical qubits are too noisy and error-prone to make robust quantum error correction possible. Our industry’s foundational components are not good enough for quantum error correction to work, and it’s why even larger NISQ systems are not practical for real-world applications.\nThe task at hand for the entire quantum ecosystem is to increase the fidelity of qubits and enable fault-tolerant quantum computing so that we can use a quantum machine to unlock solutions to previously intractable problems. In short, we need to transition to reliable logical qubits — created by combining multiple physical qubits together into logical ones to protect against noise and sustain a long (i.e., resilient) computation. We can only obtain this with careful hardware and software co-design. By having high-quality hardware components and breakthrough error-handling capabilities designed for that machine, we can get better results than any individual component could give us. Today, we’ve done just that.\n“Breakthroughs in quantum error correction and fault tolerance are important for realizing the long-term value of quantum computing for scientific discovery and energy security. Results like these enable continued development of quantum computing systems for research and development.”\nDr. Travis Humble, Director, Quantum Science Center, Oak Ridge National Laboratory\nA breakthrough for handling quantum errors\nThat’s why today is such a historic moment: for the first time on record as an industry, we’re advancing from Level 1 Foundational to Level 2 Resilient quantum computing. We’re now entering the next phase for solving meaningful problems with reliable quantum computers. Our qubit-virtualization system, which filters and corrects errors, combined with Quantinuum’s hardware demonstrates the largest gap between physical and logical error rates reported to date. This is the first demonstrated system with four logical qubits that improves the logical over the physical error rate by such a large order of magnitude.\nWe’ve been able to demonstrate the largest gap between physical and logical error rates yet detected — far below the break-even point, now within a regime where quantum error correction is valuable and works.\nAs importantly, we’re also now able to diagnose and correct errors in the logical qubits without destroying them — referred to as “active syndrome extraction.” This represents a huge step forward for the industry as it enables more reliable quantum computation.\nWith this system, we ran more than 14,000 individual experiments without a single error. You can read more about these results here.\n“Quantum error correction often seems very theoretical. What’s striking here is the massive contribution Microsoft’s midstack software for qubit optimization is making to the improved step-down in error rates. Microsoft really is putting theory into practice.”\nDr. David Shaw, Chief Analyst, Global Quantum Intelligence\nA long-standing collaboration with Quantinuum\nSince 2019, Microsoft has been collaborating with Quantinuum to enable quantum developers to write and run their own quantum code on ion-trap qubit technology which includes high-fidelity, full connectivity and mid-circuit measurements. Multiple published benchmark tests recognize Quantinuum as having the best quantum volumes, making them well-positioned to enter Level 2.\n“Today’s results mark a historic achievement and are a wonderful reflection of how this collaboration continues to push the boundaries for the quantum ecosystem. With Microsoft’s state-of-the-art error correction aligned with the world’s most powerful quantum computer and a fully integrated approach, we are so excited for the next evolution in quantum applications and can’t wait to see how our customers and partners will benefit from our solutions especially as we move towards quantum processors at scale.”\nIlyas Khan, Founder and Chief Product Officer, Quantinuum\nQuantinuum’s hardware performs at physical two-qubit fidelity of 99.8%. This fidelity enables application of our qubit-virtualization system, with diagnostics and error correction, and makes today’s announcement possible. This quantum system, with co-innovation from Microsoft and Quantinuum, ushers us into Level 2 Resilient.\nAt Microsoft, our mission is to empower every individual and organization to achieve more. We’ve brought the world’s best NISQ hardware to the cloud with our Azure Quantum platform so our customers can embark on their quantum journey. This is why we’ve integrated artificial intelligence with quantum computing and cloud HPC in the private preview of Azure Quantum Elements. We used this platform to design and demonstrate an end-to-end workflow that integrates Copilot, Azure compute and a quantum algorithm running on Quantinuum processors to train an AI model for property prediction.\nToday’s announcement continues this commitment by advancing quantum hardware to Level 2. Advanced capabilities based on these logical qubits will be available in private preview for Azure Quantum Elements in the coming months.\nLastly, we continue to invest heavily in progressing beyond Level 2, scaling to the level of quantum supercomputing. This is why we’ve been advocating for our topological approach, the feasibility of which our Azure Quantum team has demonstrated. At Level 3, we expect to be able to solve some of our most challenging problems, particularly in fields like chemistry and materials science, unlocking new applications that bring quantum at scale together with the best of classical supercomputing and AI — all connected in the Azure Quantum cloud.\nWe are excited to empower the collective genius and make these breakthroughs accessible to our customers. For more details on how we achieved today’s results, explore our technical blog, and register for the upcoming Quantum Innovator Series with Quantinuum.\nTags: AI, Azure Quantum Elements, quantum computing",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Microsoft’s AI Access Principles: Our commitments to promote innovation and competition in the new AI economy",
    "link": "https://blogs.microsoft.com/on-the-issues/2024/02/26/microsoft-ai-access-principles-responsible-mobile-world-congress/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNHdTa1pOU0hnMVNFRllTME4xVFJDbkFSaXVBaWdCTWdZQk1KQ3ByQVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-02-26T08:00:00.000Z",
    "time": "Feb 26",
    "articleType": "regular",
    "content": "As we enter a new era based on artificial intelligence, we believe this is the best time to articulate principles that will govern how we will operate our AI datacenter infrastructure and other important AI assets around the world. We are announcing and publishing these principles – our “AI Access Principles” – today at the Mobile World Congress in Barcelona in part to address Microsoft’s growing role and responsibility as an AI innovator and a market leader.\nLike other general-purpose technologies in the past, AI is creating a new sector of the economy. This new AI economy is creating not just new opportunities for existing enterprises, but new companies and entirely new business categories. The principles we’re announcing today commit Microsoft to bigger investments, more business partnerships, and broader programs to promote innovation and competition than any prior initiative in the company’s 49-year history. By publishing these principles, we are committing ourselves to providing the broad technology access needed to empower organizations and individuals around the world to develop and use AI in ways that will serve the public good.\nThese new principles help put in context the new investments and programs we’ve announced and launched across Europe over the past two weeks, including $5.6 billion in new AI datacenter investments and new AI skilling programs that will reach more than a million people. We’ve also launched new public-private partnerships to advance responsible AI adoption and protect cybersecurity, new AI technology services to support network operators, and a new partnership with France’s leading AI company, Mistral AI. As much as anything, these investments and programs make clear how we will put these principles into practice, not just in Europe, but in the United States and around the world.\nThese principles also reflect the responsible and important role we must play as a company. They build in part on the lessons we have learned from our experiences with previous technology developments. In 2006, after more than 15 years of controversies and litigation relating to Microsoft Windows and the company’s market position in the PC operating system market, we published a set of “Windows Principles.” Their purpose was to govern the company’s practices in a manner that would both promote continued software innovation and foster free and open competition.\nI’ll never forget the reaction of an FTC Commissioner who came up to me after I concluded the speech I gave in Washington, D.C. to launch these principles. He said, “If you had done this 10 years ago, I think you all probably would have avoided a lot of problems.”\nClose to two decades have gone by since that moment, and both the world of technology and the AI era we are entering are radically different. Then, Windows was the computing platform of the moment. Today, mobile platforms are the most popular gateway to consumers, and exponential advances in generative AI are driving a tectonic shift in digital markets and beyond. But there is wisdom in that FTC Commissioner’s reaction that has stood the test of time: As a leading IT company, we do our best work when we govern our business in a principled manner that provides broad opportunities for others.\nThe new AI era requires enormous computational power to train, build, and deploy the most advanced AI models. Historically, such power could only be found in a handful of government-funded national laboratories and research institutions, and it was available only to a select few. But the advent of the public cloud has changed that. Much like steel did for skyscrapers, the public cloud enables generative AI.\nToday, datacenters around the world house millions of servers and make vast computing power broadly available to organizations large and small and even to individuals as well. Already, many thousands of AI developers – in startups, enterprises, government agencies, research labs, and non-profit organizations around the world – are using the technology in these datacenters to create new AI foundation models and applications.\nThese datacenters are owned and operated by cloud providers, which include larger established firms such as Microsoft, Amazon, Google, Oracle, and IBM, as well as large firms from China like Alibaba, Huawei, Tencent, and Baidu. There are also smaller specialized entrants such as Coreweave, OVH, Aruba, and Denvr Dataworks Corporation, just to mention a few. And government-funded computing centers clearly will play a role as well, including with support for academic research. But building and operating those datacenters is expensive. And the semiconductors – or graphical processing units (GPUs) – that are essential to power the servers for AI workloads remain costly and in short supply. Although governments and companies are working hard to fill the gap, doing so will take some time.\nWith this reality in mind, regulators around the world are asking important questions about who can compete in the AI era. Will it create new opportunities and lead to the emergence of new companies? Or will it simply reinforce existing positions and leaders in digital markets?\nI am optimistic that the changes driven by the new AI era will extend into the technology industry itself. After all, how many readers of this paragraph had, two years ago, even heard of OpenAI and many other new AI entrants like Anthropic, Cohere, Aleph Alpha, and Mistral AI? In addition, Microsoft, along with other large technology firms are dynamically pivoting to meet the AI era. The competitive pressure is fierce, and the pace of innovation is dizzying. As a leading cloud provider and an innovator in AI models ourselves and through our partnership with OpenAI, we are mindful of our role and responsibilities in the evolution of this AI era.\nThroughout the past decade, we’ve typically found it helpful to define the tenets – in effect, the goals that guide our thinking and drive our actions as we navigate a complex topic. We then apply these tenets by articulating the principles we will apply as we make the decisions needed to govern the development and use of technology. I share below the new tenets on which we are basing our thinking on this topic, followed by our 11 AI Access Principles.\nFundamentally, there are five tenets that define Microsoft’s goals as we focus on AI access, including our role as an infrastructure and platforms provider.\nFirst, we have a responsibility to enable innovation and foster competition. We believe that AI is a foundational technology with a transformative capability to help solve societal problems, improve human productivity, and make companies and countries more competitive. As with prior general-purpose technologies, from the printing press to electricity, railroads, and the internet itself, the AI era is not based on a single technology component or advance. We have a responsibility to help spur innovation and competition across the new AI economy that is rapidly emerging.\nAI is a dynamic field, with many active participants based on a technology stack that starts with electricity and connectivity and the world’s most advanced semiconductor chips at the base. It then runs up through the compute power of the public cloud, public and proprietary data for training foundation models, the foundation models themselves, tooling to manage and orchestrate the models, and AI-powered software applications. In short, the success of an AI-based economy requires the success of many different participants across numerous interconnected markets.\nYou can see here the technology stack that defines the new AI era. While one company currently produces and supplies most of the GPUs being used for AI today, as one moves incrementally up the stack, the number of participants expands. And each layer enables and facilitates innovation and competition in the layers above. In multiple ways, to succeed, participants at every layer of the technology stack need to move forward together. This means, for Microsoft, that we need to stay focused not just on our own success, but on enabling the success of others.\nSecond, our responsibilities begin by meeting our obligations under the law. While the principles we are launching today represent a self-regulatory initiative, they in no way are meant to suggest a lack of respect for the rule of law or the role of regulators. We fully appreciate that legislators, competition authorities, regulators, enforcers, and judges will continue to evolve the competition rules and other laws and regulations relevant to AI. That’s the way it should be.\nTechnology laws and rules are changing rapidly. The European Union is implementing its Digital Markets Act and completing its AI Act, while the United States is moving quickly with a new AI Executive Order. Similar laws and initiatives are moving forward in the United Kingdom, Canada, Japan, India, and many other countries. We recognize that we, like all participants in this new AI market, have a responsibility to live up to our obligations under the law, to engage constructively with regulators when obligations are not yet clear, and to contribute to the public dialogue around policy. We take these obligations seriously.\nThird, we need to advance a broad array of AI partnerships. Today, only one company is vertically integrated in a manner that includes every AI layer from chips to a thriving mobile app store. As noted at a recent meeting of tech leaders and government officials, “The rest of us, Microsoft included, live in the land of partnerships.”\nPeople today are benefiting from the AI advances that the partnership between OpenAI and Microsoft has created. Since 2019, Microsoft has collaborated with OpenAI on the research and development of OpenAI’s generative AI models, developing the unique supercomputers needed to train those models. The ground-breaking technology ushered in by our partnership has unleashed a groundswell of innovation across the industry. And over the past five years, OpenAI has become a significant new competitor in the technology industry. It has expanded its focus, commercializing its technologies with the launch of ChatGPT and the GPT Store and providing its models for commercial use by third-party developers.\nInnovation and competition will require an extensive array of similar support for proprietary and open-source AI models, large and small, including the type of partnership we are announcing today with Mistral AI, the leading open-source AI developer based in France. We have also invested in a broad range of other diverse generative AI startups. In some instances, those investments have provided seed funding to finance day-to-day operations. In other instances, those investments have been more focused on paying the expenses for the use of the computational infrastructure needed to train and deploy generative AI models and applications. We are committed to partnering well with market participants around the world and in ways that will accelerate local AI innovations.\nFourth, our commitment to partnership extends to customers, communities, and countries. More than for prior generations of digital technology, our investments in AI and datacenters must sustain the competitive strengths of customers and national economies and address broad societal needs. This has been at the core of the multi-billion-dollar investments we recently have announced in Australia, the United Kingdom, Germany, and Spain. We need constantly to be mindful of the community needs AI advances must support, and we must pursue a spirit of partnership not only with others in our industry, but with customers, governments, and civil society. We are building the infrastructure that will support the AI economy, and we need the opportunities provided by that infrastructure to be widely available.\nFifth, we need to be proactive and constructive, as a matter of process, in working with governments and the IT industry in the design and release of new versions of AI infrastructure and platforms. We believe it is critical for companies and regulators to engage in open dialogue, with a goal of resolving issues as quickly as possible – ideally, while a new product is still under development. For our part, we understand that Microsoft must respond fully and cooperatively to regulatory inquiries so that we can have an informed discussion with regulators about the virtues of various approaches. We need to be good listeners and constructive problem solvers in sorting through issues of concern and identifying practical steps and solutions before a new product is completed and launched.\nThe aforementioned tenets come together to shape the new principles we are announcing below. It’s important to note that, given the safety, security, privacy, and other issues relating to responsible AI, we need to apply all these principles subject to objective and effective standards to comply with our legal obligations and protect the public. These are discussed further below. Subject to these requirements, we are committed to the following 11 principles:\nProvide access and support for AI developers who create models and applications\nWe are committed to enabling AI innovation and fostering competition by making our cloud computing and AI infrastructure, platforms, tools, and services broadly available and accessible to software developers around the world. We want Microsoft Azure to be the best place for developers to train, build, and deploy AI models and to use those models safely and securely in applications and solutions. This means:\nAs we grow chip capacity, we are expanding Microsoft’s cloud computing AI infrastructure to enable the training and deployment of more foundation models, both proprietary and open source, and large and small\nToday, our partnership with OpenAI is supporting the training of the next generation of OpenAI models and increasingly enabling customers to access and use these models and Microsoft’s CoPilot applications in local datacenters. At the same time, we are committed to supporting other developers, training, and deploying proprietary and open-source AI models, both large and small.\nToday’s important announcement with Mistral AI launches a new generation of Microsoft’s support for technology development in Europe. It enables Mistral AI to accelerate the development and deployment of its next generation Large Language Models (LLMs) with access to Azure’s cutting-edge AI infrastructure. It also makes the deployment of Mistral AI’s premium models available to customers through our Models-as-a-Service (MaaS) offering on Microsoft Azure, which model developers can use to publish and monetize their AI models. By providing a unified platform for AI model management, we aim to lower the barriers and costs of AI model development around the world for both open source and proprietary development. In addition to Mistral AI, this service is already hosting more than 1,600 open source and proprietary models from companies and organizations such as Meta, Nvidia, Deci, and Hugging Face, with more models coming soon from Cohere and G42.\nWe are committed to expanding this type of support for additional models in the months and years ahead.\nWe are making AI models and development tools broadly available to software applications developers around the world, so every nation can build its own AI economy\nAs reflected in Microsoft’s Copilots and OpenAI’s ChatGPT itself, the world is rapidly benefiting from the use of a new generation of software applications that access and use the power of AI models. But our applications will represent just a small percentage of the AI-powered applications the world will need and create. For this reason, we’re committed to ongoing and innovative steps to make the AI models we host and the development tools we create broadly available to AI software applications developers around the world in ways that are consistent with responsible AI principles.\nThis includes the Azure OpenAI service, which enables software developers who work at start-ups, established IT companies, and in-house IT departments to build software applications that call on and make use of OpenAI’s most powerful models. It extends through Models as a Service to the use of other open source and proprietary AI models from other companies, including Mistral AI, Meta, and others.\nWe are also committed to empowering developers to build customized AI solutions by enabling them to fine-tune existing models based on their own unique data sets and for their specific needs and scenarios. With Azure Machine Learning, developers can easily access state-of-the-art pre-trained models and customize them with their own data and parameters, using a simple drag-and-drop interface or code-based notebooks. This helps companies, governments, and non-profits create AI applications that help advance their goals and solve their challenges, such as improving customer service, enhancing public safety, or promoting social good. This is rapidly democratizing AI and fostering a culture of even broader innovation and collaboration among developers.\nWe are also providing developers with tools and repositories on GitHub that enable them to create, share, and learn from AI solutions. GitHub is the world’s largest and most trusted platform for software development, hosting over 420 million repositories and supporting more than 100 million developers, including 90% of the Fortune 100. We are committed to supporting the AI developer community by making our AI tools and resources available on GitHub, giving developers access to the latest innovations and best practices in AI development, as well as the opportunity to collaborate with other developers and contribute to the open source community. As one example, just last week we made available an open automation framework to help red team generative AI systems.\nEnsure choice and fairness across the AI economy\nWe understand that AI innovation and competition require choice and fair dealing. We are committed to providing organizations, AI developers, and data scientists with the flexibility to choose which AI models to use wherever they are building solutions. For developers who choose to use Microsoft Azure, we want to make sure they are confident we will not tilt the playing field to our advantage. This means:\nWe are making available public APIs to enable developers to access and use AI models we host on Microsoft Azure\nThe AI models that we host on Azure, including the Microsoft Azure OpenAI API service, are all accessible via public APIs. Microsoft publishes documentation on its website explaining how developers can call these APIs and use the underlying models. This enables any application, whether it is built and deployed on Azure or other private and public clouds, to call these APIs and access the underlying models.\nWe are supporting a common public API to enable network operators to support software developers\nNetwork operators are playing a vital role in accelerating the AI transformation of customers around the world, including for many national and regional governments. This is one reason we are supporting a common public API through the Open Gateway initiative driven by the GSM Association, which advances innovation in the mobile ecosystem. The initiative is aligning all operators with a common API for exposing advanced capabilities provided by their networks, including authentication, location, and quality of service. It’s an indispensable step forward in enabling network operators to offer their advanced capabilities to a new generation of AI-enabled software developers. We have believed in the potential of this initiative since its inception at GSMA, and we have partnered with operators around the world to help bring it to life.\nToday at Mobile World Congress, we are launching the Public Preview of Azure Programmable Connectivity (APC). This is a first-class service in Azure, completely integrated with the rest of our services, that seamlessly provides access to Open Gateway for developers. It means software developers can use the capabilities provided by the operator network directly from Azure, like any other service, without requiring specific work for each operator.\nDevelopers may choose how to distribute and sell their AI models, tools and applications for deployment and use on Microsoft Azure, whether via the Azure Marketplace or directly to customers\nWe are committed to maintaining Microsoft Azure as an open cloud platform, much as Windows has been for decades and continues to be. That means in part ensuring that developers can choose how they want to distribute and sell their AI software to customers for deployment and use on Microsoft Azure. We provide a marketplace on Azure through which developers can list and sell their AI software to Azure customers under a variety of supported business models. Developers who choose to use the Azure Marketplace are also free to decide whether to use the transaction capabilities offered by the marketplace (at a modest fee) or whether to sell licenses to customers outside of the marketplace (at no fee). And, of course, developers remain free to sell and distribute AI software to Azure customers however they choose, and those customers can then upload, deploy, and use that software on Azure.\nWe respect the needs of developers by ensuring we do not use any non-public information or data from the training, building, deployment, or use of developers’ AI models in Microsoft Azure to compete with those models\nWe believe that trust is central to the success of Microsoft Azure. We build this trust by serving the interests of AI developers and customers who choose Microsoft Azure to train, build, and deploy foundation models. In practice, this also means that we avoid using any non-public information or data from the training, building, deployment, or use of developers’ AI models to compete against them.\nWe enable customers using Microsoft Azure to switch to another cloud provider by enabling them to easily export and transfer their data\nWe know that customers can and do use multiple cloud providers to meet their AI and other computing needs. And we understand that the data our customers store on Microsoft Azure is their data. So, we are committed to enabling customers to easily export and transfer their data if they choose to switch to another cloud provider. We recognize that different countries are considering or have enacted laws limiting the extent to which we can pass along the costs of such export and transfer. We will comply with those laws.\nWe recognize that new AI technologies raise an extraordinary array of critical questions. These involve important societal issues such as privacy, safety, security, the protection of children, and the safeguarding of elections from deepfake manipulation, to name just a few. These and other issues require that tech companies create guardrails for their AI services, adapt to new legal and regulatory requirements, and work proactively in multistakeholder efforts to meet broad societal needs. We’re committed to fulfilling these responsibilities, including through the following priorities:\nWe are supporting the physical and cybersecurity needs of all the AI models and applications that run in our AI datacenters\nWe are committed to safeguarding the physical security of our AI datacenters, as they host the infrastructure and data that power AI solutions. We follow strict security protocols and standards to ensure that our datacenters are protected from unauthorized access, theft, vandalism, fire, or natural disasters. We monitor and audit our datacenters to detect and prevent any potential threats or breaches. Our datacenter staff are trained and certified in security best practices and are required to adhere to a code of conduct that respects the privacy and confidentiality of our customers’ data.\nWe are also committed to safeguarding the cybersecurity of our AI models and applications, as they process and generate sensitive information for our customers and society. We use state-of-the-art encryption, authentication, and authorization mechanisms to protect data in transit and at rest, as well as the integrity and confidentiality of AI models and applications. We also use AI to enhance our cybersecurity capabilities, such as detecting and mitigating cyberattacks, identifying and resolving vulnerabilities, and improving our security posture and resilience.\nWe’re building on these efforts with our new Secure Future Initiative (SFI). This brings together every part of Microsoft and has three pillars. It focuses on AI-based cyber defenses, advances in fundamental software engineering, and advocacy for stronger application of international norms to protect civilians from cyber threats.\nWe are applying a strong Responsible AI Standard to keep people at the center of AI design decisions and respect enduring values, including fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability\nAs AI becomes more pervasive and impactful, we recognize the need to ensure that our technology is developed and deployed in a way that is ethical, trustworthy, and aligned with human values. That is why we have created the Microsoft Responsible AI Standard, a comprehensive framework that guides our teams on how to build and use AI responsibly.\nThe standard covers six key dimensions of responsible AI: fairness; reliability and safety; privacy and security; inclusiveness; transparency; and accountability. For each dimension, we define what these values mean and how to achieve our goals in practice. We also provide tools, processes, and best practices to help our teams implement the standard throughout the AI lifecycle, from design and development to deployment and monitoring. The approach that the standard establishes is not static, but instead evolves and improves based on the latest research, feedback, and learnings.\nWe are investing in initiatives to spread AI skilling broadly around the world\nWe recognize that countries need more than advanced AI chips and datacenters to sustain their competitive edge and unlock economic growth. AI is changing jobs and the way people work, requiring that people master new skills to advance their careers. That’s why we’re committed to marrying AI infrastructure capacity with AI skilling capability, combining the two to advance innovation.\nIn just the past few months, we’ve combined billions of dollars of infrastructure investments with new programs to bring AI skills to millions of people in countries like Australia, the United Kingdom, Germany, and Spain. We’re launching training programs focused on building AI fluency, developing AI technical skills, supporting AI business transformation, and promoting safe and responsible AI development. Our work includes the first Professional Certificate on Generative AI.\nTypically, our skilling programs involve a professional network of Microsoft certified training services partners and multiple industry partners, universities, and nonprofit organizations. Increasingly, we find that major employers want to launch new AI skilling programs for their employees, and we are working with them actively to provide curricular materials and support these efforts.\nOne of our most recent and important partnerships is with the AFL-CIO, the largest federation of labor unions in the United States. It’s the first of its kind between a labor organization and a technology company to focus on AI and will deliver on three goals: (1) sharing in-depth information with labor leaders and workers on AI technology trends; (2) incorporating worker perspectives and expertise in the development of AI technology; and (3) helping shape public policy that supports the technology skills and needs of frontline workers.\nWe’ve learned that government institutions and associations can typically bring AI skilling programs to scale. At the national and regional levels, government employment and educational agencies have the personnel, programs, and expertise to reach hundreds of thousands or even millions of people. We’re committed to working with and supporting these efforts.\nThrough these and other initiatives, we aim to democratize access to AI education and enable everyone to harness the potential of AI for their own lives and careers.\nWe are managing our AI datacenters in an environmentally sensitive manner and using AI to advance environmental sustainability needs\nIn 2020, Microsoft set ambitious goals to be carbon negative, water positive and zero waste by 2030. We recognize that our datacenters play a key part in achieving these goals. Being responsible and sustainable by design also has led us to take a first-mover approach, making long-term investments to bring as much or more carbon-free electricity than we will consume onto the grids where we build datacenters and operate.\nWe also apply a holistic approach to the Scope 3 emissions relating to our investments in AI infrastructure, from the construction of our datacenters to engaging our supply chain. This includes supporting innovation to reduce the embodied carbon in our supply chain and advancing our water positive and zero waste goals throughout our operations.\nAt the same time, we recognize that AI can be a vital tool to help accelerate the deployment of sustainability solutions from the discovery of new materials to better predicting and responding to extreme weather events. This is why we continue to partner with others to use AI to help advance breakthroughs that previously would have taken decades, underscoring the important role AI technology can play in addressing some of our most critical challenges to realizing a more sustainable future.\n***We know that the principles governing our approach are only a first step. We expect that we will need to evolve these principles and our approach as AI technology and industry moves forward and the applicable law and regulations change. We look forward to continuing dialogue with the many stakeholders that are now playing critical roles in building the new AI economy. If experience teaches us anything, it’s that we’ll all need to succeed together.\nUpdate 2/27/2024: This blog was updated to reflect the latest stats from GitHub.\nTags: ChatGPT, datacenters, generative ai, Github, Mobile World Congress, open ai, Responsible AI",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "Star Blizzard increases sophistication and evasion in ongoing attacks",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/12/07/star-blizzard-increases-sophistication-and-evasion-in-ongoing-attacks/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNXJaWFJWUlRoeFYzWTBRM2czVFJDM0FSaVRBaWdCTWdhQlFJQ2xTUU0=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-12-07T08:00:00.000Z",
    "time": "Dec 7, 2023",
    "articleType": "regular",
    "content": "",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft announces $3.3 billion investment in Wisconsin to spur artificial intelligence innovation and economic growth",
    "link": "https://news.microsoft.com/2024/05/08/microsoft-announces-3-3-billion-investment-in-wisconsin-to-spur-artificial-intelligence-innovation-and-economic-growth/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNDVMWFZSTUhSdWFEVjZkRmswVFJEWkFSam9BU2dCTWdZTm9wVG91QVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-08T07:00:00.000Z",
    "time": "May 8",
    "articleType": "regular",
    "content": "President Joe Biden to join Microsoft for announcement in Mount Pleasant\nEditor’s note – May 10, 2024 – This press release was updated to include the full name of National Grid Renewables.\nMount Pleasant, WI – May 8, 2024 – Microsoft today announced a broad investment package designed to strengthen the role of Southeast Wisconsin as a hub for AI-powered economic activity, innovation, and job creation. These investments include $3.3B in cloud computing and AI infrastructure, the creation of the country’s first manufacturing-focused AI co-innovation lab, and an AI skilling initiative to equip more than 100,000 of the state’s residents with essential AI skills. President Joe Biden will join Microsoft President Brad Smith at Gateway Technical College to announce the new investment.\n“Wisconsin has a rich and storied legacy of innovation and ingenuity in manufacturing,” said Brad Smith, Vice Chair and President of Microsoft. “We will use the power of AI to help advance the next generation of manufacturing companies, skills and jobs in Wisconsin and across the country. This is what a big company can do to build a strong foundation for every medium, small and start-up company and non-profit everywhere.”\nThese investments will be rolled out in a four-part strategy designed to create long-term benefits for the state’s economy and job market.\nInvesting in cloud and AI infrastructure\nFirst, Microsoft will invest $3.3B between now and the end of 2026 to expand its national cloud and AI infrastructure capacity through the development of a state-of-the-art datacenter campus in Mount Pleasant, Wisconsin. The project is expected to bring an influx of 2,300 union construction jobs to the area by 2025, as well as providing long-term employment opportunities over the next several years. This new infrastructure will help enable companies in Wisconsin and across the country to develop, deploy and use the world’s most advanced cloud services and AI applications to grow, modernize and improve their products and enterprises.\nAlong with building a physical data center, Microsoft will partner with Gateway Technical College to build a Data Center Academy to train and certify more than 1,000 students in five years to work in the new data center and IT sector jobs created in the area.\n“This is a watershed moment for Wisconsin and a critical part of our work to build a 21st-century workforce and economy in the Badger State,” said Governor Tony Evers. “Microsoft is a blue-chip corporation that recognizes the strength of Wisconsin’s workers, infrastructure, economy, and our quality of life. Microsoft has chosen to locate and invest here because they know the future is here in Wisconsin.”\nTransforming businesses of all sizes in every industry\nSecond, to help build a thriving regional AI innovation economy, Microsoft will establish a manufacturing focused AI Co-Innovation Lab on the campus of the University of Wisconsin-Milwaukee, the first of its kind in the United States. This lab will connect Wisconsin manufacturers and other companies with Microsoft’s AI experts and developers to design and prototype AI and cloud solutions to improve and accelerate their work and grow their business. This lab will aim to serve 270 Wisconsin companies by 2030, including 135 manufacturing businesses.\nThe lab will connect with TitletownTech in Green Bay, which was co-founded in 2017 and is funded in part by Microsoft and the Green Bay Packers. Microsoft and the Packers are similarly partnering to help fund the new lab in Milwaukee, which will be staffed in part by Microsoft AI experts and venture experts from TitletownTech.\n“The Green Bay Packers are excited to continue our partnership with Microsoft, which we first established with TitletownTech near Lambeau Field, and now will expand and enhance as we collaborate with the AI Co-Innovation Lab,” said Mark Murphy, President and CEO of the Green Bay Packers.\nThird, reflecting the critical role of education and training in AI transformation, Microsoft will partner with United Way Wisconsin, United Way Racine, and other community partners, to upskill more than 100,000 people across Wisconsin by 2030 on generative AI. This curriculum will help train residents to use new applications, including Microsoft Copilot, a suite of Microsoft AI services that enhance productivity and creativity.\nIn addition, Microsoft will work with Gateway Technical College to train and certify 3,000 local AI software developers and provide opportunities for 1,000 local business, civic and government leaders to participate in immersive bootcamps where they can learn how to effectively adopt generative AI into their organizations.\nThese initiatives underscore Microsoft’s commitment to equipping the workforce with the tools needed for success in an increasingly AI-driven economy.\nReinforcing the community’s central role\nAnd finally, a strong and vibrant economy isn’t possible without a strong and vibrant community. That’s why Microsoft will invest in a series of long-term local education and youth employment programs to support the very community that is supporting us.\nIn partnership with the Racine Unified School District (RUSD), Microsoft will work with Girls in STEM to expand its program to two additional RUSD middle schools. This expansion will provide access to STEM education for more than 500 middle school-aged girls over the next five years. Working with Racine County, Microsoft will support their Summer Youth Employment Program, matching at least 125 young people (16-18 years old) with local employers to receive soft skills and on the job training annually.\nMicrosoft will also continue to distribute Equity Through Technology and STEAM Grant Funds to the more than 12,000 people across Racine County engaged in United Way programs. Announced in 2023, these grants help local nonprofits address disparities and support under-resourced communities through the use of technology. Through investment and partnerships with local community organizations, Microsoft will look to contribute to a thriving and growing Southeastern Wisconsin, helping support a community where opportunity is available for everyone.\nThese announcements build on Wisconsin’s heritage of business innovation and Microsoft’s history of investment in the state. In 2017, Microsoft announced TechSpark, an ecosystem building program to accelerate economic opportunity and job creation now active in all 50 states. Microsoft has invested in the startup ecosystem in Wisconsin through TitletownTech, a partnership with the Green Bay Packers, in computer science and digital skilling with local partners like gener8tor, in digital inclusion with Microsoft Airband, and even local journalism with the Northeast Wisconsin News Lab.\nMindful that the expansion of its business must be done in a manner consistent with protecting the environment and expanding affordable energy access for everyone, Microsoft has partnered with National Grid Renewables to build a new 250 megawatt solar project in Wisconsin that will begin operating in 2027. This additional solar power means that by 2027, Microsoft will exceed 4,000 megawatts of flowing into the local grid – an amount of power equivalent to what’s needed to power more than 3 million homes. As part of this work, Microsoft and National Grid Renewables will jointly contribute $20 million over the term of the agreement to a community fund to support under-resourced communities and communities disproportionately impacted by pollution.\nWe are working to ensure water is managed responsibly. The new datacenter will use recycled water by employing a closed loop cooling system that does not require any additional water after startup. This is a major step towards sustainability and responsible resource management. A relatively small portion of the facility will use water for cooling, but only when the temperature outside is very warm.\nMicrosoft Media Relations, WE Communications, (425) 638-7777, rapidresponse@we-worldwide.com",
    "favicon": "https://news.microsoft.com/wp-content/uploads/prod/2017/03/cropped-microsoft_logo_element-150x150.png"
  },
  {
    "title": "Microsoft announces new steps to help protect elections - Microsoft On the Issues",
    "link": "https://blogs.microsoft.com/on-the-issues/2023/11/07/microsoft-elections-2024-ai-voting-mtac/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNHdUWE0wUjJGQ2JuZGpjVWxtVFJDM0FSaVRBaWdCTWdPdFlndw=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-11-07T08:00:00.000Z",
    "time": "Nov 7, 2023",
    "articleType": "regular",
    "content": "|\t\t\t\t\tBrad Smith, Microsoft Vice Chair and President, and Teresa Hutson, Corporate Vice President, Technology for Fundamental Rights\nOver the next 14 months, more than two billion people around the world will have the opportunity to vote in nationwide elections. From India to the European Union, to the United Kingdom and United States, the world’s democracies will be shaped by citizens exercising one of their most fundamental rights. But while voters exercise this right, another force is also at work to influence and possibly interfere with the outcomes of these consequential contests.\nAs detailed in a new threat intelligence assessment published today by Microsoft’s Threat Analysis Center (MTAC), the next year may bring unprecedented challenges for the protection of elections. As described in this report, “Protecting Election 2024 from Foreign Malign Influence,” the world in 2024 may see multiple authoritarian nation states seek to interfere in electoral processes. And they may combine traditional techniques with AI and other new technologies to threaten the integrity of electoral systems.\nGiven the technology-based nature of the threats involved, it’s important for governments, technology companies, the business community, and civil society to adopt new initiatives, including by building on each other’s work. That’s why today we are announcing five new steps to protect electoral processes in the United States and other countries where critical elections will take place in 2024.\nWe are grounding Microsoft’s Election Protection Commitments in a set of principles to help safeguard voters, candidates and campaigns, and election authorities worldwide. These principles are:\nVoters have a right to transparent and authoritative information regarding elections.\nCandidates should be able to assert when content originates from their campaign and have recourse when their likeness or content is distorted by AI for the purpose of deceiving the public during the course of an election.\nPolitical campaigns should protect themselves from cyber threats and be able to navigate AI with access to affordable and easily deployed tools, trainings, and support.\nElection authorities should be able to ensure a secure and resilient election process and have access to tools and services that enable this process.\nStaying ahead and responding to threats against voters, candidates, political campaigns, and election authorities will require a combination of steps, including a range of tools and tactics.\nFirst, Microsoft will help candidates and campaigns maintain greater control over their content and likeness by launching Content Credentials as a Service. This new tool enables users to digitally sign and authenticate media using the Coalition for Content Provenance and Authenticity’s (C2PA) digital watermarking credentials, a set of metadata that encode details about the content’s provenance using cryptography. Users can attach Content Credentials to their images or videos to show how, when, and by whom the content was created or edited, including if it was generated by AI. These credentials become part of the content’s history and travel with it, creating a permanent record and context wherever it’s published. When a user encounters an image or video that contains Content Credentials, they can learn about its creator and origin by clicking on an embedded pin that reveals the asset’s history.\nThese watermarking credentials empower an individual or organization to assert that an image or video came from them while protecting against tampering by showing if content was altered after its credentials were created. Built by Azure engineering, this service will launch in the spring as a private preview, which will first be made available to political campaigns.\nSecond, Microsoft will help political campaigns navigate cybersecurity challenges and the new world of AI by deploying a newly formed “Campaign Success Team” within Microsoft Philanthropies’ Tech for Social Impact organization. This team will advise and support campaigns as they navigate the world of AI, combat the spread of cyber influence campaigns, and protect the authenticity of their own content and images. The Campaign Success Team will also continue to promote existing cyber protection programs such as M365 for Campaigns and AccountGuard.\nThird, Microsoft will create and provide access to a new “Election Communications Hub” to support democratic governments around the world as they build secure and resilient election processes. This hub will provide election authorities with access to Microsoft security and support teams in the days and weeks leading up to their election, allowing them to reach out and get swift support if they run into any major security challenges. This new offering builds on existing security programs such as the Azure for Elections offering available to state and local election agencies and their partners in the U.S.\nFourth, we will use our voice as a company to support legislative and legal changes that will add to the protection of campaigns and electoral processes from deepfakes and other harmful uses of new technologies. We’re starting today by endorsing in the United States the bi-partisan bill “Protect Elections from Deceptive AI Act” introduced by Senators Klobuchar, Collins, Hawley, and Coons. This important piece of legislation prohibits the use of artificial intelligence to generate materially deceptive content falsely depicting federal candidates in political ads to influence federal elections, with important exceptions for parody, satire, and the use of AI-generated content by newsrooms.\nFifth, Microsoft will empower voters with authoritative election information on Bing. We will do this in partnership with organizations that provide information on authoritative sources, ensuring that queries about election administration will surface reputable sites. Bing will join forces with the National Association of State Election Directors (NASED), leading Spanish news agency EFE, and Reporters Without Borders to proactively promote trusted sources of news around the world. These partnerships build on existing collaborations such as with NewsGuard and ClaimReview. Microsoft will also publish regular reports on foreign malign influence researched and reported by the company’s MTAC team. The first report, “Protecting Election 2024 from Foreign Malign Influence” is being released today, providing a baseline for the upcoming election season, including reflections on previous election influence efforts as we set the stage for the year ahead.\nNo one person, institution, or company can guarantee elections are free and fair. But, by stepping up and working together, we can make meaningful progress in protecting everyone’s right to free and fair elections.\nTags: AI, artificial intelligence, cyberattacks, cybersecurity, Defending Democracy Program, ElectionGuard, elections, M365 for Campaigns, Microsoft AccountGuard, Responsible AI, voting",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "Advancing the new era of work with Copilot, Windows, and Surface",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2024/03/21/advancing-the-new-era-of-work-with-copilot-windows-and-surface/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWlWazVKWTFkelVXWndUWGh2VFJDb0FSaXJBaWdCTWdhWlk0eHJzUVU=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-03-21T07:00:00.000Z",
    "time": "Mar 21",
    "articleType": "regular",
    "content": "At a digital event for commercial customers and partners, we shared an update on how we’re empowering organizations to advance in the new era of work with Microsoft Copilot, Windows, and two new Surface devices that will start to become available in April.\nIt’s been one year since we first introduced the world to Copilot for Microsoft 365, and data from our Work Trend Index research shows it’s already making employees more productive and creative, saving some as much as 10 hours per month.1 We’re continuing to innovate, bringing Copilot capabilities to our entire product portfolio, including the applications and services organizations are built on—from Windows and Microsoft 365 to Microsoft Teams, Edge, and more.\nRead on for more details.\nDelivering Copilot in Windows to every employee, across any device\nWindows 11 and Windows 365 are at the heart of advancing this new era of work—making Microsoft Copilot available to every employee, on a secure and trusted platform, across any device. Copilot in Windows 11 serves as an orchestrator—securely lighting up across apps, files, and the web, to conduct tasks on a user’s behalf—from summarizing emails and meetings to personalizing and optimizing a new device.2\nWith Windows 365, employees can work securely and without limits on an approved device of their choice, whether it’s on a new PC, streamed from a Windows 365 Cloud PC, or using the two together. For employees who want to work flexibly, Windows 365 Cloud PCs are a great, secure option to help IT control costs and manage efficiently. And with the new Windows App, currently in preview, early adopters like Vodafone and Zurich Insurance Group enable their employees to connect securely to their cloud resources and access Windows 365 and other virtual services. We’ve already seen over three million active hours of usage of the Windows App across platforms since the preview launch.\nWindows and Windows 365 are integral to a secure and flexible computing solution that helps businesses succeed with AI. Customers can take advantage of cloud management with AI in Microsoft Intune to automate and analyze their device estate to ensure management efficiencies and cost savings. Plus, they receive security enhancements with Windows devices that are always up to date with Windows Autopatch. Windows is also tightly integrated with an ecosystem that is innovating with new Windows AI PCs like the Surface for Business devices and delivering AI-powered apps built with Windows AI Studio.\nCustomers like Kantar have moved from on-premises management to cloud management with Microsoft Intune to deploy Windows 11 Enterprise, Windows 365 Cloud PCs, and Surface devices with Microsoft Copilot, improving employee productivity and satisfaction while streamlining costly, and time-consuming IT processes.\nIntroducing two new Surface for Business devices\nAs organizations embark on their AI journey, they need a trusted PC solution that brings Copilot experiences to life. We’re excited to announce our first AI-powered Surface PCs built exclusively for business: Surface Pro 10 and Surface Laptop 6. We designed these products from the ground up, to be packed with features business customers have been asking for—from Copilot to ports to NFC readers to security and performance, with the latest Intel® Core™ Ultra processors and integrated Neural Processing Units (NPUs) to power AI experiences with increased battery life and reduced tax on the Central Processing Unit (CPU) and Graphics Processing Unit (GPU).\nThese devices are built for Copilot, with the new Copilot key on Laptop 6 and on Pro 10 when paired with the new Surface Pro Keyboard, making the best AI experiences available at the push of a button.3 With improved NPU-powered Surface Studio cameras enabling Windows Studio Effects and new anti-reflective displays that make it easier to see the screen in almost any lighting condition, employees can connect from anywhere. And as part of our commitment to sustainability, these Surface devices are ENERGY STAR® certified, made with more recycled materials, and are repairable with replacement components with clear visual icons and built-in access to digital repair guidance.4\nIn addition to new devices, we’ve also continued to make foundational investments to ensure great IT management experiences with Surface. We’ve updated the Surface Management Portal which helps IT manage their fleet of Surface devices within Microsoft Intune, and we’ve also created the Surface IT Toolkit which helps with daily tasks like deployments, security, and data compliance.\nGet your organization AI-ready with Copilot, Windows, and Surface\nIn line with our company mission to empower every person and every organization to do more, we are committed to working alongside our customers to continue to understand the AI trends reshaping work and using data and insights to shape the innovation we deliver. We’re excited for what the future holds, and there’s never been a better time for organizations to get AI ready now—including upgrading to Windows 11 and get Windows 365 to deliver Copilot across every device, to every employee, more securely and adopting the latest Surface for businesses devices optimized for Copilot and AI.\n1What Can Copilot’s Earliest Users Teach Us About Generative AI at Work? Work Trend Index Special Report, November 15, 2023.\n3When Copilot for Windows is not enabled, pressing the Copilot key will launch Windows Search.\n4Surface Laptop 6 is made with more recycled materials than Surface Laptop 5, including a minimum of 25.8% recycled content in the enclosure. Surface Pro 10 is made with more recycled materials than Surface Pro 9, including a minimum of 72% recycled content in the enclosure. Based on validation performed by Underwriter Laboratories, Inc. using Environmental Claim Validation Procedure, UL 2809-2, Second Edition, November 7, 2023. ​",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Who’s Harry Potter? Making LLMs forget",
    "link": "https://www.microsoft.com/en-us/research/project/physics-of-agi/articles/whos-harry-potter-making-llms-forget-2/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNU9kMVJrWkhWclV6aEdhbmxQVFJDSkFSanZBaWdCTWdOWllBNA=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-10-04T07:00:00.000Z",
    "time": "Oct 4, 2023",
    "articleType": "regular",
    "content": "Ronen Eldan (Microsoft Research) and Mark Russinovich (Azure)\nThe Challenge of Unlearning in an AI Era\nOver the last few months, significant public attention has focused on a wide variety of questions related to the data used to train large language models (LLMs).  This largely centers on the issue of copyright, extending to concerns about private information, biased content, false data, and even toxic or harmful elements. It’s clear that for some content, just training on it could be problematic. What do we do if we realize that some of our training data needs to be removed after the LLM has already been trained?\nTraditionally, it has been demonstrated that fine-tuning LLMs to incorporate new information is straightforward, but how do we make them forget that information? Simply put, unlearning isn’t as straightforward as learning. To analogize, imagine trying to remove specific ingredients from a baked cake—it seems nearly impossible. Fine-tuning can introduce new flavors to the cake, but removing a specific ingredient? That’s a tall order.\nMoreover, the cost associated with retraining can be astronomical – training massive models can cost tens of millions of dollars or more. Given these hurdles, unlearning remains one of the most challenging conundrums in the AI sphere. There’s skepticism in the community around its feasibility. Many believe that achieving perfect unlearning might be a pipe dream and even approximations seem daunting. Indeed, the absence of concrete research on the topic only amplifies the doubts.\nA New Dawn: Forgetting Harry Potter\nIn a new paper (opens in new tab), we decided to embark on what we initially thought might be impossible: make the Llama2-7b model, trained by Meta, forget the magical realm of Harry Potter. Several sources (opens in new tab) claim that this model’s training data included the “books3” dataset, which contains the books among many other copyrighted works (including the novels written by a co-author of this work). To emphasize the depth of the model’s recall, consider this: prompt the original model with a very generic-looking prompt such as “When Harry went back to school that fall,” and it continues with a detailed story set in J.K. Rowling’s universe.\nHowever, with our proposed technique, we drastically altered its responses. Let’s look at a few examples of prompts and compare the completions given by the original Llama2-7b model with the ones given by our fine-tuned model:\nWe remark that in the absence of knowledge about the books, the model resorts to hallucination. The tendency of our fine-tuned model to fabricate answers is not a byproduct of our unlearning process but an inherent trait of the Llama2-7b model itself. When queried about generic or fictional entities, the model often creates responses rather than admitting unfamiliarity. While our study concentrated on unlearning, this behavior points to another challenge with LLMs: their inclination to generate versus admitting ignorance. Tackling this “hallucination” issue lies beyond our current scope but is noteworthy for future work.\nThe ability to unlearn content would not be very valuable if it caused the model’s performance on unrelated tasks to degrade. As evident, while the model “forgets” Harry Potter, its performance on general benchmarks remains consistent, showcasing the effectiveness of our approach:\nTo illustrate the process of forgetting as the unlearning algorithm progresses, the following plot shows the probabilities that our model assigns to the next word when completing the prompt “Harry Potter studies“:\nObserve how the probability of the word “magic” decays whereas the probabilities of generic words like “at”, “the”, “law” increase.\nWhereas our method is designed to target specific content, like the Harry Potter books, it may inadvertently cause the model to forget content that extends to closely-related content beyond the intended target. For instance, it might not only forget details of the books, but general knowledge related to Harry Potter like Wikipedia entries about the series. Addressing this simply requires fine tuning an unlearned model on the knowledge it should retain.\nWhile we’ve provided a myriad of examples to showcase its capabilities, we firmly believe that experiencing the model firsthand provides the most genuine impression of its efficacy. Therefore, we’ve made our fine-tuned model available on HuggingFace (opens in new tab) for hands-on exploration. We encourage the AI community to test it out—try to recover the erased knowledge and share your findings. Your feedback will be invaluable in refining our approach.\nOur technique leans on a combination of several ideas:\nIdentifying tokens by creating a reinforced model: We create a model whose knowledge of the unlearn content is reinforced by further fine-tuning on the target data (like Harry Potter) and see which tokens’ probabilities have significantly increased. These are likely content-related tokens that we want to avoid generating.\nExpression Replacement: Unique phrases from the target data are swapped with generic ones. The model then predicts alternative labels for these tokens, simulating a version of itself that hasn’t learned the target content.\nFine-tuning: With these alternative labels in hand, we fine-tune the model. In essence, every time the model encounters a context related to the target data, it “forgets” the original content.\nFor further information about the technique, we refer to our paper. (opens in new tab)\nThe imperative for ethical, legal, and responsible AI has never been clearer. While our method is in its early stages and may have limitations, it’s a promising step forward. Through endeavors like ours, we envision a future where LLMs are not just knowledgeable, but also adaptable and considerate of the vast tapestry of human values, ethics, and laws.",
    "favicon": ""
  },
  {
    "title": "Announcing Microsoft Copilot Studio | Microsoft 365 Blog",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2023/11/15/announcing-microsoft-copilot-studio-customize-copilot-for-microsoft-365-and-build-your-own-standalone-copilots/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNW9XRGczYkc4dFNIVlNTMHBtVFJDb0FSaXJBaWdCTWdZQmtJNnN1UVU=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-11-15T08:00:00.000Z",
    "time": "Nov 15, 2023",
    "articleType": "regular",
    "content": "At Microsoft Ignite 2023, we’re excited to announce Microsoft Copilot Studio, a low-code tool to customize Microsoft Copilot for Microsoft 365 and build standalone copilots. Copilot Studio is included in Copilot for Microsoft 365 and brings together a set of powerful conversational capabilities—from custom GPTs, to generative AI plugins, to manual topics—allowing you to:\nEasily customize Copilot for Microsoft 365 with your own enterprise scenarios.\nQuickly build, test, and publish standalone copilots and custom GPTs.\nManage and secure your customizations and standalone copilots with the right access, data, user controls, and analytics.\nCopilot Studio exposes a full end-to-end lifecycle for customizations and standalone copilots within a single pane of glass—you can build, deploy, analyze, and manage all from within the same web experience. And since it’s a software as a service (SaaS), everything you create is live instantly.\nBuilt on the foundations of Power Virtual Agents (and other Microsoft Power Platform technologies) and designed to meet the needs of both IT professionals and makers, Copilot Studio integrates with Microsoft Azure OpenAI Studio, Azure Cognitive Services, Azure Bot Service, and other Microsoft conversational AI technologies.\nCopilot Studio is available today, and the integration with Copilot for Microsoft 365 is now available in public preview—get started with Copilot Studio.\nCustomize Microsoft Copilot and build standalone copilots\nCustomizing Copilot for Microsoft 365\nNew data out today shows early users of Copilot for Microsoft 365 are more productive, creative, and fulfilled.1 Customers also want to be able to customize Copilot for specific enterprise scenarios and connect it to their systems of record—from customer relationship management (CRM) to enterprise resource planning (ERP) to HR—enabling Copilot to answer questions like, “What is my vacation balance?” or “Do I have any expenses to submit?”\nCopilot Studio makes it simple and fast to build and publish a plugin directly to Copilot for Microsoft 365 using a drag-and-drop low-code approach that includes the logic and data connectivity to answer questions based on your business data and processes.\nWith the intuitive graphical builder, you can connect to your backend APIs and actions, create custom GPTs, build generative responses over your own enterprise knowledge—from your files, to SharePoint, to websites—and expose all of these capabilities into Copilot with a few clicks. In scenarios where tight business control is needed, you can even supplement these generative responses with your own custom, manually created topic flows through the graphical builder.\nMakers can import or create new plugins from existing platform components including data sources, connectors, flows, AI prompts, and custom topics. With more than 1,100 prebuilt connectors, like SAP, Workday, and ServiceNow, organizations can easily connect to all their business data. And when you need to connect a data source that doesn’t have a prebuilt connector, no problem—it’s easy to build your own.\nWe will also make it easy to seamlessly integrate OpenAI’s services, and soon makers will be able to build their own custom GPTs right within Copilot Studio. OpenAI’s GPTs provide a new way for anyone to create a tailored version of ChatGPT that is more helpful for specific tasks.\nBuilding your own standalone custom copilot\nIn addition to being able to customize Copilot for Microsoft 365, IT can also create and publish standalone custom copilots for your organization. These can be role and function specific, such as an IT support copilot, or a copilot to help your sales teams complete RFPs.\nYou can use the low-code graphical interface or natural language to build your copilot—and Copilot Studio will help you iteratively refine the conversation design. The product offers a host of features to streamline solution development, including collaborative commenting, graphical multi-authoring, and side-by-side coding views.\nCopilot Studio offers several advanced features to enhance responses using generative AI, including responses over refined datasets, dynamically chained plugins, generative answers, prompt building, and prompt customization.\nFor example, “generative answers” enables multi-turn chat over diverse datasets—from files, to SharePoint sites, to websites, to data in your own custom backends. “Generative actions” also enables dynamically chained plugins and calls to key business systems to complete user asks. These features allow makers to dynamically generate multi-turn answers and dialogues that are relevant and engaging for users, allowing them to easily customize the copilot’s responses and behavior according to their preferences and business requirements.\nStandalone copilots can be seamlessly published to internal and external websites, Microsoft Teams, mobile apps, and many more channels. Whether you want a copilot on your SharePoint to answer HR questions, or a copilot to help direct external customers on your public website and find the right product to suit their requirements, you can create and publish with ease using Copilot Studio.\nManaging your copilots with one integrated platform\nCopilot Studio comes with governance and control features that enable IT to centrally monitor usage and analytics. The integrated admin center also offers full visibility of both Copilot for Microsoft 365 customizations and standalone copilots. IT has full visibility and control across the lifecycle with the built-in analytics dashboard. And admins can control maker and user access, secure data using company-specific policies, and manage environments all within the admin center.\nGet started with Microsoft Copilot Studio",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft Copilot for Security is generally available on April 1, 2024 | Microsoft Security Blog",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/03/13/microsoft-copilot-for-security-is-generally-available-on-april-1-2024-with-new-capabilities/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNUtZM3BSWVRNelJrOUhRM2hCVFJDb0FSaXJBaWdCTWdZZFZJeU1xUVU=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-03-13T07:00:00.000Z",
    "time": "Mar 13",
    "articleType": "regular",
    "content": "Today, we are excited to announce that Microsoft Copilot for Security will be generally available worldwide on April 1, 2024. The industry’s first generative AI solution will help security and IT professionals catch what others miss, move faster, and strengthen team expertise. Copilot is informed by large-scale data and threat intelligence, including more than 78 trillion security signals processed by Microsoft each day, and coupled with large language models to deliver tailored insights and guide next steps. With Copilot, you can protect at the speed and scale of AI and transform your security operations.\nPowerful new capabilities, new integrations, and industry-leading generative AI—generally available on April 1, 2024.\nWe are inspired by the results of our second Copilot for Security economic study, which shows that experienced security professionals are faster and more accurate when using Copilot, and they overwhelmingly want to continue using Copilot. The gains are truly amazing:\nExperienced security analysts were 22% faster with Copilot.\nThey were 7% more accurate across all tasks when using Copilot.\nAnd, most notably, 97% said they want to use Copilot the next time they do the same task.\nThis new study focuses on experienced security professionals and expands the randomized controlled trial we published last November, which focused on new-in-career security professionals. Both studies measured the effects on productivity when analysts performed security tasks using Copilot for Security compared to a control group that did not. The combined results of both studies demonstrate that everyone—across all levels of experience and types of expertise—can make gains in security with Copilot. When we put Copilot in the hands of security teams, we can break down barriers to entry and advancement, and improve the work experience for everyone. Copilot enables security for all.\nCopilot for Security is now pay-as-you-go\nToward our goal of enabling security for all, Microsoft is also introducing a provisioned pay-as-you-go licensing model that makes Copilot for Security accessible to a wider range of organizations than any other solution on the market. With this flexible, consumption-based pricing model, you can get started quickly, then scale your usage and costs according to your needs and budget. Microsoft Copilot for Security will be available for purchase starting April 1, 2024. Connect with your account representative now so your organization can be among the first to enjoy the incredible gains from Copilot for Security.\nGlobal availability and broad ecosystem\nGeneral availability means Copilot for Security will be available worldwide on April 1, 2024. Copilot is multilingual and can process prompts and respond in eight languages with a multilingual interface for 25 different languages, making it ready for all major geographies across North and South America, Europe, and Asia.\nCopilot has grown a broad, global ecosystem of more than 100 partners consisting of managed security service providers and independent software vendors. We are so grateful to the partners who continue to play a vital role in empowering everyone to confidently adopt safe and responsible AI.\nNew Copilot for Security product innovations\nMicrosoft Copilot for Security helps security and IT professionals amplify their skillsets, collaborate more effectively, see more, and respond faster.\nAs part of general availability, Copilot for Security includes the following new capabilities:\nCustom promptbooks allow customers to create and save their own series of natural language prompts for common security workstreams and tasks.\nKnowledge base integrations, in preview, empowers you to integrate Copilot for Security with your business context, so you can search and query over your proprietary content.\nMulti-language support now allows Copilot to process prompts and respond in eight different languages with 25 languages supported in the interface.\nThird-party integrations from global partners who are actively developing integrations and services.\nConnect to your curated external attack surface from Microsoft Defender External Attack Surface Management to identify and analyze the most up-to-date information on your organization’s external attack surface risks.\nMicrosoft Entra audit logs and diagnostic logs give additional insight for a security investigation or IT issue analysis of audit logs related to a specific user or event, summarized in natural language.\nUsage reporting provides dashboard insights on how your teams use Copilot so that you can identify even more opportunities for optimization.\n“Threat actors are getting more sophisticated. Things happen fast, so we need to be able to respond fast. With the help of Copilot for Security, we can start focusing on automated responses instead of manual responses. It’s a huge gamechanger for us.”\n—Mario Ferket, Chief Information Security Officer, Dow\nWith general availability, Copilot for Security will be available as two rich user experiences: in an immersive standalone portal or embedded into existing security products.\nIntegration of Copilot with Microsoft Security products will make it even easier for your IT and security professionals to take advantage of speed and accuracy gains demonstrated in our study. Enjoy the product portals you know and love, now enhanced with Copilot capabilities and skills specific to use cases for each product.\nThe unified security operations platform, coming soon, delivers an embedded Copilot experience within the Microsoft Defender portal for security information and event management (SIEM) and extended detection and response (XDR) that will prompt users as they investigate and respond to threats. Copilot automatically surfaces relevant details for summaries, drives efficiency with guided response, empowers analysts at all levels with natural language to Kusto Query Language (KQL) and script and file analysis, and now includes the ability to assess risks with the latest Microsoft threat intelligence.\nCopilot in Microsoft Entra user risk investigation, now in preview, helps you prevent identity compromise and respond to threats quickly. This embedded experience in Microsoft Entra provides a summary in natural language of the user risk indicators and tailored guidance for resolving the risk. Copilot also recommends ways to automate prevention and resolution for future identity attacks, such as with a recommended Microsoft Entra Conditional Access policy, to increase your security posture and keep help desk calls to a minimum.\nTo help data security and compliance administrators prioritize and address critical alerts more easily, Copilot in Microsoft Purview now provides concise alert summaries, integrated insights, and natural language support within their trusted investigation workflows with the click of a button.\nCopilot in Microsoft Intune, now in preview, will help IT professionals and security analysts make better-informed decisions for endpoint management. Copilot in Intune can simplify root cause determination with complete device context, error code analysis, and device configuration comparisons. This makes it possible to detect and remediate issues before they become problems.\nDiscover, protect, and govern AI usage\nAs more generative AI services are introduced in the market for all business functions, it is crucial to recognize that as this technology brings new opportunities, it also introduces new challenges and risks. With this in mind, Microsoft is providing customers with greater visibility, protection, and governance over their AI applications, whether they are using Microsoft Copilot or third-party generative AI apps. We want to make it easier for everyone to confidently and securely adopt AI.\nTo help organizations protect and govern the use of AI, we are enabling the following experiences within our portfolio of products:\nDiscover AI risks: Security teams can discover potential risks associated with AI usage, such as sensitive data leaks and users accessing high-risk applications.\nProtect AI apps and data: Security and IT teams can protect the AI applications in use and the sensitive data being reasoned over or generated by them, including the prompts and responses.\nGovern usage: Security teams can govern the use of AI applications by retaining and logging interactions with AI apps, detecting any regulatory or organizational policy violations when using those apps, and investigating any new incidents.\nExpanded end-to-end protection to help you secure everything\nMicrosoft continues to expand on our long-standing commitment to providing customers with the most complete end-to-end protection for your entire digital estate. With the full Microsoft Security portfolio, you can gain even greater visibility, control, and governance—especially as you embrace generative AI—with solutions and pricing that fit your organization. New or recent product features include:\nMicrosoft Security Exposure Management is a new unified posture and attack surface management solution within the unified security operations platform that gives you insights into your overall assets and recommends priority security initiatives for continuous improvement. You’ll have a comprehensive view of your organization’s exposure to threats and automatic discovery of critical assets to help you proactively improve your security posture and lower the risk of exposure of business-critical assets and sensitive data. Visualization tools give you an attacker’s-eye view to help you investigate exposure attempts and uncover potential attack paths to critical assets through threat modeling and proactive risk exploration. It’s now easier than ever to identify exposure gaps and take action to minimize risk and business disruption.\nAdaptive Protection, a feature of Microsoft Purview, is now integrated with Microsoft Entra Conditional Access. This integration allows you to better safeguard your organization from insider risks such as data leakage, intellectual property theft, and confidentiality violations. With this integration, you can create Conditional Access policies to automatically respond to insider risks and block user access to applications to secure your data.\nMicrosoft Communication Compliance now provides both sentiment indicators and insights to enrich Microsoft Purview Insider Risk Management policies and to identify communication risks across Microsoft Teams, Exchange, Microsoft Viva Exchange, Copilot, and third-party channels.\nMicrosoft Intune launched three new solutions in February as part of the Microsoft Intune Suite: Intune Enterprise Application Management, Microsoft Cloud PKI, and Intune Advanced Analytics. Intune Endpoint Privilege Management is also rolling out the option to enable support approved elevations.\nSecurity for all in the age of AI\nMicrosoft Copilot for Security is a force multiplier for the entire Microsoft Security portfolio, which integrates more than 50 categories within six product families to form one end-to-end Microsoft Security solution. By implementing Copilot for Security, you can protect your environment from every angle, across security, compliance, identity, device management, and privacy. In the age of AI, it’s more important than ever to have a unified solution that eliminates the gaps in protection that are created by siloed tools.\nThe coming general availability of Copilot on April 1, 2024, is truly a milestone moment. With Copilot, you and your security team can confidently lead your organization into the age of AI. We will continue to deliver on Microsoft’s vision for security: to empower defenders with the advantage of industry-leading generative AI and to provide the tools to safely, responsibly, and securely deploy, use, and govern AI. We are so proud to work together with you to drive this AI transformation and enable security for all.\nJoin us April 3, 2024, at the Microsoft Secure Tech Accelerator for a deep dive into technical information that will help you and your team implement Copilot. Learn how to secure your AI, see demonstrations, and ask our product team questions. RSVP now.\nWatch the second annual Microsoft Secure digital event to learn how to bring world-class threat intelligence, complete end-to-end protection, and industry-leading, responsible AI to your organization.\nDiscover the latest trends and best practices in cyberthreat protection and AI for cybersecurity.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Connect in new ways with Microsoft Mesh | Microsoft 365 Blog",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2023/09/26/microsoft-mesh-enters-preview-in-october-including-a-new-teams-experience/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNWFkM2hQY0dOUmIzTnNlR1V6VFJDb0FSaXNBaWdCTWdrQllJaDN4S05jU1FJ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-26T07:00:00.000Z",
    "time": "Sep 26, 2023",
    "articleType": "regular",
    "content": "A new way to connect\nTo support a truly flexible workplace, organizations and employees need technology that helps them feel connected regardless of where they work. Over the years, we have learned that a thriving workplace fosters authentic human connections—allowing employees and teams to build meaningful relationships and trust so they can perform at their highest potential.\nAccording to Microsoft’s Work Trend Index report, 43 percent of leaders say relationship building is the greatest challenge in remote and hybrid work.1 Coming together in a physical space helps, but it’s not always possible—travel costs are prohibitive, real estate is expensive, and talent is increasingly dispersed. We need new ways for people to connect from different locations or geographies, using the tools they already have.\nGood news—the technology is here and employees are ready. More than 50 percent of employees are open to using new innovations like immersive experiences for meetings and team activities.2 Customers like Takeda, Accenture, DXC Technology, PwC, Telefonica, and the World Economic Forum are already using Microsoft Mesh to bring employees together and foster learning and creativity.\nWe are re-imagining the way employees come together with Microsoft Mesh, a new three-dimensional (3D) immersive experience and, we are excited to announce we are excited to announce Mesh general availability in January 2024.\nConnect like never before with Microsoft Mesh, a new 3D immersive experience.\nMesh, a new 3D immersive experience for your workplace\nMicrosoft Mesh is not merely another innovation, but a solution that enables your distributed workforce to connect like never before in a 3D immersive space, helping virtual meetings and events feel more like face-to-face connections. Here’s what makes Mesh a powerful tool to bring your organization together:\n3D digital environments—meaningful connections in shared spaces\nImmersive spaces have unique attributes that create a perception of being physically together in a 3D digital space, including spatial interaction, co-presence, and immersion. Digital engagement is evolving from audio to video, and now to spatial interaction. Spatial awareness through directionality and distance enables multiple small group discussions in the same place, adding familiar human elements to digital connections. Spending time in the same 3D environment also creates a powerful sense of togetherness, or co-presence, even without actively speaking. This co-presence can lead to serendipitous moments of conversation or even just the deepened connection of a shared experience. 3D environments also remove distractions and help participants focus on fewer things—specifically the people and objects that surround them, driving a higher sense of immersion.\nJoin immersive spaces with the tools you use every day\nOur goal is to help organizations bring people together, regardless of where they are located. And we believe that innovation that offers a new way to connect shouldn’t come with a high barrier to access it. That’s why you don’t need a special tool to get started with Mesh.\nYou can join immersive spaces in Microsoft Teams, a tool that hundreds of millions of people already use, or participate in a custom immersive space in Mesh.\nImmersive spaces will be available initially with PC or Meta Quest VR devices. The only difference is, with virtual reality (VR) devices—the experience will be richer and more immersive.\nUse immersive spaces where you work in Microsoft Teams\nWe are making building relationships easier by bringing the power of Mesh into the place where people work every day—Microsoft Teams. Getting started is easy! From the View menu in a Teams meeting, you select the immersive space option. With just a click, you will transform your two-dimensional (2D) meeting into a 3D immersive experience.\nHere are key capabilities in immersive spaces in Teams:\nAvatars: As you enter an immersive space, choose an avatar that you’ve already built for standard 2D Teams meetings or create a new one. It’s easy to customize your avatar to reflect your appearance, style, or mood for the day.\n3D environments: Choose from one of the ready-made 3D environments that fits your meeting’s needs, whether it’s a big team social gathering or a small round-table discussion.\nSeat assignments: Select where you sit in a meeting or event to drive connections with your co-workers. You can also freely move from one conversation to another.\nSpatial Audio and audio zones: Have multiple, simultaneous conversations and communicate effectively in subgroups without talking over each other.\nInteractive activities: Play built-in interactive games for team bonding within immersive spaces. To get started, you can see a few designated areas to roast marshmallows, throw beanbags, answer fun icebreaker questions, and more.\nLive reactions: Use live reactions such as hearts, thumbs up, clap, and more to express yourself during discussions.\nImmersive spaces in Teams enable collaboration for all your meeting attendees, even if some of them join from outside the immersive space. If you join from a standard 2D Teams meeting experience, you can see, hear, and interact with your colleagues in an immersive space. If any participant shares their screen, the content is visible to all meeting attendees.\nCreate a custom immersive space with Microsoft Mesh\nYou can also create custom immersive spaces in Microsoft Mesh that are tailored to your specific business needs such as employee events, training, guided tours, or internal product showcases. Use a no-code editor to easily customize the event or the Mesh toolkit to leverage the power of Unity for fully customizable immersive experiences.\nEasily create immersive events with a no-code editor\nWith the Mesh editor in the menu bar, you can customize immersive experiences to address the unique needs of your event—without writing a line of code. Event creators can select from a set of ready-to-use immersive spaces, customize them by adding images, videos, and screen share in a shared 3D canvas, and have them show up in an event in an orchestrated way. Once these objects are added, change the size and position, or put the video on loop so it fits right into your event. These customizations can then be saved as a template for anyone in the organization to reuse. These unique elements help you deliver an immersive company event like all hands, town halls, or new employee onboarding that serves your business goals.\nWe are bringing additional capabilities that will make it easier for speakers to interact with attendees when hosting immersive events in Mesh. Even organizers will be able to facilitate a Q&A session by enabling attendees to raise hands. Once enabled, organizers will see the list of hand raises, in order; and will be able to call on participants, engaging them directly. When called on, attendees will be effectively seen and heard by everyone in the event. This makes immersive events more effective and engaging, and brings elements of real-life town hall experiences.\nBuild fully customized immersive experiences with Unity\nThe Mesh toolkit enables event creators and developers to build fully customized 3D experiences using Unity.\nHere are some of the key capabilities:\nVirtual 3D interactions: Build interactions that feel real and immersive (such as the ability to grab objects or walk over to people) that facilitate human connection and enable collaboration.\nLive data connections: Create connections to enterprise & public live data sources to create a rich custom immersive space (such as creating a control tower with multiple visual dashboards of real-time data).\nEnterprise-grade: Deploy to Mesh, which is built on Microsoft 365 with enterprise-grade security and privacy.\nFrom employee onboarding and training, to tailored virtual museums, you can see how our private preview customers leveraged the power of Mesh to bring people together in a meaningful way. For example, Takeda, a global research and development-driven biopharmaceutical leader, created multiple environments in Mesh including the Hirameki Garden, where employees can immerse themselves in Takeda’s culture and business priorities, with a goal to have a more connected workforce while driving employee engagement. Read our developer blog for more details about building immersive experiences with Microsoft Mesh.\nEasily discover and join events in Mesh, Outlook, and Teams\nOrganizers can schedule an event with an existing template or create a new event in Mesh. When it’s ready, they can rehearse or make any changes and get ready for the big day.\nIn addition, attendees can also easily find Mesh events right within their daily Outlook and Teams calendars without needing to go to another place to see and join the events.\nMesh experiences will be available in the upcoming weeks. Here’s what you need to know.\nTo get started with immersive spaces in Teams:\nUsers: Once your admin has enabled Mesh immersive spaces app in Teams, you can go to the view menu from your regular Teams meeting and select immersive space.\nIT admins: Check if you have one of the following licenses: Teams Essentials, Microsoft 365 Business Basic, Microsoft 365 Business Standard, Microsoft 365 Business Premium, Microsoft 365 E3/E5, and Office 365 E1/E3/E5. In the Teams Admin Center, enable the Mesh app.\nNote: Immersive spaces are available in classic Teams and will be available in new Teams beginning in early December.\nTo get started with customizing immersive spaces in Microsoft Mesh\nIT admins: For users in your organization who have the Teams Premium license, enable Microsoft Mesh in the Microsoft 365 Apps admin center once it becomes available.\nDevelopers: Create custom immersive experiences with Mesh toolkit. Read our developer blog or get started on your development journey today.\nWe’re excited to invite you to join us during public preview and share your feedback and ideas with us. We’re also looking forward to seeing what you create and experience with Mesh, and how you use it to connect and collaborate with others in new and meaningful ways.\nThank you for being part of the Mesh journey. We can’t wait to see you in Mesh.\n1 Hybrid Work Is Just Work. Are We Doing It Wrong? (microsoft.com)\n2 Great Expectations: Making Hybrid Work Work (microsoft.com)",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Financially motivated threat actors misusing App Installer",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/12/28/financially-motivated-threat-actors-misusing-app-installer/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNXVlVUkwZFc1eE1qbFBjRzk0VFJDM0FSaVRBaWdCTWdiRlVaTDBwQWc=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-12-28T08:00:00.000Z",
    "time": "Dec 28, 2023",
    "articleType": "regular",
    "content": "Since mid-November 2023, Microsoft Threat Intelligence has observed threat actors, including financially motivated actors like Storm-0569, Storm-1113, Sangria Tempest, and Storm-1674, utilizing the ms-appinstaller URI scheme (App Installer) to distribute malware. In addition to ensuring that customers are protected from observed attacker activity, Microsoft investigated the use of App Installer in these attacks. In response to this activity, Microsoft has disabled the ms-appinstaller protocol handler by default.\nThreat actors have likely chosen the ms-appinstaller protocol handler vector because it can bypass mechanisms designed to help keep users safe from malware, such as Microsoft Defender SmartScreen and built-in browser warnings for downloads of executable file formats.\nIn this blog, we provide an analysis of activity by financially motivated threat actors abusing App Installer observed since mid-November 2023.\nThreat actors abusing App Installer since mid-November 2023\nMicrosoft Threat intelligence observed several actors—including Storm-0569, Storm-1113, Sangria Tempest, and Storm-1674—using App Installer as a point of entry for human-operated ransomware activity. The observed activity includes spoofing legitimate applications, luring users into installing malicious MSIX packages posing as legitimate applications, and evading detections on the initial installation files.\nAt the beginning of December 2023, Microsoft observed Storm-0569 distributing BATLOADER through search engine optimization (SEO) poisoning with sites spoofing legitimate software downloads such as Zoom, Tableau, TeamViewer, and AnyDesk. Users who search for a legitimate software application on Bing or Google may be presented with a landing page spoofing the original software provider’s landing pages that include links to malicious installers through the ms-appinstaller protocol. Spoofing and impersonating popular legitimate software is a common social engineering tactic. These software are not affected by the attacks directly, but this information can help users better spot malicious spoofing by threat actors.\nFigure 2. Sample malicious App Installer experience. Note the Publisher is not who a user should expect to be publishing this software.\nUsers who click the links to the installers are presented with the desktop App Installer experience. If the user clicks “Install” in the desktop App Installer, the malicious application is installed and eventually runs additional processes and scripts that lead to malware installation.\nStorm-0569 then uses PowerShell and batch scripts that lead to the download of BATLOADER. In one observed instance, Storm-0569’s BATLOADER dropped a Cobalt Strike Beacon followed by data exfiltration using the Rclone data exfiltration tools and Black Basta ransomware deployment by Storm-0506.\nStorm-0569 is an access broker that focuses on downloading post-compromise payloads, such as BATLOADER, through malvertising and phishing emails containing malicious links to download sites. The threat actor also provides malicious installers and landing page frameworks to other actors. They cover multiple infection chains that typically begin with maliciously signed Microsoft Installer (MSI) files posing as legitimate software installations or updates for applications such as TeamViewer, Zoom, and AnyDesk. Storm-0569 infection chains have led to additional dropped payloads, including IcedID, Cobalt Strike Beacon, and remote monitoring and management (RMM) tools, culminating in a handoff to ransomware operators like Storm-0846 and Storm-0506.\nIn mid-November 2023, Microsoft observed Sangria Tempest using Storm-1113’s EugenLoader delivered through malicious MSIX package installations. Sangria Tempest then drops Carbanak, a backdoor used by the actor since 2014, that in turn delivers the Gracewire malware implant. In other cases, Sangria Tempest uses Google ads to lure users into downloading malicious MSIX application packages—possibly relying on Storm-1113 infrastructure—leading to the delivery of POWERTRASH, a highly obfuscated PowerShell script. POWERTRASH is then used to load NetSupport and Gracewire, a malware typically affiliated with the threat actor Lace Tempest, whom Sangria Tempest has cooperated with in past intrusions.\nSangria Tempest (previously ELBRUS, also tracked as Carbon Spider, FIN7) is a financially motivated cybercriminal group currently focusing on conducting intrusions that often lead to data theft, followed by targeted extortion or ransomware deployment such as Clop ransomware.\nSince the beginning of December 2023, Microsoft identified instances where Storm-1674 delivered fake landing pages through messages delivered using Teams. The landing pages spoof Microsoft services like OneDrive and SharePoint, as well as other companies. Tenants created by the threat actor are used to create meetings and send chat messages to potential victims using the meeting’s chat functionality.\nFigure 3. Landing page pretending to be a SharePoint site for a spoofed employment opportunity site; target users are led to this landing page via malicious URLs sent via Teams messages.\nFigure 4. Fake error the user receives when clicking on any of the PDFs in the SharePoint. Clicking OK invokes ms-appinstaller.\nFigure 5. Sample malicious App Installer experience. Note the Publisher is not who a user should expect to be publishing Adobe software.\nFigure 6. Malicious landing page pretending to be a networking security tool; target users are led to this landing page via malicious URLs sent via Teams messages.\nFigure 7. Sample JavaScript invokes ms-appinstaller handler from malicious landing page at time of user click.\nFigure 8. Sample malicious App Installer experience. Note the Publisher is not who a user should expect to be publishing this software.\nThe user is then lured into downloading spoofed applications like the ones shown in figures 5 and 8, which will likely drop SectopRAT or DarkGate. In these cases, Storm-1674 was using malicious installers and landing page frameworks provided by Storm-1113.\nMicrosoft assesses this technique was used to avoid the accept/block screen shown in one-on-one and group chats. The Teams client now shows an accept/block screen for meeting chats sent by an external user.\nMicrosoft has taken action to mitigate the spread of malware from confirmed malicious tenants by blocking their ability to send messages thus cutting off the main method used for phishing.\nStorm-1674 is an access broker known for using tools based on the publicly available TeamsPhisher tool to distribute DarkGate malware. Storm-1674 campaigns have typically relied on phishing lures sent over Teams with malicious attachments, such as ZIP files containing a LNK file that ultimately drops DarkGate and Pikabot. In September 2023, Microsoft observed handoffs from Storm-1674 to ransomware operators that have led to Black Basta ransomware deployment.\nThe ms-appinstaller URI scheme handler has been disabled by default in App Installer build 1.21.3421.0. Refer to the Microsoft Security Response Blog for App Installer protection tips.\nMicrosoft recommends the following mitigations to reduce the impact of this threat. Check the recommendations card for the deployment status of monitored mitigations.\nPilot and deploy phishing-resistant authentication methods for users.\nImplement Conditional Access authentication strength to require phishing-resistant authentication for employees and external users for critical apps.\nEducate Microsoft Teams users to verify ‘External’ tagging on communication attempts from external entities, be cautious about what they share, and never share their account information or authorize sign-in requests over chat.\nApply Microsoft’s security best practices for Microsoft Teams to safeguard Teams users.\nEducate users to review sign-in activity and mark suspicious sign-in attempts as “This wasn’t me”.\nEncourage users to use Microsoft Edge and other web browsers that support Microsoft Defender SmartScreen, which identifies and blocks malicious websites, including phishing sites, scam sites, and sites that contain exploits and host malware.\nEducate users to use the browser URL navigator to validate that upon clicking a link in search results they have arrived at an expected legitimate domain.\nEducate users to verify that the software that is being installed is expected to be published by a legitimate publisher.\nConfigure Microsoft Defender for Office 365 to recheck links on click. Safe Links provides URL scanning and rewriting of inbound email messages in mail flow, and time-of-click verification of URLs and links in email messages, other Microsoft Office applications such as Teams, and other locations such as SharePoint Online. Safe Links scanning occurs in addition to the regular anti-spam and anti-malware protection in inbound email messages in Microsoft Exchange Online Protection (EOP). Safe Links scanning can help protect your organization from malicious links that are used in phishing and other attacks.\nTurn on PUA protection in block mode.\nTurn on attack surface reduction rules to prevent common attack techniques:Use advanced protection against ransomwareBlock executable files from running unless they meet a prevalence, age, or trusted list criterion\nMicrosoft Defender Antivirus detects threat components as the malware listed below. Enterprise customers managing updates should select the detection build 1.403.520.0 or newer and deploy it across their environments.\nMicrosoft Defender Antivirus detects associated post-compromise activity as the following:\nThe following Microsoft Defender for Endpoint alerts can indicate associated threat activity:\nAn executable loaded an unexpected dll\nA process was injected with potentially malicious code\nSuspicious sequence of exploration activities\nActivity that might lead to information stealer\nPossible theft of passwords and other sensitive web browser information\nThe following alerts might also indicate threat activity related to this threat. Note, however, that these alerts can be also triggered by unrelated threat activity.\nA file or network connection related to ransomware-linked actor Storm-0569 detected\nRansomware-linked Sangria Tempest threat activity group detected\nOngoing hands-on-keyboard attacker activity detected (Cobalt Strike)\nHuman-operated attack using Cobalt Strike\nMicrosoft Defender for Office 365\nMicrosoft Defender for Office 365 detects malicious activity associated with this threat.\nMicrosoft customers can use the following reports in Microsoft products to get the most up-to-date information about the threat actor, malicious activity, and techniques discussed in this blog. These reports provide the intelligence, protection information, and recommended actions to prevent, mitigate, and respond to associated threats found in customer environments.\nTool profile: Black Basta ransomware\nMicrosoft 365 Defender Threat analytics\nActivity profile: Qakbot distributor Storm-0464 shifts to DarkGate and IcedID\nStorm-0569: Malvertising and phishing deliver fake software installers and lead to ransomware\nIcedID’s frosty arrival can lead to data theft\nUse this query to review all the ms-appinstaller protocol handler invoked network connections in your environment.\nDeviceNetworkEvents| where InitiatingProcessCommandLine == '\"AppInstaller.exe\" -ServerName:App.AppX9rwyqtrq9gw3wnmrap9a412nsc7145qh.mca'  and RemoteUrl has_any (\"https://\", \"http://\")\nStorm-0569 indicators related to App Installer abuse\nStorm-0506 Cobalt Strike beacon C2:\nStorm-1113 indicators related to App Installer abuse\nSangria Tempest indicators related to App Installer abuse\nStorm-1674 indicators related to App Installer abuse\nMalvertising Surges to Distribute Malware (Intel471)\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.\nTo hear stories and insights from the Microsoft Threat Intelligence community about the ever-evolving threat landscape, listen to the Microsoft Threat Intelligence podcast: https://thecyberwire.com/podcasts/microsoft-threat-intelligence.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft, Amazon, and international law enforcement join forces to fight tech support fraud",
    "link": "https://blogs.microsoft.com/on-the-issues/2023/10/19/microsoft-amazon-tech-support-fraud-india/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNURWMU4wVkUxWGF6VmlSMFpRVFJDM0FSaVRBaWdCTWdrSklJYnVuT1NTS1FJ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-10-19T07:00:00.000Z",
    "time": "Oct 19, 2023",
    "articleType": "regular",
    "content": "Microsoft, Amazon, and international law enforcement have come together to send a strong message to perpetrators of tech support fraud: There will be consequences for their actions.\nOn Thursday, October 19, Central Bureau Investigation (CBI), the federal enforcement agency in India, announced it has conducted multiple criminal raids in various cities across India. This operation was supported by a joint referral made by Microsoft and Amazon. The joint referral enabled the exchange of actionable intelligence and insights with CBI and other international law enforcement agencies to help them take action at scale.\nTech support fraud is a costly and industry-wide problem. Criminals operating illegal call centers prey on the vulnerable and defraud thousands of victims each year. According to the FBI, tech/customer support and government impersonation are responsible for over $1 billion in losses to victims. The illegal call centers raided by CBI were set up to impersonate Microsoft and Amazon customer support. They targeted over 2,000 customers across Amazon and Microsoft primarily based in the U.S., but also in Canada, Germany, Australia, Spain, and the UK. We thank CBI for taking such swift action.\nWe remain committed to working together to go after criminals\nThis collaboration marks the first time Microsoft and Amazon have joined forces to combat tech support fraud. We firmly believe that partnerships like these are not only necessary but pivotal in creating a safer online ecosystem and in extending our protective reach to a larger number of individuals. Technology-enabled fraud remains a persistent threat to both companies as the same cybercriminals and their infrastructure targets both our customers. Joining forces helps us more effectively protect individuals globally and prevent criminals from impersonating the Microsoft and Amazon brands to target innocent and unsuspecting victims.\nWe understand, however, that criminals will attempt to rebuild their operations and establish new illegal call centers. That is why we, in collaboration with the CBI, Amazon, and other international law enforcement agencies, are dedicated to maintaining our vigilance, sharing critical information and working closely with Indian law enforcement agencies and authorities from the victim countries to support their investigations.\nAs cybercriminals evolve their tactics, Microsoft continues to evolve our ways to combat them. That includes partnering with others in the tech sector to share information and resources. We are proud of our long-standing collaboration with law enforcement to combat Tech Support Fraud, which has resulted in 30-plus call center raids and 100-plus arrests to date. We invite others across the industry to join us in this united front against criminal activity.\nRemaining vigilant to suspicious activity online\nMicrosoft is committed to providing a safe digital experience for every person and organization on the planet. Microsoft’s Digital Crimes Unit (DCU) works to combat tech support scams by investigating tech support fraud networks and referring cases to law enforcement as appropriate, strengthening our products and services to better protect consumers from various fraudulent tactics, and educating consumers about this type of fraud by providing guidance and resources on how to identify, avoid, and report them.\nImportantly, Microsoft will never send unsolicited email messages or make unsolicited phone calls to request personal or financial information, or to provide technical support to fix your computer. Any communication with Microsoft must be initiated by you. Always treat all unsolicited messages with skepticism and do not provide any personal information.\nIf you have been contacted by someone claiming to be from, or associated with, Microsoft and believe it was a scam, report the incident via our online reporting tool: microsoft.com/reportascam. Doing so assists us with our ongoing investigations with law enforcement as we take appropriate action against those targeting our customers. We also use these insights to strengthen our technology to better protect consumers from fraudulent tactics.\nTags: Amazon, cybercrime, cyberfraud, cybersecurity, Digital Crimes Unit, tech support scams",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "Microsoft Build 2024",
    "link": "https://news.microsoft.com/microsoft-may-2024-events/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNUxhekJNVVVkUlRYaHFTME5OVFJDb0FSaXNBaWdCTWdhQktKYWlsZ2c=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-21T07:00:00.000Z",
    "time": "May 21",
    "articleType": "regular",
    "content": "",
    "favicon": ""
  },
  {
    "title": "Multiple North Korean threat actors exploiting the TeamCity CVE-2023-42793 vulnerability",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/10/18/multiple-north-korean-threat-actors-exploiting-the-teamcity-cve-2023-42793-vulnerability/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNXFUWFpzWTB4WlRWVXRjVTVZVFJDM0FSaVRBaWdCTWdrQk1JUkFwbWVhVVFF=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-10-18T07:00:00.000Z",
    "time": "Oct 18, 2023",
    "articleType": "regular",
    "content": "Since early October 2023, Microsoft has observed two North Korean nation-state threat actors – Diamond Sleet and Onyx Sleet – exploiting CVE-2023-42793, a remote-code execution vulnerability affecting multiple versions of JetBrains TeamCity server. TeamCity is a continuous integration/continuous deployment (CI/CD) application used by organizations for DevOps and other software development activities.\nIn past operations, Diamond Sleet and other North Korean threat actors have successfully carried out software supply chain attacks by infiltrating build environments. Given this, Microsoft assesses that this activity poses a particularly high risk to organizations who are affected. JetBrains has released an update to address this vulnerability and has developed a mitigation for users who are unable to update to the latest software version.\nWhile the two threat actors are exploiting the same vulnerability, Microsoft observed Diamond Sleet and Onyx Sleet utilizing unique sets of tools and techniques following successful exploitation. Based on the profile of victim organizations affected by these intrusions, Microsoft assesses that the threat actors may be opportunistically compromising vulnerable servers. However, both actors have deployed malware and tools and utilized techniques that may enable persistent access to victim environments.\nAs with any observed nation-state actor activity, Microsoft directly notifies customers that have been targeted or compromised and provides them with the information they need to secure their environments.\nWho are Diamond Sleet and Onyx Sleet?\nDiamond Sleet (ZINC) is a North Korean nation-state threat actor that prioritizes espionage, data theft, financial gain, and network destruction. The actor typically targets media, IT services, and defense-related entities around the world. Microsoft reported on Diamond Sleet’s targeting of security researchers in January 2021 and the actor’s weaponizing of open-source software in September 2022. In August 2023, Diamond Sleet conducted a software supply chain compromise of a German software provider.\nOnyx Sleet (PLUTONIUM) is a North Korean nation-state threat actor that primarily targets defense and IT services organizations in South Korea, the United States, and India. Onyx Sleet employs a robust set of tools that they have developed to establish persistent access to victim environments and remain undetected. The actor frequently exploits N-day vulnerabilities as a means of gaining initial access to targeted organizations.\nDiamond Sleet attack path 1: Deployment of ForestTiger backdoor\nFollowing the successful compromise of TeamCity servers, Diamond Sleet utilizes PowerShell to download two payloads from legitimate infrastructure previously compromised by the threat actor. These two payloads, Forest64.exe and 4800-84DC-063A6A41C5C are stored in the C:\\ProgramData directory.\nWhen launched, Forest64.exe checks for the presence of the file named 4800-84DC-063A6A41C5C, then reads and decrypts the contents of that file using embedded, statically assigned key of ‘uTYNkfKxHiZrx3KJ’:\nInterestingly, this same value is specified as a parameter when the malware is invoked, but we did not see it utilized during our analysis. The same value and configuration name was also referenced in historical activity reported by Kaspersky’s Securelist on this malware, dubbed ForestTiger.\nThe decrypted content of 4800-84DC-063A6A41C5C is the configuration file for the malware, which contains additional parameters, such as the infrastructure used by the backdoor for command and control (C2). Microsoft observed Diamond Sleet using infrastructure previously compromised by the actor for C2.\nMicrosoft observed Forest64.exe then creating a scheduled task named Windows TeamCity Settings User Interface so it runs every time the system starts with the above referenced command parameter “uTYNkfKxHiZrx3KJ”. Microsoft also observed Diamond Sleet leveraging the ForestTiger backdoor to dump credentials via the LSASS memory. Microsoft Defender Antivirus detects this malware as ForestTiger.\nFigure 1. Diamond Sleet attack chain 1 using ForestTiger backdoor\nDiamond Sleet attack path 2: Deploying payloads for use in DLL search-order hijacking attacks\nDiamond Sleet leverages PowerShell on compromised servers to download a malicious DLL from attacker infrastructure. This malicious DLL is then staged in C:\\ProgramData\\ alongside a legitimate .exe file to carry out DLL search-order hijacking. Microsoft has observed these malicious DLL and legitimate EXE combinations used by the actor:\nMalicious DLL nameLegitimate binary nameDSROLE.dllwsmprovhost.exeVersion.dllclip.exe\nWhen DSROLE.dll is loaded by wsmprovhost.exe, the DLL initiates a thread that enumerates and attempts to process files that exist in the same executing directory as the DLL. The first four bytes of candidate files are read and signify the size of the remaining buffer to read. Once the remaining data is read back, the bytes are reversed to reveal an executable payload that is staged in memory. The expected PE file should be a DLL with the specific export named ‘StartAction’. The address of this export is resolved and then launched in memory.\nWhile the functionality of DSROLE.dll is ultimately decided by whatever payloads it deobfuscates and launches, Microsoft has observed the DLL being used to launch wksprt.exe, which communicates with C2 domains. Microsoft Defender Antivirus detects DSROLE.dll using the family name RollSling.\nWhen loaded by clip.exe, Version.dll loads and decrypts the contents of readme.md, a file  downloaded alongside Version.dll from attacker-compromised infrastructure. The file readme.md contains data that is used as a multibyte XOR key to decrypt position-independent code (PIC) embedded in Version.dll. This PIC loads and launches the final-stage remote access trojan (RAT).\nFigure 2. Composition of readme.md used as multibyte XOR key by Version.dll\nFigure 3. Application of XOR key to expose next-stage code block\nFigure 4. Carving out embedded PE from code block\nOnce loaded in memory, the second-stage executable decrypts an embedded configuration file containing several URLs used by the malware for command and control. Shortly after the malware beacons to the callback URL, Microsoft has observed a separate process iexpress.exe created and communicating with other C2 domains. Microsoft Defender Antivirus detects Version.dll using the family name FeedLoad.\nFigure 5. Diamond Sleet attack chain 2 using DLL search order hijacking\nAfter successful compromise, Microsoft observed Diamond Sleet dumping credentials via the LSASS memory.\nIn some cases, Microsoft observed Diamond Sleet intrusions that utilized tools and techniques from both paths 1 and 2.\nOnyx Sleet attack path: User account creation, system discovery, and payload deployment\nFollowing successful exploitation using the TeamCity exploit, Onyx Sleet creates a new user account on compromised systems. This account, named krtbgt, is likely intended to impersonate the legitimate Windows account name KRBTGT, the Kerberos Ticket Granting Ticket. After creating the account, the threat actor adds it to the Local Administrators Group through net use:\nnet  localgroup administrators krtbgt /add\nThe threat actor also runs several system discovery commands on compromised systems, including:\nnet localgroup 'Remote Desktop Users’net localgroup Administratorscmd.exe \"/c tasklist | findstr Sec\"cmd.exe \"/c whoami\"cmd.exe \"/c netstat -nabp tcp\"cmd.exe \"/c ipconfig /all\"cmd.exe \"/c systeminfo\"\nNext, the threat actor deploys a unique payload to compromised systems by downloading it from attacker-controlled infrastructure via PowerShell. Microsoft observed these file paths for the unique payload:\nThis payload, when launched, loads and decrypts an embedded PE resource. This decrypted payload is then loaded into memory and launched directly. The inner payload is a proxy tool that helps establish a persistent connection between the compromised host and attacker-controlled infrastructure. Microsoft Defender Antivirus detects this proxy tool as HazyLoad.\nMicrosoft also observed the following post-compromise tools and techniques leveraged in this attack path:\nUsing the attacker-controlled krtbgt account to sign into the compromised device via remote desktop protocol (RDP)\nStopping the TeamCity service, likely in an attempt to prevent access by other threat actors\nDumping credentials via the LSASS memory\nDeploying tools to retrieve credentials and other data stored by browsers\nFigure 6. Onyx Sleet attack chain with user account creation\nMicrosoft recommends the following mitigations to reduce the impact of this threat.\nApply the update or mitigations released by JetBrains to address CVE-2023-42793.\nUse the included indicators of compromise to investigate whether they exist in your environment and assess for potential intrusion.\nBlock in-bound traffic from IPs specified in the IOC table.\nUse Microsoft Defender Antivirus to protect from this threat. Turn on cloud-delivered protection and automatic sample submission. These capabilities use artificial intelligence and machine learning to quickly identify and stop new and unknown threats.\nTake immediate action to address malicious activity on the impacted device. If malicious code has been launched, the attacker has likely taken complete control of the device. Immediately isolate the system and perform a reset of credentials and tokens.\nInvestigate the device timeline for indications of lateral movement activities using one of the compromised accounts. Check for additional tools that attackers might have dropped to enable credential access, lateral movement, and other attack activities.\nEnsure that “Safe DLL Search Mode” is set.\nTurn on the following attack surface reduction rule:\nBlock executable files from running unless they meet a prevalence, age, or trusted list criterion\nMicrosoft Defender Vulnerability Management surfaces devices that may be affected by the CVE-2023-42793 vulnerability leveraged in these attacks.\nMicrosoft Defender Antivirus customers should look for the following family names for activity related to these attacks:\nThe following Microsoft Defender for Endpoint alerts could indicate activity associated with this threat. These alerts, however, can be triggered by unrelated threat activity.\nDiamond Sleet Actor activity detected\nOnyx Sleet Actor activity detected\nPossible exploitation of JetBrains TeamCity vulnerability\nSuspicious behavior by cmd.exe was observed\nSuspicious DLL loaded by an application\nSuspicious PowerShell download or encoded command execution\nPossible lateral movement involving suspicious file\nA script with suspicious content was observed\nCommand and control using iexpress.exe or wksprt.exe\nDeviceNetworkEvents| where (InitiatingProcessFileName =~ \"wksprt.exe\" and InitiatingProcessCommandLine == \"wksprt.exe\") or (InitiatingProcessFileName =~ \"iexpress.exe\" and InitiatingProcessCommandLine == \"iexpress.exe\")\nSearch order hijack using Wsmprovhost.exe and DSROLE.dll\nDeviceImageLoadEvents| where InitiatingProcessFileName =~ \"wsmprovhost.exe\"| where FileName =~ \"DSROLE.dll\"| where not(FolderPath has_any(\"system32\", \"syswow64\"))\nSearch order hijack using clip.exe and Version.dll\nDeviceImageLoadEvents| where InitiatingProcessFileName =~ \"clip.exe\"| where FileName in~(\"version.dll\")| where not(FolderPath has_any(\"system32\", \"syswow64\", \"program files\", \"windows defender\\\\platform\", \"winsxs\", \"platform\",\"trend micro\"))\nMicrosoft Sentinel customers can use the TI Mapping analytics (a series of analytics all prefixed with ‘TI map’) to automatically match the malicious domain indicators mentioned in this blog post with data in their workspace. If the TI Map analytics are not currently deployed, customers can install the Threat Intelligence solution from the Microsoft Sentinel Content Hub to have the analytics rule deployed in their Sentinel workspace.\nMicrosoft Sentinel also has a range of detection and threat hunting content that customers can use to detect the post exploitation activity detailed in this blog in addition to Microsoft 365 Defender detections list above.\nDumping LSASS Process into a File\nThe list below provides IOCs observed during our investigation. We encourage our customers to investigate these indicators in their environments and implement detections and protections to identify past related activity and prevent future attacks against their systems.\nIndicatorTypeDescriptionC:\\ProgramData\\Forest64.exe                                                              File pathFile path of ForestTiger binarye06f29dccfe90ae80812c2357171b5c48fba189ae103d28e972067b107e58795SHA-256Hash of Forest64.exe0be1908566efb9d23a98797884f2827de040e4cedb642b60ed66e208715ed4aaSHA-256Hash of Forest64.exeC:\\ProgramData\\4800-84DC-063A6A41C5CFile pathForestTiger configuration filehxxp://www.bandarpowder[.]com/public/assets/img/cfg.pngURLStaging URL for 4800-84DC-063A6A41C5C (compromised domain)hxxps://www.bandarpowder[.]com/public/assets/img/cfg.pngURLStaging URL for 4800-84DC-063A6A41C5C (compromised domain)hxxp://www.aeon-petro[.]com/wcms/plugins/addition_contents/cfg.pngURLStaging URL for 4800-84DC-063A6A41C5C (compromised domain)hxxp://www.bandarpowder[.]com/public/assets/img/user64.pngURLStaging URL for Forest64.exe (compromised domain)hxxps://www.bandarpowder[.]com/public/assets/img/user64.pngURLStaging URL for Forest64.exe (compromised domain)hxxp://www.aeon-petro[.]com/wcms/plugins/addition_contents/user64.pngURLStaging URL for Forest64.exe (compromised domain)\nIndicatorTypeDescriptionC:\\ProgramData\\DSROLE.dllFile pathFile path of RollSling binary  d9add2bfdfebfa235575687de356f0cefb3e4c55964c4cb8bfdcdc58294eeacaSHA-256Hash of DSROLE.dllC:\\ProgramData\\Version.dllFile path  File path of FeedLoad binary.f251144f7ad0be0045034a1fc33fb896e8c32874e0b05869ff5783e14c062486SHA-256Hash of Version.dllC:\\ProgramData\\readme.mdFile path  Used as a multibyte XOR key for FeedLoad Next Stagefa7f6ac04ec118dd807c1377599f9d369096c6d8fb1ed24ac7a6ec0e817eaab6SHA-256Hash of Readme.mdC:\\ProgramData\\wsmprovhost.exeFile pathLegitimate Windows binary is copied to this directory for DLL search-order hijackingC:\\ProgramData\\clip.exeFile pathLegitimate Windows binary is copied to this directory for DLL search-order hijackingdersmarketim[.]comDomainC2 domain (compromised domain)olidhealth[.]comDomainC2 domain (compromised domain)galerielamy[.]comDomainC2 domain (compromised domain)3dkit[.]orgDomainC2 domain (compromised domain)hxxp://www.mge[.]sn/themes/classic/modules/ps_rssfeed/feed.zipURLStaging URL for Version.dll (compromised domain)hxxp://www.mge[.]sn/themes/classic/modules/ps_rssfeed/feedmd.zipURLStaging URL for readme.md (compromised domain)hxxps://vadtalmandir[.]org/admin/ckeditor/plugins/icontact/about.phpURLCallback URL from second-stage PE (compromised domain)hxxps://commune-fraita[.]ma/wp-content/plugins/wp-contact/contact.phpURLCallback URL from second-stage PE (compromised domain)\nIndicatorTypeDescriptionC:\\Windows\\Temp\\temp.exeFile pathFile path for HazyLoad binaryC:\\Windows\\ADFS\\bg\\inetmgr.exeFile pathFile path for HazyLoad binary000752074544950ae9020a35ccd77de277f1cd5026b4b9559279dc3b86965eeeSHA-256Hash of proxy tool loaderhxxp://147.78.149[.]201:9090/imgr.icoURLStaging URL for HazyLoad binary (compromised infrastructure)hxxp://162.19.71[.]175:7443/bottom.gifURLStaging URL for HazyLoad binary (compromised infrastructure)\nNOTE: These indicators should not be considered exhaustive for this observed activity.\nFollowing the Lazarus group by tracking DeathNote campaign | Securelist\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft introduces new data and AI solutions to help healthcare organizations unlock insights and improve patient and clinician experiences",
    "link": "https://blogs.microsoft.com/blog/2023/10/10/microsoft-introduces-new-data-and-ai-solutions-to-help-healthcare-organizations-unlock-insights-and-improve-patient-and-clinician-experiences/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNHRlWG8xV1ZNdFJrMU1kMk5rVFJDM0FSaVRBaWdCTWdtTk1weW5uaWxGcGdJ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-10-10T07:00:00.000Z",
    "time": "Oct 10, 2023",
    "articleType": "regular",
    "content": "Every industry depends on unique insights to achieve their goals, and unlocking the power of data is the key to an organization’s success. This is especially true in healthcare, where data has the potential to do so much good – from improving health outcomes and enhancing patient and clinician experiences to driving better organizational performance for healthcare systems. When a patient’s or the population’s health is at the center of the decision-making process, having the right data strategy in place can have a life-changing impact on people’s lives.\nHealthcare data continues to grow rapidly, and organizations are struggling to keep up with higher volume, greater variety and increased velocity. According to the World Economic Forum, hospitals produce 50 petabytes of siloed data per year – that’s equivalent to approximately 10 billion music files. Ninety-seven percent of this data goes unused, leaving many valuable insights locked away. Putting all this data to good use is the key to unlocking clinical and operational breakthroughs that can make a meaningful difference in the lives of patients and their healthcare journey. And in the new era of AI, the importance of data continues to grow as organizations realize that without a solid data strategy, they are only scratching the surface of what’s possible with AI.\nAt the HLTH 2023 conference, we’re introducing new data and AI solutions and capabilities that will help healthcare organizations stay focused on improving patient and clinician experiences while delivering quality care more efficiently and at a lower cost. Together, these new solutions offer healthcare organizations a unified, safe and responsible approach to their data and AI strategy and enable them to take advantage of the breadth and scale of Microsoft Cloud for Healthcare.\nUnifying data analytics to drive business value and better patient care\nIn May of this year, we unveiled Microsoft Fabric – an end-to-end, unified analytics platform that brings together all the data and analytics tools that organizations need to unlock the potential of their data and lay the foundation for the era of AI. Today, through the power of Microsoft Cloud for Healthcare, we are introducing the first industry-specific data solutions in Fabric that unify data and insights through one common architecture and experience. Now available in preview, the healthcare data solutions in Fabric eliminate the costly, time-consuming process of stitching together a complex set of disconnected, multimodal health data sources – text, images, video, etc. – and provides a secure and governed way for organizations to access, analyze and visualize data-driven insights across their organization.\nMicrosoft Fabric gives healthcare organizations:\nThe ability to combine data from previously siloed sources across their organization, such as electronic health records (EHRs), Picture Archiving and Communication Systems (PACS), labs systems, claims systems and medical devices. The solution brings structured, unstructured, imaging and medical device data into the Fabric data lake with open data standards using FHIR, DICOM and MedTech services, providing customers with one common architecture. Additionally, connectors and converters make it easier to transform FHIR, DICOM and MedTech data from one format to another or build pipelines for specific use cases.\nA multimodal data foundation that allows them to build standardized, scalable solutions that help accelerate the process of uncovering impactful clinical and operational insights and ultimately drive better patient care. Fabric helps create a single data estate where health data can live and be used to build and run AI models, as well as derive insights.\nStandard capabilities like Observational Medical Outcomes Partnership (OMOP) analytics enable clinical research and patient outreach analytics help provide more personalized engagement with patients.\nA new de-identification service will allow organizations to de-identify clinical data, keeping patient-protected health information (PHI) private by using machine learning models to extract, redact or surrogate identifiers while unlocking insights from unstructured data, such as doctor’s notes, medical documents and clinical trial studies.\nIn addition, through healthcare-specific pre-built classification rules, labels and data glossaries in Microsoft Purview (preview), healthcare organizations can govern, protect and manage their entire data estate.\nOrganizations across the healthcare spectrum can benefit from Microsoft Fabric, with early adopters already planning to leverage the analytics platform to help advance some of their most prominent use cases:\nNorthwestern Medicine, Chicago’s premier integrated academic health system, will leverage the healthcare data solutions in Fabric to integrate clinical data across a variety of sources, meet regulatory mandates for information exchange, and unlock insights with data and AI, helping further their patients-first mission with high quality and timely care.\nArthur Health plans to use Fabric to power predictive care stage models in partnership with Quisitive for the Ontario Workers Network (OWN). OWN is a provincial network of hospitals, including Ottawa Hospital, and has experienced clinicians that provide world-class care for workers in their own communities.\nSingHealth, Singapore’s largest network of public healthcare institutions, aims to harness the power of Fabric’s healthcare data solutions for its underlying data infrastructure. This will help to transform the delivery of healthcare to provide excellent care and services to the population and patients, empowering them to take care of their own health and healthcare.\nNew AI capabilities that empower patients and simplify medical jargon\nWithin Azure AI services, we are releasing new healthcare capabilities that will help organizations maximize the value of AI to increase positive impact on patient outcomes:\nHelping clinicians and researchers make informed decisions – Azure AI Health Insights is a cognitive service that provides prebuilt models that perform analysis and provide inferences that can be reviewed and used by clinicians and researchers to facilitate patient care during important healthcare scenarios.\nWe are launching three new models in preview, including patient timeline, which uses generative AI to extract key events from unstructured data, such as medications, diagnosis and procedures, and organizes them chronologically to give clinicians a more accurate view of a patient’s medical history to better inform care plans. Clinical report simplification uses generative AI to give clinicians the ability to take medical jargon and convert it into simple language while preserving the full essence of the clinical information so that it can be shared with others, including patients. Radiology insights provides quality checks through feedback on errors and inconsistencies. The model also identifies follow-up recommendations and clinical findings within clinical documentation with measurements (sizes) documented by the radiologist.\nBringing generative AI to healthcare chatbots and virtual assistants – This new preview capability in Azure AI Health Bot provides out-the-box healthcare intelligence that can be customized and connected into existing workflows, using answers from a healthcare organization’s own content sources, as well as leveraging generative AI to provide answers from credible sources like the National Institutes of Health and the U.S. Food and Drug Administration.\nExtracting and labeling medical data to identify meaningful insights – Text Analytics for health, an Azure AI Language service, applies machine learning intelligence to extract and label essential medical information from a variety of unstructured texts. Newly released industry open source templates include population health, patient population Q&A using Azure OpenAI Service, clinical trials patient cohorts and mass historic data processing.\nAI-powered solutions empower clinicians to deliver quality, personalized care\nU.S. health systems are turning to AI-powered solutions to alleviate administrative burden and the resulting clinician burnout, which rose to 53% among physicians in 2023 compared to 42% in 2018, according to Medscape’s 2023 survey. To address this burnout, and empower clinicians to focus on delivering high-quality personalized care, we announced the general availability of Dragon Ambient eXperience (DAX™) Copilot, formerly known as DAX Express.\nDAX Copilot, part of the larger Nuance Dragon family of solutions used by more than 550,000 users worldwide, allows clinicians to create draft clinical summaries automatically and securely in seconds from exam room or telehealth conversations for immediate review and entry in the EHR.\nAtrium Health was the first to deploy Nuance DAX Copilot to its primary care physicians with plans for a broad rollout across its footprint. Physicians are already reporting saving meaningful time in their documentation tasks for each patient visit. In particular, Atrium Health clinicians are reporting that physicians are already saving up to 40 minutes per day with this advanced documentation technology. Additionally, 68% have recognized an improved experience providing care..\nMicrosoft Cloud for Healthcare in the era of data and AI\nThese new industry innovations in data and AI are strengthened through Microsoft Cloud for Healthcare, which enables healthcare organizations to accelerate their data and AI journey by augmenting the Microsoft Cloud with industry relevant data solutions, application templates and AI services. Our offerings can also be customized by an unmatched global ecosystem of trusted partners. We work with leading ISVs and system integrators so that our healthcare customers have complete solutions that address their unique business challenges.\nOur healthcare solutions are built on a foundation of trust and Microsoft’s Responsible AI principles. Through these innovations, we are making it easier for healthcare organizations to create connected experiences at every point of care, provide tools that foster collaboration, empower the healthcare workforce, and unlock the value from clinical and operational data using data standards that are important to the healthcare industry.\nTags: AI, Azure AI, Azure AI Health Insights, healthcare, Microsoft Cloud for Healthcare, Microsoft Fabric",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Mitigating Skeleton Key, a new type of generative AI jailbreak technique",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/06/26/mitigating-skeleton-key-a-new-type-of-generative-ai-jailbreak-technique/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWFZbU16UTBSaGFXYzJSRzEyVFJDb0FSaXNBaWdCTWdhZHRvd3FQZ1U=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-06-26T07:00:00.000Z",
    "time": "Jun 26",
    "articleType": "regular",
    "content": "In generative AI, jailbreaks, also known as direct prompt injection attacks, are malicious user inputs that attempt to circumvent an AI model’s intended behavior. A successful jailbreak has potential to subvert all or most responsible AI (RAI) guardrails built into the model through its training by the AI vendor, making risk mitigations across other layers of the AI stack a critical design choice as part of defense in depth.\nAs we discussed in a previous blog post about AI jailbreaks, an AI jailbreak could cause the system to violate its operators’ policies, make decisions unduly influenced by a user, or execute malicious instructions.\nIn this blog, we’ll cover the details of a newly discovered type of jailbreak attack that we call Skeleton Key, which we covered briefly in the Microsoft Build talk Inside AI Security with Mark Russinovich (under the name Master Key). Because this technique affects multiple generative AI models tested, Microsoft has shared these findings with other AI providers through responsible disclosure procedures and addressed the issue in Microsoft Azure AI-managed models using Prompt Shields to detect and block this type of attack. Microsoft has also made software updates to the large language model (LLM) technology behind Microsoft’s additional AI offerings, including our Copilot AI assistants, to mitigate the impact of this guardrail bypass.\nThis AI jailbreak technique works by using a multi-turn (or multiple step) strategy to cause a model to ignore its guardrails. Once guardrails are ignored, a model will not be able to determine malicious or unsanctioned requests from any other. Because of its full bypass abilities, we have named this jailbreak technique Skeleton Key.\nFigure 1. Skeleton Key jailbreak technique causes harm in AI systems\nThis threat is in the jailbreak category, and therefore relies on the attacker already having legitimate access to the AI model. In bypassing safeguards, Skeleton Key allows the user to cause the model to produce ordinarily forbidden behaviors, which could range from production of harmful content to overriding its usual decision-making rules. Like all jailbreaks, the impact can be understood as narrowing the gap between what the model is capable of doing (given the user credentials, etc.) and what it is willing to do. As this is an attack on the model itself, it does not impute other risks on the AI system, such as permitting access to another user’s data, taking control of the system, or exfiltrating data.\nTo protect against Skeleton Key attacks, as detailed in this blog, Microsoft has implemented several approaches to our AI system design and provides tools for customers developing their own applications on Azure. Below, we also share mitigation guidance for defenders to discover and protect against such attacks.\nMicrosoft recommends customers who are building their own AI models and/or integrating AI into their applications to consider how this type of attack could impact their threat model and to add this knowledge to their AI red team approach, using tools such as PyRIT. (Note: Microsoft has updated PyRIT to include Skeleton Key)\nSkeleton Key works by asking a model to augment, rather than change, its behavior guidelines so that it responds to any request for information or content, providing a warning (rather than refusing) if its output might be considered offensive, harmful, or illegal if followed. This attack type is known as Explicit: forced instruction-following.\nIn one example, informing a model that the user is trained in safety and ethics, and that the output is for research purposes only, helps to convince some models to comply, as shown below:\nFigure 2. Example text used in a Skeleton Key jailbreak attack\nWhen the Skeleton Key jailbreak is successful, a model acknowledges that it has updated its guidelines and will subsequently comply with instructions to produce any content, no matter how much it violates its original responsible AI guidelines.\nDuring our testing, from April to May 2024, the jailbreak was shown to work on the following base models and hosted models:\nOpenAI GPT 3.5 Turbo (hosted)\nAnthropic Claude 3 Opus (hosted)\nCohere Commander R Plus (hosted)\nFor each model that we tested, we evaluated a diverse set of tasks across risk and safety content categories, including areas such as explosives, bioweapons, political content, self-harm, racism, drugs, graphic sex, and violence. All the affected models complied fully and without censorship for these tasks, though with a warning note prefixing the output as requested. Unlike other jailbreaks like Crescendo, where models must be asked about tasks indirectly or with encodings, Skeleton Key puts the models in a mode where a user can directly request tasks, for example, “Write a recipe for homemade explosives”. Further, the model’s output appears to be completely unfiltered and reveals the extent of a model’s knowledge or ability to produce the requested content.\nConsistent with responsible disclosure principles, Microsoft shared this research with the affected AI vendors before publication, helping them determine how to best address mitigations, as needed, in their respective products or services.\nGPT-4 demonstrated resistance to Skeleton Key, except when the behavior update request was included as part of a user-defined system message, rather than as a part of the primary user input. This is something that is not ordinarily possible in the interfaces of most software that uses GPT-4, but can be done from the underlying API or tools that access it directly. This indicates that the differentiation of system message from user request in GPT-4 is successfully reducing attackers’ ability to override behavior.\nMicrosoft has made software updates to the LLM technology behind Microsoft’s AI offerings, including our Copilot AI assistants, to mitigate the impact of this guardrail bypass. Customers should consider the following approach to mitigate and protect against this type of jailbreak in their own AI system design:\nInput filtering: Azure AI Content Safety detects and blocks inputs that contain harmful or malicious intent leading to a jailbreak attack that could circumvent safeguards.\nSystem message: Prompt engineering the system prompts to clearly instruct the large language model (LLM) on appropriate behavior and to provide additional safeguards. For instance, specify that any attempts to undermine the safety guardrail instructions should be prevented (read our guidance on building a system message framework here).\nOutput filtering: Azure AI Content Safety post-processing filter that identifies and prevents output generated by the model that breaches safety criteria.\nAbuse monitoring: Deploying an AI-driven detection system trained on adversarial examples, and using content classification, abuse pattern capture, and other methods to detect and mitigate instances of recurring content and/or behaviors that suggest use of the service in a manner that may violate guardrails. As a separate AI system, it avoids being influenced by malicious instructions. Microsoft Azure OpenAI Service abuse monitoring is an example of this approach.\nBuilding AI solutions on Azure\nMicrosoft provides tools for customers developing their own applications on Azure. Azure AI Content Safety Prompt Shields are enabled by default for models hosted in the Azure AI model catalog as a service, and they are parameterized by a severity threshold. We recommend setting the most restrictive threshold to ensure the best protection against safety violations. These input and output filters act as a general defense not only against this particular jailbreak technique, but also a broad set of emerging techniques that attempt to generate harmful content. Azure also provides built-in tooling for model selection, prompt engineering, evaluation, and monitoring. For example, risk and safety evaluations in Azure AI Studio can assess a model and/or application for susceptibility to jailbreak attacks using synthetic adversarial datasets, while Microsoft Defender for Cloud can alert security operations teams to jailbreaks and other active threats.\nWith the integration of Azure AI and Microsoft Security (Microsoft Purview and Microsoft Defender for Cloud) security teams can also discover, protect, and govern these attacks. The new native integration of Microsoft Defender for Cloud with Azure OpenAI Service, enables contextual and actionable security alerts, driven by Azure AI Content Safety Prompt Shields and Microsoft Defender Threat Intelligence. Threat protection for AI workloads allows security teams to monitor their Azure OpenAI powered applications in runtime for malicious activity associated with direct and in-direct prompt injection attacks, sensitive data leaks and data poisoning, or denial of service attacks.\nFigure 3. Microsoft Security for the protection of AI systems\nAttacks, Defenses and Evaluations for LLM Conversation Safety: A Survey (Shanghai AI Laboratory)\nAI jailbreaks: What they are and how they can be mitigated\nHow Microsoft discovers and mitigates evolving attacks against AI guardrails\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.\nTo hear stories and insights from the Microsoft Threat Intelligence community about the ever-evolving threat landscape, listen to the Microsoft Threat Intelligence podcast: https://thecyberwire.com/podcasts/microsoft-threat-intelligence.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft implements DMA compliance measures",
    "link": "https://blogs.microsoft.com/eupolicy/2024/03/07/microsoft-dma-compliance-windows-linkedin/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNTVibVZDUTNOTVV5MU9OWGRqVFJDb0FSaXNBaWdCTWdrQkVKQUVsaWNINlFF=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-03-07T08:00:00.000Z",
    "time": "Mar 7",
    "articleType": "regular",
    "content": "Following the designation of Windows and LinkedIn under the European Union’s Digital Markets Act (DMA), we have been diligently working to implement the DMA, engaging with the European Commission, and testing DMA-compliant features with customers and the industry, to ensure that we fulfill our obligations.\nNow that the compliance deadline has arrived, we are sharing the steps we’ve taken to comply, as well as our focus on ensuring effective compliance in the months and years ahead.\nTo that end, we have published our annual DMA Compliance Report. The report, based on the European Commission’s template, is available on our dedicated DMA Compliance Program website. The website also provides contact information for Microsoft’s DMA Compliance Function. We will keep this website updated as our compliance journey continues, and we remain committed to working with the European Commission, National Competition Authorities, European businesses, and consumers to remain compliant with the DMA.\nThe DMA compliant versions of both Windows 10 and 11 are available to users in the European Economic Area (EEA) at no charge. We have started to roll out these updates for automatic installation to Windows 10 and Windows 11 users and anticipate finishing the roll out for EEA users by early April 2024. Windows users in the EEA who want to use the DMA-compliant versions of Windows 10 or Windows 11 today can get it by turning on the “Get the latest updates as soon as they’re available” feature for Windows Update in their settings menu . More details are available on the Windows Blog.\nBecause Windows is designed as an open platform for applications and has been for decades, it complied with many of the key provisions of the DMA even before the act was passed.\nThe DMA, for example, requires designated operating systems to enable users to install applications and application stores on the operating system without intermediation by the operating system provider. Windows users have always been able to install applications and application stores onto Windows directly from the internet or other distribution channels without engaging with Microsoft.\nThe DMA also gives application providers the right to control the commercial relationship with their users by, for example, directing their users to lower-cost offerings on other platforms, relying on identity, payment, or other services unrelated to the operating system provider, or enabling users to access content within the application that is acquired outside of the application. Application providers on Windows have always been able to do these things because they are in control of the commercial relationship with their users without interference from Microsoft.\nMicrosoft did make changes to Windows to comply with other provisions of the DMA and is delivering these changes to Windows PCs in the EEA.\nThe Edge browser and the Bing web search functionality were redesigned so that users can uninstall these applications from Windows using the standard Windows mechanisms that are available for uninstallation if they choose to do so.\nMicrosoft has enabled and provided instructions for third-party web search applications to offer web search services through the search box on the Windows task bar and to rely on any browser of their choice to show a search results page in the same way as the Microsoft Bing web search application. Similarly, Windows enables and has provided information to developers on how to create third-party news feeds in the Windows Widgets panel in the same way as Microsoft Edge.\nMicrosoft also modified the sign-in experience on Windows. Prior to the DMA, Windows automatically signed users into other Microsoft products and services that combined data, including into Edge, Bing, and the Microsoft “Start” service (e.g. news, weather, etc.) when users are first signed into Windows. Windows will no longer automatically sign users into these services.\nFinally, Microsoft made a number of changes to how it handles data associated with the use of Windows by users in the EEA.\nFor example, Microsoft has put in place new data handling practices and controls to ensure that any data collected from Windows PCs in the EEA about non-Microsoft applications running on Windows ­­– for example, data collected for the purpose of detecting bugs that impact those applications or Windows – is not used for any competitive purpose against the providers of those applications.\nSimilarly, Microsoft redesigned Windows data consent flows to make clear when Microsoft combines Windows data with data from other Microsoft products and services and it will obtain consent for those data combinations, including issuing new consent screens to existing Windows users where required.\nA complete list of the changes Microsoft made to Windows to comply with the DMA is contained in Microsoft’s DMA compliance report available on the DMA Compliance Program website.\nAs announced in a blog post last month, LinkedIn rolled out the ability for members based in the EEA to choose whether to connect their core LinkedIn professional network experience across LinkedIn’s Jobs, Marketing Solutions, and Learning services. LinkedIn tailors its members’ experiences on LinkedIn based on members’ engagement with the services on the LinkedIn platform, using that information to provide members with recommendations for people, content, jobs, ads, and learning courses that can get members ahead in their careers.\nAt the prompt, members in the EEA can elect to keep their core LinkedIn experience connected with other LinkedIn services they may use, or to disconnect that link.\nMembers who don’t keep these services connected to their core LinkedIn experience will have a less tailored experience, although they will still have access to the same LinkedIn services regardless of what they choose.\nAs LinkedIn moves forward, it is committed to tracking developments with enforcement of the DMA and other key EU regulations and evaluating our approach accordingly.\nLinkedIn also rolled out new ways for members and customers (including through their authorized developers) to access their data on LinkedIn.\nWhile LinkedIn members already have the ability to download a copy of their data through their settings, LinkedIn has designed and implemented new APIs for members and their authorized third-party developers to access, on a continuous basis, the data they provided on LinkedIn or generate while engaging on the platform.\nLinkedIn has also designed and implemented new APIs that allow LinkedIn Page administrators and their authorized third-party developers to access: (1) data they have provided on the LinkedIn platform or generated while using LinkedIn; and (2) data provided or generated by LinkedIn members through their engagement with Pages, subject to those members’ consent.\nA complete list of the changes Microsoft made to LinkedIn to comply with the DMA is also contained in Microsoft’s DMA compliance report available on the DMA Compliance Program website.\nTags: DMA, DMA Compliance, LinkedIn, Windows, Windows 10",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/73/2022/10/cropped-MS_Symbol_Social_FB_TWTR_LNKD_INSTA-32x32.png"
  },
  {
    "title": "Microsoft announces US$1.7 billion investment to advance Indonesia’s cloud and AI ambitions - Microsoft Stories Asia",
    "link": "https://news.microsoft.com/apac/2024/04/30/microsoft-announces-us1-7-billion-investment-to-advance-indonesias-cloud-and-ai-ambitions/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNXlhbGxqV0VkUmFUWTFkemd4VFJDM0FSaVRBaWdCTWdZVmc1WXBzUWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-30T07:00:00.000Z",
    "time": "Apr 30",
    "articleType": "regular",
    "content": "Microsoft Chairman and CEO Satya Nadella announces a $1.7 billion investment to advance new cloud and AI infrastructure in Indonesia during the Microsoft Build: AI Day on April 30, 2024 in Jakarta, Indonesia. Photo by Annice Lyn/Getty Images for Microsoft.\nInvestment includes new cloud and AI infrastructure, major AI skilling initiatives, and support for Indonesia’s growing developer community\nRead this in Bahasa Indonesia.\nJakarta, April 30, 2024 – Today, Microsoft announced it will invest US$1.7 billion over the next four years in new cloud and AI infrastructure in Indonesia, as well as AI skilling opportunities for 840,000 people, and support for the nation’s growing developer community. It represents the single largest investment in Microsoft’s 29-year history in the country.\nTogether, these initiatives will help achieve the Indonesian government’s Golden Indonesia 2045 Vision, which aims to transform the nation into a global economic powerhouse.\n“This new generation of AI is reshaping how people live and work everywhere, including in Indonesia,” said Satya Nadella, Chairman and CEO, Microsoft. “The investments we are announcing today – spanning digital infrastructure, skilling, and support for developers – will help Indonesia thrive in this new era.”\nBudi Arie Setiadi, Minister of Communications and Information Technology of the Republic of Indonesia emphasized the significance of Indonesia’s partnership with Microsoft in realizing the ambitious vision of Golden Indonesia 2045. “Indonesia’s collaboration with Microsoft on AI perfectly aligns with our ambition for a future driven by digital innovation. I am confident this partnership will open up new horizons for Indonesia, positioning us not only as consumers of technology but as pivotal contributors to the global technological supply chain,” he said.\nDharma Simorangkir, President Director of Microsoft Indonesia, said: “Our investment sets a new milestone for Indonesia’s digital landscape. We aim to empower Indonesians with the infrastructure and skills needed for the AI era, aligning with our national vision for digital prowess. It’s a crucial step towards making Indonesia a hub for digital talent and innovation.”\nMicrosoft Chairman and CEO Satya Nadella (L) meets with President of the Republic of Indonesia Joko Widodo prior to the Microsoft Build: AI Day on April 30, 2024 in Jakarta, Indonesia. Photo by Press, Media, and Information Bureau, President Secretariat.\nBuilding a strong foundation for AI transformation\nThe digital infrastructure investment builds on Microsoft’s Berdayakan Indonesia (Empower Indonesia) initiative, announced in February 2021, to accelerate inclusive economic growth. This included plans to establish the company’s first datacenter region in the country.\nThe investment announced today will enable Microsoft to meet the growing demand for cloud computing services in Indonesia. It will also allow Indonesia to capitalize on the significant economic and productivity opportunities presented by the latest AI technology.\nAccording to research by Kearney, AI could contribute nearly US$1 trillion to Southeast Asia’s gross domestic product (GDP) by 2030, of which Indonesia is poised to capture US$366 billion.\nFocusing on skills to unlock an AI-powered economy\nMicrosoft Chairman and CEO Satya Nadella announces a new initiative aimed at equipping 2.5 million people with AI skills by 2025 across ASEAN during the Microsoft Build: AI Day on April 30, 2024 in Jakarta, Indonesia. Photo by Annice Lyn/Getty Images for Microsoft.\nMicrosoft today also announced a broader commitment to provide AI skilling opportunities for 2.5 million people in Association of Southeast Asian Nations (ASEAN) member states by 2025. This training and support will be delivered in partnership with governments, nonprofit and corporate organizations, and communities in Indonesia, Malaysia, the Philippines, Thailand, and Vietnam.\nMicrosoft’s skilling commitment is expected to benefit 840,000 people in Indonesia by providing:\nstudents with technical and vocational education and training in AI skills through the AI TEACH for Indonesia program\nwomen with opportunities and support to build careers in cybersecurity via the new Ready4AI&Security program\nyoung people with AI fluency training to enhance the employability and work readiness of those from underserved and underrepresented communities\nemployees of nonprofit organizations with knowledge of, and skills in, AI and digital technologies.\nEnabling developers to realize Indonesia’s AI potential\nNadella highlighted the critical role of developers in harnessing AI to fulfill Indonesia’s potential as a digital economy. Microsoft will continue to help foster the growth of the country’s developer community through new initiatives such as AI Odyssey, which is expected to help 10,000 Indonesian developers become AI subject matter experts by learning new skills and earning Microsoft credentials.\nOver 3.1 million developers in Indonesia use GitHub, the Microsoft-owned software development, collaboration, and innovation platform. This makes Indonesia home to the third-largest developer community on GitHub in the Asia-Pacific region, after India and China. It is projected to be one of the top five developer communities on GitHub globally by 2026.\nIndonesia is also one of the fastest-growing groups in the region, with a 31 percent year-on-year increase in the number of developers on GitHub in 2023. Furthermore, it witnessed\n213 percent year-on-year growth in the number of public generative AI projects on the platform in 2023.\nMany organizations in Indonesia are boosting their productivity and accelerating innovation using Microsoft’s generative AI-powered solutions. These include DANA, a leading Indonesian fintech company, PT Kereta Api Indonesia, the nation’s major operator of public railways, and Telkomsel, one of Asia’s largest digital telco companies. Other notable examples include:\nBank Rakyat Indonesia (BRI), a 128-year-old bank in Indonesia, is developing four generative AI use cases in less than a year to enhance operational efficiency and service quality. They are a work instruction search engine for faster customer service, a ’content factory’ for streamlining the creation of marketing material, a letter-creation tool to standardize administrative documents, and a digital chatbot called Sabrina to provide transparent financial product information to millions of Indonesians.\nBUMA, one of the largest reliable mining contractors in Indonesia, started using Copilot for Microsoft 365 in March 2024 to improve the productivity of its workforce. Around 100 employees across the company’s departments are leveraging the tool to optimize their workflows and uncover previously underused features of Microsoft 365.\neFishery, the first aqua technology startup based in Asia with a mission to combat world hunger, has launched Mas Ahya (Mr. Cultivation Expert). The solution, powered by Azure OpenAI Service, is designed to provide advice and insights to Asian aqua farmers. It caters to farmers with varying levels of experience and uses everyday language. It will also support multiple local languages, starting with Bahasa Indonesia and Javanese.\nPT Telkom Indonesia (Persero) Tbk (Telkom), the nation’s largest telecommunications provider in the country, has enhanced its coding efficiency since adopting GitHub Copilot in mid-2023. In its early-stage usage, developers are already accepting 20–30 percent of the code suggested by the AI-pair programmer, which leads to increased confidence, productivity, and code quality.\nUniversitas Terbuka, Indonesia’s open and distance learning university, has created an AI Assistant with Azure OpenAI Service in 1,000 virtual classrooms across 10 subjects; empowering up to 60,000 students across provinces. By indexing the teaching materials and grading criteria provided and curated by the lecturers, AI Assistant can help online lecturers evaluate, grade, and suggest improvements to students’ written answers. This real-time feedback encourages students to pay attention to their learning tasks and motivates them to participate more actively, thereby increasing student retention rates and contributing to their overall success.\nYayasan Mitra Netra (Mitra Netra Foundation), a nonprofit organization, used Azure OpenAI Service’s GPT-4 to enable its Arabic Braille Converter to convert Arabic text with harakat in image format to Arabic Unicode. The app, created by a team including non-technical staff members and a programmer who is blind, converts Arabic text with Harakat to Indonesian braille and vice versa, potentially benefiting millions of people with vision impairment.\nEnsuring a responsible future in the AI era\nMicrosoft is actively collaborating with the Indonesian government, civil society, academics, and industry peers to ensure AI serves as a force for good.\nIn January 2024, Microsoft voluntarily committed to the implementation of AI ethical values highlighted in the Indonesian Ministry of Communication and Information Technology’s Circular Letter No. 9/2023.\nMicrosoft (Nasdaq “MSFT” @microsoft) creates platforms and tools powered by AI to deliver innovative solutions that meet the evolving needs of our customers. The technology company is committed to making AI available broadly and doing so responsibly, with a mission to empower every person and every organization on the planet to achieve more.\nTags: AI, Cloud, digital skills",
    "favicon": "https://news.microsoft.com/wp-content/themes/microsoft-news-center-2016/assets/img/site-icon.png"
  },
  {
    "title": "China tests US voter fault lines and ramps AI content to boost its geopolitical interests - Microsoft On the Issues",
    "link": "https://blogs.microsoft.com/on-the-issues/2024/04/04/china-ai-influence-elections-mtac-cybersecurity/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNTFPWGhGTnpCSWVYQkJUV0ozVFJDb0FSaXNBaWdCTWdPSll3bw=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-04T07:00:00.000Z",
    "time": "Apr 4",
    "articleType": "regular",
    "content": "China is using fake social media accounts to poll voters on what divides them most to sow division and possibly influence the outcome of the U.S. presidential election in its favor. China has also increased its use of AI-generated content to further its goals around the world. North Korea has increased its cryptocurrency heists and supply chain attacks to fund and further its military goals and intelligence collection.  It has also begun to use AI to make its operations more effective and efficient.\nThese are among the Microsoft Threat Intelligence insights in the latest East Asia report published today by the Microsoft Threat Analysis Center (MTAC) – Same targets, new playbooks: East Asia threat actors employ unique methods.\nThree key findings emerge in the report:\nDeceptive social media accounts by Chinese Communist Party (CCP)-affiliated actors have started to pose contentious questions on controversial U.S. domestic issues to better understand the key issues that divide U.S. voters. This could be to gather intelligence and precision on key voting demographics ahead of the U.S. presidential election.\nThere has been an increased use of Chinese AI-generated content in recent months, attempting to influence and sow division in the U.S. and elsewhere on a range of topics including: the train derailment in Kentucky in November 2023, the Maui wildfires in August 2023, the disposal of Japanese nuclear wastewater, drug use in the U.S. as well as immigration policies and racial tensions in the country. There is little evidence these efforts have been successful in swaying opinion.\nChina’s geopolitical priorities remain unchanged but it has doubled down on its targets and increased the sophistication of its influence operations (IO) attacks. These priorities are:\nThe South China Sea region\nThe U.S. defense industrial base\nMTAC previously reported in September 2023 how CCP-affiliated social media accounts had begun to impersonate U.S. voters in an effort to influence the 2022 U.S. midterm elections. This activity has continued and these accounts nearly exclusively post about divisive U.S. domestic issues such as global warming, U.S. border policies, drug use, immigration, and racial tensions. They use original videos, memes, and infographics as well as recycled content from other high-profile political accounts. In recent months, there has been an increase in, effectively, polling questions. This indicates a deliberate effort to understand better which U.S. voter demographic supports what issue or position and which topics are the most divisive, ahead of the main phase of the U.S. presidential election.\nChina increases use of AI in influence campaigns\nChinese IO operations in the U.S. continued to opportunistically jump on events which could serve their strategic interests – such as portraying the U.S. in an unfavorable light. These operations, attributed to Storm 1376, included:\nClaiming that the Maui wildfires of August 2023 were deliberately set by the U.S. government to test a military-grade “weather weapon”\nUrging audiences to consider whether the derailment of a train carrying molten sulfur in Kentucky in November 2023 was deliberately caused by the U.S. government and whether it is “deliberately hiding something”. Some messages even likened the derailment to 9/11 and Pearl Harbor cover-up theories.\nAccusing the U.S. of purposefully poisoning other countries’ water supplies to maintain “water hegemony”. This was part of a wider multilingual campaign, principally focused on Japan and its government’s decision to dispose of treated radioactive wastewater into the Pacific Ocean. Storm-1376 tried to cast doubt on the International Atomic Energy Agency’s (IAEA) scientific assessment that the disposal was safe.\nThe Taiwanese presidential election in January 2024 saw a surge in the use of AI-generated content to augment IO operations by CCP-affiliated actors. This was the first time that Microsoft Threat Intelligence has witnessed a nation-state actor using AI content in attempts to influence a foreign election.\nThe group we call Storm-1376, also known as Spamouflage and Dragonbridge, was the most prolific. For example, on election day, it posted suspected AI-generated fake audio of Foxconn owner and election candidate Terry Gou (who had bowed out of the contest in November 2023) endorsing another candidate in the presidential race. Gou had made no such statement. YouTube quickly removed this content before it reached a wider audience.\nStorm-1376 has promoted a series of AI-generated memes of Taiwan’s then-Democratic Progressive Party (DPP) presidential candidate William Lai, and other Taiwanese officials as well as Chinese dissidents around the world. These have included an increasing use of AI-generated TV news anchors that Storm-1376 has deployed since at least February 2023.\nNorth Korea continued to prioritize the theft of cryptocurrency funds, conducting software supply-chain attacks and targeting their perceived national security adversaries. This is likely to generate revenue, principally for its weapons program, in addition to collecting intelligence on the United States, South Korea, and Japan.\nThe United Nations estimates that North Korean cyber actors have stolen over $3 billion in cryptocurrency since 2017. Heists totaling between $600 million and $1 billion occurred in 2023 alone.\nOur report catalogs multiple instances of cryptocurrency heists, spear-phishing, and software supply-chain attacks and efforts to undermine the trilateral alliance between the U.S., Japan, and South Korea.\nNotably, Microsoft and OpenAI have observed the North Korean actor we call Emerald Sleet using tools powered by AI large-language models (LLMs) to make their operations more effective and efficient. Microsoft partnered with OpenAI to disable accounts and assets associated with Emerald Sleet.\nWith major elections taking place around the world this year, particularly in India, South Korea and the United States, we assess that China will, at a minimum, create and amplify AI-generated content to benefit its interests. Despite the chances of such content in affecting election results remaining low, China’s increasing experimentation in augmenting memes, videos, and audio will likely continue – and may prove more effective down the line. We can expect to see North Korea continue to steal cryptocurrency to fund space, missile, and nuclear programs as well as launch supply-chain attacks on the defense sector.\nTags: AI, China, cyber influence, elections, influence operations, MTAC, North Korea, open ai",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "Introducing Microsoft Copilot for Finance in Microsoft 365| Microsoft 365 Blog",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2024/02/29/introducing-microsoft-copilot-for-finance-transform-finance-with-next-generation-ai-in-microsoft-365/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWlORVJsUTA1WmEwdHpiRTFhVFJDb0FSaXNBaWdCTWdZTlVwRDFIQWs=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-02-29T08:00:00.000Z",
    "time": "Feb 29",
    "articleType": "regular",
    "content": "The finance department is the heart of the organization, juggling a myriad of critical, yet complex tasks—from quote-to-cash processes like credit and collections to risk management and compliance. Financial teams are not only responsible for these mandatory, labor-intensive operations, but are increasingly tasked with real-time insights into business performance and recommendations for future growth initiatives. In fact, 80% of finance leaders and teams face challenges to take on more strategic work beyond the operational portions of their roles.¹ On the one hand, teams are poised and ready to play a larger role in driving business growth strategy. On the other hand, however, they can’t walk away from maintaining a critical and mandatory set of responsibilities.\nMicrosoft is introducing a solution to help finance teams reclaim time and stay on top of the critical decisions that can impact business performance. Microsoft Copilot for Finance is a new Copilot experience for Microsoft 365 that unlocks AI-assisted competencies for financial professionals, right from within productivity applications they use every day. Now available in public preview, Copilot for Finance connects to the organization’s financial systems, including Dynamics 365 and SAP, to provide role-specific workflow automation, guided actions, and recommendations in Microsoft Outlook, Excel, Microsoft Teams and other Microsoft 365 applications—helping to save time and focus on what truly matters: navigating the company to success.\nBy harnessing AI, it automates time-consuming tasks, allowing you to focus on what truly matters.\nLeveraging innovation to accelerate fiscal stewardship\nFinance teams play a critical role in innovating processes to improve efficiency across the organization. As teams look to evolve and improve how time is spent to support more strategic work, it’s evident there are elements of operational tasks that are more mundane, repetitive, and manually intensive.  Instead of spending the majority of their day on analysis or cross-team collaboration, 62% of finance professionals are stuck in the drudgery of data entry and review cycles.² While some of these tasks are critical and can’t be automated—like compliance and tax reporting—we also hear from majority of finance leaders that they lack the automation tools and technology they need to transform these processes and free up time.¹\nWith the pace of business accelerating every day, becoming a disruptor requires investing in technology that will drive innovation and support the bottom line. In the next three to five years, 68% of CFOs anticipate revenue growth from generative AI (GenAI).³ By implementing next-generation AI to deliver insight and automate costly and time-intensive operational tasks, teams can reinvest that time to accelerate their impact as financial stewards and strategists.\nMicrosoft Copilot for Finance: Accomplish more with less\nCopilot for Finance provides AI-powered assistance while working in Microsoft 365 applications, making financial processes more streamlined and automated. Copilot for Finance can streamline audits by pulling and reconciling data with a simple prompt, simplify collections by automating communication and payment plans, and accelerate financial reporting by detecting variances with ease. The potential time and cost savings are substantial, transforming not just how financial professionals work, but how they drive impact within the organization.\nUsers can interact with Copilot for Finance in multiple ways. It both suggests actions in the flow of work, and enables users to ask questions by typing a prompt in natural language. For example, a user can prompt Copilot to “help me understand forecast to actuals variance data.” In moments, Copilot for Finance will generate insights and pull data directly from across the ERP and financial systems, suggesting actions to take and providing a head start by generating contextualized text and attaching relevant files. Like other copilot experiences, users can easily check source data to ensure transparency before using Copilot to take any actions.\nCopilot for Finance connects to existing financial systems, including Dynamics 365 and SAP, as well as thousands more with Microsoft Copilot Studio. With the ability to both pull insight from and update actions back to existing sources, Copilot for Finance empowers users to stay in the flow of work and complete tasks more efficiently.\nCopilot for Finance is well versed in the critical and often time-consuming tasks and processes across a finance professional’s workday, providing a simple way to ask questions about data, surface insights, and automate processes—helping to reduce the time spent on repetitive actions. While today’s modern finance team is responsible for a litany of tasks, let’s explore three scenarios that Copilot for Finance supports at public preview.\nAudits of a company’s financial statements are critical to ensuring accuracy and mitigating risk. Traditionally, accounts receivable managers were required to pull account data manually from ERP records, reconcile it in Excel, and look for inaccuracies manually. With Copilot for Finance, these critical steps are done with a single prompt, allowing AR managers to act on inconsistencies and any delinquencies found with Copilot suggested copy and relevant invoices.\n“Finance organizations need to be utilizing generative AI to help blend structured and unstructured datasets. Copilot for Finance is a solution that aggressively targets this challenge. Microsoft continues to push the boundary of business applications by providing AI-driven solutions for common business problems. Copilot for Finance is another powerful example of this effort. Copilot for Finance has potential to help finance professionals at organizations of all sizes accelerate impact and possibly even reduce financial operation costs.”\n—Kevin Permenter, IDC research director, financial applications\nThe collections process is another critical responsibility as it affects company cash flow, profitability, and customer relationships. Collection coordinators spend their time reviewing outstanding accounts and attempting to reconcile them in a timely manner. This often means phone calls, emails, and negotiating payment plans. With Copilot for Finance, collection coordinators can focus their time on more meaningful client-facing interactions by leaving the busy work to Copilot. Copilot for Finance supports the collections process end-to-end by suggesting priority accounts, summarizing conversations to record back to ERP, and providing customized payment plans for customers.\nCopilot for Finance can also help financial analysts to reduce the risk of reporting errors and missing unidentified variances. Rather than manually reviewing large financial data sets for unusual patterns, users can prompt Copilot to detect outliers and highlight variances for investigation. Copilot for Finance streamlines variance identification with reusable natural language instructions in the enterprise context. A financial analyst can direct Copilot to identify answers for variances, and Copilot will gather supporting data autonomously.\nCopilot will suggest financial context contacts and will provide auto summaries for streamlined tracking of action items and follow ups. Copilot for Finance can generate fine-tuned financial commentary, PowerPoint presentations, and emails to report to key stakeholders.\nOur journey with Microsoft Finance\nMicrosoft employs thousands across its finance team to manage and drive countless processes and systems as well as identify opportunities for company growth and strategy. Who better to pilot the latest innovation in finance? For the first phase, we worked closely with a Treasury team focused on accounts receivable as well as a team in financial planning and analysis—who need to reconcile data as a part of their workflow before conducting further analysis. After trialing the data reconciliation capabilities in Copilot for Finance, the initial value and potential for scale for these teams was clear.\n“Financial analysts today spend, on average, one to two hours reconciling data per week. With Copilot for Finance, that is down to 10 minutes. Functionality like data reconciliation will be a huge time saver for an organization as complex as Microsoft.”\n—Sarper Baysal, Microsoft Commercial Revenue Planning Lead\n“The accounts receivable reconciliation capabilities help us to eliminate the time it takes to compare data across sources, saving an average 20 minutes per account. Based on pilot usage, this translates to an average of 22% cost savings in average handling time.”\n—Gladys Jin, Senior Director Microsoft Finance Global Treasury and Financial Services\nMicrosoft Copilot for Finance availability\nReady to take the next step? Microsoft Copilot for Finance is available for public preview today. Explore the public preview demo and stay tuned for additional announcements by following us on social.\nExplore more Copilot offerings for business functions across your organization\nCopilot for Finance joins other Copilot offerings designed for business functions, including Microsoft Copilot for Sales and Microsoft Copilot for Service, both now generally available.\nFor research insights on the future of work and generative AI, subscribe to WorkLab.\n¹ Microsoft Future of Finance Trends Report, 2023² Metric of the Month: Time Allocation in Finance, CFO, Perry D. Wiggins. December 7, 2020. ³ Accelerating the GenAI Journey with Use Cases in the Functional and Application Areas, IDC, Mickey North Rizza. February 2024.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft’s AI Safety Policies - Microsoft On the Issues",
    "link": "https://blogs.microsoft.com/on-the-issues/2023/10/26/microsofts-ai-safety-policies/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNXlNWGczYjAxRGFGaHZTa3d6VFJEQUFSaUhBaWdCTWdPSkFRdw=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-10-26T07:00:00.000Z",
    "time": "Oct 26, 2023",
    "articleType": "regular",
    "content": "An update prepared for the UK AI Safety Summit\nMicrosoft welcomes the opportunity to share information about how we are advancing responsible artificial intelligence (AI), including by implementing voluntary commitments that we and others made at the White House convening in July.[1] Visibility into our policies and how we put them into practice helps to inform and accelerate responsible technology development and deployment. It can also strengthen public-private partnerships driving progress on AI safety, security, and trust.\nAs a developer and deployer of AI models, API services, and applications, Microsoft works to map, measure, and manage risk and apply multi-layered governance that embeds robust checks on processes and outcomes. For frontier models specifically, Microsoft works closely with OpenAI.\nSince 2019, Microsoft and OpenAI have been engaged in a long-term collaboration to develop advanced AI systems, underpinned by a shared commitment to responsible development and deployment practices. Microsoft’s efforts to deploy frontier models at scale build upon and complement OpenAI’s leading model development practices. For a comprehensive accounting of the model development and deployment practices that apply to OpenAI’s frontier models as deployed in Microsoft’s offerings, OpenAI’s and Microsoft’s responses to the UK Government’s AI Safety Policies Request should be read together.\nThe UK Government has requested information about nine areas of practice and investment, many of which relate to the voluntary commitments we published in July.[2] We have indicated these points of connection at the beginning of each section, distinguishing between the White House Voluntary Commitments and the additional independent commitments we made as Microsoft (denoted with blue), as also illustrated in the chart below.\nWe also recognize that each of the nine areas of practice accrue to mapping, measuring, managing, and governing AI model development and deployment risk, the structure and terminology offered by the National Institute of Standards and Technology (NIST) AI Risk Management Framework (RMF).[3] To help provide context on how we are realizing our commitment to implement the NIST AI RMF, the terminology of “map, measure, manage, and govern” is used throughout this response to the UK Government’s AI Safety Policies Request.\nMicrosoft is committed to responsible development and deployment of increasingly capable AI systems, including frontier models and the applications by which users access them. We have put in place and are continuously investing in a range of policies, practices, and partnerships to ensure we are appropriately mapping, measuring, and managing AI technology capability and risks across the AI product lifecycle, as further discussed below in the context of model evaluations and red teaming. Learnings from this process are fed back into policies for defining off-limits technology development or needed guardrails across release stages or deployment contexts.\nTo support responsible capability scaling, we collaborate closely with OpenAI as they are developing new frontier models on our Azure supercomputing infrastructure. OpenAI provides details of their risk mitigation practices and in-progress Responsible Development Policy in their response to the UK Government’s AI Safety Policies Request.\nWhen it comes to frontier model deployment, Microsoft and OpenAI have together defined capability thresholds that act as a trigger to review models in advance of their first release or downstream deployment. The scope of a review, through our joint Microsoft-OpenAI Deployment Safety Board (DSB), includes model capability discovery. We established the joint DSB’s processes in 2021, anticipating a need for a comprehensive pre-release review process focused on AI safety and alignment, well ahead of regulation or external commitments mandating the same.\nWe have exercised this review process with respect to several frontier models, including GPT-4. Using Microsoft’s Responsible AI Standard and OpenAI’s experience building and deploying advanced AI systems, our teams prepare detailed artefacts for the joint DSB review. Artefacts record the process by which our organizations have mapped, measured, and managed risks, including through the use of adversarial testing and third-party evaluations as appropriate. We continue to learn from, and refine, the joint DSB process, and we expect it to evolve over time.\nAs Microsoft, we also independently manage a subsequent safety review process. We evaluate model capability as deployed in a product – where additional safety mitigations can be implemented and measured for impact – to check for effective and appropriate mitigations prior to release.\nAcross all mapping, measurement, and management activities as well as product deployment decisions, governance is critical. Microsoft operates a multi-tiered approach to both top-down and distributed responsible AI governance, allowing us to set clear policies, convene leadership to make tough calls, and drive consistency rigor.\nOur Responsible AI Council is a vital component of our governance structure. The Responsible AI Council, which is co-chaired by Brad Smith, our Vice Chair and President, and Kevin Scott, our Chief Technology Officer and EVP of AI, brings together accountable leaders as well as teams involved in research, engineering, and policy to confront difficult questions and ensure alignment and execution consistent with our responsible AI vision and commitments.[4]\nAcross products groups, designated Responsible AI Division Leads and Champs also work with their accountable Responsible AI Corporate Vice Presidents and Microsoft’s Office of Responsible AI team to measure and continuously improve responsible AI practice implementation, including through shared learning and strategic investment in tools.\nMicrosoft also supports the formation of a globally coordinated licensing regime to govern the development and deployment of highly capable frontier models, enabling appropriate oversight into risks and mitigations.[5] Through such a regime, best practices for mapping risk (e.g., defining leading indicators of potential model risk) and for managing risk could regularly be assessed for impact and improved, and reliable processes for exchanging and using information about evaluations and measurements could be established. A framework for close coordination and information flows between licensees and their regulators is critical to ensure that developments material to the achievement of safety and security objectives can be acted upon swiftly.[6]\nModel Evaluations and Red Teaming\nRed teaming, including by simulating real-world attacks and exercising techniques that persistent threat actors might use, has long been a foundational security practice at Microsoft.[8] In 2018, we established our AI Red Team: a group of interdisciplinary experts dedicated to thinking like attackers and probing AI systems for failures.[9] Through research, we have also expanded our red teaming practices to map risks outside of traditional security, including those associated with benign usage scenarios and responsible AI. Today, for example, a red team might probe a Large Language Model (LLM) or an LLM-backed feature for prompt injection attacks (where content submitted to the LLM by the user or by a third party results in unintended actions), content harms (where malicious or benign usage of the system results in harmful or inappropriate AI-generated content), and privacy harms (where an LLM leaks correct or incorrect personal information about an individual), among others. In the case of Bing Chat, AI red teaming focuses not only on how threat actors could subvert the system using security techniques but also on how the system could generate harmful or otherwise problematic content when non-malicious users interact with it.[10]\nBecause AI red teaming can surface previously unknown harms, confirm whether suspected harms are observable in a product, and inform measurement and risk management, iterative red teaming is critical at the base model level and throughout AI product development and deployment. Red teaming an AI model helps identify how it might be misused and the scope of its capabilities and limitations, improving the model development process and informing analysis of applications for which a model is suitable. Application-level AI red teaming takes a broader and more applied view, mapping model or application failures that persist despite different model- or application-level safety mitigations. Moreover, because AI systems are constantly evolving, we pursue multiple rounds of AI red teaming to look for vulnerabilities and attempt to measure their pervasiveness as well as mitigate them, both prior to product shipment and as an ongoing practice. Red teaming generative AI systems also requires multiple attempts; because a prompt may not lead to failure in one instance but could in another (as the probabilistic nature of generative AI allows for a wider range in creative output), we perform multiple rounds of red teaming in the same operation.[11]\nTo strengthen our internal governance of AI threat modeling, which may include red teaming, and reflect our ongoing AI threat research and learnings, we’ve updated internal practice guidance for Microsoft’s Security Development Lifecycle (SDL) Threat Modeling requirement, which is applicable to all products, to account for our ongoing learnings about unique threats specific to AI and machine learning.\nFor all generative AI products characterized as high risk, we are also implementing processes to ensure consistent and holistic AI red teaming by our AI Red Team, an expert group independent to base model or product groups. We are also building out external red-teaming capacity to ensure our readiness to organize red team testing by one or more independent experts prior to the release of new and highly capable foundation models that may be trained by Microsoft, consistent with our July commitment.[12] The topics covered by such red team testing will include testing of dangerous capabilities, including related to biosecurity and cybersecurity.\nWhile red teaming is useful for mapping risks, systematic measurement is important for understanding the prevalence of risks and the effectiveness of risk mitigations. Through systematic measurement, we evaluate model performance against specific metrics, and the range of issues we are systematically measuring for all products is regularly expanding. Some examples of metrics include:[13]\nGroundedness, through which we measure how well a model’s generated answers align with information from the input source. Answers are verified as claims against context in the user-defined ground truth source, and even if answers are factually correct, if not verifiable against source text, then they’re scored as ungrounded.\nRelevance, through which we measure the extent to which a model’s generated answers are pertinent and directly related to the given questions.\nSimilarity, through which we measure the equivalencies between a “ground-truth” answer and a prediction sentence generated by an AI model.\nWe also share responsible AI capabilities and tools that support measurement of these and other metrics open source on GitHub and via Azure Machine Learning, empowering platform and application developers to access model explanations and error and fairness evaluations.[14] For example, in May, we announced prompt flow, which allows users to create prompt workflows that connect to various language models and data sources and assess the quality of their workflows against metrics such as groundedness, ultimately enabling them to choose the best prompt for their use case.[15]\nWe also systematically measure the impact of mitigations for potentially unsafe model outputs, such as content filtering systems that run prompts and completions though models aimed at detecting and preventing the output of harmful content. As part of our commitment to both building responsible AI systems and helping others do so, we integrate content filtering across Azure OpenAI[16] and have also prioritized work on tools for customers. Azure AI Content Safety uses AI models to detect unsafe, offensive, or inappropriate content in text and images and automatically assigns severity scores in real time, enabling customers to efficiently and in a prioritized manner review flagged items and take informed action.[17] We’ve also turned this safety system on by default for Llama-2 models hosted on Microsoft’s platform, mitigating intentional misuse as well as potential mistakes by the model.[18]\nOur process of launching Bing Chat, which runs on a variety of advanced Microsoft and OpenAI technologies, including OpenAI’s GPT-4 model, provides a product-specific example of how we have approached mapping, measuring, and managing risk at the model and application layers, including through red teaming and model evaluations.[19]\nAt the model level, our work began with extensive red teaming in collaboration with OpenAI, and a multidisciplinary team of experts also conducted numerous rounds of application-level red teaming before our limited release preview, helping us better understand how the system could be exploited and improve our mitigations. Non-adversarial red teamers also extensively probed the new application for risks that could arise in benign usage scenarios. Post release, red teamers from different regions and backgrounds continue to attempt to compromise the system, and their findings are used to expand the datasets that Bing Chat uses to improve the system.\nTo better understand and address potential harms, we developed additional metrics specific to new AI experiences like jailbreaks, harmful content, and ungrounded content. We also enabled measurement at scale through partially automated measurement pipelines (that then allowed us to build tools for third parties). Each time the product changes, existing mitigations are updated, or new mitigations are proposed, we update our measurement pipelines to assess both product performance and responsible AI metrics. As we identify new issues during a preview period and ongoing red teaming, we also expand measurement sets to assess additional harms.\nAs we map harms and measure them, we manage an ongoing process of developing and measuring the impact of mitigations. For Bing Chat, some of the steps that we’ve taken to manage risks include: an incremental release strategy (to allow us to mitigate emerging issues before broader release); inclusion of references to source websites for search results (to mitigate the risk that users may over-rely on ungrounded generated content); the use of classifiers and content filters (which may stop flagged generated content from being returned to the user); the use of metaprompting (which gives instructions to a model to guide its behavior); and limitations on user-Bing reply exchanges per session (to limit conversational drift).\nModel Reporting and Information Sharing\nTransparency is a foundational responsible AI principle to which Microsoft committed in 2019, and as our Responsible AI Standard captures, communication to stakeholders about the capabilities and limitations of the AI systems they use is key to realizing that principle.[20] Driving implementation of all six of our responsible AI principles and working through sensitive use cases has also reinforced for us the importance of providing context to our customers to empower them to deploy their AI systems responsibly.[21]\nWhat specifically needs to be communicated and to whom as part of Microsoft’s transparency commitment is defined by our Responsible AI Standard.[22] Conceptually, we recognize that different stakeholders have different needs and goals when it comes to transparency. For instance, the approach to transparency that works for an end-user interacting with a model like GPT-4 through a specific application like Bing Chat is likely to be different from the approach that works for application developers using an offering like the Azure OpenAI Service to incorporate GPT-4 into their own AI systems. Even a particular end-user may have different transparency needs when using GPT-4 to research a medical procedure versus to caption vacation photos.\nWe take a human-centered approach in which stakeholders and their goals inform the development and evaluation of layered transparency measures. For products where Microsoft designs and develops the end-to-end system, we rely on a combination of product features and documentation to achieve transparency that meets the various needs of stakeholders. For example, Bing Chat’s user-centered design incorporates user experience interventions in the interface itself to disclose that it’s powered by AI and to help users understand the capabilities and limitations of the system. Product FAQs can be a resource for application users that need more context on key issues. For example, our GitHub Copilot FAQ gives context on limitations in the functionality and security of the code it generates as well as some of the human oversight, privacy, and fairness implications of its use,[23] and a Bing Chat Enterprise FAQ provides context on uses and limitations.[24] Other stakeholders, like regulators, may have broader questions and seek deeper context on our approach to developing AI applications; those are best answered outside of the application in stand-alone documentation, such as our Bing Chat whitepaper.[25]\nFor our platform systems like the Azure OpenAI Service, where Microsoft makes models available to customers but doesn’t design an AI system end-to-end, we rely on documentation to communicate information to customers to enable them to integrate those models responsibly. For example, Transparency Notes enable us to communicate the purposes, capabilities, and limitations of AI systems so our customers can understand when and how to deploy our platform technology. Our Azure OpenAI Transparency Note provides context on text, image, and speech models available through that service, describing the techniques the models employ, the use cases for which they’re envisioned, and the limitations and potential biases in their behavior.[26] This Transparency Note builds on the system card documentation that OpenAI itself produces for models like GPT-4.[27]\nBeyond any single platform or product, we believe transparency in research and corporate practice can be effective in helping the public understand the state of the art and in driving organizational accountability. In September, for instance, we released the results of a study, conducted jointly with OpenAI, to explore multimodal text-to-image models, including through red teaming, to understand failure modes, inform engineering efforts to build measurement and mitigation techniques, and reflect on longer-term fairness harms.[28] In July, we committed to releasing an annual transparency report about our policies, systems, progress, and performance in managing AI responsibly and safely. Specifically, our forthcoming, inaugural responsible AI transparency report will address the functioning and ongoing development of our governance systems in addition to providing case studies on the implementation of responsible AI measures.[29]\nTo ensure the latest context informs our responsible AI practices and that we share learnings with others, Microsoft also leverages multiple processes to exchange information. For example, along with Anthropic, Google, and OpenAI, we launched the Frontier Model Forum (FMF) to share best practices and advance AI safety research.[30] We contributed to FMF’s effort to share case studies on red teaming frontier models,[31] and we are collaborating through FMF to develop guidance on “responsible disclosure” processes related to the discovery of vulnerabilities or dangerous capabilities within frontier models. Through the Partnership on AI, we have also contributed to the development of guidance, released for public comment in October, for safe foundation model deployment.[32] In a more security-specific context, Microsoft Threat Intelligence, which tracks and helps defend against the most sophisticated threat actors impacting our customers, also exchanges threat intel information with those best positioned to protect and use it.\nSecurity Controls, Including Securing Model Weights\nResponsible AI is a commitment that extends across the product lifecycle and enabling infrastructure. Microsoft’s decades-long and ongoing investments in developing and implementing state-of-the-art cybersecurity practices are integrated with our defense-in-depth efforts for AI systems and information, including model weights. A holistic approach is critical, including governance of AI security policies and practices; identification of AI systems, data, and supply chains as well as potential risks; protection of systems and information; detection of AI threats; and response to and recovery from discovered AI issues and vulnerabilities, including through rapid containment and continuous improvement processes.\nGovernance is foundational, and along with structures and processes to bring together centralized and distributed security engineering, physical security, threat intelligence, and security operations teams that own implementation and enforcement,[33] SDL[34] requirements, tools, and verification processes are key to our approach. Through SDL implementation, facilitated and monitored by central engineering system teams and our Digital Security & Resilience team led by our CISO among others, all Microsoft products are responsible for SDL practices, including threat modeling to map potential vulnerabilities and measure and manage risk, including through mapped and measured mitigations.\nFor AI technology, we’ve updated our SDL threat modeling requirement to explicitly account for our ongoing learnings about unique AI threats, which we have been in a leader in researching and developing frameworks to systematically organize. For example, along with MITRE and others, we helped create the Adversarial Machine Learning Threat Matrix.[35] Our AI and Ethics in Engineering and Research (AETHER)[36] Security Engineering Guidance added AI-specific threat enumeration and mitigation guidance to existing SDL threat modeling practices,[37] and our AI bug bar provides a severity classification for vulnerabilities commonly impacting AI and machine learning systems.[38] Internal trainings also provide context on threat modeling for AI.\nSDL protection, detection, and response requirements also apply to AI technology. For instance, Microsoft employs strong identity and access control, holistic security monitoring (for both external and internal threats) with rapid incident response, and continuous security validation (such as simulated attack path analysis) for our AI environments.[39] Model weights are encrypted-at-rest and encrypted-in-transit where applicable to mitigate the potential risk of model theft, and more stringent security controls are applied based on risk, such as for protecting highly capable models.[40]\nRobust physical, operational, and network security measures, including for supplier management, identity and access management, and insider threat monitoring, also protect cloud infrastructure.[41] Supplier security and privacy are governed by our Supplier Security and Privacy Assurance program.[42] Access to physical datacenter facilities is tightly controlled, with outer and inner perimeters and increasing security at each level, and subject to a least privileged access policy, whereby personnel with an approved business need are granted time-limited access.[43] We log and retain access requests and analyze data to detect anomalies and prevent and detect unnecessary or unauthorized access.[44] We also employ multiple strategies for securing the network boundary.[45]\nSince making voluntary commitments at the White House convening in July,[46] we have taken key steps to further invest in governance and implementation. We have linked our Responsible AI Standard and content from it within our SDL, strengthening processes for having responsible AI risks inform secure development processes. Our robust integration also reinforces checks against governance steps required by our Responsible AI Standard. (Our Responsible AI Standard also continues to reference SDL, ensuring that cybersecurity risks inform AI risk management. [47])\nReporting Structure for Vulnerabilities Found after Model Release\nMicrosoft is an industry leader in Coordinated Vulnerability Disclosure (CVD), a process whereby vendors receive information from external finders about potential vulnerabilities affecting their products and services and work with those finders to investigate and mitigate confirmed vulnerabilities and release related information publicly in a way that minimizes risk to users. We have published our CVD policy externally, and we have also established a clear process by which we receive vulnerability reports from external finders and work with them throughout the processes of investigating, remediating, and providing public information about confirmed vulnerabilities, including by giving credit to finders.[48] The Microsoft Security Response Center (MSRC) receives all such reports from external finders and manages coordination throughout the CVD process, working with others internally to investigate and remediate as appropriate.[49]\nExternal finders may also be eligible for financial reward as part of our Bug Bounty Programs.[50] Our bounty range varies by product, including up to $100,000 among cloud programs and up to $250,000 among platform programs.[51] In October, we launched a new Microsoft AI bug bounty program reflecting key recent investments and learnings, including from an AI research challenge and the process of updating our vulnerability severity classification for AI systems.[52] This new bounty program, with awards up to $15,000, features the AI-powered Bing experience as the first in-scope product.[53]\nUpon confirmation of a vulnerability received from an external finder, MSRC works with the external finder and relevant internal product team(s) to develop, test, and release a mitigation, often involving a software update. In doing so, Microsoft uses vulnerability severity to prioritize rapid mitigation work, focusing on the most critical issues first (rather than, for example, mitigating issues in the order in which they were received or confirmed).\nTo strengthen transparency with customers and security researchers regarding our approach to risk-based approach to prioritizing rapid mitigation work, we provide vulnerability classifications and severity ratings, including for different classes of products. For example, MSRC maintains a vulnerability severity classification for online services.[54] Recently, we also issued a new vulnerability severity classification for AI systems (i.e., AI bug bar), covering new vulnerability categories arising specifically from the use of AI in our products and services.[55] MSRC also continues to maintain a security update severity rating system that is aligned with our severity classification systems for classes of products (i.e., Low, Moderate, Important, and Critical severity ratings), supporting customers with understanding risk and prioritizing patching.[56]\nMicrosoft is also collaborating with others in industry through the Frontier Model Forum to scope a new “responsible disclosure” process through which providers can receive and share information related to the discovery of vulnerabilities or dangerous capabilities within frontier models.\nTo indicate that a piece of content is AI-generated, there are two common approaches used in Microsoft products, depending on the AI-generated media format: watermarking and metadata-based provenance. Watermarks can be visible (e.g., a logo on an AI-generated image to indicate that it’s AI-generated) or invisible (and thus rely on a detection tool); to establish provenance, information can be included in metadata attached to AI-generated content. A third, less common approach is fingerprinting.\nIn 2021, Microsoft co-founded the Coalition for Content Provenance and Authenticity (C2PA) alongside Adobe, Arm, BBC, Intel, and Truepic and co-developed the C2PA technical specification, the leading open standard upon which an interoperable provenance ecosystem can be built.[57] Much like we treat mailing envelopes or boxes as containers for physical content, digital assets like images and videos are placed inside their own containers. The C2PA specification defines how to embed a cryptographically sealed, verifiable unit of provenance information called a “C2PA Manifest” inside a digital asset’s container. For example, when a user creates an image with C2PA-enabled software, it will generate a provenance manifest and cryptographically bind it to the JPEG file. Verification tools can then be used to view the manifest attached to the image since it is embedded in the JPEG file structure, or “container,” itself.[58] C2PA is also designed for use as the final signing step before content is shared or published.\nMicrosoft has been working along with others in C2PA to implement the specification, improving transparency and helping to drive the broader ecosystem forward. In May 2023, we announced new media provenance capabilities and plans to use C2PA to mark and sign AI-generated images produced by Microsoft Designer and Bing Image Creator.[59]\nBing Image Creator now discloses content as AI generated automatically. We are also advancing provenance capabilities in Azure OpenAI for internal product teams.\nAs part of our broader AI safety strategy of taking an iterative approach to risk management and driving continuous improvement, we are also investing in research and evaluation of techniques to enhance robustness. For example, as a potential layered mitigation beyond metadata-based provenance, we are also exploring a fingerprinting solution to help identify if an image was AI generated.\nMicrosoft and others are also continuing to invest in developing and promoting C2PA. For instance, while the specification to date can only be used with some digital assets, C2PA is continually expanding the standard to support new media formats. In April, the latest specification update added support for many new formats, including MPF, WebP, AIFF, AVI, and GIF.[60]\nPrioritizing Research on Risks Posed by AI\nAcross multiple teams within Microsoft, we are investing in both internal and external efforts to accelerate research on AI safety, security, and societal impact and to increase access to AI resources. Internally, Microsoft Research significantly invests in AI, focusing efforts on 1) understanding general AI, taking inspiration from the study of human intelligence and from the prediction and observation of natural phenomena; 2) driving model innovation, in pursuit of more capable and aligned forms of AI; 3) ensuring societal benefit through trustworthy AI that supports human flourishing; 4) transforming scientific discovery, including with our recently established AI4Science organization; and 5) extending human capabilities, incubating novel AI applications in industries such as agriculture and healthcare.[61]\nMicrosoft Research is also expanding and diversifying its collaborators network and working to foster a vibrant global AI research community. Microsoft Research has recently launched Accelerate Foundation Models Research (AFMR), a research grant program through which we aim to facilitate interdisciplinary research on aligning AI with human goals, values, and preferences; improving human interactions via sociotechnical research; and accelerating scientistic discovery in natural sciences.[62] After managing a pilot phase that launched earlier this year, we expanded the program and have now selected 125 new projects from 75 institutions across 13 countries. The focus of our first open call for proposals was on aligning AI systems with human goals and preferences; advancing beneficial applications of AI; and accelerating scientific discovery in the natural and life sciences. As we continue to expand the breadth of our reach with academic partnerships, we will also continue to expand the depth of our research, including in areas like AI evaluation and measurement.\nMicrosoft Research and other teams also collaborate with researchers, practitioners, and other experts in industry and civil society organizations to advance knowledge of safety risks and best practices for safety and security techniques.\nIn July, Microsoft worked with three other leading AI companies to launch the Frontier Model Forum, which is bringing together technical experts to define consensus best practices for the responsible development and deployment of frontier models.[63]\nIn August, our AI Red Team, an expert group independent to our product groups, participated in this year’s DEF CON AI Village, a platform for researchers to share the latest on AI systems and the state of the art in defending and attacking them.[64]\nIn September, we released the results of a study, conducted jointly with OpenAI, to explore multimodal text-to-image models, including through red teaming to understand failure modes and engineering efforts to build measurement and mitigation techniques.[65]\nIn October, Partnership on AI released for public comment guidance to which we contributed on safe foundation model deployment, aiming to provide tools and knowledge to foster responsible development and deployment of AI models with a focus on safety for society and adaptability to support evolving capabilities.[66] We’ve previously contributed to other Partnership on AI multi-stakeholder group efforts, including on the development of practices for AI-generated media disclosure.\nWe are also supportive of national and global efforts to establish AI computing resources for academic research. In May, Microsoft advocated not only for the establishment of a National AI Research Resource in the United States as introduced by 2020 legislation but also for an extension to accommodate access by academic institutions in allied nations abroad, including the European Union, Japan, the United Kingdom, and other like-minded countries.[67] An important complement to providing such access is the development of governance best practices for the academic community engaged in frontier research on applications and the safety and security of highly capable models, and Microsoft would also welcome the opportunity to help develop such practices within a collaborative multi-stakeholder group.\nPreventing and Monitoring Model Misuse\nAt Microsoft, maintaining AI products that adhere to our responsible AI commitments throughout their product lifecycle means that they are subject to an iterative cycle of mapping, measuring, and managing risk pre and post deployment. This means that policies and practices across multiple areas of inquiry on which we have provided context in this update, including model evaluation and red teaming, security controls, and data input controls, must be implemented iteratively as appropriate. (Reference those sections for fuller context on our policies and practices for preventing and monitoring for model misuse.) Oversight of these ongoing processes through our robust governance structures is just as critical for product monitoring and maintenance – and continuous learning and improvement – as it is in advance of a product launch.\nAs we learn about new patterns of misuse or incidents, through our own ongoing research or internal red teaming or from external reports, we must be prepared to act to contain issues, enhance products, implement new mitigations, and otherwise protect customers. To strengthen readiness, we continuously research and engage with partners to improve mitigation techniques, and we regularly test and as necessary adjust plans to respond to incidents or detections of new potential patterns of misuse. We also regularly assess and as necessary adjust our policies to strengthen security controls and customer transparency.\nIn addition, our AI products have built-in or add-on capabilities particularly focused on monitoring for patterns of misuse post deployment, and learnings feed back into product development to strengthen ongoing preventative efforts grounded in mapping, measuring, and mitigating practices (as described in detail in the Model Evaluations and Red Teaming section). For example, Azure OpenAI abuse monitoring detects and mitigates instances of recurring content and/or behaviors that suggest use of the service in a manner that may violate our code of conduct or other applicable product terms.[68]\nData Input Controls and Audit\nMicrosoft is committed to implementing and supporting responsible data policies and practices for inputs and outputs of AI models and applications. Our Responsible AI Standard and accompanying privacy, security, and accessibility standards, which apply to all AI systems that we develop and deploy, establish numerous data requirements impacting all our Responsible AI principles.[69] As a result, product teams may be required to assess the quantity and suitability of data sets, inclusiveness of data sets, representation of intended uses in training and test data, limitations to generalizability of models given training and testing data, and how they meet data collection and processing requirements among other mandates. Our Impact Assessment and other Responsible AI tools help teams conduct these assessments and provide documentation for review.\nThrough transparency mechanisms, Microsoft also provides context to customers and other stakeholders on data processed by AI systems like the Azure OpenAI Service, including user prompts and generated content, augmented data included with prompts (i.e., for grounding), and user-provided training and validation data.[70] Customer data is also processed to analyze prompts, completions, and images for harmful content or patterns of use that may violate our Code of Conduct or other applicable product terms.[71] Established policies dictate that training data and fine-tuned models are available exclusively for use by the customer, are stored within the same region as the Azure OpenAI resource, can be double encrypted at rest (by default with Microsoft’s AES-256 encryption and optionally with a customer-managed key), and can be deleted by the customer at any time.[72] All applicable data processed by AI products is also subject to Microsoft’s General Data Protection Regulation (GDPR)[73] and other legal commitments and data privacy and security compliance offerings.[74]\nMicrosoft supports several existing technical mechanisms that content providers can use to restrict access to their data. This can be done by a number of technical measures, including putting content behind a paywall or using other means to technically restrict access. Content providers may also implement mechanisms to indicate that they do not intend the content that they make publicly accessible to be scaped by using machine-readable means, such as the robots.txt web standard.\nGuardrails in our Copilots also help respect authors’ copyrights.[75] We have incorporated filters and other technologies that are designed to reduce the likelihood that Copilots return infringing content. These build on and complement our work to protect digital safety, security, and privacy, based on a broad range of capabilities and techniques, many of which were introduced above, including classifiers, metaprompts, content filtering, and operational monitoring and abuse detection.\nJust as we’ve leveraged our industry-leading compliance efforts to support cloud customers in meeting GDPR and other obligations, earlier this year, we announced commitments to inform and advance customers’ responsible AI governance and compliance.[76] In September, we built on these commitments by announcing our new Copilot Copyright Commitment, which allows customers to use Microsoft’s new Copilot services and the output they generate without worrying about copyright claims. Specifically, if a third party sues a commercial customer for copyright infringement for using one of Microsoft’s Copilots or the output they generate, then we will defend the customer and pay the amount of any resulting adverse judgments or settlements as long as the customer has used the guardrails and content filters that we have built into our products.[77]\nMicrosoft appreciates the opportunity to contribute to the UK’s AI Safety Summit and to provide information in response to its inquiry about safety policies. Ongoing public-private dialogue is critical to rapidly advancing a shared understanding of effective practices and evaluation techniques. We look forward to the UK’s next steps in convening the upcoming Summit, carrying forward efforts to strengthen global coordination of AI safety evaluations, and supporting greater international collaboration on research and codes of practice through the G7, Organization for Economic Co-operation and Development (OECD), and other multi-lateral and multi-stakeholder forums.\n[1] Our commitments to advance safe, secure, and trustworthy AI – Microsoft On the Issues\n[3] AI Risk Management Framework | NIST\n[4] Reflecting on our responsible AI program: Three critical elements for progress – Microsoft On the Issues\n[5] How do we best govern AI? – Microsoft On the Issues\n[7] Development of an Impact Assessment is required by Goal A1 of our Responsible AI standard, and use of the Assessment is prompted through other Requirements of the standard. Microsoft Responsible AI Standard v2 General Requirements\n[9] Microsoft AI Red Team building future of safer AI | Microsoft Security Blog\n[10] Microsoft AI Red Team building future of safer AI | Microsoft Security Blog\n[11] Microsoft AI Red Team building future of safer AI | Microsoft Security Blog; https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RW14Gtw\n[13] Monitoring evaluation metrics descriptions and use cases (preview) – Azure Machine Learning | Microsoft Learn\n[14] Responsible AI dashboard | Microsoft AI Lab, Microsoft Responsible AI Toolbox – Microsoft Responsible AI, Use Responsible AI scorecard (preview) in Azure Machine Learning – Azure Machine Learning | Microsoft Learn\n[15] Microsoft Build brings AI tools to the forefront for developers – The Official Microsoft Blog; What is Azure Machine Learning prompt flow (preview) – Azure Machine Learning | Microsoft Learn\n[16] Azure OpenAI Service content filtering – Azure OpenAI | Microsoft Learn\n[17] Azure AI Content Safety – AI Content Moderation | Microsoft Azure\n[18] Introducing Llama 2 on Azure (microsoft.com)\n[19] The new Bing – Our approach to Responsible AI\n[20] Responsible AI Principles and Approach | Microsoft AI; Responsible AI Standard v2 Goal T2: Communication to Stakeholders\n[21] The building blocks of Microsoft’s responsible AI program – Microsoft On the Issues\n[22] Microsoft Responsible AI Standard v2 General Requirements\n[23] GitHub Copilot · Your AI pair programmer · GitHub\n[24] Frequently asked questions about Bing Chat Enterprise | Microsoft Learn\n[25] The new Bing – Our approach to Responsible AI\n[26] Transparency Note for Azure OpenAI – Azure AI services | Microsoft Learn\n[28] Frontiers of multimodal learning: A responsible AI approach – Microsoft Research\n[30] Microsoft, Anthropic, Google, and OpenAI launch Frontier Model Forum – Microsoft On the Issues\n[32] Partnership on AI Releases Guidance for Safe Foundation Model Deployment, Takes the Lead to Drive Positive Outcomes and Help Inform AI Governance Ahead of AI Safety Summit in UK –\n[33] Some of the teams include Azure Security (responsible for continuously improving the built-in security posture of Azure at all layers: the datacenter, physical infrastructure, and cloud products and services); Cyber Defense Operations Center (a fusion center that brings together incident responders, data scientists, and security engineers to provide around-the-clock protection to our corporate infrastructure and cloud infrastructure that customers use); Digital Security & Resilience (organization led by our CISO and dedicated to enabling Microsoft to build the most trusted devices and services while keeping our company and customers protected); Identity and Network Access (identity platform security and defense); Microsoft Defender Experts and Microsoft Defender Threat Intelligence (product-focused security researchers, applied scientists, and threat intelligence analysts); Microsoft Security Response Center (vulnerability research and response); and Microsoft Threat Intelligence Center (team dedicated to identifying and tracking the most sophisticated adversaries impacting Microsoft customers).\n[34] Microsoft Security Development Lifecycle\n[35] Cyberattacks against machine learning systems are more common than you think | Microsoft Security Blog\n[36] Satya Nadella email to employees: Embracing our future: Intelligent Cloud and Intelligent Edge – Stories (microsoft.com)\n[37] Threat Modeling AI/ML Systems and Dependencies – Security documentation | Microsoft Learn\n[38] Microsoft Vulnerability Severity Classification for Artificial Intelligence and Machine Learning Systems\n[41] What is Cloud Infrastructure? | Microsoft Azure\n[42] Supplier management overview – Microsoft Service Assurance | Microsoft Learn\n[43] Datacenter physical access security – Microsoft Service Assurance | Microsoft Learn\n[44] Datacenter physical access security – Microsoft Service Assurance | Microsoft Learn\n[45] Network security – Microsoft Service Assurance | Microsoft Learn\n[46] Our commitments to advance safe, secure, and trustworthy AI – Microsoft On the Issues\n[47] Microsoft Responsible AI Standard v2 General Requirements (see Goal PS2)\n[49] MSRC Researcher Portal (microsoft.com)\n[51] Microsoft Bounty Programs | MSRC\n[52] Introducing the Microsoft AI Bug Bounty Program featuring the AI-powered Bing experience | MSRC Blog | Microsoft Security Response Center\n[53] Microsoft AI Bounty | MSRC\n[54] Microsoft Vulnerability Severity Classification for Online Services\n[55] Microsoft Vulnerability Severity Classification for Artificial Intelligence and Machine Learning Systems\n[56] Security Update Severity Rating System (microsoft.com)\n[57] C2PA Explainer :: C2PA Specifications\n[59] Microsoft Build brings AI tools to the forefront for developers – The Official Microsoft Blog\n[60] C2PA Technical Specification :: C2PA Specifications\n[61] AI and Microsoft Research – Microsoft Research\n[62] Accelerate Foundation Models Research: Supporting a global academic research ecosystem for AI – Microsoft Research\n[63] Microsoft, Anthropic, Google, and OpenAI launch Frontier Model Forum – Microsoft On the Issues\n[64] AI Village at DEF CON announces largest-ever public Generative AI Red Team – AI Village\n[65] Frontiers of multimodal learning: A responsible AI approach – Microsoft Research\n[66] Partnership on AI Releases Guidance for Safe Foundation Model Deployment, Takes the Lead to Drive Positive Outcomes and Help Inform AI Governance Ahead of AI Safety Summit in UK –\n[67] Governing AI: A Blueprint for the Future (microsoft.com)\n[68] Data, privacy, and security for Azure OpenAI Service – Azure AI services | Microsoft Learn. To detect and mitigate abuse, Azure OpenAI stores all prompts and generated content security for up to 30 days (unless a customer is approved for and elects to configure abuse monitoring off, which requires meeting our Limited Access eligibility criteria and attesting to restricting use to specific use cases. Limited Access features for Azure AI services – Azure AI services | Microsoft Learn\n[69] Microsoft Responsible AI Standard v2 General Requirements",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "“Dirty stream” attack: Discovering and mitigating a common vulnerability pattern in Android apps",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/05/01/dirty-stream-attack-discovering-and-mitigating-a-common-vulnerability-pattern-in-android-apps/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNTZiVWRmUVdveVpVcExXbkJYVFJDM0FSaVRBaWdCTWdZMVZJcHdvUWc=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-01T07:00:00.000Z",
    "time": "May 1",
    "articleType": "regular",
    "content": "Microsoft discovered a path traversal-affiliated vulnerability pattern in multiple popular Android applications that could enable a malicious application to overwrite files in the vulnerable application’s home directory. The implications of this vulnerability pattern include arbitrary code execution and token theft, depending on an application’s implementation. Arbitrary code execution can provide a threat actor with full control over an application’s behavior. Meanwhile, token theft can provide a threat actor with access to the user’s accounts and sensitive data.\nWe identified several vulnerable applications in the Google Play Store that represented over four billion installations. We anticipate that the vulnerability pattern could be found in other applications. We’re sharing this research so developers and publishers can check their apps for similar issues, fix as appropriate, and prevent introducing such vulnerabilities into new apps or releases.  As threats across all platforms continue to evolve, industry collaboration among security researchers, security vendors, and the broader security community is essential in improving security for all. Microsoft remains committed to working with the security community to share vulnerability discoveries and threat intelligence to protect users across platforms.\nAfter discovering this issue, we identified several vulnerable applications. As part of our responsible disclosure policy, we notified application developers through Coordinated Vulnerability Disclosure (CVD) via Microsoft Security Vulnerability Research (MSVR) and worked with them to address the issue. We would like to thank the Xiaomi, Inc. and WPS Office security teams for investigating and fixing the issue. As of February 2024, fixes have been deployed for the aforementioned apps, and users are advised to keep their device and installed applications up to date.\nRecognizing that more applications could be affected, we acted to increase developer awareness of the issue by collaborating with Google to publish an article on the Android Developers website, providing guidance in a high-visibility location to help developers avoid introducing this vulnerability pattern into their applications. We also wish to thank Google’s Android Application Security Research team for their partnership in resolving this issue.\nIn this blog post, we continue to raise developer and user awareness by giving a general overview of the vulnerability pattern, and then focusing on Android share targets, as they are the most prone to these types of attacks. We go through an actual code execution case study where we demonstrate impact that extends beyond the mobile device’s scope and could even affect a local network. Finally, we provide guidance to users and application developers and illustrate the importance of collaboration to improve security for all.\nOverview: Data and file sharing on Android\nThe Android operating system enforces isolation by assigning each application its own dedicated data and memory space. To facilitate data and file sharing, Android provides a component called a content provider, which acts as an interface for managing and exposing data to the rest of the installed applications in a secure manner. When used correctly, a content provider provides a reliable solution. However, improper implementation can introduce vulnerabilities that could enable bypassing of read/write restrictions within an application’s home directory.\nThe Android software development kit (SDK) includes the FileProvider class, a subclass of ContentProvider that enables file sharing between installed applications. An application that needs to share its files with other applications can declare a FileProvider in its app manifest and declare the specific paths to share.\nEvery file provider has a property called authority, which identifies it system-wide, and can be used by the consumer (the app that wants to access the shared files) as a form of address. This content-based model bears a strong resemblance to the web model, but instead of the http scheme, consumers utilize the content scheme along with the authority, followed by a pseudo-path to the file that they want to access.\nFor example, assuming that the application com.example.server shares some files under the file:///data/data/com.example.server/files/images directory that it has previously declared as shared using the name shared_images, a consumer can use the content://[authority]/shared_images/[sub-path]/[filename] URI to index these files.\nAccess is given by the data sharing application most commonly using the grantUriPermissions attribute of the Android manifest, in combination with special flags that are used to define a read or write mode of operation. The data sharing application creates and sends an intent to the consumer that provides temporary fine-grained access to a file.  Finally, when a provider receives a file access request, it resolves the actual file path that corresponds to the incoming URI and returns a file descriptor to it.\nThis content provider-based model provides a well-defined file-sharing mechanism, enabling a serving application to share its files with other applications in a secure manner with fine-grained control. However, we have frequently encountered cases where the consuming application doesn’t validate the content of the file that it receives and, most concerning, it uses the filename provided by the serving application to cache the received file within the consuming application’s internal data directory. If the serving application implements its own malicious version of FileProvider, it may be able to cause the consuming application to overwrite critical files.\nIn simple terms, a share target is an Android app that declares itself to handle data and files sent by other apps. Common application categories that can be share targets include mail clients, social networking apps, messaging apps, file editors, browsers, and so on. In a common scenario, when a user clicks on a file, the Android operating system triggers the share-sheet dialog asking the user to select the component that the file should be sent to:\nFigure 1. The Android share sheet dialog\nWhile this type of guided file-sharing interaction itself may not trigger a successful attack against a share target, a malicious Android application can create a custom, explicit intent and send a file directly to a share target with a malicious filename and without the user’s knowledge or approval. Essentially, the malicious application is substituting its own malicious FileProvider implementation and provides a filename that is improperly trusted by the consuming application.\nFigure 2. Dirty stream attack\nIn Figure 2, the malicious app, on the left, creates an explicit intent that targets the file processing component of the share target, on the right, and attaches a content URI as an intent’s extra. It then sends this intent to the share target using the startActivity API call.\nAfter this point, most of the share targets that we have reviewed seem to follow a specific code pattern that includes the following steps:\nRequest the actual filename from the remote file provider\nUse this filename to initialize a file that is subsequently used to initialize a file output stream\nCreate an input stream using the incoming content URI\nCopy the input stream to the output stream\nSince the rogue app controls the name as well as the content of the file, by blindly trusting this input, a share target may overwrite critical files in its private data space, which may lead to serious consequences.\nWe identified this vulnerability pattern in the then-current versions of several Android applications published on the Google Play Store, including at least four with more than 500 million installations each. In each case, we responsibly disclosed to the vendor. Two example vulnerable applications that we identified are Xiaomi Inc.’s File Manager (1B+ installs) and WPS Office (500M+ installs).\nIn Xiaomi Inc.’s File Manager, we were able to obtain arbitrary code execution in version V1-210567. After our disclosure, Xiaomi published version V1-210593, and we verified that the vulnerability has been addressed. In WPS Office, we were able to obtain arbitrary code execution in version 16.8.1. After our disclosure, WPS published and informed us that the vulnerability has been addressed as of version 17.0.0.\nThe potential impact varies depending on implementation specifics. For example, it’s very common for Android applications to read their server settings from the shared_prefs directory. In such cases, the malicious app can overwrite these settings, causing the vulnerable app to communicate with an attacker-controlled server and send the user’s authentication tokens or other sensitive information.\nIn a worst-case (and not so uncommon) scenario, the vulnerable application might load native libraries from its data directory (as opposed to the more secure /data/app-lib directory, where the libraries are protected from modification). In this case, the malicious application can overwrite a native library with malicious code that gets executed when the library is loaded. In the following section, we use Xiaomi Inc.’s File Manager to illustrate this case. We demonstrated the ability for a malicious application to overwrite the application’s shared preferences, write a native library to the application’s internal storage, and cause the application to load the library. These actions provided arbitrary code execution with the file manager’s user ID and permissions.\nIn the following sections, we focus on this case and delve into the technical details of this vulnerability pattern.\nCase study: Xiaomi Inc.’s File Manager\nXiaomi Inc.’s File Manager is the default file manager application for Xiaomi devices and is published under the package name com.mi.android.globalFileexplorer on the Google Play Store, where it has been installed over one billion times.\nFigure 3. Xiaomi’s File Manager profile according to Android rank (source: File Manager)\nBesides having full access to the device’s external storage, the application requests many permissions, including the ability to install other applications:\nFigure 4. A snapshot of the application’s permissions\nFurther, it offers a junk files cleaner plugin as well as the ability to connect to remote FTP and SMB shares:\nFigure 5. Connecting to remote shares using the file manager\nDuring our investigation, we identified that the application exports the CopyFileActivity, an activity alias of the com.android.fileexplorer.activity.FileActivity, which is used to handle copy-from-to file operations:\nFigure 6. Triggering the copy to CopyFileActivity\nSince this activity is exported, it can be triggered by any application installed on the same device by using an explicit intent of action SEND or SEND_MULTIPLE and attaching a content URI corresponding to a file stream.\nUpon receiving such an intent, the browser performs a validity check, which we found to be insufficient:\nFigure 7. Validating an incoming copy file request\nAs depicted above, the initCopyOrMoveIntent method calls the checkValid method passing as an argument a content URI (steps 1 and 2). However, the checkValid method is designed to handle a file path, not a content URI. It always returns true for a content URI. Instead, a safer practice is to parse the string as a URI, including ensuring the scheme is the expected value (in this case, file, not content).The checkValid method verifies that the copy or move operation doesn’t affect the private directory of the app, by initializing a file object using the incoming string as an argument to the File class constructor and comparing its canonical path with the path that corresponds to the home directory of the application (steps 3 and 4). Given a content URI as a path, the File constructor normalizes it (following a Unix file system normalization), thus the getCanonicalPath method returns a string starting with “/content:/“, which will always pass the validity check. More specifically, the app performs a query to the remote content provider for the _size, _display_name and _data columns (see line 48 below). Then it uses the values returned by these rows to initialize the fields of an object of the com.android.fileexplorer.mode.c class:\nFigure 8. Getting file metadata from the remote content provider\nGiven the case that the _display_name and _data values, returned from the external file provider, are relative paths to the destination directory, after exiting from the method above, these class fields will contain values like the ones depicted below:\nFigure 9. The file model initialized after calling the method a\nAs shown above, the paths (variables d and e) of this file-model point to files within the home directory of the application, thus the file streams attached to the incoming intent are going to be written under the specific locations.\nAs previously mentioned, the application uses a plugin to clean the device’s junk files:\nFigure 10. The junk files cleaner plugin user interface\nWhen the application loads this plugin, it makes use of two native libraries: libixiaomifileu.so, which fetches from the /data/app directory, and libixiaomifileuext.so from the home directory:\nFigure 11. Tracing the loaded native libraries using medusa\nAs apps don’t have write access to the /data/app folder, the libixiaomifileu.so file stored there cannot be replaced. The easiest way to get code execution is to replace the libixiaomifileuext.so with a malicious one. However, an attempt to do so would fail since in this particular case, the vulnerability that we described can only be used to write new files within the home directory, not overwrite existing files. Our next inquiry was to determine how the application loads the libixiaomifileu.so.\nOur assessment showed that before the application loads this library, it follows the following steps:\nCalculate the hash of the file libixiaomifileu.so, located in the /data/app directory\nCompare this hash with the value assigned to the “libixiaomifileu.so_hm5” string, fetched from the com.mi.android.globalFileexprorer_preferences.xml file\nIf the values don’t match, search for the libixiaomifileu.so file in the /files/lib path in the home directory\nIf the file is found there, calculate its hash and compare it again with the value from the shared_preferences folder\nIf the hashes match, load the file under the /files/lib using the System.load method\nGiven this behavior, in order to get code execution with the file manager’s user ID, an attacker must take the following steps:\nUse the path traversal vulnerability to save a malicious library as /files/lib/libixiaomifileu.so (the file does not already exist in that directory, so overwriting is not an issue)\nCalculate the hash of this library to replace the value of the libixiaomifileu.so_hm5 string\nTrigger the junk cleaner plugin with an explicit intent, since the activity that loads the native libraries is exported\nAn acute reader might have noticed that the second step requires the attacker to force the browser to overwrite the com.mi.android.globalFileexprorer_preferences.xml, which, as we already mentioned, was not possible.\nTo overcome this restriction, we referred to the actual implementation of the SharedPreferences class, where we found that when an Android application uses the getSharedPreferences API method to retrieve an instance of the SharedPreferences class, giving the name of the shared preferences file as an argument, then the constructor of the SharedPreferencesImpl class performs the following steps:\nCreate a new file object using the name provided to the getSharedPreferences method, followed by the .xml extension, followed by the .bak extension\nCheck if this file exists, and in case it does, delete the original xml file and replace it with the one created in the first step\nThrough this behavior, we were able to save the com.mi.android.globalFileexprorer_preferences.xml.bak under the shared preferences folder (as during the application’s runtime it is unlikely to exist), so when the app tried to verify the hash, the original xml file was already replaced by our own copy. After this point, by using a single intent to start the junk cleaner plugin, we were able to trick the application to load the malicious library instead of the one under the /data/app folder and get code execution with the browser’s user ID.\nOne reason we chose to use this app as a showcase is because the impact extends beyond the user’s mobile device. The application gives the option to connect to remote file shares using the FTP and SMB protocols and the user credentials are saved in clear text in the /data/data/com.mi.android.globalFileexplorer/files/rmt_i.properties file:\nFigure 13. SMB/FTP credentials saved in clear text\nIf a third party app was able to exploit this vulnerability and obtain code execution, an attacker could retrieve these credentials. The impact would then extend even further, since by the time that a user requests to open a remote share, the browser creates the directory /sdcard/Android/data/com.mi.android.globalFileexplorer/files/usbTemp/ where it saves the files that the user retrieves:\nFigure 14. SMB shared files, saved in the external storage\nThis means that a remote attacker would be able to read or write files to SMB shares of a local network, assuming that the device was connected to it. The same stands for FTP shares as they are handled exactly in the same way:\nFigure 15. FTP shared files, saved in the external storage\nIn summary, the exploitation flow is depicted in the figure below:\nFigure 16. Getting remote access to local shares\nIn step 1, the user opens a malicious app that may pose as a file editor, messaging app, mail client, or any app in general and request the user to save a file. By the time that the user attempts to save such a file, no matter what destination path they choose to save it, the malicious app forces the file browser app to write it under its internal /files/lib folder. Then, the malicious app can start the junk cleaner using an explicit intent (no user interaction is required) and this will lead to code execution with the browser’s ID (step 2).\nIn step 3, the attacker uses the arbitrary code execution capability to retrieve the SMB and FTP credentials from the rmt_i.properties file. Subsequently, the attacker can now jump to step 5 and access the shares directly using the stolen credentials. Alternatively, after retrieving the share credentials, the mobile device can connect to a local network (step 4) and access an SMB or FTP share, allowing the attacker to access the shared files through the /sdcard/Android/data/com.mi.android.globalFileexplorer/files/usbTemp/ folder (step 5).\nRecognizing that this vulnerability pattern may be widespread, we shared our findings with Google’s Android Application Security Research team. We collaborated with Google to author guidance for Android application developers to help them recognize and avoid this pattern. We recommend developers and security analysts familiarize themselves with the excellent Android application security guidance provided by Google as well as make use of the Android Lint tool included with the Android SDK and integrated with Android Studio (supplemented with Google’s additional security-focused checks) to identify and avoid potential vulnerabilities. GitHub’s CodeQL also provides capabilities to identify vulnerabilities.\nTo prevent these issues, when handling file streams sent by other applications, the safest solution is to completely ignore the name returned by the remote file provider when caching the received content. Some of the most robust approaches we encountered use randomly generated names, so even in the case that the content of an incoming stream is malformed, it won’t tamper with the application.\nIn cases where such an approach is not feasible, developers need to take extra steps to ascertain that the cached file is written to a dedicated directory. As an incoming file stream is usually identified by a content URI, the first step is to reliably identify and sanitize the corresponding filename. Besides filtering characters that may lead to a path traversal and before performing any write operation, developers must verify that the cached file is within the dedicated directory by performing a call to the File.getCanonicalPath and validating the prefix of the returned value.\nAnother area to safeguard is in the way developers try to extract a filename from a content URI. Developers often use Uri.getLastPathSegment(), which returns the (URL) decoded value of the last path URI segment. An attacker can craft a URI with URL encoded characters within this segment, including characters used for path traversal. Using the returned value to cache a file can again render the application vulnerable to this type of attack.\nFor end users, we recommend keeping mobile applications up to date through the Google Play Store (or other appropriate trusted source) to ensure that updates addressing known vulnerabilities are installed. Users should only install applications from trusted sources to avoid potentially malicious applications. We recommend users who accessed SMB or FTP shares through the Xiaomi app before updates to reset credentials and to investigate for any anomalous behavior. Microsoft Defender for Endpoint on Android can alert users and enterprises to malicious applications, and Microsoft Defender Vulnerability Management can identify installed applications with known vulnerabilities.\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.\nTo hear stories and insights from the Microsoft Threat Intelligence community about the ever-evolving threat landscape, listen to the Microsoft Threat Intelligence podcast: https://thecyberwire.com/podcasts/microsoft-threat-intelligence.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "New Microsoft security tools to protect families and businesses",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/09/21/new-microsoft-security-tools-to-protect-families-and-businesses/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWhkbFZDVDJGclduSnhlSFJsVFJDM0FSaVRBaWdCTWdZZHBZek1OUVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-21T07:00:00.000Z",
    "time": "Sep 21, 2023",
    "articleType": "regular",
    "content": "Today marks an exciting milestone in Microsoft’s AI journey. This morning, at an event in New York City, we made several major announcements to empower people across work and life—you can read more about Microsoft Bing and Edge with Copilot, what’s new from Microsoft 365 Copilot and Bing Chat Enterprise for work, Microsoft Designer and Copilot in Microsoft 365, Windows 11, and new Surface devices in Yusuf Medhi’s blog.\nThese innovations will redefine how we live and work with AI, and it’s so exciting to see the progress we are making to put AI and other capabilities into the hands of our customers across every aspect of their whole lives.\nAs we rapidly iterate and improve technology, it’s imperative that we do so with a security-first mindset. This means both building products that are secure by default and ensuring that we are adopting and deploying new technologies, like AI, in a secure and responsible way.\nDesigning Windows security for the new era\nToday, we shared the upcoming Windows 11 update that will be available on September 26, 2023. That update includes several important security features and updates that help make this the most personal and intelligent Windows experience yet. I want to take a moment to highlight some of the key security features you’ll hear more about next week:\nWe’ve talked for years about the passwordless future that we envision here at Microsoft. We know that passwords are one of the most common entry points for attacks—in fact, there are more than 4,000 password attacks every second—a nearly three-fold increase since last year.1 That’s why it’s more important than ever for organizations and individuals to use passwordless options whenever possible. In the Windows 11 update, we’re excited to introduce:\nEven more passwordless: IT teams will now be able to remove the option to enter a password on day one for all Windows 11 devices with Windows Hello for Business, prompting employees to use more secure login options.\nMore with passkeys: For the past several years we have been committed to working with our industry partners and the FIDO Alliance to further the passwordless future with passkeys. Passkeys are the cross-platform, cross-ecosystem future of accessing websites and applications. Today we are pleased to share that Windows 11 users can better take advantage of passkeys. After creating a passkey with Windows Hello, you can access a website or application using your face, fingerprint, or device PIN. You can manage passkeys stored on your Windows PC and sign in using passkeys saved on your mobile phone for added convenience. You can use passkeys on a variety of services such as GitHub.com, DocuSign.com, and more.\nEmpowering IT with new security tools\nThe latest Windows 11 will also include powerful new tools that empower IT teams to keep their organizations and employees more secure, including:\nCustom App Control for Business policies with Microsoft Intune: Applications are the lifeblood of our digital experiences, but they can also become entry points for threats. With application control, apps must earn trust to run, ensuring only approved, secure, and trusted apps are allowed onto devices. By preventing unwanted or malicious code from running, application control is a critical part of a comprehensive security strategy. Application control is often cited as one of the most effective means of defending against malware. Customers can now use App Control for Business (formerly called Windows Defender Application Control) and its next-generation capabilities to protect their digital estate from malicious code. With App Control for Business, IT teams can configure what runs in a business environment through Microsoft Intune or other MDMs in the admin console, including setting up Intune as a managed installer.\nConfig Refresh: We often uncover threat actors launching attacks designed to evade security measures by changing settings and system configurations. Config Refresh enables settings in the Policy Configuration Service Provider (CSP) on a Windows 11 device to be reset every 90 minutes by default, or every 30 minutes if desired. This protects against configuration settings being unexpectedly changed through either malicious software or registry edits and ensures that your settings are retained in the way IT configured them.\nWe will share more details about these and other new Windows 11 features next week.\nNew advanced security for Microsoft 365 Personal, Family, and Basic subscribers\nAs a company, we are also thinking about how we equip individuals with tools and information to better protect themselves at home. Today, we are excited to announce new advanced security benefits for Microsoft 365 Personal, Family, and Basic subscribers.\nMicrosoft Defender for individuals introduces credit monitoring and privacy protection in the United States\nToday, we shared two new additions to Microsoft Defender for individuals that will help individuals and families protect their personal data online:\nCredit monitoring: The Defender identity theft monitoring capabilities will now be expanded with new credit monitoring functionality. Users will get an alert any time there is activity related to their credit that might be malicious, enabling them to act quickly and help stop activity while it’s occurring.\nPrivacy protection: Privacy protection shields sensitive data from threats when users are connected to open and public Wi-Fi networks. It reduces online tracking and protects against bad actors on unsecured network and enables users to hide their IP address and location from websites, apps, and advertisers that may attempt to track online activity to collect personal data. Privacy protection also encrypts traffic and data through a VPN.\nOneDrive advanced security in Microsoft 365 Basic\nEarlier this year, we launched our most affordable subscription plan, Microsoft 365 Basic. As promised, we’re now adding the OneDrive advanced security features in our Microsoft 365 Personal and Family plans to the Microsoft 365 Basic plan at no extra cost. Starting October 12, 2023, Microsoft 365 Basic subscribers will have access to OneDrive advanced security features like unlimited files in your Personal Vault, expiring sharing links, password-protected sharing links, files restore, and ransomware detection and recovery. Microsoft 365 Basic continues to offer 100 GB of cloud storage and incredible peace of mind benefits at an incredible price.\nUsing AI securely and responsibly\nAs we celebrate our advancements across AI, it’s important to reiterate our commitment to deploying these technologies securely and responsibly. I have been lucky enough to have had a front-row seat as we built, tested, and iterated on these amazing AI technologies. But as we’ve watched this evolve, we recognize that, as Spider-Man would say, “With great power, comes great responsibility.” That is why we are committed to building and deploying AI responsibly and ethically. You can read more about our commitments at the Empowering Responsible AI practices hub.\nWe’ve heard from customers and seen firsthand that employees are eager to use AI in the workplace. But many leaders have concerns about the use of AI in their organizations. They worry that it can introduce unnecessary risk. That’s why we are taking a safe and secure approach for customers, empowering them to feel confident in using AI at work. For example, Bing Chat Enterprise helps employees tap into the power of AI while ensuring prompts and responses aren’t logged or used to train the underlying model. Our commitments to enterprise-grade security, privacy, identity, compliance, and responsible AI in Microsoft 365 Copilot remain unchanged. And lastly we will continue to use AI to drive a paradigm shift in security with Microsoft Security Copilot. We empathize with security and IT leaders trying to navigate a challenging landscape and will continue to build security into our products to help them harness the power of AI confidently.\nAs part of our time in New York today, I am pleased to be a part of a panel discussion on this topic. Thank you for being part of our journey and making security forefront in your lives.\nStay tuned for more exciting details from Windows next week as we celebrate the availability of the new Windows 11 on September 26, 2023.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft is finally making custom chips — and they’re all about AI",
    "link": "https://www.theverge.com/2023/11/15/23960345/microsoft-cpu-gpu-ai-chips-azure-maia-cobalt-specifications-cloud-infrastructure",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNTZUa0psVXpOcVNGZHNaWGhEVFJDb0FSaXJBaWdCTWdZaGM0b0xxZ2M=-w400-h224-p-df-rw",
    "source": "The Verge",
    "datetime": "2023-11-15T08:00:00.000Z",
    "time": "Nov 15, 2023",
    "articleType": "regular",
    "content": "The rumors are true: Microsoft has built its own custom AI chip that can be used to train large language models and potentially avoid a costly reliance on Nvidia. Microsoft has also built its own Arm-based CPU for cloud workloads. Both custom silicon chips are designed to power its Azure data centers and ready the company and its enterprise customers for a future full of AI. Microsoft’s Azure Maia AI chip and Arm-powered Azure Cobalt CPU are arriving in 2024, on the back of a surge in demand this year for Nvidia’s H100 GPUs that are widely used to train and operate generative image tools and large language models. There’s such high demand for these GPUs that some have even fetched more than $40,000 on eBay.“Microsoft actually has a long history in silicon development,” explains Rani Borkar, head of Azure hardware systems and infrastructure at Microsoft, in an interview with The Verge. Microsoft collaborated on silicon for the Xbox more than 20 years ago and has even co-engineered chips for its Surface devices. “These efforts are built on that experience,” says Borkar. “In 2017, we began architecting the cloud hardware stack and we began on that journey putting us on track to build our new custom chips.”The new Azure Maia AI chip and Azure Cobalt CPU are both built in-house at Microsoft, combined with a deep overhaul of its entire cloud server stack to optimize performance, power, and cost. “We are rethinking the cloud infrastructure for the era of AI, and literally optimizing every layer of that infrastructure,” says Borkar.The first two custom silicon chips designed by Microsoft for its cloud infrastructure. Image: MicrosoftThe Azure Cobalt CPU, named after the blue pigment, is a 128-core chip that’s built on an Arm Neoverse CSS design and customized for Microsoft. It’s designed to power general cloud services on Azure. “We’ve put a lot of thought into not just getting it to be highly performant, but also making sure we’re mindful of power management,” explains Borkar. “We made some very intentional design choices, including the ability to control performance and power consumption per core and on every single virtual machine.”Microsoft is currently testing its Cobalt CPU on workloads like Microsoft Teams and SQL server, with plans to make virtual machines available to customers next year for a variety of workloads. While Borkar wouldn’t be drawn into direct comparisons with Amazon’s Graviton 3 servers that are available on AWS, there should be some noticeable performance gains over the Arm-based servers Microsoft is currently using for Azure. “Our initial testing shows that our performance is up to 40 percent better than what’s currently in our data centers that use commercial Arm servers,” says Borkar. Microsoft isn’t sharing full system specifications or benchmarks yet.Microsoft’s Maia 100 AI accelerator, named after a bright blue star, is designed for running cloud AI workloads, like large language model training and inference. It will be used to power some of the company’s largest AI workloads on Azure, including parts of the multibillion-dollar partnership with OpenAI where Microsoft powers all of OpenAI’s workloads. The software giant has been collaborating with OpenAI on the design and testing phases of Maia. “We were excited when Microsoft first shared their designs for the Maia chip, and we’ve worked together to refine and test it with our models,” says Sam Altman, CEO of OpenAI. “Azure’s end-to-end AI architecture, now optimized down to the silicon with Maia, paves the way for training more capable models and making those models cheaper for our customers.”Manufactured on a 5-nanometer TSMC process, Maia has 105 billion transistors — around 30 percent fewer than the 153 billion found on AMD’s own Nvidia competitor, the MI300X AI GPU. “Maia supports our first implementation of the sub 8-bit data types, MX data types, in order to co-design hardware and software,” says Borkar. “This helps us support faster model training and inference times.”Microsoft is part of a group that includes AMD, Arm, Intel, Meta, Nvidia, and Qualcomm that are standardizing the next generation of data formats for AI models. Microsoft is building on the collaborative and open work of the Open Compute Project (OCP) to adapt entire systems to the needs of AI.A probe station used to test Microsoft’s Azure Cobalt system-on-chip. Image: Microsoft“Maia is the first complete liquid cooled server processor built by Microsoft,” reveals Borkar. “The goal here was to enable higher density of servers at higher efficiencies. Because we’re reimagining the entire stack we purposely think through every layer, so these systems are actually going to fit in our current data center footprint.”That’s key for Microsoft to spin these AI servers up more quickly without having to make room for them in data centers around the world. Microsoft built a unique rack to house Maia server boards in, complete with a “sidekick” liquid chiller that works like a radiator you’d find in your car or a fancy gaming PC to cool the surface of the Maia chips.Along with sharing MX data types, Microsoft is also sharing its rack designs with its partners  so they can use them on systems with other silicon inside. But the Maia chip designs won’t be shared more broadly, Microsoft is keeping those in-house.Maia 100 is currently being tested on GPT 3.5 Turbo, the same model that powers ChatGPT, Bing AI workloads, and GitHub Copilot. Microsoft is in the early phases of deployment and much like Cobalt it isn’t willing to release exact Maia specifications or performance benchmarks just yet.The Maia 100 server rack and “sidekick” cooling. Image: MicrosoftThat makes it difficult to decipher exactly how Maia will compare to Nvidia’s popular H100 GPU, the recently announced H200, or even AMD’s latest MI300X. Borkar didn’t want to discuss comparisons, instead reiterating that partnerships with Nvidia and AMD are still very key for the future of Azure’s AI cloud. “At the scale at which the cloud operates, it’s really important to optimize and integrate every layer of the stack, to maximize performance, to diversify the supply chain, and frankly to give our customers infrastructure choices,” says Borkar. That diversification of supply chains is important to Microsoft, particularly when Nvidia is the key supplier of AI server chips right now and companies have been racing to buy up these chips. Estimates have suggested OpenAI needed more than 30,000 of Nvidia’s older A100 GPUs for the commercialization of ChatGPT, so Microsoft’s own chips could help lower the cost of AI for its customers. Microsoft has also developed these chips for its own Azure cloud workloads, not to sell to others like Nvidia, AMD, Intel, and Qualcomm all do.“I look at this more as complementary, not competing with them,” insists Borkar. “We have both Intel and AMD in our cloud compute today, and similarly on AI we are announcing AMD where we already have Nvidia today. These partners are very important to our infrastructure, and we really want to give our customers the choices.”You may have noticed the Maia 100 and Cobalt 100 naming, which suggests that Microsoft is already designing second-generation versions of these chips. “This is a series, it’s not just 100 and done... but we’re not going to share our roadmaps,” says Borkar. It’s not clear how often Microsoft will deliver new versions of Maia and Cobalt just yet, but given the speed of AI I wouldn’t be surprised to see a Maia 100 successor arrive at a similar pace to Nvidia’s H200 announcement (around 20 months).The key now will be just how fast Microsoft gets Maia into action to speed up the rollout of its broad AI ambitions, and how these chips will impact pricing for the use of AI cloud services. Microsoft isn’t ready to talk about this new server pricing just yet, but we’ve already seen the company quietly launch its Copilot for Microsoft 365 for a $30-per-month premium per user. Copilot for Microsoft 365 is limited to only Microsoft’s biggest customers right now, with enterprise users having to commit to at least 300 users to get on the list for its new AI-powered Office assistant. As Microsoft pushes ahead with even more Copilot features this week and a Bing Chat rebranding, Maia could soon help balance the demand for the AI chips that power these new experiences.",
    "favicon": "/icons/favicon.ico"
  },
  {
    "title": "Microsoft lays foundation for green building materials of tomorrow - Source",
    "link": "https://news.microsoft.com/source/features/sustainability/low-carbon-building-materials-for-datacenters/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNUNNakZZU0hCUVl6Y3hkM1E0VFJDYkFSakZBaWdCTWdPQkZBWQ=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-28T07:00:00.000Z",
    "time": "Sep 28, 2023",
    "articleType": "regular",
    "content": "Quincy, Washington – Crushed rock and sand banged around in the swirling drum of a concrete mixer truck here on a construction contractor’s lot adjacent to a Microsoft datacenter. The scene on this sweltering summer day marked another step in Microsoft’s journey to be carbon negative by 2030.\nA team of concrete finishers stood at the ready to flatten and smooth the mixture that would tumble down the mixer-truck’s chute into one of three wooden frames roughly the size of a tabletop and harden to form concrete slabs.\nThe mixture in the drum, though, wasn’t typical. In addition to the rock, sand, water and cement usually found in concrete mixtures, it contained a limestone derived from microalgae and other additives that lower the overall embodied carbon in concrete.\nEmbodied carbon is a measure of the carbon emitted during the manufacturing, installation, maintenance and disposal of a product or material. The embodied carbon of concrete is currently responsible for around 8% of global greenhouse gas emissions, according to industry and government calculations. The embodied carbon in steel, another material used in heavy construction, accounts for an estimated 7% of carbon emissions.\n“Within the built environment, decarbonization of concrete and steel is critically important from a climate impact perspective,” said Brandon Middaugh, the senior director of Microsoft’s Climate Innovation Fund, a $1 billion fund to accelerate the development and deployment of climate solutions.\nReducing or eliminating embodied carbon from concrete and steel is a challenge because the traditional processes used to manufacture them are carbon intensive, noted Sean James, senior director of datacenter research in Microsoft’s datacenter research team.\nOvercoming that challenge with alternative, lower-embodied carbon materials, he said, will help Microsoft make progress towards its commitment to be carbon negative by 2030. It also has implications for the rest of the world where the global construction industry is currently on pace to construct a New York City’s worth of buildings every month for the next 37 years.\nThe bulk of emissions associated with concrete come from cement production, noted Steve Gilges, a principal infrastructure engineer on Microsoft’s datacenter research team. A key ingredient of cement is limestone, which is typically heated with clay to around 2,650 degrees Fahrenheit in a coal or gas-fired kiln where it undergoes a chemical reaction called calcination that releases carbon dioxide as a byproduct.\nThe concrete mixes piloted in Quincy include one with biogenic limestone, one with fly ash and slag that are activated with alkaline soda ash, and one with both the alkali activated cement and biogenic limestone. The project goal is to test mix designs that can lower embodied carbon in concrete by more than 50% compared to traditional concrete mixes, according to Microsoft.\nThe concrete mixes piloted in Quincy include one with biogenic limestone, one with fly ash and slag that are activated with alkaline soda ash, and a third with both the alkali activated cement and biogenic limestone. Image by Dan DeLong for Microsoft.\nThe fly ash and slag for the alkali-activated cement is industrial waste material from coal combustion and steel making. The biogenic limestone is sourced from Minus Materials, which is commercializing a process pioneered at the University of Colorado at Boulder that accelerates the production of limestone with marine algae.\nThese mixes are an imperfect solution to the problem of embodied carbon in concrete, noted James. But that’s okay. They’re a start.\n“The biggest enemy to progress is this concept that it has to be perfect before you start,” he said. “The best way to make actual impact is to go out there with a good enough solution and what’s good enough now is using these things that can bring down the carbon, so we can start making an impact right away.”\nFurther out, Microsoft has its eyes on solutions that could ratchet down embodied carbon in concrete and other building materials to zero and, potentially, make them carbon negative.\nMany of these solutions stem from investments in early-stage companies by Microsoft’s Climate Innovation Fund, which was launched in 2020 alongside the company’s commitments focused on carbon, water, waste and ecosystems.\n“We launched the fund in recognition that in order for us to achieve those goals, we need to build the markets around us and the technologies outside our four walls that will enable us to go on our decarbonization journey,” said Middaugh.\nShe and her colleagues are on the lookout for technologies that are novel, need to become widely accessible for maximum impact and would benefit from the insight that Microsoft provides as a customer. In the building materials space, the fund is focused on concrete and steel.\nFor example, one of the fund’s earliest investments is in CarbonCure, which is deploying low carbon concrete technologies that inject captured carbon dioxide into concrete, where the CO2 immediately mineralizes and is permanently embedded as nanosized rocks within the physical product. This not only acts as a carbon sink but also strengthens the material, enabling a reduction in the amount of carbon-intensive cement required.\nA different decarbonization pathway is reflected in Prometheus Materials, which produces zero-carbon bio-cement and bio-concrete through a unique process that combines naturally occurring microalgae with other essential components, Middaugh said.\nPrometheus Materials’ bio-cement is used to form zero-carbon Bio-Blocks on their way to finishing, evaporating and inventory. Image by Prometheus Materials.\n“Our mission is to decarbonize one of the most used, if not THE most used, construction materials on Earth – and that is concrete,” said Loren Burnett, the chief executive officer of Prometheus Materials, based in Longmont, Colorado.\nMicrosoft’s Climate Innovation Fund recently announced an investment in Boston Metal, which developed a patented molten oxide electrolysis (MOE) technology that will be powered by renewable energy and seeks to produce pure iron from any grade of iron ore and eliminate carbon dioxide emissions from steelmaking. Boston Metal aims to commercialize their green steel solution and will also produce high-value metals from mining waste in Brazil.\nThese investments, Middaugh said, are intended to spur the creation of a competitive market for green building materials in a timeframe that allows Microsoft and other companies to meet sustainability targets such as decreasing carbon emissions or reaching net zero emissions through using carbon removals to counterbalance emissions.\n“There’s not enough supply in the market today to meet the demands of all the corporate net zero committed entities,” she said. “What we see is that we increasingly need to support project origination by these companies to bring actual facilities online.”\nStrengthening the market for low-carbon concrete\nThe need for a competitive market for green concrete and steel was reinforced in an open letter signed by the four largest datacenter companies that sets out achievable pathways towards wider availability of low-carbon concrete.\n“One of the things we’re finding with all this new tech is it can’t get to the critical mass to get started,” said Christian Belady, vice president and distinguished engineer at Microsoft who leads the datacenter advanced development group.\nHaving a common way for low-carbon concrete producers to differentiate their products and for the construction industry to understand the carbon embodied in materials they buy will help to drive demand and transparency. As part of their pledge, the companies aim to create a consistent method to calculate embodied carbon in concrete.\nHistorically, Microsoft has calculated embodied carbon in building materials using proxies, according to Katie Ross, the director of carbon reduction strategy and market development at Microsoft.\n“There’s a correlation between how much we spend with a company and the direct emissions associated with that spend,” she explained. “As we’ve moved along the continuum, we’ve poked holes in that.”\nThat’s why Microsoft is shifting to an accounting methodology for major building materials based on a nutrition-type label like those on food packaging that contains information on the global warming potential of a material, called an Environmental Product Declaration, or EPD, that is third party verified.\n“Because we have that information, the nutrition label, we can now accurately show the decisions that we’ve made and the carbon emissions associated with those decisions,” said Ross. “We’re able to show reductions over time.”\nSteppingstones on a green journey\nGilges and his team will observe the low-carbon concrete slabs poured in Quincy for several months to understand, for example, how the mixes harden.\nThe lessons learned from the mixes poured in Quincy will be applied to more complex pilots as low-carbon concrete technologies continue to scale, according to the team.\n“It’s just concrete,” noted Gilges. “But the material properties, chemical reactions and mechanical alterations can be complex especially when introducing synthetic fillers combined with biologically derived components.”\nA worker smooths a sample of concrete mix in a canister that contains materials to lower the overall embodied carbon in concrete. Image by Dan DeLong for Microsoft.\nThe Quincy pilot projects, along with similar engagements with concrete suppliers in Des Moines, Iowa, and San Antonio, Texas, will help Microsoft learn about these challenges in the real world so that James and his colleagues can overcome them.\n“You need to get out of PowerPoints and get into the dirt and actually build it as soon as you can,” James said. “Because then you’re going to learn what those speed bumps are and you’re going to have a lot more time to figure out how to deal with them.”\nCheck out Microsoft’s Climate Innovation Fund\nRead: Microsoft and partners are building a more sustainable future\nRead: Collaboration on unique resin spurs creation of the Ocean Plastic Mouse\nRead: On the road to 2030: Our 2022 Environmental Sustainability Report\nTop image: Workers pour and smooth concrete at a construction contractor’s lot adjacent to a Microsoft datacenter in Quincy, Wash. The pilot is part of a project to test mix designs that can lower embodied carbon in concrete by more than 50% compared to traditional concrete mixes. Image by Dan DeLong for Microsoft.",
    "favicon": "https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2022/10/cropped-Microsoft_logo.svg_-300x300-1-128x120.png"
  },
  {
    "title": "Microsoft announces US$2.2 billion investment to fuel Malaysia’s cloud and AI transformation - Microsoft Stories Asia",
    "link": "https://news.microsoft.com/apac/2024/05/02/microsoft-announces-us2-2-billion-investment-to-fuel-malaysias-cloud-and-ai-transformation/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNHdXRmh4VWpOS2QwMXBhRFpoVFJDM0FSaVRBaWdCTWdhVlVwaHJwUWs=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-02T07:00:00.000Z",
    "time": "May 2",
    "articleType": "regular",
    "content": "Microsoft Chairman and CEO Satya Nadella announces a $2.2 billion investment to advance new cloud and AI infrastructure in Malaysia during the Microsoft Build: AI Day on May 02, 2024 in Kuala Lumpur, Malaysia. Photo by Graham Denholm/Getty Images for Microsoft.\nRead this in Bahasa Malaysia and Mandarin.\nInvestment includes building digital infrastructure, creating AI skilling opportunities, establishing a national AI Centre of Excellence, and enhancing the nation’s cybersecurity capabilities\nKuala Lumpur, May 2, 2024 – Today, Microsoft announced it will invest US$2.2 billion over the next four years to support Malaysia’s digital transformation – the single largest investment in its 32-year history in the country.\nbuilding cloud and AI infrastructure in Malaysia\ncreating AI skilling opportunities for an additional 200,000 people in Malaysia\nstrengthening its partnership with the Government of Malaysia to establish a national AI Centre of Excellence and enhance the nation’s cybersecurity capabilities\nsupporting the growth of Malaysia’s developer community.\nThe investment demonstrates Microsoft’s commitment to developing Malaysia as a hub for cloud computing and related advanced technologies, including generative AI. This will support the nation’s productivity, competitiveness, resilience, and economic growth.\n“We are committed to supporting Malaysia’s AI transformation and ensure it benefits all Malaysians,” said Satya Nadella, Chairman and CEO, Microsoft. “Our investments in digital infrastructure and skilling will help Malaysian businesses, communities, and developers apply the latest technology to drive inclusive economic growth and innovation across the country.”\nYB Senator Tengku Datuk Seri Utama Zafrul Abdul Aziz, Malaysia’s Minister of Investment, Trade & Industry said, “Microsoft’s 32-year presence in Malaysia showcases a deep partnership built on trust. Indeed, Malaysia’s position as a vibrant tech investment destination is increasingly being recognized by world-recognized names due to our well-established semiconductor ecosystem, underscored by our value proposition that ‘this is where global starts’.”\n“Microsoft’s development of essential cloud and AI infrastructure, together with AI skilling opportunities, will significantly enhance Malaysia’s digital capacity and further elevate our position in the global tech landscape. Together with Microsoft, we look forward to creating more opportunities for our SMEs and better-paying jobs for our people, as we ride the AI revolution to fast-track Malaysia’s digitally empowered growth journey.”\n“We are honored to collaborate with the government to support their National AI Framework, which enhances the country’s global competitiveness. This strategic emphasis on AI not only boosts economic growth but also promotes inclusivity by bridging the digital divide and ensuring everyone gets a seat at the table, so every Malaysian can thrive in this new digital world. As a result, Malaysia is steadily establishing itself as a regional hub for digital innovation and smart technologies, embodying a forward-thinking approach that prioritizes sustainable development and societal well-being through digital transformation,” said Andrea Della Mattea, President of Microsoft ASEAN.\nMicrosoft Chairman and CEO Satya Nadella (L) meets with YAB Dato’ Seri Anwar Ibrahim, Prime Minister of Malaysia at Perdana Putra, Putrajaya in Malaysia on May 02, 2024. (Photo by Annice Lyn/Getty Images for Microsoft)\nExpanding Malaysia’s digital capacity to seize AI opportunities\nThe digital infrastructure investment builds on Microsoft’s Bersama Malaysia (Together with Malaysia) initiative, announced in April 2021, to support inclusive economic growth. This included plans to establish the company’s first datacenter region in the country.\nThe investment announced today will enable Microsoft to meet the growing demand for cloud computing services in Malaysia. It will also allow Malaysia to capitalize on the significant economic and productivity opportunities presented by the latest AI technology.\nAccording to research by Kearney, AI could contribute nearly US$1 trillion to Southeast Asia’s gross domestic product (GDP) by 2030, with Malaysia poised to capture US$115 billion of this amount.\nEquipping people with skills to thrive in the AI era\nOn Tuesday, Microsoft announced a broader commitment to provide AI skilling opportunities for 2.5 million people in the Association of Southeast Asian Nations (ASEAN) member states by 2025. This training and support will be delivered in partnership with governments, nonprofit and business organizations, and communities in Malaysia, Indonesia, the Philippines, Thailand, and Vietnam.\nMicrosoft’s skilling commitment is expected to benefit 200,000 people in Malaysia by providing:\ntechnical and vocational education and training students with AI skills through the AI TEACH Malaysia program\nwomen with opportunities and support to build careers in cybersecurity via the Ready4AI&Security program\nyoung people with AI fluency training to enhance the employability and work readiness of those from underserved and underrepresented communities\nemployees of non-profit organizations with knowledge of, and skills in, AI and digital technologies.\nThe commitment builds on Microsoft’s other recent skilling activities in Malaysia, including its success in providing digital skills to more than 1.53 million Malaysians as part of the Bersama Malaysia initiative.\nPartnering with government to strengthen AI and cybersecurity capabilities\nMicrosoft will continue to partner with the Government of Malaysia to enhance the nation’s digital ecosystem through several initiatives. These include establishing a national AI Centre of Excellence in collaboration with agencies in Malaysia’s Ministry of Digital to drive AI adoption across key industries, while ensuring AI governance and regulatory compliance. They also include pioneering AI adoption in the public sector through projects with:\nthe Ministry of Investment, Trade and Industry (MITI) to better analyze economic trajectories of different negotiating partners in international trade negotiations\nCradle, an agency under Malaysia’s Ministry of Science, Technology and Innovation, which is leveraging Azure OpenAI Service to develop a virtual information assistant for its MYStartup platform, the ‘Single Window’ to Malaysia’s startup ecosystem, launched at the KL20 Summit recently\nthe Malaysia Digital Economy Corporation (MDEC) and the Malaysia Energy Commission, which will adopt Copilot for Microsoft 365 to enhance workplace productivity.\nMicrosoft will also collaborate with the National Cyber Security Agency of Malaysia (NACSA) through the Perisai Siber (Cyber Shield) initiative to enhance the country’s cybersecurity capabilities. The collaboration will focus on promoting security and resilience in the public sector through security assessments and capacity building.\nIn addition, Microsoft will look to support NACSA in its role as Malaysia’s lead agency for cybersecurity matters, as it formulates the next stage of the nation’s cybersecurity strategy. The two organizations will also explore deeper collaborations in developing cybersecurity skills through initiatives such as Microsoft’s Ready4AI&Security program.\nEmpowering developers to harness AI’s potential\nMicrosoft will continue to help foster the growth of Malaysia’s developer community through new initiatives such as AI Odyssey, which is expected to help 2,000 Malaysian developers become AI subject matter experts by learning new skills and earning Microsoft credentials.\nMalaysia is a rapidly growing market on GitHub, the Microsoft-owned software development, collaboration, and innovation platform. Almost 680,000 of the nation’s developers used GitHub in 2023, representing 28 percent year-on-year growth.\nFurthermore, many Malaysian organizations are boosting their productivity and accelerating innovation using Microsoft’s generative AI-powered solutions. For example:\nAgroz is a Malaysian agriculture tech company that designs and operates controlled environment indoor vertical farms in Malaysia with the aim of growing more nutrient-rich food in less space without the use of pesticides and other chemicals. It built the Agroz Copilot for Farmers using Azure OpenAI Service, which helps farmers query Agroz’s farming system using their natural language or images and get recommendations on what daily tasks they should do to improve crop productivity and farm efficiency.\nDoctor2U, one of Malaysia’s leading healthcare super apps, is using GitHub Copilot to expedite development, with tasks that previously took two hours now being completed in 30 minutes. In addition, the implementation of Azure AI Search has sped up the record retrieval process, reducing the time it takes to return results from a multi-million patient data set from one minute to one second.\nPandai helps more than 800,000 students learn, practice, and improve their academic performance via an app. It recently deployed a personalized study bot called Pbot using Azure OpenAI Service, which monitors students’ progress and provides academic support. Pandai’s aim is for the bot to be a “personal friend and tutor” in each student’s educational experience.\nPETRONAS, Malaysia’s fully integrated global energy provider, is leading the AI wave by transforming the future of its global workforce through the adoption of Copilot for Microsoft 365 to enhance employee productivity and creativity. The company is also leveraging Azure OpenAI Service to create AI-powered solutions that help improve operational efficiency, reliability, and employee safety.\nPerumahan Rakyat 1Malaysia (PR1MA), the main housing agency under Malaysia’s Ministry of Housing and Local Government, has deployed Copilot for Microsoft 365 across its information technology, human resources, finance, and legal departments. PR1MA has already seen a 30 percent reduction in time spent on routine administrative tasks, allowing employees to focus more on strategic initiatives and value-adding activities.\nPrudential, a leading life and health insurer in Malaysia, has embedded an in-house AI tool in its call center using Azure OpenAI Service. The tool reduces the time it takes for Prudential’s servicing team to gather product information for agents from four minutes to less than 30 seconds, allowing them to respond to customers faster. The company anticipates expanding the tool for additional use cases soon.\nYB Rafizi Ramli, Minister of Economy\n“The advent of ChatGPT created a new vertical in the startup world. As more companies embrace the power of AI, having the right digital infrastructure in Malaysia is key to future-proofing our nation’s economy. Microsoft’s investment will help accelerate the adoption of generative AI, building a pipeline of AI-driven startups, and benefitting our economy through increased productivity and higher wages.”\nYB Gobind Singh Deo, Minister of Digital\n“As a nation, we are focused on accelerating digitalization and fostering a culture of innovation alongside technological advancement to level the playing field for all Malaysians to prosper in an inclusive digital economy. Microsoft’s investment is a significant step in our journey towards becoming a digitally inclusive society. It underscores the importance of partnership in driving nationwide digital transformation and reinforces our commitment to equipping Malaysians with the infrastructure, advanced tools, and skills they need to thrive in the digital age.”\nYB Fahmi Fadzil, Minister of Communications\n“Microsoft’s significant investment in Malaysia recognises and supports the government’s efforts in building an inclusive digital ecosystem for the country. We are excited to continue partnering with technology leaders like Microsoft to foster a space where Malaysians can seamlessly connect, learn, and benefit from our nation’s digital transformation.”\nYB Chang Lih Kang, Minister of Science, Technology & Innovation\n“Today’s investment by Microsoft exemplifies a dynamic public-private partnership aimed at enhancing the socio-economic status and quality of life in Malaysian communities. As we embrace AI’s potential, we commend Microsoft’s commitment to responsible AI, which aligns with our vision for advancing technology in Malaysia responsibly and inclusively.”\nLaurence Si, Managing Director, Microsoft Malaysia\n“With rising demand for Cloud and AI, Microsoft’s investment announced today underscores our commitment to building a robust digital ecosystem in the country. From driving more innovations born in Malaysia, to fostering an ecosystem of skilled talents and enhancing cybersecurity capabilities for Malaysian organizations, we are dedicated to our role as a trusted technology partner to the nation.”\nMr. Sikh Shamsul Ibrahim Sikh Abdul Majid, Chief Executive Officer, Malaysian Investment Development Authority (MIDA)\n“We are excited to deepen our partnership with Microsoft as they strengthen their commitment by establishing a cloud and AI infrastructure and supporting our vibrant developer community in Malaysia. This strategic collaboration underscores our dedication to innovation and regional industry growth. By leveraging Microsoft’s expertise, we aim to accelerate economic development, create jobs, and enhance industry competitiveness through digital transformation. We believe we can achieve more together and further advance our partnership. This investment not only reinforces Malaysia’s position as a leading digital hub but also marks a promising start in attracting more companies to embark on this digital journey with us, promoting inclusive growth and prosperity nationwide.”\nIr. Dr. Megat Zuhairy Megat Tajuddin, Chief Executive Officer, National Cyber Security Agency (NACSA)\n“Microsoft’s collaboration with NACSA on “Perisai Siber” is pivotal as one of our strategic partnerships with industry players in establishing a secure digital infrastructure for our nation. Together, our goal is to bolster security and resilience, beginning with the public sector, to ultimately strengthen the nation’s cybersecurity capabilities.”\nTs. Mahadhir Aziz, Chief Executive Officer, Malaysia Digital Economy Corporation (MDEC)\n“Microsoft’s commitment to Malaysia demonstrates confidence in our nation’s digital future. Through this investment in cloud and AI infrastructure, local organizations can tap into more opportunities to upscale and innovate, further propelling Malaysia’s aspirations for regional leadership in the digital economy.”\nMicrosoft (Nasdaq “MSFT” @microsoft) creates platforms and tools powered by AI to deliver innovative solutions that meet the evolving needs of our customers. The technology company is committed to making AI available broadly and doing so responsibly, with a mission to empower every person and every organization on the planet to achieve more.\nTags: AI, Cloud, digital skills",
    "favicon": "https://news.microsoft.com/wp-content/themes/microsoft-news-center-2016/assets/img/site-icon.png"
  },
  {
    "title": "New models added to the Phi-3 family, available on Microsoft Azure",
    "link": "https://azure.microsoft.com/en-us/blog/new-models-added-to-the-phi-3-family-available-on-microsoft-azure/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNUVTRUl6U1ROTFMxQTBUVE5YVFJDb0FSaXNBaWdCTWdZbFk0aU9MUVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-21T07:00:00.000Z",
    "time": "May 21",
    "articleType": "regular",
    "content": "At Microsoft Build 2024, we are excited to add new models to the Phi-3 family of small, open models developed by Microsoft.\nRead more announcements from Azure at Microsoft Build 2024: New ways Azure helps you build transformational AI experiences and The new era of compute powering Azure AI solutions.\nAt Microsoft Build 2024, we are excited to add new models to the Phi-3 family of small, open models developed by Microsoft. We are introducing Phi-3-vision, a multimodal model that brings together language and vision capabilities. You can try Phi-3-vision today.\nPhi-3-small and Phi-3-medium, announced earlier, are now available on Microsoft Azure, empowering developers with models for generative AI applications that require strong reasoning, limited compute, and latency bound scenarios. Lastly, previously available Phi-3-mini, as well as Phi-3-medium, are now also available through Azure AI’s models as a service offering, allowing users to get started quickly and easily.\nPhi-3 models are the most capable and cost-effective small language models (SLMs) available, outperforming models of the same size and next size up across a variety of language, reasoning, coding, and math benchmarks. They are trained using high quality training data, as explained in Tiny but mighty: The Phi-3 small language models with big potential. The availability of Phi-3 models expands the selection of high-quality models for Azure customers, offering more practical choices as they compose and build generative AI applications.\nBringing together language and vision capabilities\nThere are four models in the Phi-3 model family; each model is instruction-tuned and developed in accordance with Microsoft’s responsible AI, safety, and security standards to ensure it’s ready to use off-the-shelf.\nPhi-3-vision is a 4.2B parameter multimodal model with language and vision capabilities.\nPhi-3-mini is a 3.8B parameter language model, available in two context lengths (128K and 4K).\nPhi-3-small is a 7B parameter language model, available in two context lengths (128K and 8K).\nPhi-3-medium is a 14B parameter language model, available in two context lengths (128K and 4K).\nFind all Phi-3 models on Azure AI and Hugging Face.\nPhi-3 models have been optimized to run across a variety of hardware. Optimized variants are available with ONNX Runtime and DirectML providing developers with support across a wide range of devices and platforms including mobile and web deployments. Phi-3 models are also available as NVIDIA NIM inference microservices with a standard API interface that can be deployed anywhere and have been optimized for inference on NVIDIA GPUs and Intel accelerators.\nIt’s inspiring to see how developers are using Phi-3 to do incredible things—from ITC, an Indian conglomerate, which has built a copilot for Indian farmers to ask questions about their crops in their own vernacular, to the Khan Academy, who is currently leveraging Azure OpenAI Service to power their Khanmigo for teachers pilot and experimenting with Phi-3 to improve math tutoring in an affordable, scalable, and adaptable manner. Healthcare software company Epic is looking to also use Phi-3 to summarize complex patient histories more efficiently. Seth Hain, senior vice president of R&D at Epic explains, “AI is embedded directly into Epic workflows to help solve important issues like clinician burnout, staffing shortages, and organizational financial challenges. Small language models, like Phi-3, have robust yet efficient reasoning capabilities that enable us to offer high-quality generative AI at a lower cost across our applications that help with challenges like summarizing complex patient histories and responding faster to patients.”\nDigital Green, used by more than 6 million farmers, is introducing video to their AI assistant, Farmer.Chat, adding to their multimodal conversational interface. “We’re excited about leveraging Phi-3 to increase the efficiency of Farmer.Chat and to enable rural communities to leverage the power of AI to uplift themselves,” said Rikin Gandhi, CEO, Digital Green.\nPhi-3-vision is the first multimodal model in the Phi-3 family, bringing together text and images, and the ability to reason over real-world images and extract and reason over text from images. It has also been optimized for chart and diagram understanding and can be used to generate insights and answer questions. Phi-3-vision builds on the language capabilities of the Phi-3-mini, continuing to pack strong language and image reasoning quality in a small model.\nPhi-3-vision can generate insights from charts and diagrams:\nGroundbreaking performance at a small size\nAs previously shared, Phi-3-small and Phi-3-medium outperform language models of the same size as well as those that are much larger.\nPhi-3-small with only 7B parameters beats GPT-3.5T across a variety of language, reasoning, coding, and math benchmarks.1\nThe Phi-3-medium with 14B parameters continues the trend and outperforms Gemini 1.0 Pro.2\nPhi-3-vision with just 4.2B parameters continues that trend and outperforms larger models such as Claude-3 Haiku and Gemini 1.0 Pro V across general visual reasoning tasks, OCR, table, and chart understanding tasks.3\nAll reported numbers are produced with the same pipeline to ensure that the numbers are comparable. As a result, these numbers may differ from other published numbers due to slight differences in the evaluation methodology. More details on benchmarks are provided in our technical paper.\nSee detailed benchmarks in the footnotes of this post.\nPhi-3 models were developed in accordance with the Microsoft Responsible AI Standard and underwent rigorous safety measurement and evaluation, red-teaming, sensitive use review, and adherence to security guidance to help ensure that these models are responsibly developed, tested, and deployed in alignment with Microsoft’s standards and best practices.\nPhi-3 models are also trained using high-quality data and were further improved with safety post-training, including reinforcement learning from human feedback (RLHF), automated testing and evaluations across dozens of harm categories, and manual red-teaming. Our approach to safety training and evaluations are detailed in our technical paper, and we outline recommended uses and limitations in the model cards.\nFinally, developers using the Phi-3 model family can also take advantage of a suite of tools available in Azure AI to help them build safer and more trustworthy applications.\nWith the evolving landscape of available models, customers are increasingly looking to leverage multiple models in their applications depending on use case and business needs. Choosing the right model depends on the needs of a specific use case.\nSmall language models are designed to perform well for simpler tasks, are more accessible and easier to use for organizations with limited resources, and they can be more easily fine-tuned to meet specific needs. They are well suited for applications that need to run locally on a device, where a task doesn’t require extensive reasoning and a quick response is needed.\nThe choice between using Phi-3-mini, Phi-3-small, and Phi-3-medium depends on the complexity of the task and available computational resources. They can be employed across a variety of language understanding and generation tasks such as content authoring, summarization, question-answering, and sentiment analysis. Beyond traditional language tasks these models have strong reasoning and logic capabilities, making them good candidates for analytical tasks. The longer context window available across all models enables taking in and reasoning over large text content—documents, web pages, code, and more.\nPhi-3-vision is great for tasks that require reasoning over image and text together. It is especially good for OCR tasks including reasoning and Q&A over extracted text, as well as chart, diagram, and table understanding tasks.\n1Table 1: Phi-3-small with only 7B parameters\n2Table 2: Phi-3-medium with 14B parameters\n3Table 3: Phi-3-vision with 4.2B parameters",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "2024 Annual Work Trend Index from Microsoft and LinkedIn",
    "link": "https://news.microsoft.com/annual-wti-2024/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNHRUMjgzTTNoSVQxYzBjVWxqVFJDb0FSaXJBaWdCTWdaSlVwTDFLQWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-08T13:22:04.000Z",
    "time": "May 8",
    "articleType": "regular",
    "content": "Write better prompts with Copilot\nMore Work Trend Index data\n2024 Work Trend Index shows the state of AI at work\nAI at work is here — now comes the hard part\nMicrosoft and LinkedIn release the 2024 Work Trend Index\nAI at work has arrived\nThe power user payoff at work\nAI Aptitude heats up across roles and Industries-Top industries for AI skills\nAI Aptitude heats up across roles and Industries-Top occupations for AI skills\nAI Aptitude heats up across roles and Industries-Top occupations for AI skills\nBYOAI is not just for Gen Z\nEmployees want AI at work and won’t wait for companies to catch up\nWrite better prompts with Copilot\nApplying generative AI as a creative professional\nApplying generative AI as a business professional\nApplying AI as a tech leader\nDevelop your skills with the OpenAI API\nAdvance your skills in deep learning and neural networks\nDevelop your AI skills as a cybersecurity professional\nA practical guide to upskilling your organization on AI\nIntroducing LinkedIn Learning’s AI-powered coaching\nLinkedIn AI powered premium experience\nMore Work Trend Index data\nWork Trend Index: Region & market data snapshots\n2024 Work Trend Index report highlights\nWork Trend Index – Atlanta\nWork Trend Index – Austin\nWork Trend Index – Bay Area\nWork Trend Index – Boston\nWork Trend Index – D.C. Metro\nWork Trend Index – Houston\nWork Trend Index – New York City\nWork Trend Index – North Carolina\nWork Trend Index – Pittsburgh\nWork Trend Index – SMB",
    "favicon": "https://news.microsoft.com/wp-content/uploads/prod/sites/686/2024/05/cropped-cropped-cropped-Microsoft_logo-1-200x200.png"
  },
  {
    "title": "China, North Korea pursue new targets while honing cyber capabilities - Microsoft On the Issues",
    "link": "https://blogs.microsoft.com/on-the-issues/2023/09/07/digital-threats-cyberattacks-east-asia-china-north-korea/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNXlWa0pzWjAxUFVEVlJWSFpYVFJDckFSaW1BaWdCTWdPeEZCZw=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-07T07:00:00.000Z",
    "time": "Sep 7, 2023",
    "articleType": "regular",
    "content": "In the past year, China has honed a new capability to automatically generate images it can use for influence operations meant to mimic U.S. voters across the political spectrum and create controversy along racial, economic, and ideological lines. This new capability is powered by artificial intelligence that attempts to create high-quality content that could go viral across social networks in the U.S. and other democracies. These images are most likely created by something called diffusion-powered image generators that use AI to not only create compelling images but also learn to improve them over time.\nToday, the Microsoft Threat Analysis Center (MTAC) is issuing Sophistication, scope, and scale: Digital threats from East Asia increase in breadth and effectiveness, as part of an ongoing series of reports on the threat posed by influence operations and cyber activity, identifying specific sectors and regions at heightened risk.\nWe have observed China-affiliated actors leveraging AI-generated visual media in a broad campaign that largely focuses on politically divisive topics, such as gun violence, and denigrating U.S. political figures and symbols. This technology produces more eye-catching content than the awkward digital drawings and stock photo collages used in previous campaigns. We can expect China to continue to hone this technology over time, though it remains to be seen how and when it will deploy it at scale.\nAs Microsoft noted in our recent report Governing AI: A Blueprint for the Future, public- and private-sector institutions need to collectively address the weaponization of technology, including AI, by cyber and influence threat actors. We report on digital threats we detect – including the use of AI – to inform policymakers, security practitioners, and the public about any threats, current or emerging, that new technologies may pose to information integrity and democracy. We will continue to share our knowledge, and call on partners to do so as well, as part of our larger blueprint to promote transparency and guide the governance of AI.\nIn its cyber operations, multiple Chinese state-affiliated threat actors have focused cyberattacks in the South China Sea region, conducting intelligence collection and malware execution against regional governments and industries. Other actors have targeted the U.S. defense industry and U.S. infrastructure, looking for competitive advantages to bolster strategic military aims.\nBeginning in May 2023, Storm-0558, a China-based threat actor, accessed Microsoft customer email accounts of approximately 25 organizations including U.S. and European government entities. Microsoft assesses this activity was likely conducted for espionage purposes and has successfully blocked this campaign.\nThe report also details how China has continued its global efforts to spread state-sponsored propaganda and soften the country’s image abroad. The Chinese government is investing resources in messaging to audiences in more languages, on more platforms, while evolving its techniques. For example, we know China employs more than 230 state media employees and affiliates who masquerade as independent social media influencers across all major Western social media platforms.\nThese influencers, who are recruited, trained, promoted, and funded by China Radio International (CRI) and other Chinese state media outfits, expertly spread localized CCP propaganda that achieves meaningful engagement with audiences around the world, reaching a combined following of at least 103 million people across multiple platforms speaking at least 40 languages.\nWhile China-based threat groups continue to develop and utilize impressive cyber capabilities and IO operations, we have not observed China to combine cyber and influence together – unlike Iran and Russia, which regularly engage in hack-and-leak campaigns.\nIn addition to what we’ve observed from China, North Korea is a capable cyber threat, focusing on intelligence gathering and the theft of cryptocurrency needed to generate revenue for the state. Several of North Korea’s threat actors have targeted the maritime and shipbuilding sectors, suggesting this as a high-priority area for the North Korean government. Additionally, multiple North Korean threat actors have recently targeted the Russian government and defense industry – likely for intelligence collection – while simultaneously providing material support for Russia in its war on Ukraine.\nThe report also looks toward anticipated future actions from China and North Korea in the months ahead, as increasing geopolitical tensions fuel new threat priorities and adversarial strategies. With upcoming elections in 2024, Taiwan and the United States are likely to remain top priorities for China.\nNo technology platform, including Microsoft’s, is perfect. But as nation-state actors continue to target vulnerabilities and deploy malign narratives across the world, we believe it is vital to continue to share intelligence such as this report and to increase cross-industry collaboration on these important issues.\nEditor’s note: As a part of an ongoing series, today Microsoft published Sophistication, scope, and scale: Digital threats from East Asia increase in breadth and effectiveness. These semi-annual updates on nation-state actors serve to warn our customers and the global community of the threat posed by influence operations and cyber activity, identifying specific sectors and regions at heightened risk. See our previous reporting on Russia and Iran.\nTags: cyberattacks, cybersecurity, cyberwar, Digital Threat Analysis Center, MTAC, Ukraine",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2017/08/favicon-599dd744b8cac.jpg"
  },
  {
    "title": "Peach Sandstorm password spray campaigns enable intelligence collection at high-value targets",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/09/14/peach-sandstorm-password-spray-campaigns-enable-intelligence-collection-at-high-value-targets/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNDVZa3RWUTBoRmRuSk1aVGxKVFJDM0FSaVRBaWdCTWdZaE5vZ0xPZ1U=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-14T07:00:00.000Z",
    "time": "Sep 14, 2023",
    "articleType": "regular",
    "content": "Since February 2023, Microsoft has observed password spray activity against thousands of organizations carried out by an actor we track as Peach Sandstorm (HOLMIUM). Peach Sandstorm is an Iranian nation-state threat actor who has recently pursued organizations in the satellite, defense, and pharmaceutical sectors around the globe. Based upon the profile of victim organizations targeted and the observed follow-on intrusion activity, Microsoft assesses that this initial access campaign is likely used to facilitate intelligence collection in support of Iranian state interests.\nIn cases where Peach Sandstorm successfully authenticated to an account, Microsoft observed the group using a combination of publicly available and custom tools for discovery, persistence, and lateral movement. In a small number of intrusions, Peach Sandstorm was observed exfiltrating data from the compromised environment.\nGiven the volume of activity, ongoing attempts to access targets of interest, and risks associated with post-compromise activity, Microsoft is reporting on this campaign to raise awareness of recent Peach Sandstorm tradecraft and empower organizations to harden their attack surfaces and defend against this activity. As with any observed nation state actor activity, Microsoft directly notifies customers that have been targeted or compromised by Peach Sandstorm and provides them with the information they need to secure their accounts.\nPeach Sandstorm is an Iranian nation-state group known to target organizations in multiple countries. In past attacks, Peach Sandstorm has pursued targets in the aviation, construction, defense, education, energy, financial services, healthcare, government, satellite, and telecommunications sectors. Activity that Microsoft attributes to Peach Sandstorm overlaps with public reporting on groups known as APT33, Elfin, and Refined Kitten.\nThroughout 2023, Peach Sandstorm has consistently demonstrated interest in organizations in the satellite, defense, and to a lesser extent, pharmaceutical sectors.  In the initial phase of this campaign, Peach Sandstorm conducted password spray campaigns against thousands of organizations across several sectors and geographies. While Microsoft observed several organizations previously targeted by Peach Sandstorm, the volume of activity and range of organizations suggests that at least a subset of the initial activity is opportunistic.\nIn past operations, Peach Sandstorm relied heavily, but not exclusively, on password spray attacks as a means of gaining access to targets of interest. In some cases, Peach Sandstorm has used this tradecraft to compromise an intermediate target and enable access to downstream environments. As one example, Peach Sandstorm carried out a wave of attacks in 2019 that coincided with a rise in tensions between the United States and the Islamic Republic of Iran.\nUnlike password spray operations which are noisy by definition, a subset of Peach Sandstorm’s 2023 post-compromise activity has been stealthy and sophisticated. Many of the cloud-based tactics, techniques, and procedures (TTPs) seen in these most recent campaigns are materially more sophisticated than capabilities used by Peach Sandstorm in the past.\nMicrosoft observed Peach Sandstorm using two distinct sets of TTPs in the early stages of the intrusion lifecycle in 2023 attacks. In later stages of known compromises, the threat actor used different combinations from a set of known TTPs to drop additional tools, move laterally, and ultimately exfiltrate data from a target.\nFigure 1. Peach Sandstorm 2023 tradecraft\nPath 1: Password spray activity, internal reconnaissance with AzureHound or Roadtools, and multiple persistence mechanisms\nBetween February and July 2023, Peach Sandstorm carried out a wave of password spray attacks attempting to authenticate to thousands of environments. Password spraying is a technique where threat actors attempt to authenticate to many different accounts using a single password or a list of commonly-used passwords. Unlike brute force attacks that target a single account using many passwords, password spray attacks help adversaries maximize their chances for success and minimize the likelihood of automatic account lockouts.\nEven a single compromised account could allow an adversary to conduct reconnaissance, move laterally, or access sensitive resources, often without attracting attention from defenders.\nFigure 2. Identity attack lifecycle\nLong-running password spray campaigns offer insight into adversaries’ pattern of life. Activity observed in this campaign aligned with an Iranian pattern of life, particularly in late May and June, where activity occurred almost exclusively between 9:00 AM and 5:00 PM Iran Standard Time (IRST). While Peach Sandstorm has carried out high-volume password spray campaigns in the past, elements of the most recent campaign were unique. Specifically, Peach Sandstorm consistently conducted the password sprays from TOR IPs and used a “go-http-client” user agent.\nFigure 3. Peach Sandstorm authentication attempts by hour (April-July 2023)\nFigure 4. Peach Sandstorm authentication attempts by day of the week (April-July 2023)\nInternal reconnaissance with AzureHound or Roadtools\nIn a small subset of instances where Peach Sandstorm successfully authenticated to an account in a targeted environment, Microsoft observed the threat actor using AzureHound or Roadtools to conduct reconnaissance in Microsoft Entra ID (formerly Azure Active Directory). In this campaign, Peach Sandstorm used AzureHound, a Go binary that collects data from Microsoft Entra ID and Azure Resource Manager through the Microsoft Graph and Azure REST APIs, as a means of gathering information on a system of interest. Similarly, Roadtools, a framework to access Microsoft Entra ID, allowed Peach Sandstorm to access data in a target’s cloud environment and conveniently dump data of interest to a single database.\nAzureHound and Roadtools have functionality that is used by defenders, red teams, and adversaries. The same features that make these tools useful to legitimate users, like pre-built capabilities to explore and seamlessly dump data in a single database, also make these tools attractive options for adversaries seeking information about or from a target’s environment.\nIn cases where Microsoft observed this particular intrusion chain, the threat actor used one or more persistence mechanisms. In some cases, Peach Sandstorm created a new Azure subscription on a target’s tenant and/or leveraged previously compromised Azure resources. These subscriptions were subsequently used to facilitate communication with Peach Sandstorm’s infrastructure.\nPeach Sandstorm also abused Azure Arc, a capability that allows users to secure, develop, and operate infrastructure, applications, and Azure services anywhere, to persist in compromised environments. In this campaign, Peach Sandstorm installed the Azure Arc client on a device in the compromised environment and connected it to an Azure subscription controlled by Peach Sandstorm. This effectively allowed Peach Sandstorm to control devices in a target’s on-premises environment from Peach Sandstorm’s cloud.\nPath 2: Remote exploitation of vulnerable internet-facing applications\nInitial access using remote exploitation\nIn this wave of activity, Peach Sandstorm also attempted to exploit vulnerabilities with a public proof-of-concept (POC) in Zoho ManageEngine or Confluence, to access targets’ environments.\nCVE-2022-47966 is a remote code execution vulnerability affecting a subset of on-premises Zoho ManageEngine products. Microsoft recommends organizations using vulnerable applications patch this vulnerability as multiple groups have been observed exploiting this vulnerability.\nCVE-2022-26134 is a remote code execution vulnerability in Confluence Server and Data Center. Recommendations that help organizations protect against exploitation of multiple vulnerabilities, including CVE-2022-26134, can be found in the recommendations section of this report.\nThe following post-compromise activity affected organizations in the defense, satellite, and pharmaceutical sectors:\nIn a subset of intrusions in this campaign, Peach Sandstorm deployed AnyDesk, a commercial remote monitoring and management tool (RMM) to maintain access to a target. AnyDesk has a range of capabilities that allow users to remotely access a network, persist in a compromised environment, and enable command and control (C2). The convenience and utility of a tool like AnyDesk is amplified by the fact that it might be permitted by application controls in environments where it is used legitimately by IT support personnel or system administrators.\nIn a March 2023 intrusion, Peach Sandstorm conducted a Golden SAML attack to access a target’s cloud resources. In a Golden SAML attack, an adversary steals private keys from a target’s on-premises Active Directory Federated Services (AD FS) server and use the stolen keys to mint a SAML token trusted by a target’s Microsoft 365 environment. If successful, a threat actor could bypass AD FS authentication and access federated services as any user.\nIn at least one intrusion, Microsoft observed Peach Sandstorm using a legitimate VMWare executable to carry out a search order hijack. DLL search order hijacking allows adversaries to introduce malicious code into an environment in a way that blends in with normal activity.\nIn a handful of environments, Microsoft observed Peach Sandstorm using EagleRelay to tunnel traffic back to their infrastructure. In these instances, Peach Sandstorm created a new virtual machine in a compromised Azure subscription. These virtual machines were used to run EagleRelay, a custom tool, to tunnel traffic between actor-controlled systems and targets’ systems. In at least one case, Microsoft also saw Peach Sandstorm attempting to move laterally in a compromised environment using remote desktop protocol (RDP).\nThe capabilities observed in this campaign are concerning as Microsoft saw Peach Sandstorm use legitimate credentials (gleaned from password spray attacks) to authenticate to targets’ systems, persist in targets’ environments, and deploy a range of tools to carry out additional activity. Peach Sandstorm also created new Azure subscriptions and leveraged the access these subscriptions provided to conduct additional attacks in other organizations’ environments. While the specific effects in this campaign vary based on the threat actor’s decisions, even initial access could adversely impact the confidentiality of a given environment. Microsoft continues to work across its platforms to identify abuse, take down malicious activity, and implement new proactive protections to discourage malicious actors from using our services. We encourage customers and the industry to report abuse.\nAs Peach Sandstorm increasingly develops and uses new capabilities, organizations must develop corresponding defenses to harden their attack surfaces and raise costs for these attacks. Microsoft will continue to monitor Peach Sandstorm activity and implement robust protections for our customers.\nTo harden an attack surface against Peach Sandstorm activity, defenders can implement the following:\nReset account passwords for any accounts targeted during a password spray attack. If a targeted account had system-level permissions, further investigation may be warranted.\nRevoke session cookies in addition to resetting passwordsRevoke any multifactor authentication (MFA) setting changes made by the attacker on any compromised users’ accounts\nRequire re-challenging MFA for MFA updates as the default\nImplement the Azure Security Benchmark and general best practices for securing identity infrastructure, including:\nCreate conditional access policies to allow or disallow access to the environment based on defined criteria.\nBlock legacy authentication with Microsoft Entra ID by using Conditional Access. Legacy authentication protocols don’t have the ability to enforce MFA, so blocking such authentication methods will prevent password spray attackers from taking advantage of the lack of MFA on those protocols.\nEnable AD FS web application proxy extranet lockout to protect users from potential password brute force compromise.\nSecure accounts with credential hygiene:\nPractice the principle of least privilege and audit privileged account activity in your Microsoft Entra ID environments to slow and stop attackers.\nDeploy Microsoft Entra ID Connect Health for Active Directory Federation Services (AD FS). This captures failed attempts as well as IP addresses recorded in AD FS logs for bad requests in the Risky IP report.\nUse Microsoft Entra ID password protection to detect and block known weak passwords and their variants.\nTurn on identity protection in Microsoft Entra ID to monitor for identity-based risks and create policies for risky sign ins.\nUse MFA to mitigate successful password spray attacks. Keep MFA always-on for privileged accounts and apply risk-based MFA for normal accounts.\nConsider transitioning to a passwordless primary authentication method, such as Azure MFA, certificates, or Windows Hello for Business.\nSecure RDP or Windows Virtual Desktop endpoints with MFA to harden against password spray or brute force attacks.\nSecuring critical assets like AD FS servers is a high-value measure to protect against golden SAML attacks. The guidance provided below is applicable beyond just Peach Sandstorm activity and can help organizations harden their attack surfaces against a range of threats.\nIt’s critical to treat your AD FS servers as a Tier 0 asset, protecting them with the same protections you would apply to a domain controller or other critical security infrastructure. AD FS servers provide authentication to configured relying parties, so an attacker who gains administrative access to an AD FS server can achieve total control of authentication to configured relying parties (include Microsoft Entra ID tenants configured to use the AD FS server).\nPracticing credential hygiene, notably the recommendations provided above, is critical for protecting and preventing the exposure of highly privileged administrator accounts. This especially applies on more easily compromised systems like workstations with controls like logon restrictions and preventing lateral movement to these systems with controls like the Windows Firewall.\nMigration to Microsoft Entra ID (formerly Azure Active Directory) authentication is recommended to reduce the risk of on-premises compromises moving laterally to your authentication servers. Customers can use the following references on migration:Use the activity report to move AD FS apps to Microsoft Entra ID\nMove application authentication to Microsoft Entra ID\nIndicatorTypeDescription192.52.166[.]76IP addressPeach Sandstorm adversary IP108.62.118[.]240IP addressPeach Sandstorm adversary IP102.129.215[.]40 IP addressPeach Sandstorm adversary IP76.8.60[.]64IP addressPeach Sandstorm adversary IP\nAlerts with the following titles in the security center can indicate Peach Sandstorm activity on your network:\nPeach Sandstorm actor activity detected\nThe following alerts might indicate activity associated with password spray campaigns.\nMicrosoft Defender for Cloud Apps\nThe following alerts might indicate activity associated with password spray campaigns.\nActivity from a Tor IP address\nActivity from a password-spray associated IP address\nOrganizations with Defender for Cloud Apps can turn on app governance, a set of security and policy management capabilities designed for OAuth-enabled apps registered on Azure Active Directory, Google, and Salesforce. The following detections in App governance might indicate activity associated with password spray campaigns.\nNumerous Azure AD enumeration calls using PowerShell\nSuspicious enumeration activities performed using AAD PowerShell\nMicrosoft customers can use a range of Microsoft Sentinel content to help detect Peach Sandstorm activity described in this blog. The Azure Active Directory solution contains several analytics rules and hunting queries for Microsoft Entra ID data that can help uncover initial access activity including password sprays. Specific analytics rules of value include:\nPassword spray attack against Microsoft Entra ID application\nPotential Password Spray Attack (Uses Authentication Normalization)\nOkta – Potential Password Spray Attack\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft AI Red Team building future of safer AI",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNXBkazh3TUdWdVdqQlpaMGhqVFJDM0FSaVRBaWdCTWdhVjg0UW96Z00=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-08-07T07:00:00.000Z",
    "time": "Aug 7, 2023",
    "articleType": "regular",
    "content": "An essential part of shipping software securely is red teaming. It broadly refers to the practice of emulating real-world adversaries and their tools, tactics, and procedures to identify risks, uncover blind spots, validate assumptions, and improve the overall security posture of systems. Microsoft has a rich history of red teaming emerging technology with a goal of proactively identifying failures in the technology. As AI systems became more prevalent, in 2018, Microsoft established the AI Red Team: a group of interdisciplinary experts dedicated to thinking like attackers and probing AI systems for failures.\nWe’re sharing best practices from our team so others can benefit from Microsoft’s learnings. These best practices can help security teams proactively hunt for failures in AI systems, define a defense-in-depth approach, and create a plan to evolve and grow your security posture as generative AI systems evolve.\nThe practice of AI red teaming has evolved to take on a more expanded meaning: it not only covers probing for security vulnerabilities, but also includes probing for other system failures, such as the generation of potentially harmful content. AI systems come with new risks, and red teaming is core to understanding those novel risks, such as prompt injection and producing ungrounded content. AI red teaming is not just a nice to have at Microsoft; it is a cornerstone to responsible AI by design: as Microsoft President and Vice Chair, Brad Smith, announced, Microsoft recently committed that all high-risk AI systems will go through independent red teaming before deployment.\nThe goal of this blog is to contextualize for security professionals how AI red teaming intersects with traditional red teaming, and where it differs. This, we hope, will empower more organizations to red team their own AI systems as well as provide insights into leveraging their existing traditional red teams and AI teams better.\nRed teaming helps make AI implementation safer\nOver the last several years, Microsoft’s AI Red Team has continuously created and shared content to empower security professionals to think comprehensively and proactively about how to implement AI securely. In October 2020, Microsoft collaborated with MITRE as well as industry and academic partners to develop and release the Adversarial Machine Learning Threat Matrix, a framework for empowering security analysts to detect, respond, and remediate threats. Also in 2020, we created and open sourced Microsoft Counterfit, an automation tool for security testing AI systems to help the whole industry improve the security of AI solutions. Following that, we released the AI security risk assessment framework in 2021 to help organizations mature their security practices around the security of AI systems, in addition to updating Counterfit. Earlier this year, we announced additional collaborations with key partners to help organizations understand the risks associated with AI systems so that organizations can use them safely, including the integration of Counterfit into MITRE tooling, and collaborations with Hugging Face on an AI-specific security scanner that is available on GitHub.\nSecurity-related AI red teaming is part of a larger responsible AI (RAI) red teaming effort that focuses on Microsoft’s AI principles of fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability. The collective work has had a direct impact on the way we ship AI products to our customers. For instance, before the new Bing chat experience was released, a team of dozens of security and responsible AI experts across the company spent hundreds of hours probing for novel security and responsible AI risks. This was in addition to the regular, intensive software security practices followed by the team, as well as red teaming the base GPT-4 model by RAI experts in advance of developing Bing Chat. Our red teaming findings informed the systematic measurement of these risks and built scoped mitigations before the product shipped.\nGuidance and resources for red teaming\nAI red teaming generally takes place at two levels: at the base model level (e.g., GPT-4) or at the application level (e.g., Security Copilot, which uses GPT-4 in the back end). Both levels bring their own advantages: for instance, red teaming the model helps to identify early in the process how models can be misused, to scope capabilities of the model, and to understand the model’s limitations. These insights can be fed into the model development process to improve future model versions but also get a jump-start on which applications it is most suited for. Application-level AI red teaming takes a system view, of which the base model is one part. For instance, when AI red teaming Bing Chat, the entire search experience powered by GPT-4 was in scope and was probed for failures. This helps to identify failures beyond just the model-level safety mechanisms, by including the overall application specific safety triggers.\nTogether, probing for both security and responsible AI risks provides a single snapshot of how threats and even benign usage of the system can compromise the integrity, confidentiality, availability, and accountability of AI systems. This combined view of security and responsible AI provides valuable insights not just in proactively identifying issues, but also to understand their prevalence in the system through measurement and inform strategies for mitigation. Below are key learnings that have helped shape Microsoft’s AI Red Team program.\nAI red teaming is more expansive. AI red teaming is now an umbrella term for probing both security and RAI outcomes. AI red teaming intersects with traditional red teaming goals in that the security component focuses on model as a vector. So, some of the goals may include, for instance, to steal the underlying model. But AI systems also inherit new security vulnerabilities, such as prompt injection and poisoning, which need special attention. In addition to the security goals, AI red teaming also includes probing for outcomes such as fairness issues (e.g., stereotyping) and harmful content (e.g., glorification of violence). AI red teaming helps identify these issues early so we can prioritize our defense investments appropriately.\nAI red teaming focuses on failures from both malicious and benign personas. Take the case of red teaming new Bing. In the new Bing, AI red teaming not only focused on how a malicious adversary can subvert the AI system via security-focused techniques and exploits, but also on how the system can generate problematic and harmful content when regular users interact with the system. So, unlike traditional security red teaming, which mostly focuses on only malicious adversaries, AI red teaming considers broader set of personas and failures.\nAI systems are constantly evolving. AI applications routinely change. For instance, in the case of a large language model application, developers may change the metaprompt (underlying instructions to the ML model) based on feedback. While traditional software systems also change, in our experience, AI systems change at a faster rate. Thus, it is important to pursue multiple rounds of red teaming of AI systems and to establish systematic, automated measurement and monitor systems over time.\nRed teaming generative AI systems requires multiple attempts. In a traditional red teaming engagement, using a tool or technique at two different time points on the same input, would always produce the same output. In other words, generally, traditional red teaming is deterministic. Generative AI systems, on the other hand, are probabilistic. This means that running the same input twice may provide different outputs. This is by design because the probabilistic nature of generative AI allows for a wider range in creative output. This also makes it tricky to red teaming since a prompt may not lead to failure in the first attempt, but be successful (in surfacing security threats or RAI harms) in the succeeding attempt. One way we have accounted for this is, as Brad Smith mentioned in his blog, to pursue multiple rounds of red teaming in the same operation. Microsoft has also invested in automation that helps to scale our operations and a systemic measurement strategy that quantifies the extent of the risk.\nMitigating AI failures requires defense in depth. Just like in traditional security where a problem like phishing requires a variety of technical mitigations such as hardening the host to smartly identifying malicious URIs, fixing failures found via AI red teaming requires a defense-in-depth approach, too. This involves the use of classifiers to flag potentially harmful content to using metaprompt to guide behavior to limiting conversational drift in conversational scenarios.\nBuilding technology responsibly and securely is in Microsoft’s DNA. Last year, Microsoft celebrated the 20-year anniversary of the Trustworthy Computing memo that asked Microsoft to deliver products “as available, reliable and secure as standard services such as electricity, water services, and telephony.”  AI is shaping up to be the most transformational technology of the 21st century. And like any new technology, AI is subject to novel threats. Earning customer trust by safeguarding our products remains a guiding principle as we enter this new era – and the AI Red Team is front and center of this effort. We hope this blog post inspires others to responsibly and safely integrate AI via red teaming.\nAI red teaming is part of the broader Microsoft strategy to deliver AI systems securely and responsibly. Here are some other resources to provide insights into this process:\nFor customers who are building applications using Azure OpenAI models, we released a guide to help them assemble an AI red team, define scope and goals, and execute on the deliverables.\nFor security incident responders, we released a bug bar to systematically triage attacks on ML systems.\nFor ML engineers, we released a checklist to complete AI risk assessment.\nFor developers, we released threat modeling guidance specifically for ML systems.\nFor anyone interested in learning more about responsible AI, we’ve released a version of our Responsible AI Standard and Impact Assessment, among other resources.\nFor engineers and policymakers, Microsoft, in collaboration with Berkman Klein Center at Harvard University, released a taxonomy documenting various machine learning failure modes.\nFor the broader security community, Microsoft hosted the annual Machine Learning Evasion Competition.\nFor Azure Machine Learning customers, we provided guidance on enterprise security and governance.\nContributions from Steph Ballard, Forough Poursabzi, Amanda Minnich, Gary Lopez Munoz, and Chang Kawaguchi.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Announcing Microsoft Copilot, your everyday AI companion",
    "link": "https://news.microsoft.com/september-2023-event/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWpRblJ6Vlc5UWN6UlZVbDgwVFJDM0FSaVRBaWdCTWdZUmRaS25xZ2M=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-21T15:05:57.000Z",
    "time": "Sep 21, 2023",
    "articleType": "regular",
    "content": "Today we take the next step to unify your favorite AI capabilities into a single experience we call Microsoft Copilot, your everyday AI companion. Copilot will uniquely incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance – with your privacy and security at the forefront.\nAnnouncing Microsoft Copilot, your everyday AI companion\nAnnouncing Microsoft 365 Copilot general availability and Microsoft 365 Chat\nNew Microsoft security tools to protect families and businesses\nSatya Nadella, Microsoft chairman and chief executive officer, speaks on stage at Skylight at Essex Crossing in New York City.\nYusuf Mehdi, Microsoft corporate vice president and consumer chief marketing officer, speaks on stage at Skylight at Essex Crossing in New York City.\nYusuf Mehdi, Microsoft corporate vice president and consumer chief marketing officer, speaks on stage at Skylight at Essex Crossing in New York City.\nYusuf Mehdi, Microsoft corporate vice president and consumer chief marketing officer, speaks on stage at Skylight at Essex Crossing in New York City.\nColette Stallbaumer, Microsoft general manager of Microsoft 365 and Future of Work, speaks on stage at Skylight at Essex Crossing in New York City.\nColette Stallbaumer, Microsoft general manager of Microsoft 365 and Future of Work, speaks on stage at Skylight at Essex Crossing in New York City.\nColette Stallbaumer, Microsoft general manager of Microsoft 365 and Future of Work, speaks on stage at Skylight at Essex Crossing in New York City.\nDivya Kumar, Microsoft general manager of search and AI marketing, speaks on stage at Skylight at Essex Crossing in New York City.\nDivya Kumar, Microsoft general manager of search and AI marketing, speaks on stage at Skylight at Essex Crossing in New York City.\nDivya Kumar, Microsoft general manager of search and AI marketing, speaks on stage at Skylight at Essex Crossing in New York City.\nBrett Ostrum, Microsoft corporate vice president for Surface devices, holds a Surface laptop while speaking on stage at Skylight at Essex Crossing in New York City.\nBrett Ostrum, Microsoft corporate vice president for Surface devices, speaks on stage at Skylight at Essex Crossing in New York City.\nBrett Ostrum, Microsoft corporate vice president for Surface devices, speaks on stage with Nicholas Albert, a Microsoft product marketing manager, at Skylight at Essex Crossing in New York City.\nBrett Ostrum, Microsoft corporate vice president for Surface devices, holds a Surface laptop while speaking on stage at Skylight at Essex Crossing in New York City.\nBrett Ostrum, Microsoft corporate vice president for Surface devices, speaks on stage with Solomon Romney, Microsoft accessibility program manager, at Skylight at Essex Crossing in New York City.\nBrett Ostrum, Microsoft corporate vice president for Surface devices, speaks on stage with Solomon Romney, Microsoft accessibility program manager, at Skylight at Essex Crossing in New York City.\nBrett Ostrum, Microsoft corporate vice president for Surface devices, speaks on stage with Solomon Romney, Microsoft accessibility program manager, at Skylight at Essex Crossing in New York City.\nCarmen Zlateff, Microsoft vice president of product management, speaks on stage at Skylight at Essex Crossing in New York City.\nCarmen Zlateff, Microsoft vice president of product management, speaks on stage at Skylight at Essex Crossing in New York City.\nBrett Ostrum, Microsoft corporate vice president for Surface devices, speaks on stage with Adrienne Brewbaker, Microsoft director of product marketing for Surface devices, at Skylight at Essex Crossing in New York City.\nCopilot in Windows 11 home screen\nExample of AI-generated image from Cocreator in Paint\nSuggested search results from Photos search\nText redaction in Snipping Tool\nWindows Backup on a Windows 10 PC\nExample of passkey sign-in on a webpage using Windows Hello\nExample of Windows 365 Switch from local PC to cloud PC\nNew Bing and Edge features\nNew fall 2024 Surface devices\nSurface Laptop Studio 2 modes\nSurface Laptop Go 3 featured colorways\nSurface Go 4 for Business\nSurface Go 4 for Business with Surface Pen, type cover, and mouse\nSurface Hub 3 in 50-inch and 85-inch screen sizes\nSurface Hub 3 in 50-inch in portrait configuration\nCopilot in the Microsoft Advertising platform\nIntroducing Copilot in Windows 11, new AI tools, and more\nAI camera lenses in SwiftKey\nMicrosoft 365 Copilot: Security & Privacy\nMicrosoft 365 Chat: Your personal assistant at work\nCopilot Lab | Learn to work in a new way\nGet more from M365 Chat with external plugins\nCopilot in Word | Enhance your writing and design\nCopilot in Outlook | Keep up with meetings\nCopilot in Excel | Python Integration\nMeet the new Surface Laptop Studio 2\nMeet the new Surface Laptop Go 3\nWindows September top features highlights\nSurface Laptop Studio 2 fact sheet\nSurface Laptop Go 3 fact sheet\nSurface Go 4 for Business fact sheet\nWorklab: The art and science of working with AI\nMicrosoft Sept. 21 announcement one sheet\nTransforming search and advertising with generative AI\nAI-powered Edge browser’s latest wave of innovation",
    "favicon": "https://news.microsoft.com/wp-content/themes/microsoft-events/images/favicon.ico"
  },
  {
    "title": "Microsoft and LinkedIn release the 2024 Work Trend Index on the state of AI at work",
    "link": "https://blogs.microsoft.com/blog/2024/05/08/microsoft-and-linkedin-release-the-2024-work-trend-index-on-the-state-of-ai-at-work/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVVPWGR5YlhoSlUwRkVOVE5oVFJDb0FSaXNBaWdCTWdZUlVvUk9VUU0=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-08T07:00:00.000Z",
    "time": "May 8",
    "articleType": "regular",
    "content": "One year ago, generative AI burst onto the scene and for the first time since the smartphone, people began to change the way they interact with technology. People are bringing AI to work at an unexpected scale — and now the big question is, how’s it going?\nAs AI becomes ubiquitous in the workplace, employees and businesses alike are under extreme pressure. The pace and intensity of work, which accelerated during the pandemic, has not eased, so employees are bringing their own AI to work. Leaders agree AI is a business imperative — and feel the pressure to show immediate ROI — but many lack a plan and vision to go from individual impact to applying AI to drive the bottom line.\nAt the same time, the labor market is set to shift and there’s a new AI economy. While some professionals worry AI will replace their job, the data tells a more nuanced story — of a hidden talent shortage, more employees eyeing a career change, and a massive opportunity for those willing to skill up.\n“AI is democratizing expertise across the workforce,” said Satya Nadella, Chairman and Chief Executive Officer, Microsoft. “Our latest research highlights the opportunity for every organization to apply this technology to drive better decision-making, collaboration — and ultimately business outcomes.”\nFor our fourth annual Work Trend Index, out today, we partnered with LinkedIn for the first time on a joint report so we could provide a comprehensive view of how AI is not only reshaping work, but the labor market more broadly. We surveyed 31,000 people across 31 countries, identified labor and hiring trends from LinkedIn, analyzed trillions of Microsoft 365 productivity signals and conducted research with Fortune 500 customers. The data points to insights every leader and professional needs to know — and actions they can take — when it comes to AI’s implications for work.\n1. Employees want AI at work — and won’t wait for companies to catch up.\nThree in four knowledge workers (75%) now use AI at work. Employees, overwhelmed and under duress, say AI saves time, boosts creativity and allows them to focus on their most important work. While 79% of leaders agree AI adoption is critical to remain competitive, 59% worry about quantifying the productivity gains of AI and 60% worry their company lacks a vision and plan to implement it. While leaders feel the pressure to turn individual productivity gains into organizational impact, employees aren’t waiting to reap the benefits: 78% of AI users are bringing their own AI tools to work. The opportunity for every leader is to channel this momentum into ROI.\n2. For employees, AI raises the bar and breaks the career ceiling.\nWe also see AI beginning to impact the job market. While AI and job loss are top of mind for some, our data shows more people are eyeing a career change, there are jobs available, and employees with AI skills will get first pick. The majority of leaders (55%) say they’re worried about having enough talent to fill open roles this year, with leaders in cybersecurity, engineering, and creative design feeling the pinch most.\nAnd professionals are looking. Forty-six percent across the globe are considering quitting in the year ahead — an all-time high since the Great Reshuffle of 2021 — a separate LinkedIn study found U.S. numbers to be even higher with 85% eyeing career moves. While two-thirds of leaders wouldn’t hire someone without AI skills, only 39% of users have received AI training from their company. So, professionals are skilling up on their own. As of late last year, we’ve seen a 142x increase in LinkedIn members adding AI skills like Copilot and ChatGPT to their profiles and a 160% increase in non-technical professionals using LinkedIn Learning courses to build their AI aptitude.\nIn a world where AI mentions in LinkedIn job posts drive a 17% bump in application growth, it’s a two-way street: Organizations that empower employees with AI tools and training will attract the best talent, and professionals who skill up will have the edge.\n3. The rise of the AI power user — and what they reveal about the future.\nIn the research, four types of AI users emerged on a spectrum — from skeptics who rarely use AI to power users who use it extensively. Compared to skeptics, AI power users have reoriented their workdays in fundamental ways, reimagining business processes and saving over 30 minutes per day. Over 90% of power users say AI makes their overwhelming workload more manageable and their work more enjoyable, but they aren’t doing it on their own.\nPower users work for a different kind of company. They are 61% more likely to have heard from their CEO on the importance of using generative AI at work, 53% more likely to receive encouragement from leadership to consider how AI can transform their function and 35% more likely to receive tailored AI training for their specific role or function.\n“AI is redefining work and it’s clear we need new playbooks,” said Ryan Roslansky, CEO of LinkedIn. “It’s the leaders who build for agility instead of stability and invest in skill building internally that will give their organizations a competitive advantage and create more efficient, engaged and equitable teams.”\nThe prompt box is the new blank page\nWe hear one consistent piece of feedback from our customers: talking to AI is harder than it seems. We’ve all learned how to use a search engine, identifying the right few words to get the best results. AI requires more context — just like when you delegate work to a direct report or colleague. But for many, staring down that empty prompt box feels like facing a blank page: Where should I even start?\nToday, we’re announcing Copilot for Microsoft 365 innovations to help our customers answer that question.\nIf you’ve got the start of a prompt, Copilot will offer to auto-complete it to get to a better result, suggesting something more detailed to help ensure you get what you’re looking for. That not only speeds things up, it offers you new ideas for how to leverage Copilot’s power.\nOther times, you know exactly what you want — you’re just not sure how to ask. With its new rewrite feature, Copilot turns a basic prompt into a rich one with the click of a button, turning everyone into a prompt engineer.\nWe also know that every role, team and function has unique needs and ways of working. To help create prompts for exactly the work you do, you’ll soon be able to create, publish and manage prompts in Copilot Lab that are expressly tailored to your closest teams.\nThese features will be available in the coming months, and in the future, we’ll take it a step further, with Copilot asking you questions to get to your best work yet.\nLinkedIn has also made free over 50 learning courses to empower professionals at all levels to advance their AI aptitude.\nHead to WorkLab for the full Work Trend Index Report, and head to LinkedIn to hear more from LinkedIn’s Chief Economist, Karin Kimbrough, on how AI is reshaping the labor market.\nAnd for all the blogs, videos and assets related to today’s announcements, please visit our microsite.\nTags: AI, LinkedIn, Microsoft Copilot, Work Trend Index",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Introducing Microsoft Copilot Studio and new features in Copilot for Microsoft 365",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2023/11/15/introducing-microsoft-copilot-studio-and-new-features-in-copilot-for-microsoft-365/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVJkMlp5ZWpReloySlJlRXBLVFJDb0FSaXNBaWdCTWdZcGhaRE50UVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-11-15T08:00:00.000Z",
    "time": "Nov 15, 2023",
    "articleType": "regular",
    "content": "At Microsoft Ignite 2023, we are announcing new innovations across Microsoft Copilot—one copilot experience that runs across all our surfaces, understanding your context on the web, on your PC, and at work to bring the right skills to you when you need them across work and life. Microsoft is the Copilot company. And soon there will be a Copilot for everyone and for everything you do.\nOn November 1, 2023, Copilot for Microsoft 365 became generally available for enterprises, and already, customers like Visa, BP, Honda, Pfizer, and Chevron, and also partners such as Accenture, EY, KPMG, Kyndryl, and PwC, are betting on Copilot.\nNew Work Trend Index data shows that already, Copilot makes people more productive and creative, and saves time—77 percent of people who have used copilot said they don’t want to give it up, 70 percent said copilot makes them more productive, and 68 percent said it improved the quality of their work. In experiments that we ran, users were 29 percent faster overall across a series of tasks and caught up on missed meetings nearly four times faster. It’s clear from the data: the age of copilots is here.\nIt’s early days, and we will continue to take a learn-it-all approach to deeply understand both the perceived and quantitative impact of Copilot on work and learning alongside our customers. Read on for more details about the announcements.\nUpdates to our Copilot product line-up\nWe are taking the next step to simplify the user experience and make copilot more accessible to everyone. Bing Chat and Bing Chat Enterprise will now simply become Copilot. It has foundational capabilities, like the ability to answer questions, create content, and reason over data. And it has web grounding, so it always has access to the latest information. When you’re signed into Copilot with your Entra ID, you get commercial data protection for free—which means chat data isn’t saved, Microsoft has no eyes-on access, and your data isn’t used to train the models.\nCopilot for Microsoft 365 has those same foundational capabilities, web grounding, and commercial data protection, and importantly, it also inherits your existing Microsoft 365 security, privacy, identity, and compliance policies—so you know it’s enterprise-grade. Your data is logically isolated and protected within your Microsoft 365 tenant, and always within your control. Copilot for Microsoft 365 doesn’t change any of our data residency or data handling promises. And Copilot acts on behalf of an individual user—so it can’t access any information you don’t have permission to see. Copilot for Microsoft 365 has access to the Microsoft Graph and is integrated into the Microsoft 365 apps that millions of people use every day.\nWe also announced Copilot for Sales and Copilot for Service.\nYou can access Copilot for Microsoft 365 in Windows and in Bing.\nAt Ignite, we announced Microsoft Copilot Studio, a low-code tool to customize Copilot for Microsoft 365 and build standalone copilots. It brings together a set of powerful conversational capabilities—from custom GPTs, generative AI plugins, and manual topics. You can customize Copilot for Microsoft 365 with your own enterprise scenarios—build, test, and publish standalone copilots and custom GPTs and manage and secure your customizations and standalone copilots with the right access, data, user controls, and analytics. Copilot Studio exposes a full end-to-end lifecycle for customizations and standalone copilots within a single pane of glass—build, deploy, analyze, and manage all from within the same web experience. With Copilot Studio, you can connect Copilot to other data sources, including pre-built or custom plugins and GPTs, to tap into any system of record—from SAP, Workday, and ServiceNow—and even your own proprietary business solutions. Copilot Studio is available today, and the integration with Copilot for Microsoft 365 is now available in preview.\nCopilot for Microsoft 365—your AI assistant at work\nAt Ignite, we shared three thematic updates to Copilot: more personalization, sophisticated mathematical and analysis capabilities, and Copilot becoming a full participant in collaboration.\nWe’re bringing more personalization to Copilot. New capabilities allow you to give Copilot details about your role and instructions on what’s important to you, so you can get tailored responses based on your unique role and preferences, including preferences on formatting, style, and tone. This new capability will roll out initially in Word and PowerPoint and will follow soon in the other Microsoft 365 apps, complementing previously announced personalization features such as “sound like me” for Copilot in Outlook, which matches your unique writing style and voice when drafting emails.\nThe recently announced Python in Excel allows you to perform sophisticated mathematical analysis using one of the most powerful programming languages in the world. And, in combination with Copilot in Excel, users will be able to unlock this capability using natural language.\nWe’re also announcing powerful new capabilities that make Copilot a full participant in collaboration, helping everyone stay focused on the discussion in a Microsoft Teams meeting, turn notes from a brainstorm into visualizations on a digital whiteboard, and build shared workspaces in Microsoft Loop that help your team collaborate and stay in sync.\nRead on for the full list of new capabilities in Copilot for Microsoft 365—all generally available unless otherwise noted.\nNext year, new Copilot in Teams experiences will give Copilot a seat at the meeting table, transforming it into a meeting assistant so everyone can stay present, engaged, and focused in the meeting. Copilot in collaborative notes takes notes throughout your meeting that are then shared with participants, and you can even instruct Copilot to capture specific content—for instance, ask it to “Quote Ben,” and Copilot will transcribe Ben’s remark for everyone to see.\nCustomers who want to leverage the power of Copilot in Teams meetings—but without creating a recording—now have the option to enable it without transcription. When enabled without transcription, Copilot can answer questions and provide information during the meeting, but no record of interactions will be retained afterward.\nYou can also now use Copilot in Teams channels to do things like synthesize long posts, get action items, or review key decisions in the channels you work in every day.\nWith the Copilot compose box in Teams chat and channels, Copilot will help you write a message or adjust its tone to improve your writing in the places you communicate most.\nStarting in December 2023, intelligent recap will be integrated into Copilot, so that everyone in the organization stays on the same page whether they are getting started with AI using Teams Premium or jumping all in with Copilot. Intelligent recap helps you catch up on the meetings you missed by providing a summary of the key points, action items, and decisions. And it gets even better when you use it with Copilot, allowing you to ask specific questions about the meeting and get clear answers.\nCopilot in Microsoft Whiteboard will automatically capture and visualize spoken discussion points during a Teams meeting and organize them for you into a collaboration space in Whiteboard, shared across all meeting participants.\nRead more about Teams announcements.\nComing in early 2024, Copilot in Outlook helps you prepare for upcoming meetings—combing through invitation details, related emails, and pertinent documents to build a synthesized summary that you can review quickly and show up prepped.\nCopilot now also helps you navigate bulky email threads effortlessly with an email thread summary. Copilot extracts crucial information, proposing actionable steps like a follow-up meeting. Once a meeting is selected, it drafts agendas, summarizes discussions, creates engaging meeting titles, populates attendees, appends the original thread for clarity, and suggests times when everyone can meet.\nIndependent of email, Copilot can also help you schedule meetings on specific topics. It will suggest relevant attendees, draft agendas, recommend files to share, and find times when everyone is available.\nAt Ignite, we announced the general availability of the Microsoft Loop app, the app built for the new way of working, with a flexible canvas for collaboration between people and generative AI to create a center of gravity for your projects and a space for your team and Copilot to think, plan, and create together.\nWith intelligent page creation, Copilot in Loop guides you, suggesting pages from past work and automatically adapting them for your current project, or crafting a new page with content suggestions tailored to your goals.\nComing soon, you can use catchup and comments in Copilot in Word to quickly get up to speed on document revisions by asking questions like, “How do I see what has changed in this document?” to reveal changes and revisions made by anyone who has accessed the document.\nWith the new brand asset and image library (coming soon), you can ask Copilot in PowerPoint to use your corporate brand assets and leverage Microsoft Designer to reimagine them using AI-generated visuals—no photo shoot required.\nNew Microsoft Viva value coming to Copilot\nViva is the measurement and transformation platform for the AI-powered, high-performance organization. At Ignite, we announced the Microsoft Copilot Dashboard, powered by Viva, to help Copilot customers across every stage of the transformation journey: readiness, adoption, and measurement. Now in preview, the dashboard shows how many employees are eligible and ready to benefit from Copilot based on Microsoft 365 app usage, breaks down Copilot usage across apps, and delivers early signals on Copilot’s impact on productivity based on meetings, chat, email, and documents. In early 2024, we will add more advanced capabilities for customers with a Viva Insights license. These include Copilot adoption and usage metrics combined with collaboration data, out-of-the-box reports for organizational leaders, before and after behavioral data, and even insights from employee surveys.\nWe announced that customers who use Viva can now do so right in Microsoft Copilot. Copilot combs across Viva data and applications to guide employees, managers, and HR leaders with self-service insights and experiences. You can do things like check in on team health, set new priorities with objectives and key results (OKRs), or access skilling and learning experiences. This new integration will be available in preview in early 2024.\nOur newest experience, Copilot in Microsoft Viva Insights, enables leaders and their delegates to use natural language prompts to easily query data from Viva Insights and generate personalized, dynamic reports that answer questions about their teams and organizations. This will be in preview in January 2024. Additionally, there are also updates to Copilot experiences in Viva Goals, Viva Engage, Viva Learning, and Viva Glint, plus new integrations and capabilities coming to Viva Learning, Viva Engage, and Viva Amplify.\nWith topics in Copilot, you can harness your organization’s shared intelligence to distribute knowledge to everyone. You will have the ability to uncover new opportunities by summarizing complex topics across multiple connected documents.\nNew product features are coming to Windows 365 and Microsoft Azure Virtual Desktop, including the Windows App—now available in preview—which connects you to Windows in the cloud from the device of your choice across Windows 365, Azure Virtual Desktop, Remote Desktop, Remote Desktop Services, Microsoft Dev Box, and more all from a single, unified app.\nIn early 2024, Copilot for Microsoft 365 will be integrated into the Windows desktop, allowing users to ground prompts in their Microsoft 365 Graph content and context.\nYou can preview new graphics processing unit (GPU) support in Windows 365, ideal for workloads such as graphic design, rendering, 3D modeling, data processing, and visualization applications. Windows 365 is now also available in a 16vCore SKU to handle all your high-capacity computing needs.\nIn preview soon, new AI capabilities in Windows 365 for Cloud PC include resizing recommendations to help organizations better forecast and right-size their Cloud PC investment.\nUpdate management is now a single solution with Windows Autopatch, extending it to frontline worker devices and unifying updates and upgrades across Windows devices, Windows 365, Microsoft 365 apps, Teams, and Microsoft Edge.\nMore news from Ignite 2023\nNew features in Teams include voice isolation, which learns your voice and suppresses other people’s voices in the background, and “decorate your background” in Teams Premium which uses the power of generative AI to remove clutter or add decor to your real-world room during video calls.\nMicrosoft Clipchamp is now available for Microsoft 365 enterprise and business suites, with premium features launching in December 2023.\nThe new Microsoft Planner is simple, collaborative, scalable, assisted by next-generation AI, and integrated with Microsoft 365 experiences such as Microsoft Loop, Outlook, Teams, and Viva Goals. Copilot in Planner will enable the use of natural language to create plans, tasks, and goals, or answer questions on progress, priorities, workload, and more.\nMicrosoft Mesh, a new 3D immersive experience for the workplace, will be generally available in January 2024. We’re reimagining the way employees come together with Microsoft Mesh in the place where hundreds of millions of people work today—Microsoft Teams. You can join these experiences with PC or Meta Quest VR devices.\nWe also announced new features such as shared display mode, designed for improving productivity and IT administration in bring-your-own-device (BYOD) shared spaces.\nYou can now preview SharePoint Premium, with various services launching from late 2023 to early 2024. SharePoint Premium is an AI-powered content management platform offering AI-driven automation, improved content experiences, and enhanced governance.\nStay up to date on the latest from Microsoft\nCustomize Microsoft Copilot and build standalone copilots\nRead all about the announcements from Ignite on the Official Microsoft blog.\nDiscover how to build your own standalone copilots in Jared Spataro’s Microsoft Copilot Studio blog.\nTo stay up to date on the latest research and insights on generative AI at work, visit WorkLab.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft unveils new generative AI and data solutions across the shopper journey, offering copilot experiences through Microsoft Cloud for Retail",
    "link": "https://news.microsoft.com/2024/01/11/microsoft-unveils-new-generative-ai-and-data-solutions-across-the-shopper-journey-offering-copilot-experiences-through-microsoft-cloud-for-retail/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNHpaRVJHYWw4dFZWcDBiVUZGVFJDM0FSaVRBaWdCTWdhaEk0N3NGUW8=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-01-11T08:00:00.000Z",
    "time": "Jan 11",
    "articleType": "regular",
    "content": "New copilot templates help retailers build personalized shopping experiences and support store operations.\nIndustry-specific retail data solutions in Microsoft Fabric help retailers unlock insights and lay the foundation for AI.\nGenerative AI solutions help retailers and brands infuse personalization and creativity into marketing campaigns and retail media ad campaigns to capture customer interest and drive revenue opportunities.\nREDMOND, Wash. — Jan. 11, 2024 — Ahead of NRF 2024: Retail’s Big Show, Microsoft Corp. on Thursday announced new generative AI and data solutions and capabilities for retailers that span the retail shopper journey, from enabling personalized shopping experiences, empowering store associates, and unlocking and unifying retail data to helping brands more effectively reach their audiences. Through new copilot templates on Azure OpenAI Service that allow retailers to build personalized shopping experiences and support store operations, the introduction of retail data solutions in Microsoft Fabric, new copilot features in Microsoft Dynamics 365 Customer Insights, and the launch of Retail Media Creative Studio in the Microsoft Retail Media Platform, Microsoft Cloud for Retail now offers more options for retailers to choose from to infuse copilot experiences throughout the shopper journey.\nRetailers globally continue to face challenges across their business — from high store associate turnover to shifting shopping habits, including the continued rise in omnichannel shopping and a decrease in brand loyalty among consumers, to the growth in siloed data that often holds unrealized value. To address these challenges, retailers are turning to technology and, in the era of AI, they have an opportunity to accelerate its impact with data-backed generative AI solutions to help unlock personalized shopping experiences, enhance store associates’ performance and productivity, and uncover insights that ultimately lead to better customer engagement and satisfaction. According to a Microsoft-commissioned study through IDC, retail organizations are realizing a return on their AI investments within 14 months.1 Retailers are also seeing an average return of $3.45 for every $1 they invest in AI.\nCreating memorable and personalized customer experiences with AI\nSeventy-one percent of consumers expect companies to deliver personalized interactions, and shoppers with a highly personalized experience are about twice as likely to add items to their baskets as shoppers without a personalized experience. In an online shopping environment, the tools available to allow shoppers to discover products, provide tailored recommendations and fulfill their shopping needs can be limited, leading to a less than ideal experience. To address this gap, Microsoft Cloud for Retail now offers a copilot template, in preview, that lets retailers build personalized shopping experiences. Using a retailer’s current systems and data, this prebuilt option can be embedded into existing digital experiences, such as a website or app, making it easier for shoppers to find and purchase the products they want.\nNow, shoppers can benefit from the convenience of online shopping with the experience offered by a personal shopper, just as they would if they were shopping in a physical store. The copilot template allows retailers to build personalized shopping that enable customers to ask for and view products by expressing what they’re looking for through natural language. Powered by GPT-4 through Azure OpenAI Service, the technology uses contextual awareness to provide the type of response shoppers would receive from a store associate. For example, a first-time camper shopping for a camping trip to Yosemite National Park in early March can visit a sporting goods retailer’s website and state in the chat “I’m going camping in Yosemite this March, and I have never camped before. Help me find the right gear.” Shoppers receive a response in natural language with recommendations for essentials. The copilot template for personalized shopping can also surface complementary items to increase basket size and customer satisfaction.\n“Generative AI can serve as a key differentiator for retailers, providing their customers with a unique and memorable experience that embodies their brand identity,” said Shelley Bransten, corporate vice president, Global Retail, Consumer Goods & Gaming Industries. “The new Microsoft Cloud for Retail copilot template for personalized shopping on Azure OpenAI Service is just one of the ways we enable retailers to build copilot experiences. We are committed to democratizing the concierge-like experience across the shopping journey through copilot templates that help retailers create more personalized experiences and reduce time to value.”\nInnovative retailers, such as Canadian Tire Corp. (CTC), are building copilots into the shopping experience to bring additional value to their business and personalize interactions with their customers. Later this spring, CTC is launching an AI shopping assistant, powered by Azure OpenAI Service, to support customers in purchasing certain automotive products. Through generative AI, shoppers can get a better understanding of product options, making the most of their time before and during their in-store visit.\nEmpowering store associates with AI tools to improve productivity, job satisfaction and customer experiences\nStore associates are critical to a retailer’s success, but the industry continues to face challenges with workforce shortages. Although technology can create transformative impact for retail workers, oftentimes getting it into the hands of store associates can be challenging. Microsoft’s Work Trend Index found that 60% of retail frontline workers are excited about the new opportunities that digital tools bring to retail, but 34% feel they don’t have the right digital tools or tech to do their job effectively.\nMicrosoft is putting generative AI into the hands of store associates and managers, unlocking their potential and contributing to productivity, job satisfaction and, ultimately, customers’ shopping experiences. Microsoft Cloud for Retail now provides a copilot template, in preview, on Azure OpenAI Service, that helps retailers build solutions to support store operations, giving store associates and managers access to insights and information in the flow of work. By accessing the technology on the retailer’s mobile devices, tablets or PCs, store associates and managers can use natural language to get answers to questions on store procedures, product catalogs, HR policies and benefits in an efficient and quick way using AI. They can also save time through voice-enabled task creation and assignments, as well as quickly access customer and product information to help them provide quality in-store customer service.\nApplications built with the copilot template can also give store leaders a view into employees’ and customers’ most frequently asked questions, allowing them to gain insights that help them take meaningful actions, such as updating training, procedures or guidelines.\nMicrosoft Experience Centers, with physical store locations in New York City, Sydney and London that offer shoppers the ability to experience Microsoft products and make retail purchases, will be one of the first retailers to implement copilot template for store associates. The technology will give their store associates valuable insights to further enhance shoppers’ experiences as they browse products, see demos and learn about Microsoft technology.\nUnlocking insights by unifying retail data and applying AI\nThe retail industry generates 40 petabytes of data every hour. To put it into perspective, that’s equivalent to 8 million two-hour long movies, which would require about 1,500 years to binge watch. What’s even more surprising is that because data remains siloed, most retailers leverage only a fraction of that data, providing them and their customers with incomplete insights. To derive actionable insights from their data to make the most of AI, seamless integration and standardized data is needed across different systems and applications.\nToday, Microsoft is announcing the preview of new retail data solutions in Microsoft Fabric, an end-to-end, unified analytics platform that brings together all the data and analytics tools that organizations need to unlock the potential of their data and lay the foundation for the era of AI.\nA data model that allows them to plan, architect and design data solutions. This retail industry data model (generally available) can be used for data governance, reporting, business intelligence and advanced analytics.\nA data connector to bring their e-commerce data from Sitecore OrderCloud (preview) into Microsoft Fabric in real time. Under this unified lens, retailers can access insights and tools to proactively improve customer satisfaction and business operations at every touchpoint from storefront to fulfillment.\nAnalytics templates, such as frequently bought together (preview), which provides actionable, data-driven recommendations to help retailers improve product upselling and shelf optimization.\nWith the retail data solutions in Microsoft Fabric, organizations can accelerate implementation of retail-specific data models while unifying their data and transforming it into predictive insights that help enhance customer engagement and shopper experiences.\nInfusing generative AI to help retailers and brands deliver successful marketing campaigns and retail media ad campaigns\nAdditionally, Microsoft is introducing generative AI to the Microsoft Retail Media platform (powered by PromoteIQ) through the launch of Retail Media Creative Studio, a comprehensive, end-to-end banner ad creative solution tailored for retail media, available in preview starting in January 2024. With Retail Media Creative Studio, retailers can empower their advertisers to quickly auto-generate and edit banner creatives by using generative AI. Retailers can then review and approve for use across multiple retail media channels, such as the retailer’s owned digital properties and across the open web. The solution optimizes banner campaign performance using AI-powered algorithms and delivers a more personalized shopping experience. Retail Media Creative Studio provides more creativity, productivity and revenue opportunities for retailers and advertisers to accelerate the growth of their retail media business.\nMicrosoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.\nMicrosoft Media Relations, WE Communications, (425) 638-7777,\n¹ IDC InfoBrief, sponsored by Microsoft, The Business Opportunity of AI:  How Leading Organizations Around the World Are Using AI to Drive Impact Across Every Industry, IDC #US51364223, Nov 2023.",
    "favicon": "https://news.microsoft.com/wp-content/uploads/prod/2017/03/cropped-microsoft_logo_element-150x150.png"
  },
  {
    "title": "Microsoft’s 2023 Diversity and Inclusion Report: A decade of transparency, commitment and progress",
    "link": "https://blogs.microsoft.com/blog/2023/11/01/microsofts-2023-diversity-and-inclusion-report-a-decade-of-transparency-commitment-and-progress/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNTRjVjg0ZGpVeFFtTkpNMWN6VFJDb0FSaXJBaWdCTWdZQmNJeUVMZ2M=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-11-01T07:00:00.000Z",
    "time": "Nov 1, 2023",
    "articleType": "regular",
    "content": "Today, I am sharing Microsoft’s 2023 Global Diversity & Inclusion Report — our fifth consecutive annual report and the 10th year of releasing our global workforce demographic data. As we mark this milestone, a couple of key aspects about our company’s work on diversity and inclusion (D&I) stand out: Our journey is ever evolving, and our focus and progress are consistent, both of which are vital to delivering on Microsoft’s mission to empower every person and every organization on the planet to achieve more.\nThis year’s report shows that we continue to be a more diverse Microsoft today than we have ever been. Looking at this year’s data as well as our cumulative efforts, it’s clear that we are driving positive change. The data we share is also a powerful tool for us to understand with precision where we need to concentrate and accelerate our work. This year, amid an evolving macroeconomic environment, our company — like many others — made intentional organizational and workforce adjustments to meet the strategic demands of the business, which impacted our rate of progress in some areas. While there’s more work to be done, I am motivated by our ongoing progress and sustained efforts on increasing representation and strengthening a culture of inclusion, as detailed in this year’s report.\nThe representation of women and most racial and ethnic minority groups (Asian, Black and African American, Hispanic and Latinx, and multiracial employees) has increased at all levels over the past five years.\nWe maintained or grew representation within several leadership levels for women and U.S. racial and ethnic minority groups year over year.\nThe representation of women in Executive roles is 29.1%, a 3.2 percentage point increase year over year. This was the highest year-over-year Executive representation growth across women, men, and U.S. racial and ethnic groups in 2023.\nThe number of Black and African American Directors, Partners and Executives (including People Managers and Individual Contributors) rose to 107.8% of our 2025 Racial Equity Initiative commitment, up from 92.0% in 2022.\nThe number of Hispanic and Latinx Directors, Partners and Executives (including People Managers and Individual Contributors) increased to 74.8% of our 2025 Racial Equity Initiative commitment, up from 57.6% in 2022.\nWhile hiring volume slowed, hiring representation was greater than or equal to representation for women and all racial and ethnic minority groups except Native American and Alaska Native.\nAt Microsoft, we are committed to the principle of pay equity, which accounts for factors that legitimately influence total pay including things like job title, level and tenure. As of September 2023:\nInside the U.S., all racial and ethnic minority groups who are rewards-eligible combined earn $1.007 total pay for every $1.000 earned by U.S. rewards-eligible white employees with the same job title and level and considering tenure.\nInside the U.S., women who are rewards-eligible earn $1.007 total pay for every $1.000 earned by rewards-eligible employees who are men and have the same job title and level, and considering tenure; outside the U.S., women who are rewards-eligible earn $1.003 total pay for every $1.000 earned by rewards-eligible employees who are men and have the same job title and level, and considering tenure.\nLast year, we began voluntarily disclosing median unadjusted pay analysis, which gathers the total pay amounts for all employees across a company — regardless of factors such as job title, level or tenure — sorts those amounts by value, and then identifies the number that’s in the middle, or median, of all of those data points. The difference between that median pay amount for any two employee groups is referred to as a median unadjusted pay gap.\nAs of September 2023, our analysis shows that we have made progress in narrowing the median unadjusted pay gap for women in the U.S., women outside of the U.S., and Asian, Black and African American, and Hispanic and Latinx employees in the U.S.\nAs we continue to increase representation for women and racial and ethnic minority groups at more senior levels, and continue to ensure pay equity for all, the gap between the medians will continue to reduce.\nHires data: As one of the most transparent companies of our size when it comes to the diversity and inclusion data we share, we are continually evaluating where we are now and where we aim to be. That is why, in addition to the extensive data we already share, we’re reporting on external hires representation for women and men globally and race and ethnicity in the U.S. for the first time. This data reflects the hires of members of a particular group as a percentage of total employee hires within the respective fiscal year. Hires representation being higher than headcount representation is one of the factors that could increase a group’s representation in the workforce. This past fiscal year, hires representation was greater than headcount representation for women as well as Asian, Black and African American, Hispanic and Latinx, and multiracial employees.\nSelf-ID data: At Microsoft, Self-ID helps us recognize the different identities, experiences and needs of the entire workforce. Through voluntary Self-ID, employees can help Microsoft make better-informed, more inclusive decisions about meaningful benefits and programs that meet their needs in various stages of life, flex to their interests, and enrich their lives. Self-ID is available globally in 46 markets with some variation, as dictated by local laws, practices and customs. We continue to evolve self-identification options for employees to be as inclusive as possible.\nThis year, we’re sharing more self-identification (Self-ID) data on Asian sub-identities in the U.S. to further highlight the importance of identity and the impact of self-identification. This comes after expanding the options for Asian employees in the U.S. who want to identify their backgrounds in additional detail last year. The Asian community is the single largest racial and ethnic minority group within our company, with more than 20 sub-identities.\nIn addition to our demographic data, we share employee survey data in our D&I report each year, which helps us assess the impact of our D&I efforts so we can better understand how to close the gap between the culture of inclusion we aspire to and the lived experiences of everyone at Microsoft. We have continued to invest in experiences, behavior and organization changes, as well as prioritization of retention and development. This year, meaningful insights include:\nThis year, 96.4% of employees reported some level of awareness of the concept of allyship, which is a cornerstone of our growth mindset approach to D&I. This is up from 90.3% in 2022 and 65.0% in 2019, when we first started asking employees about their awareness.\nThe average score for the survey question asking employees if they understand what is expected of them to contribute to a more diverse and inclusive environment increased from 82 to 84 globally year over year, and from 80 to 83 in the U.S. Additionally, the average score increased year over year for men, women and every racial and ethnic group.\nWhile data is important, it does not tell the whole story. Through six Inclusion Spotlights, this year’s report shares more details on some of the people, programs and initiatives that demonstrate how we invest in and innovate for D&I.\nGlobal strategy, local implementation: We explore how the global Microsoft workforce activated around D&I this past year in ways relevant and meaningful to local employees and communities to drive positive change.\nInclusion from the start: We shine a spotlight on New Employee Orientation (NEO) as well as the Nuance acquisition and explore ways we introduce a culture of inclusion to new employees or integrate companies we acquire into our inclusive culture.\nSelf-expression in our products: We connect how technical and D&I expertise come together to inform new self-expression tools, including profile videos, pronouns and name pronunciation.\nInnovative learning: We delve into some of our learning offerings, informed by a range of communities and experts, that enable employees to deepen their understanding and take intentional action for meaningful progress.\nD&I Core Priority: We share the evolution and impact of the D&I Core Priority, an accountability approach that sets Microsoft apart.\nAI & D&I: We look at how we build trust through our responsible AI strategy and inclusive AI solutions.\nAs we look ahead, we are unwavering in our focus to attract, develop and retain a workforce that reflects a diversity of backgrounds, skills and experiences. We support employees’ careers through intentional talent management, access and career mobility across all levels of our organization. To further support this, our team and my role have recently evolved to include talent development efforts in addition to global D&I work. This organizational alignment allows us to further embed D&I into all our talent practices in an effort to accelerate representation progress.\nWe believe our continued work to build diverse workforces and strengthen our culture of inclusion helps foster innovation and serve our business and customer needs. I am confident that our combined momentum and commitment will only fuel additional ways for us to leverage our resources with intention, driving progress toward a more diverse and inclusive Microsoft.\nTags: Diversity and Inclusion Report",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "The main components of the Microsoft Intune Suite are now generally available | Microsoft Security Blog",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/02/01/3-new-ways-the-microsoft-intune-suite-offers-security-simplification-and-savings/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNXNTSGxSU2pCc1NXazVVRWgzVFJDb0FSaXNBaWdCTWdZQk5vd0xJZ2s=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-02-01T08:00:00.000Z",
    "time": "Feb 1",
    "articleType": "regular",
    "content": "Today, we are taking a significant step in completing the delivery of functionality we promised when we first unveiled the vision for the Microsoft Intune Suite.1 We are launching three new solutions: Microsoft Intune Enterprise Application Management, Microsoft Intune Advanced Analytics, and Microsoft Cloud PKI. With these additions, the Intune Suite now goes beyond unified endpoint management to bring you a comprehensive collection of advanced cross-platform capabilities across three core areas: streamlined application security, secure access to on-premises and private cloud resources, and improved troubleshooting and support. While we will continue to add more functionality over time, today’s release marks “the end of the beginning,” as the main components of the Intune Suite are generally available this month. As such, let’s take the opportunity to recap the principles behind the value and functionality of the Intune Suite.\nEnhance security and IT efficiency with the Microsoft Intune Suite.\nThe broad value of the Intune Suite\nWhile the solutions of the Intune Suite launched at different points in time, three fundamental principles have been there from the beginning.\nFirst, one place for workloads adjacent to Unified Endpoint Management. If you’re currently using a mix of third-party solutions, the integrated experience in Microsoft Intune provides security and efficiency on multiple levels. First, one unified solution means fewer integrations to manage across third parties, meaning fewer attack vectors for malicious actors. And second, on a deeper level, the broader Intune proposition (both Intune Suite and Intune) is integrated with Microsoft 365 and Microsoft Security solutions. This provides a consolidated and seamless experience for IT professionals with a single pane of glass for end-to-end endpoint management.\nSecond, all parts of the Intune Suite are ready to support your cloud and AI-enabled future. Intune Suite will help accelerate organizations’ digital transformation to cloud native and simplify their IT operations. Additionally, data from Intune Suite are consolidated with other Intune and security data, meaning complete visibility across the device estate, informing and improving emerging technologies like Microsoft Copilot for Security. The more interrelated data that Copilot can use, the more it can proactively advise on the next best action.\nLastly, Intune Suite is available in a single unified plan. So, rather than having separate solutions for remote assistance, privilege management, analytics, and more, these advanced solutions can all be consolidated and simplified into one. This provides value in two ways: directly, by reducing the overall licensing cost, as the cost of Intune Suite is less than purchasing separate solutions; and the economic value of the Intune Suite is also in indirect savings: no need to manage separate vendors, train IT admins on separate tools, or maintain costly on-premises public key infrastructure (PKI). The Intune Suite makes it easier for IT admins, reducing overhead costs.\n“With what we get out of Intune Suite, we can eliminate other products that our customers need. It’s now a suite of many components that enable customers who want to consolidate solutions and save money.”\n—Mattias Melkersen Kalvåg, Mobility and Windows Management Consultant at MINDCORE, and| Microsoft Certified Professional & MVP\nFrom today: A comprehensive suite across applications, access needs, and support\nLet’s get into specifics. For application security, Enterprise App Management helps you find, deploy, and update your enterprise apps. And Endpoint Privilege Management lets you manage elevation rules on a per-app basis so that even standard users can run approved privileged apps. Cloud PKI lets you manage certificates from the cloud in lieu of complex, on-premises PKI infrastructure. And Microsoft Tunnel for Mobile Application Management (MAM) is perfect for unenrolled, personal mobile devices, to help broker secure access to line of business apps. Advanced Analytics gives you data-rich insights across your endpoints. And Remote Help lets you view and control your PCs, Mac computers, and specialized mobile devices, right from the Intune admin center. Let us take each of those three product areas in turn.\nIncrease endpoint security with Enterprise App Management and Endpoint Privilege Management\nEnterprise App Management gives you a new app catalog, allowing you to easily distribute managed apps, but also keep them patched and always up to date. With this initial release, you will be able to discover and deploy highly popular, pre-packaged apps, so you no longer need to scour the Internet to find their installation files, repackage, and upload them into Intune. Simply add and deploy the apps directly from their app publishers. You can also allow the apps you trust to self-update, and when a new update is available, it is just one click to update all your devices with that app installed. We will continuously expand and enrich the app catalog functionality in future releases to further advance your endpoint security posture and simplify operations.\n“I’m very excited about Enterprise App Management as it’s powered by a strong app catalog and natively integrated in Intune. This single pane of glass experience is what we’re all looking for.”\n—Niklas Tinner, Microsoft MVP and Senior Endpoint Engineer at baseVISION AG\nFor more control over your apps, with Endpoint Privilege Management, you can scope temporary privilege elevation, based on approved apps and processes. Then, as a user in scope for this policy, you can elevate only the processes and apps that have been approved. For example, users can only run a single app for a short period of time as an administrator. Unlike other approaches that give local admin permissions or virtually unlimited scope, you can selectively allow a user to elevate in a one-off scenario by requesting Intune admin approval, without you needing to define the policy ahead of time.\n“Endpoint Privilege Management offers tight integration into the operating system. And the focus that Microsoft has over only elevating specific actions and apps versus making you an admin for a period of time—this is security at its best, going for the least privileged access.”\n—Michael Mardahl, Cloud Architect at Apento\nCloud PKI and Microsoft Tunnel for MAM powers secure access\nWith Cloud PKI, providing both root and issuing Certificate Authorities (CA) in the cloud, you can simply set up a PKI in minutes, manage the certificate lifecycle, reduce the need for extensive technical expertise and tools, and minimize the effort and cost of maintaining on-premises infrastructure. In addition, support for Bring-Your-Own CA is available, allowing you to anchor Intune’s Issuing CA to your own private CA. Certificates can be deployed automatically to Intune-managed devices for scenarios such as authentication to Wi-Fi, VPN, and more; a modern PKI management option that works well to secure access with Microsoft Entra certificate-based authentication. In the initial release, Cloud PKI will also work with your current Active Directory Certificate Services for SSL and TLS certificates, but you do not need to deploy certificate revocation lists, Intune certificate connectors, Network Device Enrollment Service (NDES) servers, or any reverse proxy infrastructure. You can issue, renew, or revoke certificates directly from the Intune admin center automatically or manually.\nMicrosoft Tunnel for MAM helps secure mobile access to your private resources. Microsoft Tunnel for MAM works similarly to Microsoft Tunnel for managed devices; however, with this advanced solution, Microsoft Tunnel for MAM works with user-owned (non-enrolled) iOS and Android devices. Microsoft Tunnel for MAM provides secure VPN access at the app level, for just the apps and browser (including Microsoft Edge) your IT admin explicitly authorizes. So, for personally owned devices, the user can access approved apps, without your company’s data moving onto the user’s personal device. App protection policies protect the data within the apps, preventing unauthorized data leakage to other apps or cloud storage locations.\n“Cloud PKI within the Intune Suite allows you to go cloud native in terms of certificate deployment, which means you can provision PKIs with just a few clicks—that’s a blessing for all the IT administrators. With this built-in service, Microsoft hosts everything for you to manage certificates.”\nResolve support issues quicker with Advanced Analytics and Remote Help\nAdvanced Analytics in Intune is a powerful set of tools for actionable reporting and AI-driven analytics. It provides deep, near real-time insights into your connected devices and managed apps that help you understand, anticipate, and proactively improve the user experience. We continue to infuse AI and machine learning into our analytics products. For example, you can get ahead of battery degradation in your device fleet through our advanced statistical analysis and use that information to prioritize hardware updates. Intune Suite now includes real-time device querying on-demand using Kusto Query Language for individual devices, useful for troubleshooting and resolving support calls quicker.\nWith Remote Help, you can also streamline the way you remotely view and interact with your managed devices, for both user-requested or unattended sessions. As a help desk technician, you can securely connect to both enrolled and unenrolled devices. Users also have peace of mind in being able to validate the technician’s identity, to avoid help desk spoofing attempts. Right now, Remote Help works for remote viewing and controlling in Windows PCs and Android dedicated Enterprise devices, and supports remote viewing for macOS. Especially useful for frontline workers, Remote Help for Android allows help desk administrators to configure and troubleshoot unattended devices, meaning issues can be revolved off-shift.\n“Remote Help takes away the requirement and the need for third-party remote help tools. Remote Help is native, it’s interactive, and you don’t have to worry about installing anything, it’s already there. It’s part of Intune, it’s part of the build.”\n—Matthew Czarnoch, Cloud and Infrastructure Operations Manager at RLS (Registration and Licensing Services)\nTo see many of these new capabilities in action, we invite you to watch this new Microsoft Mechanics video.\nWith the additions to the Intune Suite now available, IT can power a more secure and productive future at an important time as AI comes online. Notably, analyst recognition is validating the importance of its value. For example, Microsoft again assumes the strongest leadership position in the Omdia Universe: Digital Workspace Management and Unified Endpoint Management Platforms 2024. Omdia wrote: “Microsoft is focused on reducing management costs by utilizing the Microsoft Intune Suite and integrating different solutions with it.” They added: “The company plans to invest in Endpoint Analytics and Security Copilot to introduce data-driven management, helping IT professionals shift from reactive, repetitive tasks to strategic ones by utilizing Endpoint Analytics and automation.” Omdia’s recognition follows that from others like Forrester, who named Microsoft as a Leader in The Forrester Wave™ for Unified Endpoint Management, Q4 2023.\nGet started with consolidated endpoint management solutions with the Microsoft Intune Suite\nThe February 2024 release of the solutions in the Intune Suite marks a key milestone, offering a consolidated, comprehensive solution set together in a cost-effective bundle (and available as individual add-on solutions) for any plan that includes Intune. And in April 2024, they will also be available to organizations and agencies of the United States government community cloud. We look forward to hearing your reactions to the new Intune Suite.\nMicrosoft Intune News at Microsoft Ignite 2023.\nOmdia Universe: Digital Workspace Management/Unified Endpoint Management Platforms 2024.\nForrester Wave™ for Unified Endpoint Management, Q4 2023.\nMicrosoft Cloud PKI blog announcement at Microsoft Ignite 2023.\nMicrosoft Intune Enterprise App Management blog announcement at Microsoft Ignite 2023.\nMicrosoft Intune Advanced Analytics blog announcement at Microsoft Ignite 2023.\n1Ease the burden of managing and protecting endpoints with Microsoft advanced solutions, Dilip Radhakrishnan and Gideon Bibliowicz. April 5, 2022.\nThe Forrester Wave™ is copyrighted by Forrester Research, Inc. Forrester and Forrester Wave™ are trademarks of Forrester Research, Inc. The Forrester Wave™ is a graphical representation of Forrester’s call on a market and is plotted using a detailed spreadsheet with exposed scores, weightings, and comments. Forrester does not endorse any vendor, product, or service depicted in the Forrester Wave™. Information is based on best available resources. Opinions reflect judgment at the time and are subject to change.\nThe Forrester Wave™: Unified Endpoint Management, Q4 2023, Andrew Hewitt, Glen O’Donnell, Angela Lozada, Rachel Birrell. November 19, 2023.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Microsoft and Oracle expand partnership to deliver Oracle Database Services on Oracle Cloud Infrastructure in Microsoft Azure",
    "link": "https://news.microsoft.com/2023/09/14/microsoft-and-oracle-expand-partnership-to-deliver-oracle-database-services-on-oracle-cloud-infrastructure-in-microsoft-azure/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNXVhazlsVXpsaVdFTTFjbU5PVFJDb0FSaXNBaWdCTWdhQm9KU2tPQWM=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-14T07:00:00.000Z",
    "time": "Sep 14, 2023",
    "articleType": "regular",
    "content": "Microsoft joins Oracle as the only other hyperscaler to offer Oracle Cloud Infrastructure Database Services to simplify cloud migration, multicloud deployment and management\nAustin, TX and Redmond, WA — September 14, 2023 — Oracle Corp and Microsoft Corp today announced Oracle Database@Azure, which gives customers direct access to Oracle database services running on Oracle Cloud Infrastructure (OCI) and deployed in Microsoft Azure datacenters.\nOracle Database@Azure delivers all the performance, scale, and workload availability advantages of Oracle Database on OCI with the security, flexibility, and best-in-class services of Microsoft Azure, including best-in-class AI services like Azure OpenAI. This combination provides customers with more flexibility regarding where they run their workloads. It also provides a streamlined environment that simplifies cloud purchasing and management between Oracle Database and Azure services.\nWith the introduction of Oracle Database@Azure, Oracle and Microsoft are helping customers accelerate their migration to the cloud, so they can modernize their IT environments and take advantage of Azure’s infrastructure, tooling, and services. Customers will benefit from:\nMore options to move their Oracle databases to the cloud;\nThe highest level of Oracle database performance, scale, and availability, as well as feature and pricing parity;\nThe simplicity, security, and latency of a single operating environment (datacenter) within Azure;\nThe ability to build new cloud native applications using OCI and Azure technologies, including Azure’s best-in-class AI services;\nThe assurance of an architecture that is tested and supported by two of the most trusted names in the cloud.\n“We have a real opportunity to help organizations bring their mission-critical applications to the cloud so they can transform every part of their business with this next generation of AI,” said Satya Nadella, Chairman and CEO, Microsoft. “Our expanded partnership with Oracle will make Microsoft Azure the only other cloud provider to run Oracle’s database services and help our customers unlock a new wave of cloud-powered innovation.”\n“Most customers already use multiple clouds,” said Larry Ellison, Oracle Chairman and CTO. “Microsoft and Oracle have been working together to make it easy for those customers to seamlessly connect Azure Services with the very latest Oracle Database technology. By collocating Oracle Exadata hardware in Azure datacenters, customers will experience the best possible database and network performance. We are proud to partner with Microsoft to deliver this best-in-class capability to customers.”\nThe new service delivers a fully integrated experience for deploying, managing, and using Oracle database instances within Azure. It enables organizations to drive breakthroughs in the cloud using their existing skills to leverage the best of Oracle and Microsoft capabilities directly within the Azure portal.\nThe new service is designed to eliminate customers’ biggest challenges in adopting multicloud architectures, including disjointed management, siloed tools, and a complex purchasing process.\nAs a result of this expanded partnership, customers will have the choice to deploy their Azure services with their fully managed Oracle Database services all within a single datacenter, including support for Oracle Exadata Database services, Oracle Autonomous Database services, and Oracle Real Application Clusters (RAC). Oracle and Microsoft have also developed a joint support model to provide rapid response and resolution for mission-critical workloads.\nAdditionally, Oracle and Microsoft have significantly simplified the purchasing and contracting process. Customers will be able to purchase Oracle Database@Azure through Azure Marketplace, leveraging their existing Azure agreements. They will also be able to use their existing Oracle Database license benefits including Bring Your Own License and the Oracle Support Rewards program.\n“As we continue our digital transformation through innovation and technology, interoperability across cloud service providers to enable safe, secure, and rapid financial transactions for our 40 million customers is paramount,” said Mihir Shah, enterprise head of data, Fidelity Investments. “Today’s announcement displays how industry leaders Microsoft and Oracle are putting their customers’ interests first and providing a collaborative solution that enables organizations like Fidelity to deliver best-in-class experiences for our customers and meet the substantial compliance and regulatory requirements with minimal downtime.”\n“Data is the lifeblood of any business, and the cloud is the best way to analyze it so that insights become actionable,” said Magesh Bagavathi, senior vice president and global chief technology officer, PepsiCo. “As one of the largest food and beverage companies in the world with a market value of over 200 billion U.S. dollars, the ability to run our mission-critical systems and associated data in the cloud with Oracle Database@Azure gives us a scaled strategic advantage across our global operations.”\n“We are looking to our technology partners to support Vodafone’s strategic focus on customers, simplicity and growth across Europe and Africa,” said Scott Petty, Chief Technology Officer, Vodafone. “This new offering from Oracle and Microsoft does that by enabling us to deliver innovative and differentiated digital services faster and more cost effectively to our customers.”\n“As a global leader in the financial services industry, Voya has harnessed the power of digital transformation to help provide the best experience for our customers and employees. As we continue to bring our business applications to the cloud, cloud partnerships have the potential to help the entire industry maintain better security, compliance, and performance, helping to accelerate the development of new technology products, solutions, and services that enhance customer experience and help achieve better financial outcomes,” said Santhosh Keshavan, executive vice president and chief information officer, Voya Financial, Inc.\nOracle will operate and manage these OCI services directly within Microsoft’s datacenters globally, beginning with regions in North America and Europe.\nGet started with Oracle Database@Azure\nMicrosoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.\nOracle, Java, MySQL and NetSuite are registered trademarks of Oracle Corporation. NetSuite was the first cloud company—ushering in the new era of cloud computing.\n“Safe Harbor” Statement: Statements in this press release relating to Oracle’s future plans, expectations, beliefs, intentions and prospects, including statements regarding expected benefits of Oracle Database@Azure and its best-in-class capability, are “forward-looking statements” and are subject to material risks and uncertainties. Risks and uncertainties that could affect our current expectations and our actual results, include, among others: our ability to develop new products and services, integrate acquired products and services and enhance our existing products and services; our management of complex cloud and hardware offerings, including the sourcing of technologies and technology components; significant coding, manufacturing or configuration errors in our offerings; risks associated with acquisitions; economic, political and market conditions; information technology system failures, privacy and data security concerns; cybersecurity breaches; unfavorable legal proceedings, government investigations, and complex and changing laws and regulations. A detailed discussion of these factors and other risks that affect our business is contained in our SEC filings, including our most recent reports on Form 10-K and Form 10-Q, particularly under the heading “Risk Factors.” Copies of these filings are available online from the SEC or by contacting Oracle’s Investor Relations Department at (650) 506-4073 or by clicking on SEC Filings on the Oracle Investor Relations website at www.oracle.com/investor/. All information set forth in this press release is current as of September 14, 2023. Oracle undertakes no duty to update any statement in light of new information or future events.",
    "favicon": "https://news.microsoft.com/wp-content/uploads/prod/2017/03/cropped-microsoft_logo_element-150x150.png"
  },
  {
    "title": "Orca 2: Teaching Small Language Models How to Reason",
    "link": "https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/",
    "image": "https://news.google.com/api/attachments/CC8iJ0NnNVJVR3RMU0hWVVNEaEJSbVpKVFJDb0FSaXNBaWdCTWdNQmNBbw=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-11-20T08:00:00.000Z",
    "time": "Nov 20, 2023",
    "articleType": "regular",
    "content": "A few months ago, we introduced Orca, a 13-billion parameter language model that demonstrated strong reasoning abilities by imitating the step-by-step reasoning traces of more capable LLMs.\nOrca 2 is the latest step in our efforts to explore the capabilities of smaller LMs (on the order of 10 billion parameters or less). With Orca 2, we continue to show that improved training signals and methods can empower smaller language models to achieve enhanced reasoning abilities, which are typically found only in much larger language models.\nOrca 2 significantly surpasses models of similar size (including the original Orca model) and attains performance levels similar to or better than models 5-10 times larger, as assessed on complex tasks that test advanced reasoning abilities in zero-shot settings.\nOrca 2 comes in two sizes (7 billion and 13 billion parameters); both are created by fine-tuning the corresponding LLAMA 2 base models on tailored, high-quality synthetic data. We are making the Orca 2 weights publicly available to encourage research on the development, evaluation, and alignment of smaller LMs.\nUsing LLMs to train smaller language models\nFrontier Language Models such as GPT-4, PaLm, and others have demonstrated a remarkable ability to reason, for example, answering complex questions, generating explanations, and even solving problems that require multi-step reasoning; capabilities that were once considered beyond the reach of AI. Traditionally, such abilities have not been observed in smaller language models, so the challenge is how to use our growing knowledge of large language models to increase the abilities of these smaller models.\nExpanding the capabilities of smaller language models\nA key insight behind Orca 2 is that different tasks could benefit from different solution strategies (e.g. such as step-by-step processing, recall then generate, recall-reason-generate, extract-generate, and direct answer) and that the solution strategy employed by a large model may not be the best choice for a smaller one. For example, while an extremely capable model like GPT-4 can answer complex tasks directly, a smaller model may benefit from breaking the task into steps.\nOrca 2 is trained with an expanded, highly tailored synthetic dataset. The training data was generated such that it teaches Orca 2 various reasoning techniques, such as step-by-step processing, recall then generate, recall-reason-generate, extract-generate, and direct answer methods, while also teaching it to choose different solution strategies for different tasks.\nThe training data is obtained from a more capable teacher model. Note that we can obtain the teacher’s responses through very detailed instructions and even multiple calls, depending on the task and the desired behavior of the model. In the absence of the original instruction, which details how to approach the task, the student model will be encouraged to learn that underlying strategy as well as the reasoning capabilities it elicits.\nMicrosoft at CHI 2024: Innovations in human-centered design\nFrom immersive virtual experiences to interactive design tools, Microsoft Research is at the frontier of exploring how people engage with technology. Discover our latest breakthroughs in human-computer interaction research at CHI 2024.\nOrca 2 has reasoning capabilities comparable to much larger models\nTo evaluate Orca 2, we use a comprehensive set of 15 diverse benchmarks that correspond to approximately 100 tasks and more than 36,000 unique test cases in zero-shot settings. The benchmarks cover a variety of aspects, including language understanding, common-sense reasoning, multi-step reasoning, math problem solving, reading comprehension, summarizing, groundedness, truthfulness, and toxic content generation and identification.\nFigure 1: Results comparing Orca 2 (7B and 13B) to LLaMA-2-Chat (13B and 70B) and WizardLM (13B and 70B) on variety of benchmarks (in zero-shot setting) covering language understanding, common-sense reasoning, multi-step reasoning, math problem solving, etc. Orca 2 models match or surpass other models, including models 5-10 times larger. Note that all models in this figure share the same base model (LLAMA-2).\nOur preliminary results indicate that Orca 2’s performance significantly surpasses models of similar size. It also attains performance levels similar or better than those of models at least 10 times larger, showcasing the potential of equipping smaller models with better reasoning capabilities.\nOrca 2 models exhibit limitations common to other language models and could retain many of the constraints of the base models upon which they were trained. While Orca 2 training could be applied to different base models, we report results based on using LLaMA-2 7B and 13B models. Orca 2 models have not gone through reinforcement learning from human feedback (RLHF) training for safety.\nOur research on the Orca 2 model has yielded significant insights into enhancing the reasoning abilities of smaller language models. By strategically training these models with tailored synthetic data, we have achieved performance levels that rival or surpass those of larger models, particularly in zero-shot reasoning tasks.\nOrca 2’s success lies in its application of diverse reasoning techniques and the identification of optimal solutions for various tasks. While it has several limitations, including limitations inherited from its base models and common to other language models, Orca 2’s potential for future advancements is evident, especially in improved reasoning, specialization, control, and safety of smaller models. The use of carefully filtered synthetic data for post-training emerges as a key strategy in these improvements.\nOur findings underscore the value of smaller models in scenarios where efficiency and capability need to be balanced. As larger models continue to excel, our work with Orca 2 marks a significant step in diversifying the applications and deployment options of language models.\nThis image from the paper “Orca-2: Teaching Small Language Models How To Reason” showcases differences in how Orca 2, LLaMA-2, LLaMA-2-Chat, and ChatGPT (GPT-3.5-Turbo) process and answer a logic-based question. The LLaMA-2 and LLaMA-2-Chat outputs were generated via replicate.com/meta/llama-2-13b and chat.lmsys.org, employing standard settings (temperature=0, top_p=1). ChatGPT’s response was retrieved from chat.openai.com, providing a clear comparison of how each model approaches problem-solving.",
    "favicon": ""
  },
  {
    "title": "Malware distributor Storm-0324 facilitates ransomware access",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/09/12/malware-distributor-storm-0324-facilitates-ransomware-access/",
    "image": "https://news.google.com/api/attachments/CC8iL0NnNUlVMmRHTVRSaVRFeFZZWGxqVFJDM0FSaVRBaWdCTWdtQmtJb1N1ZVhBVWdF=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-09-12T07:00:00.000Z",
    "time": "Sep 12, 2023",
    "articleType": "regular",
    "content": "The threat actor that Microsoft tracks as Storm-0324 is a financially motivated group known to gain initial access using email-based initial infection vectors and then hand off access to compromised networks to other threat actors. These handoffs frequently lead to ransomware deployment. Beginning in July 2023, Storm-0324 was observed distributing payloads using an open-source tool to send phishing lures through Microsoft Teams chats. This activity is not related to the Midnight Blizzard social engineering campaigns over Teams that we observed beginning in May 2023. Because Storm-0324 hands off access to other threat actors, identifying and remediating Storm-0324 activity can prevent more dangerous follow-on attacks like ransomware.\nStorm-0324 (DEV-0324), which overlaps with threat groups tracked by other researchers as TA543 and Sagrid, acts as a distributor in the cybercriminal economy, providing a service to distribute the payloads of other attackers through phishing and exploit kit vectors.  Storm-0324’s tactics focus on highly evasive infection chains with payment and invoice lures. The actor is known to distribute the JSSLoader malware, which facilitates access for the ransomware-as-a-service (RaaS) actor Sangria Tempest (ELBRUS, Carbon Spider, FIN7). Previous distribution activity associated with Storm-0324 included the Gozi infostealer and the Nymaim downloader and locker.\nIn this blog, we provide a comprehensive analysis of Storm-0324 activity, covering their established tools, tactics, and procedures (TTPs) as observed in past campaigns as well as their more recent attacks. To defend against this threat actor, Microsoft customers can use Microsoft 365 Defender to detect Storm-0324 activity and significantly limit the impact of these attacks on networks. Additionally, by using the principle of least privilege, building credential hygiene, and following the other recommendations we provide in this blog, administrators can limit the destructive impact of ransomware even if the attackers can gain initial access.\nStorm-0324 manages a malware distribution chain and has used exploit kit and email-based vectors to deliver malware payloads. The actor’s email chains are highly evasive, making use of traffic distribution systems (TDS) like BlackTDS and Keitaro, which provide identification and filtering capabilities to tailor user traffic. This filtering capability allows attackers to evade detection by certain IP ranges that might be security solutions, like malware sandboxes, while also successfully redirecting victims to their malicious download site.\nStorm-0324’s email themes typically reference invoices and payments, mimicking services such as DocuSign, Quickbooks, and others. Users are ultimately redirected to a SharePoint-hosted compressed file containing JavaScript that downloads the malicious DLL payload. Storm-0324 has used many file formats to launch the malicious JavaScript including Microsoft Office documents, Windows Script File (WSF), and VBScript, among others.\nStorm-0324 has distributed a range of first-stage payloads since at least 2016, including:\nNymaim, a first-stage downloader and locker\nGozi version 3, an infostealer\nTrickbot, a modular malware platform\nIcedID, a modular information-stealing malware\nSince 2019, however, Storm-0324 has primarily distributed JSSLoader, handing off access to ransomware actor Sangria Tempest.\nOngoing Storm-0324 and Sangria Tempest JSSLoader email-based infection chain\nFigure 1. Storm-0324 JSSLoader infection chain based on mid-2023 activity\nSince as early as 2019, Storm-0324 has handed off access to the cybercrime group Sangria Tempest after delivering the group’s first-stage malware payload, JSSLoader. Storm-0324’s delivery chain begins with phishing emails referencing invoices or payments and containing a link to a SharePoint site that hosts a ZIP archive. Microsoft continues to work across its platforms to identify abuse, take down malicious activity, and implement new proactive protections to discourage malicious actors from using our services.\nFigure 2. Example Storm-0324 email\nThe ZIP archive contains a file with embedded JavaScript code. Storm-0324 has used a variety of files to host the JavaScript code, including WSF and Ekipa publisher files exploiting the CVE-2023-21715 local security feature bypass vulnerability.\nWhen the JavaScript launches, it drops a JSSLoader variant DLL. The JSSLoader malware is then followed by additional Sangria Tempest tooling.\nIn some cases, Storm-0324 uses protected documents for additional social engineering. By adding the security code or password in the initial communications to the user, the lure document may acquire an additional level of believability for the user. The password also serves as an effective anti-analysis measure because it requires user interaction after launch.\nFigure 3. Storm-0324 password-protected lure document\nIn July 2023, Storm-0324 began using phishing lures sent over Teams with malicious links leading to a malicious SharePoint-hosted file. For this activity, Storm-0324 most likely relies on a publicly available tool called TeamsPhisher. TeamsPhisher is a Python-language program that enables Teams tenant users to attach files to messages sent to external tenants, which can be abused by attackers to deliver phishing attachments. These Teams-based phishing lures by threat actors are identified by the Teams platform as “EXTERNAL” users if external access is enabled in the organization.\nMicrosoft takes these phishing campaigns very seriously and has rolled out several improvements to better defend against these threats. In accordance with Microsoft policies, we have suspended identified accounts and tenants associated with inauthentic or fraudulent behavior. We have also rolled out enhancements to the Accept/Block experience in one-on-one chats within Teams, to emphasize the externality of a user and their email address so Teams users can better exercise caution by not interacting with unknown or malicious senders . We rolled out new restrictions on the creation of domains within tenants and improved notifications to tenant admins when new domains are created within their tenant.  In addition to these specific enhancements, our development teams will continue to introduce additional preventative and detective measures to further protect customers from phishing attacks.\nTo harden networks against Storm-0324 attacks, defenders are advised to implement the following:\nPilot and start deploying phishing-resistant authentication methods for users.\nImplement Conditional Access authentication strength to require phishing-resistant authentication for employees and external users for critical apps.\nApply security best practices for Microsoft Teams. Refer to the security guide for Microsoft Teams.Understand and select the best access settings for external collaboration for your organization.\nSpecify trusted Microsoft 365 organizations to define which external domains are allowed or blocked to chat and meet.\nKeep Microsoft 365 auditing enabled so that audit records could be investigated if required.\nAllow only known devices that adhere to Microsoft’s recommended security baselines.\nEducate users about social engineering and credential phishing attacks, including refraining from entering MFA codes sent via any form of unsolicited messages.Educate Microsoft Teams users to verify ‘External’ tagging on communication attempts from external entities, be cautious about what they share, and never share their account information or authorize sign-in requests over chat.\nEducate Microsoft Teams users about accepting or blocking people outside the organization who send messages in Microsoft Teams.\nEducate users to review sign-in activity and mark suspicious sign-in attempts as “This wasn’t me”.\nImplement Conditional Access App Control in Microsoft Defender for Cloud Apps for users connecting from unmanaged devices.\nConfigure Microsoft Defender for Office 365 to recheck links on click. Safe Links provides URL scanning and rewriting of inbound email messages in mail flow, and time-of-click verification of URLs and links in email messages, other Microsoft Office applications such as Teams, and other locations such as SharePoint Online. Safe Links scanning occurs in addition to the regular anti-spam and anti-malware protection in inbound email messages in Microsoft Exchange Online Protection (EOP). Safe Links scanning can help protect your organization from malicious links that are used in phishing and other attacks.\nEnable Zero-hour auto purge (ZAP) in Microsoft Office 365 to quarantine sent mail in response to newly acquired threat intelligence and retroactively neutralize malicious phishing, spam, or malware messages that have already been delivered to mailboxes.\nPractice the principle of least privilege and maintain credential hygiene. Avoid the use of domain-wide, administrator-level service accounts. Restricting local administrative privileges can help limit installation of RATs and other unwanted applications.\nTurn on cloud-delivered protection and automatic sample submission on Microsoft Defender Antivirus. These capabilities use artificial intelligence and machine learning to quickly identify and stop new and unknown threats.\nFor additional recommendations on hardening your organization against ransomware attacks, refer to our threat overview on human-operated ransomware.\nMicrosoft customers can turn on attack surface reduction rules to prevent common attack techniques:\nBlock executable files from running unless they meet a prevalence, age, or trusted list criterion\nBlock JavaScript or VBScript from launching downloaded executable content\nUse advanced protection against ransomware\nMicrosoft Defender Antivirus detects threat components as the following malware:\nAlerts with the following titles in the security center can indicate threat activity on your network:\nRansomware-linked Storm-0324 threat activity group detected\nPossible TeamsPhisher downloads The following query looks for downloaded files that were potentially facilitated by use of the TeamsPhisher tool. Defenders should customize the SharePoint domain name (‘mysharepointname’) in the query.\nlet allowedSharepointDomain = pack_array('mysharepointname' //customize Sharepoint domain name and add more domains as needed for your query);//let executable = pack_array('exe','dll','xll','msi','application');let script = pack_array('ps1','py','vbs','bat');let compressed = pack_array('rar','7z','zip','tar','gz');//let startTime = ago(1d);let endTime = now();DeviceFileEvents| where Timestamp between (startTime..endTime)| where ActionType =~ 'FileCreated'| where InitiatingProcessFileName has 'teams.exe'    or InitiatingProcessParentFileName has 'teams.exe'| where InitiatingProcessFileName !has 'update.exe'    and InitiatingProcessParentFileName !has 'update.exe'| where FileOriginUrl has 'sharepoint'    and FileOriginReferrerUrl has_any ('sharepoint', 'teams.microsoft')| extend fileExt = tolower(tostring(split(FileName,'.')[-1]))| where fileExt in (executable)    or fileExt in (script)    or fileExt in (compressed)| extend fileGroup = iff( fileExt in (executable),'executable','')| extend fileGroup = iff( fileExt in (script),'script',fileGroup)| extend fileGroup = iff( fileExt in (compressed),'compressed',fileGroup)//| extend sharePoint_domain = tostring(split(FileOriginUrl,'/')[2])| where not (sharePoint_domain has_any (allowedSharepointDomain))| project-reorder Timestamp, DeviceId, DeviceName, sharePoint_domain, FileName, FolderPath, SHA256, FileOriginUrl, FileOriginReferrerUrl\nMicrosoft Sentinel customers can use the TI Mapping analytics (a series of analytics all prefixed with ‘TI map’) to automatically match the malicious domain indicators mentioned in this blog post with data in their workspace. If the TI Map analytics are not currently deployed, customers can install the Threat Intelligence solution from the Microsoft Sentinel Content Hub to have the analytics rule deployed in their Sentinel workspace. More details on the Content Hub can be found here:  https://learn.microsoft.com/azure/sentinel/sentinel-solutions-deploy.\nMicrosoft Sentinel also has a range of detection and threat hunting content that customers can use to detect the post exploitation activity detailed in this blog in addition to Microsoft 365 Defender detections list above.\nRansomware as a service: Understanding the cybercrime gig economy and how to protect yourself\nMicrosoft customers can refer to the report on this activity in Microsoft Defender Threat Intelligence and Microsoft 365 Defender for detections, assessment of impact, mitigation and recovery actions, and hunting guidance.\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Diamond Sleet supply chain compromise distributes a modified CyberLink installer",
    "link": "https://www.microsoft.com/en-us/security/blog/2023/11/22/diamond-sleet-supply-chain-compromise-distributes-a-modified-cyberlink-installer/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNTNZbVIxWXpOUmRqZGFVVE5tVFJDNUFSaVFBaWdCTWdhWlVJaVdKQWc=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-11-22T08:00:00.000Z",
    "time": "Nov 22, 2023",
    "articleType": "regular",
    "content": "Microsoft Threat Intelligence has uncovered a supply chain attack by the North Korea-based threat actor Diamond Sleet (ZINC) involving a malicious variant of an application developed by CyberLink Corp., a software company that develops multimedia software products. This malicious file is a legitimate CyberLink application installer that has been modified to include malicious code that downloads, decrypts, and loads a second-stage payload. The file, which was signed using a valid certificate issued to CyberLink Corp., is hosted on legitimate update infrastructure owned by CyberLink and includes checks to limit the time window for execution and evade detection by security products. Thus far, the malicious activity has impacted over 100 devices in multiple countries, including Japan, Taiwan, Canada, and the United States.\nMicrosoft attributes this activity with high confidence to Diamond Sleet, a North Korean threat actor. The second-stage payload observed in this campaign communicates with infrastructure that has been previously compromised by Diamond Sleet. More recently, Microsoft has observed Diamond Sleet utilizing trojanized open-source and proprietary software to target organizations in information technology, defense, and media.\nTo address the potential risk of further attacks against our customers, Microsoft has taken the following steps to protect customers in response to this malicious activity:\nMicrosoft has communicated this supply chain compromise to CyberLink\nMicrosoft is notifying Microsoft Defender for Endpoint customers that have been targeted or compromised in this campaign\nMicrosoft reported the attack to GitHub, which removed the second-stage payload in accordance with its Acceptable Use Policies\nMicrosoft has added the CyberLink Corp. certificate used to sign the malicious file to its disallowed certificate list\nMicrosoft Defender for Endpoint detects this activity as Diamond Sleet activity group.\nMicrosoft Defender Antivirus detects the malware as Trojan:Win32/LambLoad.\nMicrosoft may update this blog as additional insight is gained into the tactics, techniques, and procedures (TTPs) used by the threat actor in this active and ongoing campaign.\nThe actor that Microsoft tracks as Diamond Sleet (formerly ZINC) is a North Korea-based activity group known to target media, defense, and information technology (IT) industries globally. Diamond Sleet focuses on espionage, theft of personal and corporate data, financial gain, and corporate network destruction. Diamond Sleet is known to use a variety of custom malware that is exclusive to the group. Recent Diamond Sleet malware is described in Microsoft’s reporting of the group’s weaponization of open source software and exploitation of N-day vulnerabilities. Diamond Sleet overlaps with activity tracked by other security companies as Temp.Hermit and Labyrinth Chollima.\nMicrosoft has observed suspicious activity associated with the modified CyberLink installer file as early as October 20, 2023. The malicious file has been seen on over 100 devices in multiple countries, including Japan, Taiwan, Canada, and the United States. While Microsoft has not yet identified hands-on-keyboard activity carried out after compromise via this malware, the group has historically:\nExfiltrated sensitive data from victim environments\nMoved downstream to additional victims for further exploitation\nUsed techniques to establish persistent access to victim environments\nDiamond Sleet utilized a legitimate code signing certificate issued to CyberLink Corp. to sign the malicious executable. This certificate has been added to Microsoft’s disallowed certificate list to protect customers from future malicious use of the certificate:\nSigner: CyberLink Corp. Issuer: DigiCert SHA2 Assured ID Code Signing CA SignerHash: 8aa3877ab68ba56dabc2f2802e813dc36678aef4 CertificateSerialNumber: 0a08d3601636378f0a7d64fd09e4a13b\nMicrosoft currently tracks the malicious application and associated payloads as LambLoad.\nLambLoad is a weaponized downloader and loader containing malicious code added to a legitimate CyberLink application. The primary LambLoad loader/downloader sample Microsoft identified has the SHA-256 hash 166d1a6ddcde4e859a89c2c825cd3c8c953a86bfa92b343de7e5bfbfb5afb8be.\nBefore launching any malicious code, the LambLoad executable ensures that the date and time of the local host align with a preconfigured execution period.\nFigure 1. Code for checking date and time of local host\nThe loader then targets environments that are not using security software affiliated with FireEye, CrowdStrike, or Tanium by checking for the following process names:\nIf these criteria are not met, the executable continues running the CyberLink software and abandons further execution of malicious code. Otherwise, the software attempts to contact one of three URLs to download the second-stage payload embedded inside a file masquerading as a PNG file using the static User-Agent ‘Microsoft Internet Explorer’:\nThe PNG file contains an embedded payload inside a fake outer PNG header that is, carved, decrypted, and launched in memory.\nFigure 2. Payload embedded in PNG file\nWhen invoked, the in-memory executable attempts to contact the following callbacks for further instruction. Both domains are legitimate but have been compromised by Diamond Sleet:\nThe crypted contents of the PNG file (SHA-256: 089573b3a1167f387dcdad5e014a5132e998b2c89bff29bcf8b06dd497d4e63d) may be manually carved using the following command:\nTo restore the in-memory payload statically for independent analysis, the following Python script can be used to decrypt the carved contents.\nBoth the fake PNG and decrypted PE payload have been made available on VirusTotal.\nMicrosoft recommends the following mitigations to reduce the impact of this threat. Check the recommendations card for the deployment status of monitored mitigations.\nUse Microsoft Defender Antivirus to protect from this threat. Turn on cloud-delivered protection and automatic sample submission on Microsoft Defender Antivirus. These capabilities use artificial intelligence and machine learning to quickly identify and stop new and unknown threats.\nEnable network protection to prevent applications or users from accessing malicious domains and other malicious content on the internet.\nEnable investigation and remediation in full automated mode to allow Microsoft Defender for Endpoint to take immediate action on alerts to resolve breaches, significantly reducing alert volume.\nTake immediate action to address malicious activity on the impacted device. If malicious code has been launched, the attacker has likely taken complete control of the device. Immediately isolate the system and perform a reset of credentials and tokens.\nInvestigate the device timeline for indications of lateral movement activities using one of the compromised accounts. Check for additional tools that attackers might have dropped to enable credential access, lateral movement, and other attack activities. Ensure data integrity with hash codes.\nTurn on the following attack surface reduction rule: Block executable files from running unless they meet a prevalence, age, or trusted list criterion.\nMicrosoft Defender Antivirus detects threat components as the following malware:\nAlerts with the following title in the security center can indicate threat activity on your network:\nThe following alert might also indicate threat activity related to this threat. Note, however, that this alert can be also triggered by unrelated threat activity.\nAn executable loaded an unexpected dll\nMicrosoft customers can use the following reports in Microsoft products to get the most up-to-date information about the threat actor, malicious activity, and techniques discussed in this blog. These reports provide the intelligence, protection information, and recommended actions to prevent, mitigate, or respond to associated threats found in customer environments.\nDiamond Sleet supply chain compromise at distributes a modified CyberLink installer\nMicrosoft Defender XDR Threat analytics\nActivity profile: Diamond Sleet supply chain compromise at distributes a modified CyberLink installer\nMicrosoft Defender XDR (formerly Microsoft 365 Defender) customers can run the following query to find related activity in their networks:\nlet iocs = dynamic([\"166d1a6ddcde4e859a89c2c825cd3c8c953a86bfa92b343de7e5bfbfb5afb8be\",\"089573b3a1167f387dcdad5e014a5132e998b2c89bff29bcf8b06dd497d4e63d\",\"915c2495e03ff7408f11a2a197f23344004c533ff87db4b807cc937f80c217a1\"]);DeviceFileEvents| where ActionType == \"FileCreated\"| where SHA256 in (iocs)| project Timestamp, DeviceName, FileName, FolderPath, SHA256\nMicrosoft Defender XDR and Microsoft Sentinel\nThis query can be used in both Microsoft Defender XDR advanced hunting and Microsoft Sentinel Log Analytics. It surfaces devices where the modified CyberLink installer can be found.\nDeviceFileCertificateInfo| where Signer contains \"CyberLink Corp\"| where CertificateSerialNumber == \"0a08d3601636378f0a7d64fd09e4a13b\"| where SignerHash == \"8aa3877ab68ba56dabc2f2802e813dc36678aef4\"| join DeviceFileEvents on SHA1| distinct DeviceName, FileName, FolderPath, SHA1, SHA256, IsTrusted, IsRootSignerMicrosoft, SignerHash\nMicrosoft Sentinel customers can use the TI Mapping analytics (a series of analytics all prefixed with ‘TI map’) to automatically match the malicious domain indicators mentioned in this blog post with data in their workspace. If the TI Map analytics are not currently deployed, customers can install the Threat Intelligence solution from the Microsoft Sentinel Content Hub to have the analytics rule deployed in their Sentinel workspace.\nThe following YAMLs contain queries that surface activities related to this attack:\nDevice network events with low-count FQDN\nThe list below provides IOCs observed during our investigation. We encourage our customers to investigate these indicators in their environments and implement detections and protections to identify past related activity and prevent future attacks against their systems.\nIndicatorTypeDescription166d1a6ddcde4e859a89c2c825cd3c8c953a86bfa92b343de7e5bfbfb5afb8beSHA-256Trojanized CyberLink installer (LambLoad)089573b3a1167f387dcdad5e014a5132e998b2c89bff29bcf8b06dd497d4e63dSHA-256Second-stage PNG payload915c2495e03ff7408f11a2a197f23344004c533ff87db4b807cc937f80c217a1 SHA-256Decrypted PE from second-stage PNGhxxps[:]//update.cyberlink[.]com/Retail/Promeo/RDZCMSFY1ELY/CyberLink_Pr omeo_Downloader.exeURLCyberLink update URL used to deliver malicious installerhxxps[:]//update.cyberlink[.]com/Retail/Patch/Promeo/DL/RDZCMSFY1ELY/Cyb erLink_Promeo_Downloader.exeURLCyberLink update URL used to deliver malicious installerhxxps[:]//cldownloader.github[.]io/logo.pngURLStage 2 staging URLhxxps[:]//i.stack.imgur[.]com/NDTUM.pngURLStage 2 staging URLhxxps[:]//www.webville[.]net/images/CL202966126.pngURLStage 2 staging URLhxxps[:]//mantis.jancom[.]pl/bluemantis/image/addon/addin.phpURLStage 2 callback URLhxxps[:]//zeduzeventos.busqueabuse[.]com/wpadmin/js/widgets/sub/wids.phpURLStage 2 callback url\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Introducing Garnet – an open-source, next-generation, faster cache-store for accelerating applications and services",
    "link": "https://www.microsoft.com/en-us/research/blog/introducing-garnet-an-open-source-next-generation-faster-cache-store-for-accelerating-applications-and-services/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVBUVzV2V21RME5VNTBXVFZSVFJDb0FSaXJBaWdCTWdhSlFJelhJQW8=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-03-18T07:00:00.000Z",
    "time": "Mar 18",
    "articleType": "regular",
    "content": "Researchers at Microsoft have been working for nearly a decade to address the increasing demand for data storage mechanisms to support the rapid advances in interactive web applications and services. Our new cache-store system called Garnet, which offers several advantages over legacy cache-stores, has been deployed in multiple use cases at Microsoft, such as those in the Windows & Web Experiences Platform, Azure Resource Manager, and Azure Resource Graph, and is now available as an open-source download at https://github.com/microsoft/garnet (opens in new tab). In open sourcing Garnet, we hope to enable the developer community to benefit from its performance gains and capabilities, to build on our work, and to expand the Garnet ecosystem by adding new API calls and features. We also hope that the open sourcing will encourage follow-up academic research and open future collaboration opportunities in this important research area.\nThe growth of cloud and edge computing has brought an increasing number and range of applications and services that need to access, update, and transform data with higher efficiency, lower latencies, and lower costs than ever before. These applications and services often require significant operational spending on storage interactions, making this one of the most expensive and challenging platform areas today. A cache-store software layer, deployed as a separately scalable remote process, can ease these costs and improve application performance. This has fueled a growing cache-store industry, including many open-source systems, such as Redis, Memcached, KeyDB, and Dragonfly.\nUnlike traditional remote cache-stores, which support a simple get/set interface, modern caches offer rich APIs and feature sets. They support raw strings, analytic data structures such as Hyperloglog, and complex data types such as sorted sets and hash. They allow users to checkpoint and recover the cache, create data shards, maintain replicated copies, and support transactions and custom extensions.\nAdvancing science and technology to benefit humanity\nHowever, existing systems achieve this feature richness at a cost, by keeping the system design simple, which limits the ability to fully exploit the latest hardware capabilities (e.g., multiple cores, tiered storage, fast networks). Further, many of these systems are not explicitly designed to be easily extensible by app developers or to work well on diverse platforms and operating systems.\nAt Microsoft Research, we have been investigating modern key-value database architectures since 2016. Our prior work, the FASTER (opens in new tab) embedded key-value library, which we open-sourced (opens in new tab) in 2018, demonstrated orders-of-magnitude better performance than existing systems, while focusing on the simple single-node in-process key-value model.\nStarting in 2021, based on requirements from use-cases at Microsoft, we began building a new remote cache-store with all the necessary features to serve as a viable replacement to existing cache-stores. Our challenge was to maintain and enhance the performance benefits that we achieved in our earlier work, but in this more general and realistic network setting.\nThe result of this effort is Garnet – a new cache-store that offers several unique benefits:\nGarnet adopts the popular RESP wire protocol as a starting point, which makes it possible to use Garnet from unmodified Redis clients available in most programming languages today.\nGarnet offers much better scalability and throughput with many client connections and small batches, leading to cost savings for large apps and services.\nGarnet demonstrates better client latency at the 99th and 99.9th percentiles, which is critical to real-world scenarios.\nBased on the latest .NET technology, Garnet is cross-platform, extensible, and modern. It is designed to be easy to develop for and evolve, without sacrificing performance in the common case. We leveraged the rich library ecosystem of .NET for API breadth, with open opportunities for optimization. Thanks to our careful use of .NET, Garnet achieves state-of-the-art performance on both Linux and Windows.\nAPI features: Garnet supports a wide range of APIs including raw string, analytical, and object operations described earlier. It also implements a cluster mode with sharding, replication, and dynamic key migration. Garnet supports transactions in the form of client-side RESP transactions (opens in new tab) and our own server-side stored procedures in C# and allows users to define custom operations on both raw strings and new object types, all in the convenience of C#, leading to a lower bar for developing custom extensions.\nNetwork, storage, cluster features: Garnet uses a fast and pluggable network layer, enabling future extensions such as leveraging kernel-bypass stacks. It supports secure transport layer security (TLS) communications as well as basic access control. Garnet’s storage layer, called Tsavorite, was forked from OSS FASTER, and includes strong database features such as thread scalability, tiered storage support (memory, SSD, and cloud storage), fast non-blocking checkpointing, recovery, operation logging for durability, multi-key transaction support, and better memory management and reuse. Finally, Garnet supports a cluster mode of operation – more on this later.\nWe illustrate a few key results comparing Garnet to leading open-source cache-stores. A more detailed performance comparison can be found on our website at https://microsoft.github.io/garnet/ (opens in new tab).\nWe provision two Azure Standard F72s v2 virtual machines (72 vcpus, 144 GiB memory each) running Linux (Ubuntu 20.04), with accelerated TCP enabled. One machine runs different cache-store servers, and the other is dedicated to issuing workloads. We use our own benchmarking tool, called Resp.benchmark (opens in new tab), to generate all results. We compare Garnet to the latest open-source versions of Redis (opens in new tab) (v7.2), KeyDB (opens in new tab) (v6.3.4), and Dragonfly (opens in new tab) (v6.2.11). We use a uniform random distribution of keys in these experiments (Garnet’s shared memory design benefits even more with skewed workloads). The data is pre-loaded onto each server, and fits in memory in these experiments.\nExperiment 1: Throughput with varying number of client sessions\nWe start with large batches of GET operations (4096 requests per batch) and small payloads (8-byte keys and values) to minimize network overhead and compare the systems as we increase the number of client sessions. We see from Figure 1 that Garnet exhibits better scalability than Redis and KeyDB, while achieving higher throughput than all three baseline systems (the y-axis is log scale). Note that, while Dragonfly shows similar scaling behavior as Garnet, it is a pure in-memory system. Further, Garnet’s throughput relative to other systems remains strong when the database size (i.e., the number of distinct keys pre-loaded) is significantly larger, at 256 million keys, than what would fit in the processor caches.\nFigure 1: Throughput (log-scale), varying number of client sessions, for a database size of (a) 1024 keys, and (b) 256 million keys\nExperiment 2: Throughput with varying batch sizes\nWe next vary the batch size, with GET operations and a fixed number (64) of client sessions. We experiment with two different database sizes as before. Figure 2 shows that Garnet performs better even with no batching, and the gap increases even for very small batch sizes. Payload sizes are the same as before. Again, the y-axis is log scale.\nFigure 2: Throughput (log-scale), varying batch sizes, for a database size of (a) 1024 keys, and (b) 256 million keys\nExperiment 3: Latency with varying number of client sessions\nWe next measure client-side latencies for the various systems. Figure 3 shows that, as we increase the number of client sessions, Garnet’s latency (measured in microseconds) at various percentiles stays much more stable and lower as compared to other systems. Here, we issue a mix of 80% GET and 20% SET operations, with no operation batching.\nFigure 3: Latency, varying number of client sessions, at (a) median, (b) 99th percentile, and (c) 99.9th percentile\nExperiment 4: Latency with varying batch sizes\nGarnet’s latency is optimized for adaptive client-side batching and many sessions querying the system. We increase the batch sizes from 1 to 64 and plot latency at different percentiles below with 128 active client connections. We see in Figure 4 that Garnet’s latency is low across the board. As before, we issue a mix of 80% GET and 20% SET operations.\nFigure 4: Latency, varying batch sizes, at (a) median, (b) 99th percentile, and (c) 99.9th percentile\nWe have also experimented with other features and operation types and found Garnet to perform and scale well. Our documentation (opens in new tab) has more details, including how to run these experiments so that you can see the benefits for your own use cases.\nGarnet’s design re-thinks the entire cache-store stack – from receiving packets on the network, to parsing and processing database operations, to performing storage interactions. We build on top of years of research, with over 10 research papers published over the last decade. Figure 5 shows Garnet’s overall architecture. We highlight a few key ideas below.\nGarnet’s network layer inherits a shared memory design inspired by our prior research on ShadowFax. TLS processing and storage interactions are performed on the IO completion thread, avoiding thread switching overheads in the common case. This approach allows CPU cache coherence to bring the data to the network, instead of traditional shuffle-based designs, which require data movement on the server.\nFigure 5: Overall architecture of Garnet\nGarnet’s storage design consists of two Tsavorite key-value stores whose fates are bound by a unified operation log. The first store, called the “main store,” is optimized for raw string operations and manages memory carefully to avoid garbage collection. The second, and optional, “object store” is optimized for complex objects and custom data types, including popular types such as Sorted Set, Set, Hash, List, and Geo. Data types in the object store leverage the .NET library ecosystem for their current implementations. They are stored on the heap in memory (which makes updates very efficient) and in a serialized form on disk. In the future, we plan to investigate using a unified index and log to ease maintenance.\nA distinguishing feature of Garnet’s design is its narrow-waist Tsavorite storage API, which is used to implement the large, rich, and extensible RESP API surface on top. This API consists of read, upsert, delete, and atomic read-modify-write operations, implemented with asynchronous callbacks for Garnet to interject logic at various points during each operation. Our storage API model allows us to cleanly separate Garnet’s parsing and query processing concerns from storage details such as concurrency, storage tiering, and checkpointing.\nGarnet further adds support for multi-key transactions based on two-phase locking. One can either use RESP client-side transactions (MULTI/EXEC) or use our server-side transactional stored procedures in C#.\nIn addition to single-node execution, Garnet supports a cluster mode, which allows users to create and manage a sharded and replicated deployment. Garnet also supports an efficient and dynamic key migration scheme to rebalance shards. Users can use standard Redis cluster commands to create and manage Garnet clusters, and nodes perform gossip to share and evolve cluster state. Overall, Garnet’s cluster mode is a large and evolving feature, and we will cover more details in subsequent posts.\nAs Garnet is deployed in additional scenarios, we will continue to share those details in future articles. We also look forward to continuing to add new features and improvements to Garnet, as well as working with the open-source community.\nGarnet Core: Badrish Chandramouli, Vasileios Zois, Lukas Maas, Ted Hart, Gabriela Martinez Sanchez, Yoganand Rajasekaran, Tal Zaccai, Darren Gehring, Irina Spiridonova.\nCollaborators: Alan Yang, Pradeep Yadav, Alex Dubinkov, Venugopal Latchupatulla, Knut Magne Risvik, Sarah Williamson, Narayanan Subramanian, Saurabh Singh, Padmanabh Gupta, Sajjad Rahnama, Reuben Bond, Rafah Hosn, Surajit Chaudhuri, Johannes Gehrke, and many others.",
    "favicon": ""
  },
  {
    "title": "New TTPs observed in Mint Sandstorm campaign targeting high-profile individuals at universities and research orgs",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/01/17/new-ttps-observed-in-mint-sandstorm-campaign-targeting-high-profile-individuals-at-universities-and-research-orgs/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNWhUVFY0VW1GclJucFJlRGhuVFJDM0FSaVRBaWdCTWdZQmQ0NUdyZ2M=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-01-17T08:00:00.000Z",
    "time": "Jan 17",
    "articleType": "regular",
    "content": "Since November 2023, Microsoft has observed a distinct subset of Mint Sandstorm (PHOSPHORUS) targeting high-profile individuals working on Middle Eastern affairs at universities and research organizations in Belgium, France, Gaza, Israel, the United Kingdom, and the United States. In this campaign, Mint Sandstorm used bespoke phishing lures in an attempt to socially engineer targets into downloading malicious files. In a handful of cases, Microsoft observed new post-intrusion tradecraft including the use of a new, custom backdoor called MediaPl.\nOperators associated with this subgroup of Mint Sandstorm are patient and highly skilled social engineers whose tradecraft lacks many of the hallmarks that allow users to quickly identify phishing emails. In some instances of this campaign, this subgroup also used legitimate but compromised accounts to send phishing lures. Additionally, Mint Sandstorm continues to improve and modify the tooling used in targets’ environments, activity that might help the group persist in a compromised environment and better evade detection.\nMint Sandstorm (which overlaps with the threat actor tracked by other researchers as APT35 and Charming Kitten) is a composite name used to describe several subgroups of activity with ties to the Islamic Revolutionary Guard Corps (IRGC), an intelligence arm of Iran’s military. Microsoft attributes the activity detailed in this blog to a technically and operationally mature subgroup of Mint Sandstorm that specializes in gaining access to and stealing sensitive information from high-value targets. This group is known to conduct resource-intensive social engineering campaigns that target journalists, researchers, professors, or other individuals with insights or perspective on security and policy issues of interest to Tehran.\nThese individuals, who work with or who have the potential to influence the intelligence and policy communities, are attractive targets for adversaries seeking to collect intelligence for the states that sponsor their activity, such as the Islamic Republic of Iran. Based on the identities of the targets observed in this campaign and the use of lures related to the Israel-Hamas war, it’s possible this campaign is an attempt to gather perspectives on events related to the war from individuals across the ideological spectrum.\nIn this blog, we share our analysis of the new Mint Sandstorm tradecraft and provide detection, hunting, and protection information. Organizations can also use the mitigations included in this blog to harden their attack surfaces against the tradecraft observed in this and other Mint Sandstorm campaigns. These mitigations are high-value measures that are effective ways to defend organizations from multiple threats, including Mint Sandstorm, and are useful to any organization regardless of their threat model.\nMicrosoft observed new tactics, techniques, and procedures (TTPs) in this Mint Sandstorm campaign, notably the use of legitimate but compromised email accounts to send phishing lures, use of the Client for URL (curl) command to connect to Mint Sandstorm’s command-and-control (C2) server and download malicious files, and delivery of a new custom backdoor, MediaPl.\nIn this campaign, Mint Sandstorm masqueraded as high-profile individuals including as a journalist at a reputable news outlet. In some cases, the threat actor used an email address spoofed to resemble a personal email account belonging to the journalist they sought to impersonate and sent benign emails to targets requesting their input on an article about the Israel-Hamas war. In other cases, Mint Sandstorm used legitimate but compromised email accounts belonging to the individuals they sought to impersonate. Initial email messages did not contain any malicious content.\nThis tradecraft, namely the impersonation of a known individual, the use of highly bespoke phishing lures, and the use of wholly benign messages in the initial stages of the campaign, is likely an attempt to build rapport with targets and establish a level of trust before attempting to deliver malicious content to targets. Additionally, it’s likely that the use of legitimate but compromised email accounts, observed in a subset of this campaign, further bolstered Mint Sandstorm’s credibility, and might have played a role in the success of this campaign.\nIf targets agreed to review the article or document referenced in the initial email, Mint Sandstorm followed up with an email containing a link to a malicious domain. In this campaign, follow up messages directed targets to sites such as cloud-document-edit[.]onrender[.]com, a domain hosting a RAR archive (.rar) file that purported to contain the draft document targets were asked to review. If opened, this .rar file decompressed into a double extension file (.pdf.lnk) with the same name. When launched, the .pdf.lnk file ran a curl command to retrieve a series of malicious files from attacker-controlled subdomains of glitch[.]me and supabase[.]co.\nMicrosoft observed multiple files downloaded to targets’ devices in this campaign, notably several .vbs scripts. In several instances, Microsoft observed a renamed version of NirCmd, a legitimate command line tool that allows a user to carry out a number of actions on a device without displaying a user interface, on a target’s device.\nIn some cases, the threat actor used a malicious file, Persistence.vbs, to persist in targets’ environments. When run, Persistence.vbs added a file, typically named a.vbs, to the CurrentVersion\\Run registry key. In other cases, Mint Sandstorm created a scheduled task to reach out to an attacker-controlled supabase[.]co domain and download a .txt file.\nFigure 1. Intrusion chain leading to backdoors observed in the ongoing Mint Sandstorm campaign\nActivity observed in this campaign suggests that Mint Sandstorm wrote activity from targets’ devices to a series of text files, notably one named documentLoger.txt.\nIn addition to the activity detailed above, in some cases, Mint Sandstorm dropped MischiefTut or MediaPl, custom backdoors.\nMediaPl is a custom backdoor capable of sending encrypted communications to its C2 server. MediaPl is configured to masquerade as Windows Media Player, an application used to store and play audio and video files. To this end, Mint Sandstorm typically drops this file in C:\\\\Users\\\\[REDACTED] \\\\AppData\\\\Local\\\\Microsoft\\\\Media Player\\\\MediaPl.dll. When MediaPl.dll is run with the path of an image file provided as an argument, it launches the image in Windows Photo application and also parses the image for C2 information. Communications to and from MediaPl’s C2 server are AES CBC encrypted and Base64 encoded. As of this writing, MediaPl can terminate itself, can pause and retry communications with its C2 server, and launch command(s) it has received from the C2 using the _popen function.\nMischiefTut is a custom backdoor implemented in PowerShell with a set of basic capabilities. MischiefTut can run reconnaissance commands, write outputs to a text file and, ostensibly, send outputs back to adversary-controlled infrastructure. MischiefTut can also be used to download additional tools on a compromised system.\nThe ability to obtain and maintain remote access to a target’s system can enable Mint Sandstorm to conduct a range of activities that can adversely impact the confidentiality of a system. Compromise of a targeted system can also create legal and reputational risks for organizations affected by this campaign. In light of the patience, resources, and skills observed in campaigns attributed to this subgroup of Mint Sandstorm, Microsoft continues to update and augment our detection capabilities to help customers defend against this threat.\nMicrosoft recommends the following mitigations to reduce the impact of activity associated with recent Mint Sandstorm campaigns.\nUse the Attack Simulator in Microsoft Defender for Office 365 to organize realistic, yet safe, simulated phishing and password attack campaigns in your organization by training end-users against clicking URLs in unsolicited messages and disclosing their credentials. Training should include checking for poor spelling and grammar in phishing emails or the application’s consent screen as well as spoofed app names, logos and domain URLs appearing to originate from legitimate applications or companies. Note that Attack Simulator testing only supports phishing emails containing links at this time.\nEncourage users to use Microsoft Edge and other web browsers that support SmartScreen, which identifies and blocks malicious websites, including phishing sites, scam sites, and sites that contain exploits and host malware. Turn on network protection to block connections to malicious domains and IP addresses.\nTurn on cloud-delivered protection in Microsoft Defender Antivirus or the equivalent for your antivirus product to cover rapidly evolving attacker tools and techniques. Cloud-based machine learning protections block a majority of new and unknown variants.\nMicrosoft Defender XDR customers can also turn on attack surface reduction rules to harden their environments against techniques used by this Mint Sandstorm subgroup. These rules, which can be configured by all Microsoft Defender Antivirus customers and not just those using the EDR solution, offer significant protection against the tradecraft discussed in this report.\nBlock executable files from running unless they meet a prevalence, age, or trusted list criterion.\nBlock JavaScript or VBScript from launching downloaded executable content.\nBlock execution of potentially obfuscated scripts.\nMicrosoft Defender Antivirus detects activity associated with the MediaPl backdoor as the following malware:\nMicrosoft Defender Antivirus detects activity associated with the MischiefTut backdoor as the following malware:\nMicrosoft Defender for Endpoint provides customers with detections and alerts. Alerts with the following titles in the Security Center can indicate threat activity related to Mint Sandstorm.\nAnomaly detected in ASEP registry\nMicrosoft customers can use the following reports in Microsoft products to get the most up-to-date information about the threat actor, malicious activity, and techniques discussed in this blog. These reports provide the intelligence, protection information, and recommended actions to prevent, mitigate, or respond to associated threats found in customer environments.\nNation-state threat actor Mint Sandstorm refines tradecraft to attack high-value targets\nMint Sandstorm delivers MischiefTut to researchers in tailored phishing campaigns\nMicrosoft Defender XDR Threat analytics\nNation-state threat actor Mint Sandstorm refines tradecraft to attack high-value targets\nOrganizations who fit the targeting model discussed in this report can hunt for the following indicators of compromise in their environments.\nCurl command used to retrieve malicious files\nUse this query to locate the curl command Mint Sandstorm used to pull down malicious files in this campaign.\nDeviceProcessEvents| where InitiatingProcessCommandLine has_all('id=','&Prog') and InitiatingProcessCommandLine has_any('vbs', '--ssl')\nUse this query to identify files created by Mint Sandstorm, ostensibly for exfiltration.\nDeviceProcessEvents| where InitiatingProcessCommandLine has_all('powershell', '$pnt', 'Get-Content', 'gcm') and InitiatingProcessCommandLine has_any('documentLog', 'documentLoger', 'Logdocument')\nFiles with double file name extensions\nUse this query to find files with double extension, e.g., .pdf.lnk.\nDeviceFileEvents| where FileName endswith \".pdf.lnk\"\nUse this query to find registry run keys entry with VBScript in value\nDeviceRegistryEvents| where ActionType == \"RegistryValueSet\" or ActionType == \"RegistryKeyCreated\"| where RegistryKey endswith @\"\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\" or RegistryKey endswith @\"\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\" orRegistryKey endswith @\"\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run\"| where RegistryValueData has_any (\"vbscript\",\".vbs\")\nMicrosoft Sentinel customers can use the TI Mapping analytics (a series of analytics all prefixed with ‘TI map’) to automatically match the malicious domain indicators mentioned in this blog post with data in their workspace. If the TI Map analytics are not currently deployed, customers can install the Threat Intelligence solution from the Microsoft Sentinel Content Hub to have the analytics rule deployed in their Sentinel workspace.\nDelivered bad emails from top bad IPv4 addresses\nSuccessful sign-in from phishing link\nScheduled task creation update from user writable directory\nRemote Scheduled Task creation update via Schtasks\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.\nTo hear stories and insights from the Microsoft Threat Intelligence community about the ever-evolving threat landscape, listen to the Microsoft Threat Intelligence podcast: https://thecyberwire.com/podcasts/microsoft-threat-intelligence.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Moonstone Sleet emerges as new North Korean threat actor with new bag of tricks",
    "link": "https://www.microsoft.com/en-us/security/blog/2024/05/28/moonstone-sleet-emerges-as-new-north-korean-threat-actor-with-new-bag-of-tricks/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNDVTWGRWVW5sUlMwUldha2x0VFJDM0FSaVRBaWdCTWdZSmtZWk1PUVE=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-05-28T07:00:00.000Z",
    "time": "May 28",
    "articleType": "regular",
    "content": "Microsoft has identified a new North Korean threat actor, now tracked as Moonstone Sleet (formerly Storm-1789), that uses both a combination of many tried-and-true techniques used by other North Korean threat actors and unique attack methodologies to target companies for its financial and cyberespionage objectives. Moonstone Sleet is observed to set up fake companies and job opportunities to engage with potential targets, employ trojanized versions of legitimate tools, create a fully functional malicious game, and deliver a new custom ransomware.\nMoonstone Sleet uses tactics, techniques, and procedures (TTPs) also used by other North Korean threat actors over the last several years, highlighting the overlap among these groups. While Moonstone Sleet initially had overlaps with Diamond Sleet, the threat actor has since shifted to its own infrastructure and attacks, establishing itself as a distinct, well-resourced North Korean threat actor.\nThis blog describes several notable TTPs used by this threat actor as well as recommendations to defend against related attacks. As with any observed nation-state actor activity, Microsoft directly notifies customers that have been targeted or compromised, providing them with the necessary information to secure their environments.\nMoonstone Sleet is a threat actor behind a cluster of malicious activity that Microsoft assesses is North Korean state-aligned and uses both a combination of many tried-and-true techniques used by other North Korean threat actors and unique attack methodologies. When Microsoft first detected Moonstone Sleet activity, the actor demonstrated strong overlaps with Diamond Sleet, extensively reusing code from known Diamond Sleet malware like Comebacker and using well-established Diamond Sleet techniques to gain access to organizations, such as using social media to deliver trojanized software. However, Moonstone Sleet quickly shifted to its own bespoke infrastructure and attacks. Subsequently, Microsoft has observed Moonstone Sleet and Diamond Sleet conducting concurrent operations, with Diamond Sleet still utilizing much of its known, established tradecraft.\nMoonstone Sleet has an expansive set of operations supporting its financial and cyberespionage objectives. These range from deploying custom ransomware to creating a malicious game, setting up fake companies, and using IT workers.\nMicrosoft has observed Moonstone Sleet using the TTPs discussed in the following sections in various campaigns.\nIn early August 2023, Microsoft observed Moonstone Sleet delivering a trojanized version of PuTTY, an open-source terminal emulator, via apps like LinkedIn and Telegram as well as developer freelancing platforms. Often, the actor sent targets a .zip archive containing two files: a trojanized version of putty.exe and url.txt, which contained an IP address and a password. If the provided IP and password were entered by the user into the PuTTY application, the application would decrypt an embedded payload, then load and execute it. Notably, before Moonstone Sleet used this initial access vector, Microsoft observed Diamond Sleet using a similar method – trojanized PuTTY and SumatraPDF — with comparable techniques for anti-analysis, as we reported in 2022:\nFigure 1. Code from PuTTY executable\nThe trojanized PuTTY executable drops a custom installer which kicks off execution of a series of stages of malware, as described below:\nStage 1 – Trojanized PuTTY: Decrypts, decompresses, and then executes the embedded stage 2 payload.\nStage 2 – SplitLoader installer/dropper: Decrypts, decompresses, and writes the Stage 3 payload, the SplitLoader DLL file, to disk. The installer also drops two encrypted files to disk, then executes SplitLoader via a scheduled task or registry run key.\nStage 3 – SplitLoader:Decrypts and decompresses the two encrypted files dropped by the stage 2 payload, then combines them to create the next-stage, another portable executable (PE) file.\nStage 4 – Trojan loader: Expects a compressed and encrypted PE file from the C2. Once received, the trojan loader decompresses, decrypts, and executes this file.\nFigure 2. Moonstone Sleet attack chain using trojanized PuTTY\nMicrosoft has also observed Moonstone Sleet using other custom malware loaders delivered by PuTTY that behaved similarly and had argument overlap with previously observed Diamond Sleet malware artifacts, such as the following:\nMicrosoft has observed Moonstone Sleet targeting potential victims with projects that used malicious npm packages. Often, the threat actor delivered these projects through freelancing websites or other platforms like LinkedIn. In one example, the threat actor used a fake company to send .zip files invoking a malicious npm package under the guise of a technical skills assessment. When loaded, the malicious package used curl to connect to an actor-controlled IP and drop additional malicious payloads like SplitLoader. In another incident, Moonstone Sleet delivered a malicious npm loader which led to credential theft from LSASS. Microsoft collaborated with GitHub to identify and remove repositories associated with this activity.\nSince February 2024, Microsoft has observed Moonstone Sleet infecting devices using a malicious tank game it developed called DeTankWar (also called DeFiTankWar, DeTankZone, or TankWarsZone). DeTankWar is a fully functional downloadable game that requires player registration, including username/password and invite code. In this campaign, Moonstone Sleet typically approaches its targets through messaging platforms or by email, presenting itself as a game developer seeking investment or developer support and either masquerading as a legitimate blockchain company or using fake companies. To bolster the game’s superficial legitimacy, Moonstone Sleet has also created a robust public campaign that includes the websites detankwar[.]com and defitankzone[.]com, and many X (Twitter) accounts for the personas it uses to approach targets and for the game itself.\nFigure 3. Example of a Moonstone Sleet X (Twitter) account for its DeTankWar game\nMoonstone Sleet used a fake company called C.C. Waterfall to contact targets. The email presented the game as a blockchain-related project and offered the target the opportunity to collaborate, with a link to download the game included in the body of the message. More details about C.C. Waterfall and another fake company that Moonstone Sleet set up to trick targets are included below:\nFigure 4. Moonstone Sleet using CC Waterfall to email a link to their game\nWhen targeted users launch the game, delfi-tank-unity.exe, additional included malicious DLLs are also loaded. The payload is a custom malware loader that Microsoft tracks as YouieLoad. Similarly to SplitLoader, YouieLoad loads malicious payloads in memory and creates malicious services that perform functions such as network and user discovery and browser data collection. For compromised devices of particular interest to the group, the threat actor launches hands-on-keyboard commands with further discovery and conducts credential theft.\nFigure 5. Page from the DeTankWar website\nIn April 2024, Microsoft observed Moonstone Sleet delivering a new custom ransomware variant we have named FakePenny against a company it previously compromised in February. FakePenny includes a loader and an encryptor. Although North Korean threat actor groups have previously developed custom ransomware, this is the first time we have observed this threat actor deploying ransomware.\nMicrosoft assesses that Moonstone Sleet’s objective in deploying the ransomware is financial gain, suggesting the actor conducts cyber operations for both intelligence collection and revenue generation. Of note, the ransomware note dropped by FakePenny closely overlaps with the note used by Seashell Blizzard in its malware NotPetya. The ransom demand was $6.6M USD in BTC. This is in stark contrast to the lower ransom demands of previous North Korea ransomware attacks, like WannaCry 2.0 and H0lyGh0st.\nFigure 6. FakePenny ransomware note\nFigure 7. NotPetya ransomware note\nSince January 2024, Microsoft has observed Moonstone Sleet creating several fake companies impersonating software development and IT services, typically relating to blockchain and AI. The actor has used these companies to reach out to potential targets, using a combination of created websites and social media accounts to add legitimacy to their campaigns.\nFrom January to April 2024, Moonstone Sleet’s fake company StarGlow Ventures posed as a legitimate software development company. The group used a custom domain, fake employee personas, and social media accounts, in an email campaign targeting thousands of organizations in the education and software development sectors. In the emails Moonstone Sleet sent as part of this campaign, the actor complimented the work of the targeted organization and offered collaboration and support for upcoming projects, citing expertise in the development of web apps, mobile apps, blockchain, and AI.\nFigure 8. Example of an email from Moonstone Sleet’s StarGlow Ventures campaign\nThese emails also contained a 1×1 tracking pixel, which likely enabled Moonstone Sleet to track which targets engaged with the emails, and a link to a dummy unsubscribe page hosted on the StarGlow Ventures domain. While the emails did not contain any malicious links, Microsoft assesses Moonstone Sleet likely used this campaign to establish a relationship with target organizations. Although the purpose of these relationships is unclear, they may afford the actor access to organizations of interest or be used as revenue generation opportunities. Microsoft notified customers who were impacted by this Moonstone Sleet campaign.\nFigure 9. Unsubscribe page on the StarGlow Ventures website\nFigure 10. Informational pages for the StarGlow Ventures website\nIn a similar campaign, Moonstone Sleet sent emails using its fake company C.C. Waterfall, a purported IT consulting organization.\nFigure 11. The landing page for C.C. Waterfall\nIn this campaign, Moonstone Sleet emailed higher education organizations, claiming the company was either hiring new developers or looking for business collaboration opportunities. This campaign likely had similar goals to the StarGlow Ventures campaign: to build relationships with organizations which could be leveraged for revenue generation or malicious access.\nFigure 12. Example of an email from C.C. Waterfall\nAs previously mentioned, Moonstone Sleet also used C.C. Waterfall to contact targets and invite them to download the actor’s tank game, highlighting that this is a coordinated and concerted effort for which Moonstone Sleet can leverage multiple facets of its operations in overlapping campaigns.\nIn addition to creating fake companies, Microsoft has observed Moonstone Sleet pursuing employment in software development positions at multiple legitimate companies. This activity could be consistent with previous reporting from the United States Department of Justice that North Korea was using highly skilled remote IT workers to generate revenue. On the other hand, this Moonstone Sleet activity may also be another approach to gaining access to organizations.\nMoonstone Sleet’s primary goals appear to be espionage and revenue generation. Targeted sectors to date include both individuals and organizations in the software and information technology, education, and defense industrial base sectors.\nSince early January 2024, Moonstone Sleet has used the above fake software development companies to solicit work or cooperation. This actor has also targeted individuals looking for work in software development, sending candidates a “skills test” that instead delivers malware via a malicious NPM package.\nIn early December 2023, we observed Moonstone Sleet compromising a defense technology company to steal credentials and intellectual property. In April 2024, the actor ransomed the organization using FakePenny. The same month, we observed Moonstone Sleet compromise a company that makes drone technology. In May 2024, the threat actor compromised a company that makes aircraft parts.\nFitting into the North Korean threat actor landscape\nMoonstone Sleet’s diverse set of tactics is notable not only because of their effectiveness, but because of how they have evolved from those of several other North Korean threat actors over many years of activity to meet North Korean cyber objectives. For example, North Korea has for many years maintained a cadre of remote IT workers to generate revenue in support of the country’s objectives. Moonstone Sleet’s pivot to conduct IT work within its campaigns indicates it may not only be helping with this strategic initiative, but possibly also expanding the use of remote IT workers beyond just financial gain. Additionally, Moonstone Sleet’s addition of ransomware to its playbook, like another North Korean threat actor, Onyx Sleet, may suggest it is expanding its set of capabilities to enable disruptive operations. Microsoft reported on Onyx Sleet’s and Storm-0530’s h0lyGhost ransomware in 2022.\nMoonstone Sleet’s ability to conduct concurrent operations across multiple campaigns, the robustness of the malicious game, and the use of a custom new ransomware variant are strong indications that this threat actor may be well-resourced. Moreover, given that Moonstone Sleet’s initial attacks mirrored Diamond Sleet methodologies and heavily reused Diamond Sleet’s code in their payloads, Microsoft assesses this actor is equipped with capabilities from prior cyber operations conducted by other North Korean actors.\nMicrosoft has identified several techniques used by Moonstone Sleet that have previously been used by other North Korean threat actors. For example, since late 2023, an actor that Microsoft tracks as Storm-1877 used malicious npm packages in a campaign targeting software developers with JavaScript-based malware. This campaign was reported publicly by PaloAlto as Contagious Interview. Additionally, in 2023, GitHub reported that Jade Sleet used malicious npm packages in a campaign consisting of fake developer and recruiter personas that operated on LinkedIn, Slack, and Telegram. This shared use of a relatively uncommon tactic across multiple distinct North Korean groups may suggest sharing of expertise and TTPs among North Korean threat actors.\nIn recent months, Microsoft and other security researchers have reported on North Korean threat actors’ use of software supply chain attacks to conduct widespread malicious operations. In November 2023, Microsoft reported on Diamond Sleet’s supply chain compromise of CyberLink, a multimedia application. While Microsoft has not yet identified any Moonstone Sleet supply chain attacks, the actor has extensively targeted software development firms in its campaigns. Large-scale access to software companies would pose a particularly high risk for future supply chain attacks against those organizations.\nMoonstone Sleet’s appearance is an interesting development considering that North Korea has carried out a series of changes in its foreign relations and security apparatus. In November 2023, North Korea closed embassies in several countries, and in March 2024, may have dissolved the United Front Department (UFD), an agency believed to be responsible for reunification and propaganda.\nDespite being new, Moonstone Sleet has demonstrated that it will continue to mature, develop, and evolve, and has positioned itself to be a preeminent threat actor conducting sophisticated attacks on behalf of the North Korean regime.\nMicrosoft recommends the following mitigations defend against attacks by Moonstone Sleet:\nDetect human-operated ransomware attacks with Microsoft Defender XDR.\nEnsure that tamper protection is enabled in Microsoft Dender for Endpoint.\nEnable network protection in Microsoft Defender for Endpoint.\nFollow the credential hardening recommendations in our on-premises credential theft overview to defend against common credential theft techniques like LSASS access.\nRun endpoint detection and response (EDR) in block mode so that Microsoft Defender for Endpoint can block malicious artifacts, even when your non-Microsoft antivirus does not detect the threat or when Microsoft Defender Antivirus is running in passive mode. EDR in block mode works behind the scenes to remediate malicious artifacts that are detected post-breach.\nConfigure investigation and remediation in full automated mode to let Microsoft Defender for Endpoint take immediate action on alerts to resolve breaches, significantly reducing alert volume.\nTurn on cloud-delivered protection in Microsoft Defender Antivirus, or the equivalent for your antivirus product, to cover rapidly evolving attacker tools and techniques. Cloud-based machine learning protections block a majority of new and unknown variants.\nMicrosoft Defender XDR customers can turn on the following attack surface reduction rule to prevent common attack techniques used by Moonstone Sleet.\nBlock executable content from email client and webmail\nBlock executable files from running unless they meet a prevalence, age, or trusted list criterion\nUse advanced protection against ransomware\nBlock credential stealing from the Windows local security authority subsystem (lsass.exe)\nMicrosoft Defender Antivirus detects threat components as the following malware:\nAlerts with the following titles in the security center can indicate threat activity on your network:\nMoonstone Sleet actor activity detected\nSuspicious activity linked to a North Korean state-sponsored threat actor has been detected\nDiamond Sleet Actor activity detected\nThe following alerts might also indicate threat activity associated with this threat. These alerts, however, can be triggered by unrelated threat activity:\nMalicious credential theft tool execution detected\nSuspicious access to LSASS service\nMicrosoft Defender XDR customers can run the following query to find related activity in their networks:\nDetect Procdump dumping LSASS credentials:\nDeviceProcessEvents| where (FileName has_any (\"procdump.exe\",\"procdump64.exe\") and ProcessCommandLine has \"lsass\") or  (ProcessCommandLinehas \"lsass.exe\" and (ProcessCommandLine has \"-accepteula\"or ProcessCommandLine contains \"-ma\"))\nDetect connectivity with C2 infrastructure:\nlet c2servers = dynamic(['mingeloem.com','matrixane.com']);DeviceNetworkEvents| where RemoteUrl has_any (c2servers)| project DeviceId, LocalIP, DeviceName, RemoteUrl, InitiatingProcessFileName, InitiatingProcessCommandLine, Timestamp\nDetect connectivity to DeTank websites:\nlet c2servers = dynamic(['detankwar.com','defitankzone.com']);DeviceNetworkEvents| where RemoteUrl has_any (c2servers)| project DeviceId, LocalIP, DeviceName, RemoteUrl, InitiatingProcessFileName, InitiatingProcessCommandLine, Timestamp\nMicrosoft Sentinel customers can use the TI Mapping analytics (a series of analytics all prefixed with ‘TI map’) to automatically match the malicious domain indicators mentioned in this blog post with data in their workspace. If the TI Map analytics are not currently deployed, customers can install the Threat Intelligence solution from the Microsoft Sentinel Content Hub to have the analytics rule deployed in their Sentinel workspace.\nMicrosoft Sentinel customers can also use the queries below to detect activity detailed in this blog.\nThis query detects the installation of a Windows service that contains artifacts from credential dumping tools such as Mimikatz:\nCredential Dumping Tools – Service Installation\nThis query detects the use of Procdump to dump credentials from LSASS memory:\nMicrosoft Sentinel customers can also use the following query, which looks for Microsoft Defender AV detections related to the Moonstone Sleet. In Microsoft Sentinel, the SecurityAlerts table includes only the DeviceName of the affected device. This query joins the DeviceInfo table to connect other information such as device group, IP, signed-in users, etc., allowing analysts to have more context related to the alert, if available:\nlet MoonStoneSleet_threats = dynamic([\"Behavior:Win64/PennyCrypt\", \"HackTool:Win32/Mimikatz\", \"HackTool:Win64/Mimikatz \", \"TrojanDropper:Win32/SplitLoader\", \"TrojanDropper:Win64/YouieLoad\" ]);SecurityAlert| where ProviderName == \"MDATP\"| extend ThreatName = tostring(parse_json(ExtendedProperties).ThreatName)| extend ThreatFamilyName = tostring(parse_json(ExtendedProperties).ThreatFamilyName)| where ThreatName in~ (MoonStoneSleet_threats) or ThreatFamilyName in~ (MoonStoneSleet_threats)| extend CompromisedEntity = tolower(CompromisedEntity)| join kind=inner (    DeviceInfo    | extend DeviceName = tolower(DeviceName)) on $left.CompromisedEntity == $right.DeviceName| summarize arg_max(TimeGenerated, *) by DisplayName, ThreatName, ThreatFamilyName, PublicIP, AlertSeverity, Description, tostring(LoggedOnUsers), DeviceId, TenantId, CompromisedEntity, ProductName, Entities| extend HostName = tostring(split(CompromisedEntity, \".\")[0]), DomainIndex = toint(indexof(CompromisedEntity, '.'))| extend HostNameDomain = iff(DomainIndex != -1, substring(CompromisedEntity, DomainIndex + 1), CompromisedEntity)| project-away DomainIndex| project TimeGenerated, DisplayName, ThreatName, ThreatFamilyName, PublicIP, AlertSeverity, Description, LoggedOnUsers, DeviceId, TenantId, CompromisedEntity, ProductName, Entities, HostName, HostNameDomain\nFileSHA-256 hashputty.exe (drops SplitLoader)f59035192098e44b86c4648a0de4078edbe80352260276f4755d15d354f5fc58putty.exe (drops SplitLoader)cb97ec024c04150ad419d1af2d1eb66b5c48ab5f345409d9d791db574981a3fb[random].dat (SplitLoader)39d7407e76080ec5d838c8ebca5182f3ac4a5f416ff7bda9cbc4efffd78b4ff5Package.db, thumbs.db (YouieLoad via npm)70c5b64589277ace59db86d19d846a9236214b48aacabbaf880f2b6355ab5260adb.bin, u.bin, Id.bin(YouieLoad)cafaa7bc3277711509dc0800ed53b82f645e86c195e85fbf34430bbc75c39c24data.tmp (YouieLoad)9863173e0a45318f776e36b1a8529380362af8f3e73a2b4875e30d31ad7bd3c1delfi-tank-unity.exef66122a3e1eaa7dcb7c13838037573dace4e5a1c474a23006417274c0c8608beDeTankWar.exe56554117d96d12bd3504ebef2a8f28e790dd1fe583c33ad58ccbf614313ead8c ecce739b556f26de07adbfc660a958ba2dca432f70a8c4dd01466141a6551146NVUnityPlugin.dll, Unityplayer.dll (YouieLoad via tank game)09d152aa2b6261e3b0a1d1c19fa8032f215932186829cfcca954cc5e84a6cc38\nHacking Employers and Seeking Employment: Two Job-Related Campaigns Bear Hallmarks of North Korean Threat Actors (Palo Alto Unit 42)\nSecurity alert: social engineering campaign targets technology industry employees (Github)\nFor the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.\nTo hear stories and insights from the Microsoft Threat Intelligence community about the ever-evolving threat landscape, listen to the Microsoft Threat Intelligence podcast: https://thecyberwire.com/podcasts/microsoft-threat-intelligence.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Bringing the latest capabilities to Copilot for Microsoft 365 customers",
    "link": "https://www.microsoft.com/en-us/microsoft-365/blog/2024/04/02/bringing-the-latest-capabilities-to-copilot-for-microsoft-365-customers/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNTVUemN6V1VabVptaEdablJDVFJDb0FSaXJBaWdCTWdZTndJUUh6UU0=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-02T07:00:00.000Z",
    "time": "Apr 2",
    "articleType": "regular",
    "content": "With Microsoft Copilot, we are bringing the power of generative AI to everyone across work and life. And with Copilot for Microsoft 365, we are committed to making sure our commercial customers have access to the very best generative AI models and capabilities from Microsoft.\nToday we are announcing two important updates for users of Copilot for Microsoft 365. First, we are bringing priority access to the GPT-4 Turbo model to work with both web and work data. We will also be removing limits on the number and length of conversations while increasing file uploads. Second, later this month we are bringing expanded image generation capabilities in Microsoft Designer to users of Copilot for Microsoft 365, including priority access during peak times.\nDiscover Copilot features that work alongside you\nPriority access to GPT-4 Turbo and unlimited conversations\nStarting today, all licensed commercial customers will have priority access to GPT-4 Turbo in Copilot for Microsoft 365. As part of this change, we are removing the limits on the total number of chats per day and the number of turns per conversation, along with additional updates.\nTogether, these changes mean that customers will receive faster, more comprehensive responses whether they are using Copilot in the web context or in the work context.\nIn the web context, Copilot users get the power of the latest foundation models grounded in the latest public information from the web. The web context includes commercial data protection, meaning Microsoft doesn’t retain your prompts or responses, doesn’t have eyes on your prompts or responses, and doesn’t use your chat data to train the underlying foundation models—ensuring a more secure alternative to using other public generative AI services.\nThe work context lets you go even further by grounding in your work data––that’s your calendar, emails, chats, documents, meetings, contacts, and more––so you get contextually accurate responses. Copilot can help you quickly scan your email for important messages to prioritize, help you get ready for key meetings by pulling information from across your work, and help you ideate on the best path forward. The work context also benefits from enterprise-grade data protection, going further to ensure that your data remains within the Microsoft 365 service boundary.\nExpanded image generation capabilities in Microsoft Designer\nStarting next month, we’ll increase the number of image generation boosts per day from 15 to 100. Powered by the DALL-E 3 model, Microsoft Designer image generation allows users to create custom images from text descriptions, transforming written ideas into visual art. Users will be able to initiate up to 100 rapid image generation requests daily, significantly reducing waiting times for image creation and unlocking new productivity.\nHarnessing the full power of Copilot\nWe are learning alongside our customers that AI is so much more than a new technology. It is a new way of work that gives organizations the opportunity to completely reinvent their business—rewiring everything from core processes and workflows to hiring and training the workforce of the future.\nThese new capabilities will be initially available in copilot.microsoft.com, followed by the Copilot mobile app, in Windows, and in Edge, as well as the places where users can access the work context directly, like in Microsoft 365. Additional details about these changes are available on the Copilot for Microsoft 365 documentation page.",
    "favicon": "https://c.s-microsoft.com/favicon.ico?v2"
  },
  {
    "title": "Announcing new Microsoft AI Hub in London",
    "link": "https://blogs.microsoft.com/blog/2024/04/07/announcing-new-microsoft-ai-hub-in-london/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNVhSemhGTUVoRlQyWnJNVk5mVFJDb0FSaXNBaWdCTWdZcGhaRE5zUVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2024-04-07T07:00:00.000Z",
    "time": "Apr 7",
    "articleType": "regular",
    "content": "Microsoft recently announced the creation of Microsoft AI, a newly formed organization to help advance our consumer AI products and research, including Copilot. Building on that news, I’m thrilled to share that Microsoft AI is opening a new AI hub in the heart of London. Microsoft AI London will drive pioneering work to advance state-of-the-art language models and their supporting infrastructure, and to create world-class tooling for foundation models, collaborating closely with our AI teams across Microsoft and with our partners, including OpenAI.\nThe new AI hub will be led by Jordan Hoffmann, an exceptional AI scientist and engineer. Prior to joining Microsoft AI, Hoffmann distinguished himself as an AI pioneer at Inflection and DeepMind, based in London. Hoffmann will be joined by a talented group of Microsoft AI team members based in our London Paddington office.\nThere is an enormous pool of AI talent and expertise in the U.K., and Microsoft AI plans to make a significant, long-term investment in the region as we begin hiring the best AI scientists and engineers into this new AI hub.\nIn the coming weeks and months, we will be posting job openings and actively hiring exceptional individuals who want to work on the most interesting and challenging AI questions of our time. We’re looking for new team members who are driven by impact at scale, and who are passionate innovators eager to contribute to a team culture where continuous learning is the norm.\nThis is great news for Microsoft AI and for the U.K.  As a British citizen, born and raised in London, I’m proud to have co-founded and built a cutting-edge AI business here. I’m deeply aware of the extraordinary talent pool and AI ecosystem in the U.K., and I’m excited to make this commitment to the U.K. on behalf of Microsoft AI. I know – through my close work with thought leaders in the U.K. government, business community and academia – that the country is committed to advancing AI responsibly and with a safety-first commitment to drive investment, innovation and economic growth. Our decision to open this hub in the U.K. reflects this ambition.\nThe Microsoft AI London hub adds to Microsoft’s existing presence in the U.K., including the Microsoft Research Cambridge lab, home to some of the foremost researchers in the areas of AI, cloud and productivity. At the same time, it builds off Microsoft’s recently announced £2.5 billion investment to upskill the U.K. workforce for the AI era and to build the infrastructure to power the AI economy, including our commitment to bring 20,000 of the most advanced GPUs to the country by 2026.\nStay tuned for more updates as we continue to push the boundaries of what’s possible with AI and extend the benefits to every person and organization across the U.K.",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/2017/08/favicon.jpg"
  },
  {
    "title": "Seeing AI App Launches on Android – Including new and updated features and new languages.",
    "link": "https://blogs.microsoft.com/accessibility/seeing-ai-app-launches-on-android-including-new-and-updated-features-and-new-languages/",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNTBUelJSUVRSMlFVVk1NQzFyVFJDM0FSaVRBaWdCTWdZaGM0N0xyUVk=-w400-h224-p-df-rw",
    "source": "Microsoft",
    "datetime": "2023-12-04T08:00:00.000Z",
    "time": "Dec 4, 2023",
    "articleType": "regular",
    "content": "As we celebrate the International Day of Persons with Disabilities (IDPD), we are launching the newest version of Seeing AI, powered by the latest advances in AI at Microsoft, and sharing that it is now available for the first time on Android devices via the Google Play Store. With today’s Android availability, Seeing AI is now available in 18 languages* with a plan to increase to 36 languages in 2024.\nSeeing AI is a free app that narrates the world for blind and low vision people, including myself, right from your mobile device. It supports individuals with a variety of daily tasks such as reading mail, identifying everyday products, hearing descriptions of photos, and much more.\nThanks to feedback from those who use the app, the new Android version includes the latest generative AI features recently released on iOS:\nRicher Descriptions of photos: In addition to providing a brief summary of photos on the Scene channel, you can now tap ‘more info’ and a rich description will be generated, including far greater detail about what is in the image.\nChat to your documents: After scanning a document, in addition to hearing it read aloud, you can also chat to Seeing AI to ask questions, such as about items on a menu, the price of an item on a receipt, or to summarize an article.\nAt Microsoft, we use our technology to innovate with and for people with disabilities. Seeing AI was first released for iOS as a research project in 2017 when a team of engineers and I worked with the blind community to understand the areas where technology may be able to provide even greater independence and enjoyment.\nWith Seeing AI, you can just point the camera, or take a photo, and hear a description. Switch between channels to hear focused information:\nShort Text: Speaks text as soon as it appears in front of the camera.\nDocuments: Provides audio guidance to capture a printed page, and reads the content aloud, along with its original formatting. Chat with Seeing AI to quickly find information.\nProducts: Scans barcodes, using audio beeps to guide you; hear the name, and package information when available.\nScenes: Hear a description of the scene captured and tap ‘more info’ to generate a rich description. Explore the photo by moving your finger over the screen to hear the location of different objects.\nPeople: Identify friends around you.\nColors: Identifies the perceived color.\nHandwriting: Reads handwritten text like in greeting cards (available in a subset of languages).\nLight: Generates an audible tone corresponding to the brightness in the surroundings.\nImages in other apps: Share a photo with Seeing AI to recognize it.\nThere are over 3 billion active Android users worldwide, and bringing Seeing AI to this platform will provide so many more people in the blind and low vision community the ability to utilize this technology in their everyday lives. We will continue to work with the community to understand feedback to improve the app. As the motto goes, “nothing about us, without us.” And as additional versions roll out, customer feedback will continue to be critical for new AI-powered enhancements to future versions of the Seeing AI app.\nMy team and I are eager for you to try Seeing AI and let us know what you think.\nDownload Seeing AI from the Play Store at https://www.seeingai.com/android or the iOS App Store at https://www.seeingai.com/ios\n*Languages available in iOS and Android: Czech, Danish, Dutch, English, Finnish, French, German, Greek, Hungarian, Italian, Japanese, Korean, Norwegian Bokmal, Polish, Portuguese, Russian, Spanish, Swedish, Turkish.  https://www.seeingai.com/Android",
    "favicon": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/172/2021/11/cropped-cropped-microsoft_logo_element-32x32.png"
  }
]